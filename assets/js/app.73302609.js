(window.webpackJsonp=window.webpackJsonp||[]).push([[0],[]]);!function(n){function e(e){for(var i,s,l=e[0],o=e[1],d=e[2],u=0,p=[];u<l.length;u++)s=l[u],Object.prototype.hasOwnProperty.call(r,s)&&r[s]&&p.push(r[s][0]),r[s]=0;for(i in o)Object.prototype.hasOwnProperty.call(o,i)&&(n[i]=o[i]);for(c&&c(e);p.length;)p.shift()();return a.push.apply(a,d||[]),t()}function t(){for(var n,e=0;e<a.length;e++){for(var t=a[e],i=!0,l=1;l<t.length;l++){var o=t[l];0!==r[o]&&(i=!1)}i&&(a.splice(e--,1),n=s(s.s=t[0]))}return n}var i={},r={1:0},a=[];function s(e){if(i[e])return i[e].exports;var t=i[e]={i:e,l:!1,exports:{}};return n[e].call(t.exports,t,t.exports,s),t.l=!0,t.exports}s.e=function(n){var e=[],t=r[n];if(0!==t)if(t)e.push(t[2]);else{var i=new Promise((function(e,i){t=r[n]=[e,i]}));e.push(t[2]=i);var a,l=document.createElement("script");l.charset="utf-8",l.timeout=120,s.nc&&l.setAttribute("nonce",s.nc),l.src=function(n){return s.p+"assets/js/"+({}[n]||n)+"."+{2:"c02cd514",3:"620a1f91",4:"0df20a49",5:"94069b5e",6:"90726693",7:"ba20b3c7",8:"2abb0131",9:"ece9abdb",10:"ccc2fc76",11:"15e920f7",12:"d6b747fb",13:"ee8d04f3",14:"b7513ca5",15:"f2e8ff40",16:"347a6e24",17:"6c1e9625",18:"7602b54c",19:"8f4fcc4b",20:"09885064",21:"b525f277",22:"b9ed6df2",23:"523e5d22",24:"d04239a4",25:"237a6c47",26:"6bd9bfe4",27:"ac60ace0",28:"ee14024f",29:"0caa2b3a",30:"e6e7d6f8",31:"6ec6039c",32:"37f8dd2f",33:"7e29804a",34:"8eeb5b9d",35:"72aa34f7",36:"9de84a28",37:"64e3dd13",38:"99ad5507",39:"8cda7b61",40:"ed6949c0",41:"bf343b6b",42:"cbbfd0d9",43:"39209b19",44:"7eec5b18",45:"b088db4c",46:"bfc9e511",47:"d0b2aa80",48:"49b8f1b4",49:"72f6d0a1",50:"dcbe6aa5",51:"cca2da80",52:"063ad237",53:"65573113",54:"e3b86f9a",55:"e23d17b7",56:"c47badfb",57:"8c7d3e16",58:"52fb51c8",59:"8ee7423a",60:"7c6906fd",61:"898384c1",62:"6bf3cdda",63:"fed7f6ff",64:"62128c79",65:"dd8213b3",66:"579f1a82",67:"fa647f5d",68:"d535a10d",69:"4d7e0d52",70:"4b6cd449",71:"be36a223",72:"f57cde07",73:"a4087adf",74:"8f60ef05",75:"fdc945ab",76:"d1f1faa5",77:"687a6763",78:"97f56bb1",79:"35c1de5f",80:"fbe50656",81:"102e33bc",82:"4f73285b"}[n]+".js"}(n);var o=new Error;a=function(e){l.onerror=l.onload=null,clearTimeout(d);var t=r[n];if(0!==t){if(t){var i=e&&("load"===e.type?"missing":e.type),a=e&&e.target&&e.target.src;o.message="Loading chunk "+n+" failed.\n("+i+": "+a+")",o.name="ChunkLoadError",o.type=i,o.request=a,t[1](o)}r[n]=void 0}};var d=setTimeout((function(){a({type:"timeout",target:l})}),12e4);l.onerror=l.onload=a,document.head.appendChild(l)}return Promise.all(e)},s.m=n,s.c=i,s.d=function(n,e,t){s.o(n,e)||Object.defineProperty(n,e,{enumerable:!0,get:t})},s.r=function(n){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(n,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(n,"__esModule",{value:!0})},s.t=function(n,e){if(1&e&&(n=s(n)),8&e)return n;if(4&e&&"object"==typeof n&&n&&n.__esModule)return n;var t=Object.create(null);if(s.r(t),Object.defineProperty(t,"default",{enumerable:!0,value:n}),2&e&&"string"!=typeof n)for(var i in n)s.d(t,i,function(e){return n[e]}.bind(null,i));return t},s.n=function(n){var e=n&&n.__esModule?function(){return n.default}:function(){return n};return s.d(e,"a",e),e},s.o=function(n,e){return Object.prototype.hasOwnProperty.call(n,e)},s.p="/blog/",s.oe=function(n){throw console.error(n),n};var l=window.webpackJsonp=window.webpackJsonp||[],o=l.push.bind(l);l.push=e,l=l.slice();for(var d=0;d<l.length;d++)e(l[d]);var c=o;a.push([104,0]),t()}([function(n,e,t){var i=t(56),r=i.all;n.exports=i.IS_HTMLDDA?function(n){return"function"==typeof n||n===r}:function(n){return"function"==typeof n}},function(n,e){var t=function(n){return n&&n.Math==Math&&n};n.exports=t("object"==typeof globalThis&&globalThis)||t("object"==typeof window&&window)||t("object"==typeof self&&self)||t("object"==typeof global&&global)||function(){return this}()||this||Function("return this")()},function(n,e,t){var i=t(29),r=Function.prototype,a=r.call,s=i&&r.bind.bind(a,a);n.exports=i?s:function(n){return function(){return a.apply(n,arguments)}}},function(n,e){n.exports=function(n){try{return!!n()}catch(n){return!0}}},function(n,e,t){"use strict";function i(n,e,t,i,r,a,s,l){var o,d="function"==typeof n?n.options:n;if(e&&(d.render=e,d.staticRenderFns=t,d._compiled=!0),i&&(d.functional=!0),a&&(d._scopeId="data-v-"+a),s?(o=function(n){(n=n||this.$vnode&&this.$vnode.ssrContext||this.parent&&this.parent.$vnode&&this.parent.$vnode.ssrContext)||"undefined"==typeof __VUE_SSR_CONTEXT__||(n=__VUE_SSR_CONTEXT__),r&&r.call(this,n),n&&n._registeredComponents&&n._registeredComponents.add(s)},d._ssrRegister=o):r&&(o=l?function(){r.call(this,(d.functional?this.parent:this).$root.$options.shadowRoot)}:r),o)if(d.functional){d._injectStyles=o;var c=d.render;d.render=function(n,e){return o.call(e),c(n,e)}}else{var u=d.beforeCreate;d.beforeCreate=u?[].concat(u,o):[o]}return{exports:n,options:d}}t.d(e,"a",(function(){return i}))},function(n,e,t){var i=t(3);n.exports=!i((function(){return 7!=Object.defineProperty({},1,{get:function(){return 7}})[1]}))},function(n,e){var t=Array.isArray;n.exports=t},function(n,e,t){var i=t(2),r=t(33),a=i({}.hasOwnProperty);n.exports=Object.hasOwn||function(n,e){return a(r(n),e)}},function(n,e,t){var i=t(70),r="object"==typeof self&&self&&self.Object===Object&&self,a=i||r||Function("return this")();n.exports=a},function(n,e,t){var i=t(0),r=t(56),a=r.all;n.exports=r.IS_HTMLDDA?function(n){return"object"==typeof n?null!==n:i(n)||n===a}:function(n){return"object"==typeof n?null!==n:i(n)}},function(n,e,t){var i=t(165),r=t(168);n.exports=function(n,e){var t=r(n,e);return i(t)?t:void 0}},function(n,e,t){"use strict";t.d(e,"e",(function(){return i})),t.d(e,"b",(function(){return a})),t.d(e,"j",(function(){return s})),t.d(e,"g",(function(){return o})),t.d(e,"h",(function(){return d})),t.d(e,"i",(function(){return c})),t.d(e,"c",(function(){return u})),t.d(e,"f",(function(){return p})),t.d(e,"l",(function(){return m})),t.d(e,"m",(function(){return h})),t.d(e,"d",(function(){return f})),t.d(e,"k",(function(){return b})),t.d(e,"n",(function(){return v})),t.d(e,"a",(function(){return x}));t(17);const i=/#.*$/,r=/\.(md|html)$/,a=/\/$/,s=/^[a-z]+:/i;function l(n){return decodeURI(n).replace(i,"").replace(r,"")}function o(n){return s.test(n)}function d(n){return/^mailto:/.test(n)}function c(n){return/^tel:/.test(n)}function u(n){if(o(n))return n;if(!n)return"404";const e=n.match(i),t=e?e[0]:"",r=l(n);return a.test(r)?n:r+".html"+t}function p(n,e){const t=n.hash,r=function(n){const e=n&&n.match(i);if(e)return e[0]}(e);if(r&&t!==r)return!1;return l(n.path)===l(e)}function m(n,e,t){if(o(e))return{type:"external",path:e};t&&(e=function(n,e,t){const i=n.charAt(0);if("/"===i)return n;if("?"===i||"#"===i)return e+n;const r=e.split("/");t&&r[r.length-1]||r.pop();const a=n.replace(/^\//,"").split("/");for(let n=0;n<a.length;n++){const e=a[n];".."===e?r.pop():"."!==e&&r.push(e)}""!==r[0]&&r.unshift("");return r.join("/")}(e,t));const i=l(e);for(let e=0;e<n.length;e++)if(l(n[e].regularPath)===i)return Object.assign({},n[e],{type:"page",path:u(n[e].path)});return console.error(`[vuepress] No matching page found for sidebar item "${e}"`),{}}function h(n,e,t,i){const{pages:r,themeConfig:a}=t,s=i&&a.locales&&a.locales[i]||a;if("auto"===(n.frontmatter.sidebar||s.sidebar||a.sidebar))return g(n);const l=s.sidebar||a.sidebar;if(l){const{base:t,config:i}=function(n,e){if(Array.isArray(e))return{base:"/",config:e};for(const i in e)if(0===(t=n,/(\.html|\/)$/.test(t)?t:t+"/").indexOf(encodeURI(i)))return{base:i,config:e[i]};var t;return{}}(e,l);return"auto"===i?g(n):i?i.map(n=>function n(e,t,i,r=1){if("string"==typeof e)return m(t,e,i);if(Array.isArray(e))return Object.assign(m(t,e[0],i),{title:e[1]});{r>3&&console.error("[vuepress] detected a too deep nested sidebar group.");const a=e.children||[];return 0===a.length&&e.path?Object.assign(m(t,e.path,i),{title:e.title}):{type:"group",path:e.path,title:e.title,sidebarDepth:e.sidebarDepth,initialOpenGroupIndex:e.initialOpenGroupIndex,children:a.map(e=>n(e,t,i,r+1)),collapsable:!1!==e.collapsable}}}(n,r,t)):[]}return[]}function g(n){const e=f(n.headers||[]);return[{type:"group",collapsable:!1,title:n.title,path:null,children:e.map(e=>({type:"auto",title:e.title,basePath:n.path,path:n.path+"#"+e.slug,children:e.children||[]}))}]}function f(n){let e;return(n=n.map(n=>Object.assign({},n))).forEach(n=>{2===n.level?e=n:e&&(e.children||(e.children=[])).push(n)}),n.filter(n=>2===n.level)}function b(n){return Object.assign(n,{type:n.items&&n.items.length?"links":"link"})}function v(n){return Object.prototype.toString.call(n).match(/\[object (.*?)\]/)[1].toLowerCase()}function y(n){let e=n.frontmatter.date||n.lastUpdated||new Date,t=new Date(e);return"Invalid Date"==t&&e&&(t=new Date(e.replace(/-/g,"/"))),t.getTime()}function x(n,e){return y(e)-y(n)}},function(n,e){n.exports=function(n){return null!=n&&"object"==typeof n}},function(n,e,t){var i=t(5),r=t(65),a=t(100),s=t(28),l=t(55),o=TypeError,d=Object.defineProperty,c=Object.getOwnPropertyDescriptor;e.f=i?a?function(n,e,t){if(s(n),e=l(e),s(t),"function"==typeof n&&"prototype"===e&&"value"in t&&"writable"in t&&!t.writable){var i=c(n,e);i&&i.writable&&(n[e]=t.value,t={configurable:"configurable"in t?t.configurable:i.configurable,enumerable:"enumerable"in t?t.enumerable:i.enumerable,writable:!1})}return d(n,e,t)}:d:function(n,e,t){if(s(n),e=l(e),s(t),r)try{return d(n,e,t)}catch(n){}if("get"in t||"set"in t)throw o("Accessors not supported");return"value"in t&&(n[e]=t.value),n}},function(n,e,t){var i=t(16),r=t(150),a=t(151),s=i?i.toStringTag:void 0;n.exports=function(n){return null==n?void 0===n?"[object Undefined]":"[object Null]":s&&s in Object(n)?r(n):a(n)}},function(n,e,t){var i=t(5),r=t(13),a=t(36);n.exports=i?function(n,e,t){return r.f(n,e,a(1,t))}:function(n,e,t){return n[e]=t,n}},function(n,e,t){var i=t(8).Symbol;n.exports=i},function(n,e,t){"use strict";var i=t(18),r=t(33),a=t(34),s=t(129),l=t(131);i({target:"Array",proto:!0,arity:1,forced:t(3)((function(){return 4294967297!==[].push.call({length:4294967296},1)}))||!function(){try{Object.defineProperty([],"length",{writable:!1}).push()}catch(n){return n instanceof TypeError}}()},{push:function(n){var e=r(this),t=a(e),i=arguments.length;l(t+i);for(var o=0;o<i;o++)e[t]=arguments[o],t++;return s(e,t),t}})},function(n,e,t){var i=t(1),r=t(52).f,a=t(15),s=t(112),l=t(38),o=t(66),d=t(125);n.exports=function(n,e){var t,c,u,p,m,h=n.target,g=n.global,f=n.stat;if(t=g?i:f?i[h]||l(h,{}):(i[h]||{}).prototype)for(c in e){if(p=e[c],u=n.dontCallGetSet?(m=r(t,c))&&m.value:t[c],!d(g?c:h+(f?".":"#")+c,n.forced)&&void 0!==u){if(typeof p==typeof u)continue;o(p,u)}(n.sham||u&&u.sham)&&a(p,"sham",!0),s(t,c,p,n)}}},function(n,e,t){var i=t(2),r=i({}.toString),a=i("".slice);n.exports=function(n){return a(r(n),8,-1)}},function(n,e,t){var i=t(1),r=t(62),a=t(7),s=t(64),l=t(60),o=t(59),d=i.Symbol,c=r("wks"),u=o?d.for||d:d&&d.withoutSetter||s;n.exports=function(n){return a(c,n)||(c[n]=l&&a(d,n)?d[n]:u("Symbol."+n)),c[n]}},function(n,e,t){var i=t(155),r=t(156),a=t(157),s=t(158),l=t(159);function o(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var i=n[e];this.set(i[0],i[1])}}o.prototype.clear=i,o.prototype.delete=r,o.prototype.get=a,o.prototype.has=s,o.prototype.set=l,n.exports=o},function(n,e,t){var i=t(72);n.exports=function(n,e){for(var t=n.length;t--;)if(i(n[t][0],e))return t;return-1}},function(n,e,t){var i=t(10)(Object,"create");n.exports=i},function(n,e,t){var i=t(177);n.exports=function(n,e){var t=n.__data__;return i(e)?t["string"==typeof e?"string":"hash"]:t.map}},function(n,e,t){var i=t(46);n.exports=function(n){if("string"==typeof n||i(n))return n;var e=n+"";return"0"==e&&1/n==-1/0?"-0":e}},function(n,e,t){var i,r;
/* NProgress, (c) 2013, 2014 Rico Sta. Cruz - http://ricostacruz.com/nprogress
 * @license MIT */void 0===(r="function"==typeof(i=function(){var n,e,t={version:"0.2.0"},i=t.settings={minimum:.08,easing:"ease",positionUsing:"",speed:200,trickle:!0,trickleRate:.02,trickleSpeed:800,showSpinner:!0,barSelector:'[role="bar"]',spinnerSelector:'[role="spinner"]',parent:"body",template:'<div class="bar" role="bar"><div class="peg"></div></div><div class="spinner" role="spinner"><div class="spinner-icon"></div></div>'};function r(n,e,t){return n<e?e:n>t?t:n}function a(n){return 100*(-1+n)}t.configure=function(n){var e,t;for(e in n)void 0!==(t=n[e])&&n.hasOwnProperty(e)&&(i[e]=t);return this},t.status=null,t.set=function(n){var e=t.isStarted();n=r(n,i.minimum,1),t.status=1===n?null:n;var o=t.render(!e),d=o.querySelector(i.barSelector),c=i.speed,u=i.easing;return o.offsetWidth,s((function(e){""===i.positionUsing&&(i.positionUsing=t.getPositioningCSS()),l(d,function(n,e,t){var r;return(r="translate3d"===i.positionUsing?{transform:"translate3d("+a(n)+"%,0,0)"}:"translate"===i.positionUsing?{transform:"translate("+a(n)+"%,0)"}:{"margin-left":a(n)+"%"}).transition="all "+e+"ms "+t,r}(n,c,u)),1===n?(l(o,{transition:"none",opacity:1}),o.offsetWidth,setTimeout((function(){l(o,{transition:"all "+c+"ms linear",opacity:0}),setTimeout((function(){t.remove(),e()}),c)}),c)):setTimeout(e,c)})),this},t.isStarted=function(){return"number"==typeof t.status},t.start=function(){t.status||t.set(0);var n=function(){setTimeout((function(){t.status&&(t.trickle(),n())}),i.trickleSpeed)};return i.trickle&&n(),this},t.done=function(n){return n||t.status?t.inc(.3+.5*Math.random()).set(1):this},t.inc=function(n){var e=t.status;return e?("number"!=typeof n&&(n=(1-e)*r(Math.random()*e,.1,.95)),e=r(e+n,0,.994),t.set(e)):t.start()},t.trickle=function(){return t.inc(Math.random()*i.trickleRate)},n=0,e=0,t.promise=function(i){return i&&"resolved"!==i.state()?(0===e&&t.start(),n++,e++,i.always((function(){0==--e?(n=0,t.done()):t.set((n-e)/n)})),this):this},t.render=function(n){if(t.isRendered())return document.getElementById("nprogress");d(document.documentElement,"nprogress-busy");var e=document.createElement("div");e.id="nprogress",e.innerHTML=i.template;var r,s=e.querySelector(i.barSelector),o=n?"-100":a(t.status||0),c=document.querySelector(i.parent);return l(s,{transition:"all 0 linear",transform:"translate3d("+o+"%,0,0)"}),i.showSpinner||(r=e.querySelector(i.spinnerSelector))&&p(r),c!=document.body&&d(c,"nprogress-custom-parent"),c.appendChild(e),e},t.remove=function(){c(document.documentElement,"nprogress-busy"),c(document.querySelector(i.parent),"nprogress-custom-parent");var n=document.getElementById("nprogress");n&&p(n)},t.isRendered=function(){return!!document.getElementById("nprogress")},t.getPositioningCSS=function(){var n=document.body.style,e="WebkitTransform"in n?"Webkit":"MozTransform"in n?"Moz":"msTransform"in n?"ms":"OTransform"in n?"O":"";return e+"Perspective"in n?"translate3d":e+"Transform"in n?"translate":"margin"};var s=function(){var n=[];function e(){var t=n.shift();t&&t(e)}return function(t){n.push(t),1==n.length&&e()}}(),l=function(){var n=["Webkit","O","Moz","ms"],e={};function t(t){return t=t.replace(/^-ms-/,"ms-").replace(/-([\da-z])/gi,(function(n,e){return e.toUpperCase()})),e[t]||(e[t]=function(e){var t=document.body.style;if(e in t)return e;for(var i,r=n.length,a=e.charAt(0).toUpperCase()+e.slice(1);r--;)if((i=n[r]+a)in t)return i;return e}(t))}function i(n,e,i){e=t(e),n.style[e]=i}return function(n,e){var t,r,a=arguments;if(2==a.length)for(t in e)void 0!==(r=e[t])&&e.hasOwnProperty(t)&&i(n,t,r);else i(n,a[1],a[2])}}();function o(n,e){return("string"==typeof n?n:u(n)).indexOf(" "+e+" ")>=0}function d(n,e){var t=u(n),i=t+e;o(t,e)||(n.className=i.substring(1))}function c(n,e){var t,i=u(n);o(n,e)&&(t=i.replace(" "+e+" "," "),n.className=t.substring(1,t.length-1))}function u(n){return(" "+(n.className||"")+" ").replace(/\s+/gi," ")}function p(n){n&&n.parentNode&&n.parentNode.removeChild(n)}return t})?i.call(e,t,e,n):i)||(n.exports=r)},function(n){n.exports=JSON.parse('{"name":"vuepress-plugin-comment","version":"0.7.3","description":"Comment plugin in vuepress, such as Gitalk, Valine...","main":"index.js","scripts":{"test":"echo \\"Error: no test specified\\" && exit 1"},"repository":{"type":"git","url":"git+ssh://git@github.com/dongyuanxin/vuepress-plugin-comment.git"},"keywords":["vuepress","comment","plugin","vue","gitalk","valine"],"author":"dongyuanxin","license":"MIT","bugs":{"url":"https://github.com/dongyuanxin/vuepress-plugin-comment/issues"},"homepage":"https://github.com/dongyuanxin/vuepress-plugin-comment#readme","dependencies":{"ejs":"^2.6.1","gitalk":"^1.5.0","gitalk-fix":"^1.5.2","i":"^0.3.6","npm":"^6.9.0","valine":"^1.3.9"}}')},function(n,e,t){var i=t(9),r=String,a=TypeError;n.exports=function(n){if(i(n))return n;throw a(r(n)+" is not an object")}},function(n,e,t){var i=t(3);n.exports=!i((function(){var n=function(){}.bind();return"function"!=typeof n||n.hasOwnProperty("prototype")}))},function(n,e,t){var i=t(48),r=t(53);n.exports=function(n){return i(r(n))}},function(n,e,t){var i=t(1),r=t(0),a=function(n){return r(n)?n:void 0};n.exports=function(n,e){return arguments.length<2?a(i[n]):i[n]&&i[n][e]}},function(n,e,t){var i=t(0),r=t(110),a=TypeError;n.exports=function(n){if(i(n))return n;throw a(r(n)+" is not a function")}},function(n,e,t){var i=t(53),r=Object;n.exports=function(n){return r(i(n))}},function(n,e,t){var i=t(123);n.exports=function(n){return i(n.length)}},function(n,e,t){var i=t(29),r=Function.prototype.call;n.exports=i?r.bind(r):function(){return r.apply(r,arguments)}},function(n,e){n.exports=function(n,e){return{enumerable:!(1&n),configurable:!(2&n),writable:!(4&n),value:e}}},function(n,e,t){var i=t(1),r=t(38),a=i["__core-js_shared__"]||r("__core-js_shared__",{});n.exports=a},function(n,e,t){var i=t(1),r=Object.defineProperty;n.exports=function(n,e){try{r(i,n,{value:e,configurable:!0,writable:!0})}catch(t){i[n]=e}return e}},function(n,e,t){var i=t(149),r=t(12),a=Object.prototype,s=a.hasOwnProperty,l=a.propertyIsEnumerable,o=i(function(){return arguments}())?i:function(n){return r(n)&&s.call(n,"callee")&&!l.call(n,"callee")};n.exports=o},function(n,e,t){var i=t(10)(t(8),"Map");n.exports=i},function(n,e){n.exports=function(n){var e=typeof n;return null!=n&&("object"==e||"function"==e)}},function(n,e,t){var i=t(169),r=t(176),a=t(178),s=t(179),l=t(180);function o(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var i=n[e];this.set(i[0],i[1])}}o.prototype.clear=i,o.prototype.delete=r,o.prototype.get=a,o.prototype.has=s,o.prototype.set=l,n.exports=o},function(n,e){n.exports=function(n){var e=-1,t=Array(n.size);return n.forEach((function(n){t[++e]=n})),t}},function(n,e){n.exports=function(n){return"number"==typeof n&&n>-1&&n%1==0&&n<=9007199254740991}},function(n,e,t){var i=t(6),r=t(46),a=/\.|\[(?:[^[\]]*|(["'])(?:(?!\1)[^\\]|\\.)*?\1)\]/,s=/^\w*$/;n.exports=function(n,e){if(i(n))return!1;var t=typeof n;return!("number"!=t&&"symbol"!=t&&"boolean"!=t&&null!=n&&!r(n))||(s.test(n)||!a.test(n)||null!=e&&n in Object(e))}},function(n,e,t){var i=t(14),r=t(12);n.exports=function(n){return"symbol"==typeof n||r(n)&&"[object Symbol]"==i(n)}},function(n,e){n.exports=function(n){return n}},function(n,e,t){var i=t(2),r=t(3),a=t(19),s=Object,l=i("".split);n.exports=r((function(){return!s("z").propertyIsEnumerable(0)}))?function(n){return"String"==a(n)?l(n,""):s(n)}:s},function(n,e){n.exports={}},function(n,e){n.exports=function(n){return n.webpackPolyfill||(n.deprecate=function(){},n.paths=[],n.children||(n.children=[]),Object.defineProperty(n,"loaded",{enumerable:!0,get:function(){return n.l}}),Object.defineProperty(n,"id",{enumerable:!0,get:function(){return n.i}}),n.webpackPolyfill=1),n}},function(n,e){var t=/^\s+|\s+$/g,i=/^[-+]0x[0-9a-f]+$/i,r=/^0b[01]+$/i,a=/^0o[0-7]+$/i,s=parseInt,l="object"==typeof global&&global&&global.Object===Object&&global,o="object"==typeof self&&self&&self.Object===Object&&self,d=l||o||Function("return this")(),c=Object.prototype.toString,u=Math.max,p=Math.min,m=function(){return d.Date.now()};function h(n){var e=typeof n;return!!n&&("object"==e||"function"==e)}function g(n){if("number"==typeof n)return n;if(function(n){return"symbol"==typeof n||function(n){return!!n&&"object"==typeof n}(n)&&"[object Symbol]"==c.call(n)}(n))return NaN;if(h(n)){var e="function"==typeof n.valueOf?n.valueOf():n;n=h(e)?e+"":e}if("string"!=typeof n)return 0===n?n:+n;n=n.replace(t,"");var l=r.test(n);return l||a.test(n)?s(n.slice(2),l?2:8):i.test(n)?NaN:+n}n.exports=function(n,e,t){var i,r,a,s,l,o,d=0,c=!1,f=!1,b=!0;if("function"!=typeof n)throw new TypeError("Expected a function");function v(e){var t=i,a=r;return i=r=void 0,d=e,s=n.apply(a,t)}function y(n){return d=n,l=setTimeout(k,e),c?v(n):s}function x(n){var t=n-o;return void 0===o||t>=e||t<0||f&&n-d>=a}function k(){var n=m();if(x(n))return _(n);l=setTimeout(k,function(n){var t=e-(n-o);return f?p(t,a-(n-d)):t}(n))}function _(n){return l=void 0,b&&i?v(n):(i=r=void 0,s)}function E(){var n=m(),t=x(n);if(i=arguments,r=this,o=n,t){if(void 0===l)return y(o);if(f)return l=setTimeout(k,e),v(o)}return void 0===l&&(l=setTimeout(k,e)),s}return e=g(e)||0,h(t)&&(c=!!t.leading,a=(f="maxWait"in t)?u(g(t.maxWait)||0,e):a,b="trailing"in t?!!t.trailing:b),E.cancel=function(){void 0!==l&&clearTimeout(l),d=0,i=o=r=l=void 0},E.flush=function(){return void 0===l?s:_(m())},E}},function(n,e,t){var i=t(5),r=t(35),a=t(106),s=t(36),l=t(30),o=t(55),d=t(7),c=t(65),u=Object.getOwnPropertyDescriptor;e.f=i?u:function(n,e){if(n=l(n),e=o(e),c)try{return u(n,e)}catch(n){}if(d(n,e))return s(!r(a.f,n,e),n[e])}},function(n,e,t){var i=t(54),r=TypeError;n.exports=function(n){if(i(n))throw r("Can't call method on "+n);return n}},function(n,e){n.exports=function(n){return null==n}},function(n,e,t){var i=t(107),r=t(57);n.exports=function(n){var e=i(n,"string");return r(e)?e:e+""}},function(n,e){var t="object"==typeof document&&document.all,i=void 0===t&&void 0!==t;n.exports={all:t,IS_HTMLDDA:i}},function(n,e,t){var i=t(31),r=t(0),a=t(58),s=t(59),l=Object;n.exports=s?function(n){return"symbol"==typeof n}:function(n){var e=i("Symbol");return r(e)&&a(e.prototype,l(n))}},function(n,e,t){var i=t(2);n.exports=i({}.isPrototypeOf)},function(n,e,t){var i=t(60);n.exports=i&&!Symbol.sham&&"symbol"==typeof Symbol.iterator},function(n,e,t){var i=t(61),r=t(3),a=t(1).String;n.exports=!!Object.getOwnPropertySymbols&&!r((function(){var n=Symbol();return!a(n)||!(Object(n)instanceof Symbol)||!Symbol.sham&&i&&i<41}))},function(n,e,t){var i,r,a=t(1),s=t(108),l=a.process,o=a.Deno,d=l&&l.versions||o&&o.version,c=d&&d.v8;c&&(r=(i=c.split("."))[0]>0&&i[0]<4?1:+(i[0]+i[1])),!r&&s&&(!(i=s.match(/Edge\/(\d+)/))||i[1]>=74)&&(i=s.match(/Chrome\/(\d+)/))&&(r=+i[1]),n.exports=r},function(n,e,t){var i=t(63),r=t(37);(n.exports=function(n,e){return r[n]||(r[n]=void 0!==e?e:{})})("versions",[]).push({version:"3.30.2",mode:i?"pure":"global",copyright:"© 2014-2023 Denis Pushkarev (zloirock.ru)",license:"https://github.com/zloirock/core-js/blob/v3.30.2/LICENSE",source:"https://github.com/zloirock/core-js"})},function(n,e){n.exports=!1},function(n,e,t){var i=t(2),r=0,a=Math.random(),s=i(1..toString);n.exports=function(n){return"Symbol("+(void 0===n?"":n)+")_"+s(++r+a,36)}},function(n,e,t){var i=t(5),r=t(3),a=t(99);n.exports=!i&&!r((function(){return 7!=Object.defineProperty(a("div"),"a",{get:function(){return 7}}).a}))},function(n,e,t){var i=t(7),r=t(118),a=t(52),s=t(13);n.exports=function(n,e,t){for(var l=r(e),o=s.f,d=a.f,c=0;c<l.length;c++){var u=l[c];i(n,u)||t&&i(t,u)||o(n,u,d(e,u))}}},function(n,e,t){var i=t(122);n.exports=function(n){var e=+n;return e!=e||0===e?0:i(e)}},function(n,e,t){var i=t(135),r=t(28),a=t(136);n.exports=Object.setPrototypeOf||("__proto__"in{}?function(){var n,e=!1,t={};try{(n=i(Object.prototype,"__proto__","set"))(t,[]),e=t instanceof Array}catch(n){}return function(t,i){return r(t),a(i),e?n(t,i):t.__proto__=i,t}}():void 0)},function(n,e){n.exports=function(n,e){for(var t=-1,i=e.length,r=n.length;++t<i;)n[r+t]=e[t];return n}},function(n,e){var t="object"==typeof global&&global&&global.Object===Object&&global;n.exports=t},function(n,e,t){var i=t(21),r=t(160),a=t(161),s=t(162),l=t(163),o=t(164);function d(n){var e=this.__data__=new i(n);this.size=e.size}d.prototype.clear=r,d.prototype.delete=a,d.prototype.get=s,d.prototype.has=l,d.prototype.set=o,n.exports=d},function(n,e){n.exports=function(n,e){return n===e||n!=n&&e!=e}},function(n,e,t){var i=t(14),r=t(41);n.exports=function(n){if(!r(n))return!1;var e=i(n);return"[object Function]"==e||"[object GeneratorFunction]"==e||"[object AsyncFunction]"==e||"[object Proxy]"==e}},function(n,e){var t=Function.prototype.toString;n.exports=function(n){if(null!=n){try{return t.call(n)}catch(n){}try{return n+""}catch(n){}}return""}},function(n,e,t){var i=t(181),r=t(12);n.exports=function n(e,t,a,s,l){return e===t||(null==e||null==t||!r(e)&&!r(t)?e!=e&&t!=t:i(e,t,a,s,n,l))}},function(n,e,t){var i=t(77),r=t(184),a=t(78);n.exports=function(n,e,t,s,l,o){var d=1&t,c=n.length,u=e.length;if(c!=u&&!(d&&u>c))return!1;var p=o.get(n),m=o.get(e);if(p&&m)return p==e&&m==n;var h=-1,g=!0,f=2&t?new i:void 0;for(o.set(n,e),o.set(e,n);++h<c;){var b=n[h],v=e[h];if(s)var y=d?s(v,b,h,e,n,o):s(b,v,h,n,e,o);if(void 0!==y){if(y)continue;g=!1;break}if(f){if(!r(e,(function(n,e){if(!a(f,e)&&(b===n||l(b,n,t,s,o)))return f.push(e)}))){g=!1;break}}else if(b!==v&&!l(b,v,t,s,o)){g=!1;break}}return o.delete(n),o.delete(e),g}},function(n,e,t){var i=t(42),r=t(182),a=t(183);function s(n){var e=-1,t=null==n?0:n.length;for(this.__data__=new i;++e<t;)this.add(n[e])}s.prototype.add=s.prototype.push=r,s.prototype.has=a,n.exports=s},function(n,e){n.exports=function(n,e){return n.has(e)}},function(n,e,t){var i=t(194),r=t(200),a=t(83);n.exports=function(n){return a(n)?i(n):r(n)}},function(n,e,t){(function(n){var i=t(8),r=t(196),a=e&&!e.nodeType&&e,s=a&&"object"==typeof n&&n&&!n.nodeType&&n,l=s&&s.exports===a?i.Buffer:void 0,o=(l?l.isBuffer:void 0)||r;n.exports=o}).call(this,t(50)(n))},function(n,e){var t=/^(?:0|[1-9]\d*)$/;n.exports=function(n,e){var i=typeof n;return!!(e=null==e?9007199254740991:e)&&("number"==i||"symbol"!=i&&t.test(n))&&n>-1&&n%1==0&&n<e}},function(n,e,t){var i=t(197),r=t(198),a=t(199),s=a&&a.isTypedArray,l=s?r(s):i;n.exports=l},function(n,e,t){var i=t(73),r=t(44);n.exports=function(n){return null!=n&&r(n.length)&&!i(n)}},function(n,e,t){var i=t(10)(t(8),"Set");n.exports=i},function(n,e,t){var i=t(41);n.exports=function(n){return n==n&&!i(n)}},function(n,e){n.exports=function(n,e){return function(t){return null!=t&&(t[n]===e&&(void 0!==e||n in Object(t)))}}},function(n,e,t){var i=t(88),r=t(25);n.exports=function(n,e){for(var t=0,a=(e=i(e,n)).length;null!=n&&t<a;)n=n[r(e[t++])];return t&&t==a?n:void 0}},function(n,e,t){var i=t(6),r=t(45),a=t(211),s=t(214);n.exports=function(n,e){return i(n)?n:r(n,e)?[n]:a(s(n))}},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){var i=t(147),r=t(152),a=t(223),s=t(231),l=t(240),o=t(103),d=a((function(n){var e=o(n);return l(e)&&(e=void 0),s(i(n,1,l,!0),r(e,2))}));n.exports=d},function(n,e,t){"use strict";
/*!
 * escape-html
 * Copyright(c) 2012-2013 TJ Holowaychuk
 * Copyright(c) 2015 Andreas Lubbe
 * Copyright(c) 2015 Tiancheng "Timothy" Gu
 * MIT Licensed
 */var i=/["'&<>]/;n.exports=function(n){var e,t=""+n,r=i.exec(t);if(!r)return t;var a="",s=0,l=0;for(s=r.index;s<t.length;s++){switch(t.charCodeAt(s)){case 34:e="&quot;";break;case 38:e="&amp;";break;case 39:e="&#39;";break;case 60:e="&lt;";break;case 62:e="&gt;";break;default:continue}l!==s&&(a+=t.substring(l,s)),l=s+1,a+=e}return l!==s?a+t.substring(l,s):a}},function(n,e,t){"use strict";
/**
 * @file Embedded JavaScript templating engine. {@link http://ejs.co}
 * @author Matthew Eernisse <mde@fleegix.org>
 * @author Tiancheng "Timothy" Gu <timothygu99@gmail.com>
 * @project EJS
 * @license {@link http://www.apache.org/licenses/LICENSE-2.0 Apache License, Version 2.0}
 */var i=t(249),r=t(250),a=t(251),s=!1,l=t(252).version,o=["delimiter","scope","context","debug","compileDebug","client","_with","rmWhitespace","strict","filename","async"],d=o.concat("cache"),c=/^\uFEFF/;function u(n,t){var r,a,s=t.views,l=/^[A-Za-z]+:\\|^\//.exec(n);if(l&&l.length)r=e.resolveInclude(n.replace(/^\/*/,""),t.root||"/",!0);else if(t.filename&&(a=e.resolveInclude(n,t.filename),i.existsSync(a)&&(r=a)),r||Array.isArray(s)&&s.some((function(t){return a=e.resolveInclude(n,t,!0),i.existsSync(a)}))&&(r=a),!r)throw new Error('Could not find the include file "'+t.escapeFunction(n)+'"');return r}function p(n,t){var i,r=n.filename,a=arguments.length>1;if(n.cache){if(!r)throw new Error("cache option requires a filename");if(i=e.cache.get(r))return i;a||(t=h(r).toString().replace(c,""))}else if(!a){if(!r)throw new Error("Internal EJS error: no file name or template provided");t=h(r).toString().replace(c,"")}return i=e.compile(t,n),n.cache&&e.cache.set(r,i),i}function m(n,t,i){var r;if(!i){if("function"==typeof e.promiseImpl)return new e.promiseImpl((function(e,i){try{e(r=p(n)(t))}catch(n){i(n)}}));throw new Error("Please provide a callback function")}try{r=p(n)(t)}catch(n){return i(n)}i(null,r)}function h(n){return e.fileLoader(n)}function g(n,e,t,i,r){var a=e.split("\n"),s=Math.max(i-3,0),l=Math.min(a.length,i+3),o=r(t),d=a.slice(s,l).map((function(n,e){var t=e+s+1;return(t==i?" >> ":"    ")+t+"| "+n})).join("\n");throw n.path=o,n.message=(o||"ejs")+":"+i+"\n"+d+"\n\n"+n.message,n}function f(n){return n.replace(/;(\s*$)/,"$1")}function b(n,t){t=t||{};var i={};this.templateText=n,this.mode=null,this.truncate=!1,this.currentLine=1,this.source="",this.dependencies=[],i.client=t.client||!1,i.escapeFunction=t.escape||t.escapeFunction||a.escapeXML,i.compileDebug=!1!==t.compileDebug,i.debug=!!t.debug,i.filename=t.filename,i.openDelimiter=t.openDelimiter||e.openDelimiter||"<",i.closeDelimiter=t.closeDelimiter||e.closeDelimiter||">",i.delimiter=t.delimiter||e.delimiter||"%",i.strict=t.strict||!1,i.context=t.context,i.cache=t.cache||!1,i.rmWhitespace=t.rmWhitespace,i.root=t.root,i.outputFunctionName=t.outputFunctionName,i.localsName=t.localsName||e.localsName||"locals",i.views=t.views,i.async=t.async,i.destructuredLocals=t.destructuredLocals,i.legacyInclude=void 0===t.legacyInclude||!!t.legacyInclude,i.strict?i._with=!1:i._with=void 0===t._with||t._with,this.opts=i,this.regex=this.createRegex()}e.cache=a.cache,e.fileLoader=i.readFileSync,e.localsName="locals",e.promiseImpl=new Function("return this;")().Promise,e.resolveInclude=function(n,e,t){var i=r.dirname,a=r.extname,s=(0,r.resolve)(t?e:i(e),n);return a(n)||(s+=".ejs"),s},e.compile=function(n,e){return e&&e.scope&&(s||(console.warn("`scope` option is deprecated and will be removed in EJS 3"),s=!0),e.context||(e.context=e.scope),delete e.scope),new b(n,e).compile()},e.render=function(n,e,t){var i=e||{},r=t||{};return 2==arguments.length&&a.shallowCopyFromList(r,i,o),p(r,n)(i)},e.renderFile=function(){var n,e,t,i=Array.prototype.slice.call(arguments),r=i.shift(),s={filename:r};return"function"==typeof arguments[arguments.length-1]&&(n=i.pop()),i.length?(e=i.shift(),i.length?a.shallowCopy(s,i.pop()):(e.settings&&(e.settings.views&&(s.views=e.settings.views),e.settings["view cache"]&&(s.cache=!0),(t=e.settings["view options"])&&a.shallowCopy(s,t)),a.shallowCopyFromList(s,e,d)),s.filename=r):e={},m(s,e,n)},e.Template=b,e.clearCache=function(){e.cache.reset()},b.modes={EVAL:"eval",ESCAPED:"escaped",RAW:"raw",COMMENT:"comment",LITERAL:"literal"},b.prototype={createRegex:function(){var n="(<%%|%%>|<%=|<%-|<%_|<%#|<%|%>|-%>|_%>)",e=a.escapeRegExpChars(this.opts.delimiter),t=a.escapeRegExpChars(this.opts.openDelimiter),i=a.escapeRegExpChars(this.opts.closeDelimiter);return n=n.replace(/%/g,e).replace(/</g,t).replace(/>/g,i),new RegExp(n)},compile:function(){var n,e,t,i=this.opts,s="",l="",o=i.escapeFunction;if(!this.source){if(this.generateSource(),s+='  var __output = "";\n  function __append(s) { if (s !== undefined && s !== null) __output += s }\n',i.outputFunctionName&&(s+="  var "+i.outputFunctionName+" = __append;\n"),i.destructuredLocals&&i.destructuredLocals.length){for(var d="  var __locals = ("+i.localsName+" || {}),\n",c=0;c<i.destructuredLocals.length;c++){var m=i.destructuredLocals[c];c>0&&(d+=",\n  "),d+=m+" = __locals."+m}s+=d+";\n"}!1!==i._with&&(s+="  with ("+i.localsName+" || {}) {\n",l+="  }\n"),l+="  return __output;\n",this.source=s+this.source+l}n=i.compileDebug?"var __line = 1\n  , __lines = "+JSON.stringify(this.templateText)+"\n  , __filename = "+(i.filename?JSON.stringify(i.filename):"undefined")+";\ntry {\n"+this.source+"} catch (e) {\n  rethrow(e, __lines, __filename, __line, escapeFn);\n}\n":this.source,i.client&&(n="escapeFn = escapeFn || "+o.toString()+";\n"+n,i.compileDebug&&(n="rethrow = rethrow || "+g.toString()+";\n"+n)),i.strict&&(n='"use strict";\n'+n),i.debug&&console.log(n),i.compileDebug&&i.filename&&(n=n+"\n//# sourceURL="+i.filename+"\n");try{if(i.async)try{t=new Function("return (async function(){}).constructor;")()}catch(n){throw n instanceof SyntaxError?new Error("This environment does not support async/await"):n}else t=Function;e=new t(i.localsName+", escapeFn, include, rethrow",n)}catch(n){throw n instanceof SyntaxError&&(i.filename&&(n.message+=" in "+i.filename),n.message+=" while compiling ejs\n\n",n.message+="If the above error is not helpful, you may want to try EJS-Lint:\n",n.message+="https://github.com/RyanZim/EJS-Lint",i.async||(n.message+="\n",n.message+="Or, if you meant to create an async function, pass `async: true` as an option.")),n}var h=i.client?e:function(n){return e.apply(i.context,[n||{},o,function(e,t){var r=a.shallowCopy({},n);return t&&(r=a.shallowCopy(r,t)),function(n,e){var t=a.shallowCopy({},e);return t.filename=u(n,t),p(t)}(e,i)(r)},g])};if(h.dependencies=this.dependencies,i.filename&&"function"==typeof Object.defineProperty){var f=i.filename,b=r.basename(f,r.extname(f));try{Object.defineProperty(h,"name",{value:b,writable:!1,enumerable:!1,configurable:!0})}catch(n){}}return h},generateSource:function(){var n=this.opts;n.rmWhitespace&&(this.templateText=this.templateText.replace(/[\r\n]+/g,"\n").replace(/^\s+|\s+$/gm,"")),this.templateText=this.templateText.replace(/[ \t]*<%_/gm,"<%_").replace(/_%>[ \t]*/gm,"_%>");var t=this,i=this.parseTemplateText(),r=this.opts.delimiter,s=this.opts.openDelimiter,l=this.opts.closeDelimiter;i&&i.length&&i.forEach((function(o,d){var p,m,g,f,v,y;if(0===o.indexOf(s+r)&&0!==o.indexOf(s+r+r)&&(m=i[d+2])!=r+l&&m!="-"+r+l&&m!="_"+r+l)throw new Error('Could not find matching close tag for "'+o+'".');if(n.legacyInclude&&(g=o.match(/^\s*include\s+(\S+)/))&&(p=i[d-1])&&(p==s+r||p==s+r+"-"||p==s+r+"_"))return f=a.shallowCopy({},t.opts),v=function(n,e){var t,i,r=a.shallowCopy({},e);i=h(t=u(n,r)).toString().replace(c,""),r.filename=t;var s=new b(i,r);return s.generateSource(),{source:s.source,filename:t,template:i}}(g[1],f),y=t.opts.compileDebug?"    ; (function(){\n      var __line = 1\n      , __lines = "+JSON.stringify(v.template)+"\n      , __filename = "+JSON.stringify(v.filename)+";\n      try {\n"+v.source+"      } catch (e) {\n        rethrow(e, __lines, __filename, __line, escapeFn);\n      }\n    ; }).call(this)\n":"    ; (function(){\n"+v.source+"    ; }).call(this)\n",t.source+=y,void t.dependencies.push(e.resolveInclude(g[1],f.filename));t.scanLine(o)}))},parseTemplateText:function(){for(var n,e=this.templateText,t=this.regex,i=t.exec(e),r=[];i;)0!==(n=i.index)&&(r.push(e.substring(0,n)),e=e.slice(n)),r.push(i[0]),e=e.slice(i[0].length),i=t.exec(e);return e&&r.push(e),r},_addOutput:function(n){if(this.truncate&&(n=n.replace(/^(?:\r\n|\r|\n)/,""),this.truncate=!1),!n)return n;n=(n=(n=(n=n.replace(/\\/g,"\\\\")).replace(/\n/g,"\\n")).replace(/\r/g,"\\r")).replace(/"/g,'\\"'),this.source+='    ; __append("'+n+'")\n'},scanLine:function(n){var e,t=this.opts.delimiter,i=this.opts.openDelimiter,r=this.opts.closeDelimiter;switch(e=n.split("\n").length-1,n){case i+t:case i+t+"_":this.mode=b.modes.EVAL;break;case i+t+"=":this.mode=b.modes.ESCAPED;break;case i+t+"-":this.mode=b.modes.RAW;break;case i+t+"#":this.mode=b.modes.COMMENT;break;case i+t+t:this.mode=b.modes.LITERAL,this.source+='    ; __append("'+n.replace(i+t+t,i+t)+'")\n';break;case t+t+r:this.mode=b.modes.LITERAL,this.source+='    ; __append("'+n.replace(t+t+r,t+r)+'")\n';break;case t+r:case"-"+t+r:case"_"+t+r:this.mode==b.modes.LITERAL&&this._addOutput(n),this.mode=null,this.truncate=0===n.indexOf("-")||0===n.indexOf("_");break;default:if(this.mode){switch(this.mode){case b.modes.EVAL:case b.modes.ESCAPED:case b.modes.RAW:n.lastIndexOf("//")>n.lastIndexOf("\n")&&(n+="\n")}switch(this.mode){case b.modes.EVAL:this.source+="    ; "+n+"\n";break;case b.modes.ESCAPED:this.source+="    ; __append(escapeFn("+f(n)+"))\n";break;case b.modes.RAW:this.source+="    ; __append("+f(n)+")\n";break;case b.modes.COMMENT:break;case b.modes.LITERAL:this._addOutput(n)}}else this._addOutput(n)}this.opts.compileDebug&&e&&(this.currentLine+=e,this.source+="    ; __line = "+this.currentLine+"\n")}},e.escapeXML=a.escapeXML,e.__express=e.renderFile,e.VERSION=l,e.name="ejs","undefined"!=typeof window&&(window.ejs=e)},function(n,e,t){"use strict";t.r(e);var i={name:"CodeBlock",props:{title:{type:String,required:!0},active:{type:Boolean,default:!1}}},r=(t(243),t(4)),a=Object(r.a)(i,(function(){return(0,this._self._c)("div",{staticClass:"theme-code-block",class:{"theme-code-block__active":this.active}},[this._t("default")],2)}),[],!1,null,"4f1e9d0c",null);e.default=a.exports},function(n,e,t){"use strict";t.r(e);var i={name:"CodeGroup",data:()=>({codeTabs:[],activeCodeTabIndex:-1}),watch:{activeCodeTabIndex(n){this.codeTabs.forEach(n=>{n.elm.classList.remove("theme-code-block__active")}),this.codeTabs[n].elm.classList.add("theme-code-block__active")}},mounted(){this.codeTabs=(this.$slots.default||[]).filter(n=>Boolean(n.componentOptions)).map((n,e)=>(""===n.componentOptions.propsData.active&&(this.activeCodeTabIndex=e),{title:n.componentOptions.propsData.title,elm:n.elm})),-1===this.activeCodeTabIndex&&this.codeTabs.length>0&&(this.activeCodeTabIndex=0)},methods:{changeCodeTab(n){this.activeCodeTabIndex=n}}},r=(t(244),t(4)),a=Object(r.a)(i,(function(){var n=this,e=n._self._c;return e("div",{staticClass:"theme-code-group"},[e("div",{staticClass:"theme-code-group__nav"},[e("ul",{staticClass:"theme-code-group__ul"},n._l(n.codeTabs,(function(t,i){return e("li",{key:t.title,staticClass:"theme-code-group__li"},[e("button",{staticClass:"theme-code-group__nav-tab",class:{"theme-code-group__nav-tab-active":i===n.activeCodeTabIndex},on:{click:function(e){return n.changeCodeTab(i)}}},[n._v("\n            "+n._s(t.title)+"\n          ")])])})),0)]),n._v(" "),n._t("default"),n._v(" "),n.codeTabs.length<1?e("pre",{staticClass:"pre-blank"},[n._v("// Make sure to add code blocks to your code group")]):n._e()],2)}),[],!1,null,"2f5f1757",null);e.default=a.exports},function(n,e){n.exports=["constructor","hasOwnProperty","isPrototypeOf","propertyIsEnumerable","toLocaleString","toString","valueOf"]},function(n,e,t){var i=t(1),r=t(9),a=i.document,s=r(a)&&r(a.createElement);n.exports=function(n){return s?a.createElement(n):{}}},function(n,e,t){var i=t(5),r=t(3);n.exports=i&&r((function(){return 42!=Object.defineProperty((function(){}),"prototype",{value:42,writable:!1}).prototype}))},function(n,e,t){var i=t(62),r=t(64),a=i("keys");n.exports=function(n){return a[n]||(a[n]=r(n))}},function(n,e,t){var i=t(2),r=t(7),a=t(30),s=t(120).indexOf,l=t(49),o=i([].push);n.exports=function(n,e){var t,i=a(n),d=0,c=[];for(t in i)!r(l,t)&&r(i,t)&&o(c,t);for(;e.length>d;)r(i,t=e[d++])&&(~s(c,t)||o(c,t));return c}},function(n,e){n.exports=function(n){var e=null==n?0:n.length;return e?n[e-1]:void 0}},function(n,e,t){n.exports=t(255)},function(n,e,t){"use strict";var i=t(18),r=t(126).left,a=t(127),s=t(61);i({target:"Array",proto:!0,forced:!t(128)&&s>79&&s<83||!a("reduce")},{reduce:function(n){var e=arguments.length;return r(this,n,e,e>1?arguments[1]:void 0)}})},function(n,e,t){"use strict";var i={}.propertyIsEnumerable,r=Object.getOwnPropertyDescriptor,a=r&&!i.call({1:2},1);e.f=a?function(n){var e=r(this,n);return!!e&&e.enumerable}:i},function(n,e,t){var i=t(35),r=t(9),a=t(57),s=t(109),l=t(111),o=t(20),d=TypeError,c=o("toPrimitive");n.exports=function(n,e){if(!r(n)||a(n))return n;var t,o=s(n,c);if(o){if(void 0===e&&(e="default"),t=i(o,n,e),!r(t)||a(t))return t;throw d("Can't convert object to primitive value")}return void 0===e&&(e="number"),l(n,e)}},function(n,e){n.exports="undefined"!=typeof navigator&&String(navigator.userAgent)||""},function(n,e,t){var i=t(32),r=t(54);n.exports=function(n,e){var t=n[e];return r(t)?void 0:i(t)}},function(n,e){var t=String;n.exports=function(n){try{return t(n)}catch(n){return"Object"}}},function(n,e,t){var i=t(35),r=t(0),a=t(9),s=TypeError;n.exports=function(n,e){var t,l;if("string"===e&&r(t=n.toString)&&!a(l=i(t,n)))return l;if(r(t=n.valueOf)&&!a(l=i(t,n)))return l;if("string"!==e&&r(t=n.toString)&&!a(l=i(t,n)))return l;throw s("Can't convert object to primitive value")}},function(n,e,t){var i=t(0),r=t(13),a=t(113),s=t(38);n.exports=function(n,e,t,l){l||(l={});var o=l.enumerable,d=void 0!==l.name?l.name:e;if(i(t)&&a(t,d,l),l.global)o?n[e]=t:s(e,t);else{try{l.unsafe?n[e]&&(o=!0):delete n[e]}catch(n){}o?n[e]=t:r.f(n,e,{value:t,enumerable:!1,configurable:!l.nonConfigurable,writable:!l.nonWritable})}return n}},function(n,e,t){var i=t(2),r=t(3),a=t(0),s=t(7),l=t(5),o=t(114).CONFIGURABLE,d=t(115),c=t(116),u=c.enforce,p=c.get,m=String,h=Object.defineProperty,g=i("".slice),f=i("".replace),b=i([].join),v=l&&!r((function(){return 8!==h((function(){}),"length",{value:8}).length})),y=String(String).split("String"),x=n.exports=function(n,e,t){"Symbol("===g(m(e),0,7)&&(e="["+f(m(e),/^Symbol\(([^)]*)\)/,"$1")+"]"),t&&t.getter&&(e="get "+e),t&&t.setter&&(e="set "+e),(!s(n,"name")||o&&n.name!==e)&&(l?h(n,"name",{value:e,configurable:!0}):n.name=e),v&&t&&s(t,"arity")&&n.length!==t.arity&&h(n,"length",{value:t.arity});try{t&&s(t,"constructor")&&t.constructor?l&&h(n,"prototype",{writable:!1}):n.prototype&&(n.prototype=void 0)}catch(n){}var i=u(n);return s(i,"source")||(i.source=b(y,"string"==typeof e?e:"")),n};Function.prototype.toString=x((function(){return a(this)&&p(this).source||d(this)}),"toString")},function(n,e,t){var i=t(5),r=t(7),a=Function.prototype,s=i&&Object.getOwnPropertyDescriptor,l=r(a,"name"),o=l&&"something"===function(){}.name,d=l&&(!i||i&&s(a,"name").configurable);n.exports={EXISTS:l,PROPER:o,CONFIGURABLE:d}},function(n,e,t){var i=t(2),r=t(0),a=t(37),s=i(Function.toString);r(a.inspectSource)||(a.inspectSource=function(n){return s(n)}),n.exports=a.inspectSource},function(n,e,t){var i,r,a,s=t(117),l=t(1),o=t(9),d=t(15),c=t(7),u=t(37),p=t(101),m=t(49),h=l.TypeError,g=l.WeakMap;if(s||u.state){var f=u.state||(u.state=new g);f.get=f.get,f.has=f.has,f.set=f.set,i=function(n,e){if(f.has(n))throw h("Object already initialized");return e.facade=n,f.set(n,e),e},r=function(n){return f.get(n)||{}},a=function(n){return f.has(n)}}else{var b=p("state");m[b]=!0,i=function(n,e){if(c(n,b))throw h("Object already initialized");return e.facade=n,d(n,b,e),e},r=function(n){return c(n,b)?n[b]:{}},a=function(n){return c(n,b)}}n.exports={set:i,get:r,has:a,enforce:function(n){return a(n)?r(n):i(n,{})},getterFor:function(n){return function(e){var t;if(!o(e)||(t=r(e)).type!==n)throw h("Incompatible receiver, "+n+" required");return t}}}},function(n,e,t){var i=t(1),r=t(0),a=i.WeakMap;n.exports=r(a)&&/native code/.test(String(a))},function(n,e,t){var i=t(31),r=t(2),a=t(119),s=t(124),l=t(28),o=r([].concat);n.exports=i("Reflect","ownKeys")||function(n){var e=a.f(l(n)),t=s.f;return t?o(e,t(n)):e}},function(n,e,t){var i=t(102),r=t(98).concat("length","prototype");e.f=Object.getOwnPropertyNames||function(n){return i(n,r)}},function(n,e,t){var i=t(30),r=t(121),a=t(34),s=function(n){return function(e,t,s){var l,o=i(e),d=a(o),c=r(s,d);if(n&&t!=t){for(;d>c;)if((l=o[c++])!=l)return!0}else for(;d>c;c++)if((n||c in o)&&o[c]===t)return n||c||0;return!n&&-1}};n.exports={includes:s(!0),indexOf:s(!1)}},function(n,e,t){var i=t(67),r=Math.max,a=Math.min;n.exports=function(n,e){var t=i(n);return t<0?r(t+e,0):a(t,e)}},function(n,e){var t=Math.ceil,i=Math.floor;n.exports=Math.trunc||function(n){var e=+n;return(e>0?i:t)(e)}},function(n,e,t){var i=t(67),r=Math.min;n.exports=function(n){return n>0?r(i(n),9007199254740991):0}},function(n,e){e.f=Object.getOwnPropertySymbols},function(n,e,t){var i=t(3),r=t(0),a=/#|\.prototype\./,s=function(n,e){var t=o[l(n)];return t==c||t!=d&&(r(e)?i(e):!!e)},l=s.normalize=function(n){return String(n).replace(a,".").toLowerCase()},o=s.data={},d=s.NATIVE="N",c=s.POLYFILL="P";n.exports=s},function(n,e,t){var i=t(32),r=t(33),a=t(48),s=t(34),l=TypeError,o=function(n){return function(e,t,o,d){i(t);var c=r(e),u=a(c),p=s(c),m=n?p-1:0,h=n?-1:1;if(o<2)for(;;){if(m in u){d=u[m],m+=h;break}if(m+=h,n?m<0:p<=m)throw l("Reduce of empty array with no initial value")}for(;n?m>=0:p>m;m+=h)m in u&&(d=t(d,u[m],m,c));return d}};n.exports={left:o(!1),right:o(!0)}},function(n,e,t){"use strict";var i=t(3);n.exports=function(n,e){var t=[][n];return!!t&&i((function(){t.call(null,e||function(){return 1},1)}))}},function(n,e,t){var i=t(19);n.exports="undefined"!=typeof process&&"process"==i(process)},function(n,e,t){"use strict";var i=t(5),r=t(130),a=TypeError,s=Object.getOwnPropertyDescriptor,l=i&&!function(){if(void 0!==this)return!0;try{Object.defineProperty([],"length",{writable:!1}).length=1}catch(n){return n instanceof TypeError}}();n.exports=l?function(n,e){if(r(n)&&!s(n,"length").writable)throw a("Cannot set read only .length");return n.length=e}:function(n,e){return n.length=e}},function(n,e,t){var i=t(19);n.exports=Array.isArray||function(n){return"Array"==i(n)}},function(n,e){var t=TypeError;n.exports=function(n){if(n>9007199254740991)throw t("Maximum allowed index exceeded");return n}},function(n,e,t){var i=t(18),r=t(1),a=t(133),s=t(134),l=r.WebAssembly,o=7!==Error("e",{cause:7}).cause,d=function(n,e){var t={};t[n]=s(n,e,o),i({global:!0,constructor:!0,arity:1,forced:o},t)},c=function(n,e){if(l&&l[n]){var t={};t[n]=s("WebAssembly."+n,e,o),i({target:"WebAssembly",stat:!0,constructor:!0,arity:1,forced:o},t)}};d("Error",(function(n){return function(e){return a(n,this,arguments)}})),d("EvalError",(function(n){return function(e){return a(n,this,arguments)}})),d("RangeError",(function(n){return function(e){return a(n,this,arguments)}})),d("ReferenceError",(function(n){return function(e){return a(n,this,arguments)}})),d("SyntaxError",(function(n){return function(e){return a(n,this,arguments)}})),d("TypeError",(function(n){return function(e){return a(n,this,arguments)}})),d("URIError",(function(n){return function(e){return a(n,this,arguments)}})),c("CompileError",(function(n){return function(e){return a(n,this,arguments)}})),c("LinkError",(function(n){return function(e){return a(n,this,arguments)}})),c("RuntimeError",(function(n){return function(e){return a(n,this,arguments)}}))},function(n,e,t){var i=t(29),r=Function.prototype,a=r.apply,s=r.call;n.exports="object"==typeof Reflect&&Reflect.apply||(i?s.bind(a):function(){return s.apply(a,arguments)})},function(n,e,t){"use strict";var i=t(31),r=t(7),a=t(15),s=t(58),l=t(68),o=t(66),d=t(137),c=t(138),u=t(139),p=t(143),m=t(144),h=t(5),g=t(63);n.exports=function(n,e,t,f){var b=f?2:1,v=n.split("."),y=v[v.length-1],x=i.apply(null,v);if(x){var k=x.prototype;if(!g&&r(k,"cause")&&delete k.cause,!t)return x;var _=i("Error"),E=e((function(n,e){var t=u(f?e:n,void 0),i=f?new x(n):new x;return void 0!==t&&a(i,"message",t),m(i,E,i.stack,2),this&&s(k,this)&&c(i,this,E),arguments.length>b&&p(i,arguments[b]),i}));if(E.prototype=k,"Error"!==y?l?l(E,_):o(E,_,{name:!0}):h&&"stackTraceLimit"in x&&(d(E,x,"stackTraceLimit"),d(E,x,"prepareStackTrace")),o(E,x),!g)try{k.name!==y&&a(k,"name",y),k.constructor=E}catch(n){}return E}}},function(n,e,t){var i=t(2),r=t(32);n.exports=function(n,e,t){try{return i(r(Object.getOwnPropertyDescriptor(n,e)[t]))}catch(n){}}},function(n,e,t){var i=t(0),r=String,a=TypeError;n.exports=function(n){if("object"==typeof n||i(n))return n;throw a("Can't set "+r(n)+" as a prototype")}},function(n,e,t){var i=t(13).f;n.exports=function(n,e,t){t in n||i(n,t,{configurable:!0,get:function(){return e[t]},set:function(n){e[t]=n}})}},function(n,e,t){var i=t(0),r=t(9),a=t(68);n.exports=function(n,e,t){var s,l;return a&&i(s=e.constructor)&&s!==t&&r(l=s.prototype)&&l!==t.prototype&&a(n,l),n}},function(n,e,t){var i=t(140);n.exports=function(n,e){return void 0===n?arguments.length<2?"":e:i(n)}},function(n,e,t){var i=t(141),r=String;n.exports=function(n){if("Symbol"===i(n))throw TypeError("Cannot convert a Symbol value to a string");return r(n)}},function(n,e,t){var i=t(142),r=t(0),a=t(19),s=t(20)("toStringTag"),l=Object,o="Arguments"==a(function(){return arguments}());n.exports=i?a:function(n){var e,t,i;return void 0===n?"Undefined":null===n?"Null":"string"==typeof(t=function(n,e){try{return n[e]}catch(n){}}(e=l(n),s))?t:o?a(e):"Object"==(i=a(e))&&r(e.callee)?"Arguments":i}},function(n,e,t){var i={};i[t(20)("toStringTag")]="z",n.exports="[object z]"===String(i)},function(n,e,t){var i=t(9),r=t(15);n.exports=function(n,e){i(e)&&"cause"in e&&r(n,"cause",e.cause)}},function(n,e,t){var i=t(15),r=t(145),a=t(146),s=Error.captureStackTrace;n.exports=function(n,e,t,l){a&&(s?s(n,e):i(n,"stack",r(t,l)))}},function(n,e,t){var i=t(2),r=Error,a=i("".replace),s=String(r("zxcasd").stack),l=/\n\s*at [^:]*:[^\n]*/,o=l.test(s);n.exports=function(n,e){if(o&&"string"==typeof n&&!r.prepareStackTrace)for(;e--;)n=a(n,l,"");return n}},function(n,e,t){var i=t(3),r=t(36);n.exports=!i((function(){var n=Error("a");return!("stack"in n)||(Object.defineProperty(n,"stack",r(1,7)),7!==n.stack)}))},function(n,e,t){var i=t(69),r=t(148);n.exports=function n(e,t,a,s,l){var o=-1,d=e.length;for(a||(a=r),l||(l=[]);++o<d;){var c=e[o];t>0&&a(c)?t>1?n(c,t-1,a,s,l):i(l,c):s||(l[l.length]=c)}return l}},function(n,e,t){var i=t(16),r=t(39),a=t(6),s=i?i.isConcatSpreadable:void 0;n.exports=function(n){return a(n)||r(n)||!!(s&&n&&n[s])}},function(n,e,t){var i=t(14),r=t(12);n.exports=function(n){return r(n)&&"[object Arguments]"==i(n)}},function(n,e,t){var i=t(16),r=Object.prototype,a=r.hasOwnProperty,s=r.toString,l=i?i.toStringTag:void 0;n.exports=function(n){var e=a.call(n,l),t=n[l];try{n[l]=void 0;var i=!0}catch(n){}var r=s.call(n);return i&&(e?n[l]=t:delete n[l]),r}},function(n,e){var t=Object.prototype.toString;n.exports=function(n){return t.call(n)}},function(n,e,t){var i=t(153),r=t(209),a=t(47),s=t(6),l=t(220);n.exports=function(n){return"function"==typeof n?n:null==n?a:"object"==typeof n?s(n)?r(n[0],n[1]):i(n):l(n)}},function(n,e,t){var i=t(154),r=t(208),a=t(86);n.exports=function(n){var e=r(n);return 1==e.length&&e[0][2]?a(e[0][0],e[0][1]):function(t){return t===n||i(t,n,e)}}},function(n,e,t){var i=t(71),r=t(75);n.exports=function(n,e,t,a){var s=t.length,l=s,o=!a;if(null==n)return!l;for(n=Object(n);s--;){var d=t[s];if(o&&d[2]?d[1]!==n[d[0]]:!(d[0]in n))return!1}for(;++s<l;){var c=(d=t[s])[0],u=n[c],p=d[1];if(o&&d[2]){if(void 0===u&&!(c in n))return!1}else{var m=new i;if(a)var h=a(u,p,c,n,e,m);if(!(void 0===h?r(p,u,3,a,m):h))return!1}}return!0}},function(n,e){n.exports=function(){this.__data__=[],this.size=0}},function(n,e,t){var i=t(22),r=Array.prototype.splice;n.exports=function(n){var e=this.__data__,t=i(e,n);return!(t<0)&&(t==e.length-1?e.pop():r.call(e,t,1),--this.size,!0)}},function(n,e,t){var i=t(22);n.exports=function(n){var e=this.__data__,t=i(e,n);return t<0?void 0:e[t][1]}},function(n,e,t){var i=t(22);n.exports=function(n){return i(this.__data__,n)>-1}},function(n,e,t){var i=t(22);n.exports=function(n,e){var t=this.__data__,r=i(t,n);return r<0?(++this.size,t.push([n,e])):t[r][1]=e,this}},function(n,e,t){var i=t(21);n.exports=function(){this.__data__=new i,this.size=0}},function(n,e){n.exports=function(n){var e=this.__data__,t=e.delete(n);return this.size=e.size,t}},function(n,e){n.exports=function(n){return this.__data__.get(n)}},function(n,e){n.exports=function(n){return this.__data__.has(n)}},function(n,e,t){var i=t(21),r=t(40),a=t(42);n.exports=function(n,e){var t=this.__data__;if(t instanceof i){var s=t.__data__;if(!r||s.length<199)return s.push([n,e]),this.size=++t.size,this;t=this.__data__=new a(s)}return t.set(n,e),this.size=t.size,this}},function(n,e,t){var i=t(73),r=t(166),a=t(41),s=t(74),l=/^\[object .+?Constructor\]$/,o=Function.prototype,d=Object.prototype,c=o.toString,u=d.hasOwnProperty,p=RegExp("^"+c.call(u).replace(/[\\^$.*+?()[\]{}|]/g,"\\$&").replace(/hasOwnProperty|(function).*?(?=\\\()| for .+?(?=\\\])/g,"$1.*?")+"$");n.exports=function(n){return!(!a(n)||r(n))&&(i(n)?p:l).test(s(n))}},function(n,e,t){var i,r=t(167),a=(i=/[^.]+$/.exec(r&&r.keys&&r.keys.IE_PROTO||""))?"Symbol(src)_1."+i:"";n.exports=function(n){return!!a&&a in n}},function(n,e,t){var i=t(8)["__core-js_shared__"];n.exports=i},function(n,e){n.exports=function(n,e){return null==n?void 0:n[e]}},function(n,e,t){var i=t(170),r=t(21),a=t(40);n.exports=function(){this.size=0,this.__data__={hash:new i,map:new(a||r),string:new i}}},function(n,e,t){var i=t(171),r=t(172),a=t(173),s=t(174),l=t(175);function o(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var i=n[e];this.set(i[0],i[1])}}o.prototype.clear=i,o.prototype.delete=r,o.prototype.get=a,o.prototype.has=s,o.prototype.set=l,n.exports=o},function(n,e,t){var i=t(23);n.exports=function(){this.__data__=i?i(null):{},this.size=0}},function(n,e){n.exports=function(n){var e=this.has(n)&&delete this.__data__[n];return this.size-=e?1:0,e}},function(n,e,t){var i=t(23),r=Object.prototype.hasOwnProperty;n.exports=function(n){var e=this.__data__;if(i){var t=e[n];return"__lodash_hash_undefined__"===t?void 0:t}return r.call(e,n)?e[n]:void 0}},function(n,e,t){var i=t(23),r=Object.prototype.hasOwnProperty;n.exports=function(n){var e=this.__data__;return i?void 0!==e[n]:r.call(e,n)}},function(n,e,t){var i=t(23);n.exports=function(n,e){var t=this.__data__;return this.size+=this.has(n)?0:1,t[n]=i&&void 0===e?"__lodash_hash_undefined__":e,this}},function(n,e,t){var i=t(24);n.exports=function(n){var e=i(this,n).delete(n);return this.size-=e?1:0,e}},function(n,e){n.exports=function(n){var e=typeof n;return"string"==e||"number"==e||"symbol"==e||"boolean"==e?"__proto__"!==n:null===n}},function(n,e,t){var i=t(24);n.exports=function(n){return i(this,n).get(n)}},function(n,e,t){var i=t(24);n.exports=function(n){return i(this,n).has(n)}},function(n,e,t){var i=t(24);n.exports=function(n,e){var t=i(this,n),r=t.size;return t.set(n,e),this.size+=t.size==r?0:1,this}},function(n,e,t){var i=t(71),r=t(76),a=t(185),s=t(188),l=t(204),o=t(6),d=t(80),c=t(82),u="[object Object]",p=Object.prototype.hasOwnProperty;n.exports=function(n,e,t,m,h,g){var f=o(n),b=o(e),v=f?"[object Array]":l(n),y=b?"[object Array]":l(e),x=(v="[object Arguments]"==v?u:v)==u,k=(y="[object Arguments]"==y?u:y)==u,_=v==y;if(_&&d(n)){if(!d(e))return!1;f=!0,x=!1}if(_&&!x)return g||(g=new i),f||c(n)?r(n,e,t,m,h,g):a(n,e,v,t,m,h,g);if(!(1&t)){var E=x&&p.call(n,"__wrapped__"),S=k&&p.call(e,"__wrapped__");if(E||S){var R=E?n.value():n,T=S?e.value():e;return g||(g=new i),h(R,T,t,m,g)}}return!!_&&(g||(g=new i),s(n,e,t,m,h,g))}},function(n,e){n.exports=function(n){return this.__data__.set(n,"__lodash_hash_undefined__"),this}},function(n,e){n.exports=function(n){return this.__data__.has(n)}},function(n,e){n.exports=function(n,e){for(var t=-1,i=null==n?0:n.length;++t<i;)if(e(n[t],t,n))return!0;return!1}},function(n,e,t){var i=t(16),r=t(186),a=t(72),s=t(76),l=t(187),o=t(43),d=i?i.prototype:void 0,c=d?d.valueOf:void 0;n.exports=function(n,e,t,i,d,u,p){switch(t){case"[object DataView]":if(n.byteLength!=e.byteLength||n.byteOffset!=e.byteOffset)return!1;n=n.buffer,e=e.buffer;case"[object ArrayBuffer]":return!(n.byteLength!=e.byteLength||!u(new r(n),new r(e)));case"[object Boolean]":case"[object Date]":case"[object Number]":return a(+n,+e);case"[object Error]":return n.name==e.name&&n.message==e.message;case"[object RegExp]":case"[object String]":return n==e+"";case"[object Map]":var m=l;case"[object Set]":var h=1&i;if(m||(m=o),n.size!=e.size&&!h)return!1;var g=p.get(n);if(g)return g==e;i|=2,p.set(n,e);var f=s(m(n),m(e),i,d,u,p);return p.delete(n),f;case"[object Symbol]":if(c)return c.call(n)==c.call(e)}return!1}},function(n,e,t){var i=t(8).Uint8Array;n.exports=i},function(n,e){n.exports=function(n){var e=-1,t=Array(n.size);return n.forEach((function(n,i){t[++e]=[i,n]})),t}},function(n,e,t){var i=t(189),r=Object.prototype.hasOwnProperty;n.exports=function(n,e,t,a,s,l){var o=1&t,d=i(n),c=d.length;if(c!=i(e).length&&!o)return!1;for(var u=c;u--;){var p=d[u];if(!(o?p in e:r.call(e,p)))return!1}var m=l.get(n),h=l.get(e);if(m&&h)return m==e&&h==n;var g=!0;l.set(n,e),l.set(e,n);for(var f=o;++u<c;){var b=n[p=d[u]],v=e[p];if(a)var y=o?a(v,b,p,e,n,l):a(b,v,p,n,e,l);if(!(void 0===y?b===v||s(b,v,t,a,l):y)){g=!1;break}f||(f="constructor"==p)}if(g&&!f){var x=n.constructor,k=e.constructor;x==k||!("constructor"in n)||!("constructor"in e)||"function"==typeof x&&x instanceof x&&"function"==typeof k&&k instanceof k||(g=!1)}return l.delete(n),l.delete(e),g}},function(n,e,t){var i=t(190),r=t(191),a=t(79);n.exports=function(n){return i(n,a,r)}},function(n,e,t){var i=t(69),r=t(6);n.exports=function(n,e,t){var a=e(n);return r(n)?a:i(a,t(n))}},function(n,e,t){var i=t(192),r=t(193),a=Object.prototype.propertyIsEnumerable,s=Object.getOwnPropertySymbols,l=s?function(n){return null==n?[]:(n=Object(n),i(s(n),(function(e){return a.call(n,e)})))}:r;n.exports=l},function(n,e){n.exports=function(n,e){for(var t=-1,i=null==n?0:n.length,r=0,a=[];++t<i;){var s=n[t];e(s,t,n)&&(a[r++]=s)}return a}},function(n,e){n.exports=function(){return[]}},function(n,e,t){var i=t(195),r=t(39),a=t(6),s=t(80),l=t(81),o=t(82),d=Object.prototype.hasOwnProperty;n.exports=function(n,e){var t=a(n),c=!t&&r(n),u=!t&&!c&&s(n),p=!t&&!c&&!u&&o(n),m=t||c||u||p,h=m?i(n.length,String):[],g=h.length;for(var f in n)!e&&!d.call(n,f)||m&&("length"==f||u&&("offset"==f||"parent"==f)||p&&("buffer"==f||"byteLength"==f||"byteOffset"==f)||l(f,g))||h.push(f);return h}},function(n,e){n.exports=function(n,e){for(var t=-1,i=Array(n);++t<n;)i[t]=e(t);return i}},function(n,e){n.exports=function(){return!1}},function(n,e,t){var i=t(14),r=t(44),a=t(12),s={};s["[object Float32Array]"]=s["[object Float64Array]"]=s["[object Int8Array]"]=s["[object Int16Array]"]=s["[object Int32Array]"]=s["[object Uint8Array]"]=s["[object Uint8ClampedArray]"]=s["[object Uint16Array]"]=s["[object Uint32Array]"]=!0,s["[object Arguments]"]=s["[object Array]"]=s["[object ArrayBuffer]"]=s["[object Boolean]"]=s["[object DataView]"]=s["[object Date]"]=s["[object Error]"]=s["[object Function]"]=s["[object Map]"]=s["[object Number]"]=s["[object Object]"]=s["[object RegExp]"]=s["[object Set]"]=s["[object String]"]=s["[object WeakMap]"]=!1,n.exports=function(n){return a(n)&&r(n.length)&&!!s[i(n)]}},function(n,e){n.exports=function(n){return function(e){return n(e)}}},function(n,e,t){(function(n){var i=t(70),r=e&&!e.nodeType&&e,a=r&&"object"==typeof n&&n&&!n.nodeType&&n,s=a&&a.exports===r&&i.process,l=function(){try{var n=a&&a.require&&a.require("util").types;return n||s&&s.binding&&s.binding("util")}catch(n){}}();n.exports=l}).call(this,t(50)(n))},function(n,e,t){var i=t(201),r=t(202),a=Object.prototype.hasOwnProperty;n.exports=function(n){if(!i(n))return r(n);var e=[];for(var t in Object(n))a.call(n,t)&&"constructor"!=t&&e.push(t);return e}},function(n,e){var t=Object.prototype;n.exports=function(n){var e=n&&n.constructor;return n===("function"==typeof e&&e.prototype||t)}},function(n,e,t){var i=t(203)(Object.keys,Object);n.exports=i},function(n,e){n.exports=function(n,e){return function(t){return n(e(t))}}},function(n,e,t){var i=t(205),r=t(40),a=t(206),s=t(84),l=t(207),o=t(14),d=t(74),c=d(i),u=d(r),p=d(a),m=d(s),h=d(l),g=o;(i&&"[object DataView]"!=g(new i(new ArrayBuffer(1)))||r&&"[object Map]"!=g(new r)||a&&"[object Promise]"!=g(a.resolve())||s&&"[object Set]"!=g(new s)||l&&"[object WeakMap]"!=g(new l))&&(g=function(n){var e=o(n),t="[object Object]"==e?n.constructor:void 0,i=t?d(t):"";if(i)switch(i){case c:return"[object DataView]";case u:return"[object Map]";case p:return"[object Promise]";case m:return"[object Set]";case h:return"[object WeakMap]"}return e}),n.exports=g},function(n,e,t){var i=t(10)(t(8),"DataView");n.exports=i},function(n,e,t){var i=t(10)(t(8),"Promise");n.exports=i},function(n,e,t){var i=t(10)(t(8),"WeakMap");n.exports=i},function(n,e,t){var i=t(85),r=t(79);n.exports=function(n){for(var e=r(n),t=e.length;t--;){var a=e[t],s=n[a];e[t]=[a,s,i(s)]}return e}},function(n,e,t){var i=t(75),r=t(210),a=t(217),s=t(45),l=t(85),o=t(86),d=t(25);n.exports=function(n,e){return s(n)&&l(e)?o(d(n),e):function(t){var s=r(t,n);return void 0===s&&s===e?a(t,n):i(e,s,3)}}},function(n,e,t){var i=t(87);n.exports=function(n,e,t){var r=null==n?void 0:i(n,e);return void 0===r?t:r}},function(n,e,t){var i=t(212),r=/[^.[\]]+|\[(?:(-?\d+(?:\.\d+)?)|(["'])((?:(?!\2)[^\\]|\\.)*?)\2)\]|(?=(?:\.|\[\])(?:\.|\[\]|$))/g,a=/\\(\\)?/g,s=i((function(n){var e=[];return 46===n.charCodeAt(0)&&e.push(""),n.replace(r,(function(n,t,i,r){e.push(i?r.replace(a,"$1"):t||n)})),e}));n.exports=s},function(n,e,t){var i=t(213);n.exports=function(n){var e=i(n,(function(n){return 500===t.size&&t.clear(),n})),t=e.cache;return e}},function(n,e,t){var i=t(42);function r(n,e){if("function"!=typeof n||null!=e&&"function"!=typeof e)throw new TypeError("Expected a function");var t=function(){var i=arguments,r=e?e.apply(this,i):i[0],a=t.cache;if(a.has(r))return a.get(r);var s=n.apply(this,i);return t.cache=a.set(r,s)||a,s};return t.cache=new(r.Cache||i),t}r.Cache=i,n.exports=r},function(n,e,t){var i=t(215);n.exports=function(n){return null==n?"":i(n)}},function(n,e,t){var i=t(16),r=t(216),a=t(6),s=t(46),l=i?i.prototype:void 0,o=l?l.toString:void 0;n.exports=function n(e){if("string"==typeof e)return e;if(a(e))return r(e,n)+"";if(s(e))return o?o.call(e):"";var t=e+"";return"0"==t&&1/e==-1/0?"-0":t}},function(n,e){n.exports=function(n,e){for(var t=-1,i=null==n?0:n.length,r=Array(i);++t<i;)r[t]=e(n[t],t,n);return r}},function(n,e,t){var i=t(218),r=t(219);n.exports=function(n,e){return null!=n&&r(n,e,i)}},function(n,e){n.exports=function(n,e){return null!=n&&e in Object(n)}},function(n,e,t){var i=t(88),r=t(39),a=t(6),s=t(81),l=t(44),o=t(25);n.exports=function(n,e,t){for(var d=-1,c=(e=i(e,n)).length,u=!1;++d<c;){var p=o(e[d]);if(!(u=null!=n&&t(n,p)))break;n=n[p]}return u||++d!=c?u:!!(c=null==n?0:n.length)&&l(c)&&s(p,c)&&(a(n)||r(n))}},function(n,e,t){var i=t(221),r=t(222),a=t(45),s=t(25);n.exports=function(n){return a(n)?i(s(n)):r(n)}},function(n,e){n.exports=function(n){return function(e){return null==e?void 0:e[n]}}},function(n,e,t){var i=t(87);n.exports=function(n){return function(e){return i(e,n)}}},function(n,e,t){var i=t(47),r=t(224),a=t(226);n.exports=function(n,e){return a(r(n,e,i),n+"")}},function(n,e,t){var i=t(225),r=Math.max;n.exports=function(n,e,t){return e=r(void 0===e?n.length-1:e,0),function(){for(var a=arguments,s=-1,l=r(a.length-e,0),o=Array(l);++s<l;)o[s]=a[e+s];s=-1;for(var d=Array(e+1);++s<e;)d[s]=a[s];return d[e]=t(o),i(n,this,d)}}},function(n,e){n.exports=function(n,e,t){switch(t.length){case 0:return n.call(e);case 1:return n.call(e,t[0]);case 2:return n.call(e,t[0],t[1]);case 3:return n.call(e,t[0],t[1],t[2])}return n.apply(e,t)}},function(n,e,t){var i=t(227),r=t(230)(i);n.exports=r},function(n,e,t){var i=t(228),r=t(229),a=t(47),s=r?function(n,e){return r(n,"toString",{configurable:!0,enumerable:!1,value:i(e),writable:!0})}:a;n.exports=s},function(n,e){n.exports=function(n){return function(){return n}}},function(n,e,t){var i=t(10),r=function(){try{var n=i(Object,"defineProperty");return n({},"",{}),n}catch(n){}}();n.exports=r},function(n,e){var t=Date.now;n.exports=function(n){var e=0,i=0;return function(){var r=t(),a=16-(r-i);if(i=r,a>0){if(++e>=800)return arguments[0]}else e=0;return n.apply(void 0,arguments)}}},function(n,e,t){var i=t(77),r=t(232),a=t(237),s=t(78),l=t(238),o=t(43);n.exports=function(n,e,t){var d=-1,c=r,u=n.length,p=!0,m=[],h=m;if(t)p=!1,c=a;else if(u>=200){var g=e?null:l(n);if(g)return o(g);p=!1,c=s,h=new i}else h=e?[]:m;n:for(;++d<u;){var f=n[d],b=e?e(f):f;if(f=t||0!==f?f:0,p&&b==b){for(var v=h.length;v--;)if(h[v]===b)continue n;e&&h.push(b),m.push(f)}else c(h,b,t)||(h!==m&&h.push(b),m.push(f))}return m}},function(n,e,t){var i=t(233);n.exports=function(n,e){return!!(null==n?0:n.length)&&i(n,e,0)>-1}},function(n,e,t){var i=t(234),r=t(235),a=t(236);n.exports=function(n,e,t){return e==e?a(n,e,t):i(n,r,t)}},function(n,e){n.exports=function(n,e,t,i){for(var r=n.length,a=t+(i?1:-1);i?a--:++a<r;)if(e(n[a],a,n))return a;return-1}},function(n,e){n.exports=function(n){return n!=n}},function(n,e){n.exports=function(n,e,t){for(var i=t-1,r=n.length;++i<r;)if(n[i]===e)return i;return-1}},function(n,e){n.exports=function(n,e,t){for(var i=-1,r=null==n?0:n.length;++i<r;)if(t(e,n[i]))return!0;return!1}},function(n,e,t){var i=t(84),r=t(239),a=t(43),s=i&&1/a(new i([,-0]))[1]==1/0?function(n){return new i(n)}:r;n.exports=s},function(n,e){n.exports=function(){}},function(n,e,t){var i=t(83),r=t(12);n.exports=function(n){return r(n)&&i(n)}},function(n,e,t){},function(n,e,t){},function(n,e,t){"use strict";t(89)},function(n,e,t){"use strict";t(90)},function(n,e,t){},function(n,e,t){},function(n,e,t){var i=t(18),r=t(1),a=t(248);i({global:!0},{Reflect:{}}),a(r.Reflect,"Reflect",!0)},function(n,e,t){var i=t(13).f,r=t(7),a=t(20)("toStringTag");n.exports=function(n,e,t){n&&!t&&(n=n.prototype),n&&!r(n,a)&&i(n,a,{configurable:!0,value:e})}},function(n,e){},function(n,e){function t(n,e){for(var t=0,i=n.length-1;i>=0;i--){var r=n[i];"."===r?n.splice(i,1):".."===r?(n.splice(i,1),t++):t&&(n.splice(i,1),t--)}if(e)for(;t--;t)n.unshift("..");return n}function i(n,e){if(n.filter)return n.filter(e);for(var t=[],i=0;i<n.length;i++)e(n[i],i,n)&&t.push(n[i]);return t}e.resolve=function(){for(var n="",e=!1,r=arguments.length-1;r>=-1&&!e;r--){var a=r>=0?arguments[r]:process.cwd();if("string"!=typeof a)throw new TypeError("Arguments to path.resolve must be strings");a&&(n=a+"/"+n,e="/"===a.charAt(0))}return(e?"/":"")+(n=t(i(n.split("/"),(function(n){return!!n})),!e).join("/"))||"."},e.normalize=function(n){var a=e.isAbsolute(n),s="/"===r(n,-1);return(n=t(i(n.split("/"),(function(n){return!!n})),!a).join("/"))||a||(n="."),n&&s&&(n+="/"),(a?"/":"")+n},e.isAbsolute=function(n){return"/"===n.charAt(0)},e.join=function(){var n=Array.prototype.slice.call(arguments,0);return e.normalize(i(n,(function(n,e){if("string"!=typeof n)throw new TypeError("Arguments to path.join must be strings");return n})).join("/"))},e.relative=function(n,t){function i(n){for(var e=0;e<n.length&&""===n[e];e++);for(var t=n.length-1;t>=0&&""===n[t];t--);return e>t?[]:n.slice(e,t-e+1)}n=e.resolve(n).substr(1),t=e.resolve(t).substr(1);for(var r=i(n.split("/")),a=i(t.split("/")),s=Math.min(r.length,a.length),l=s,o=0;o<s;o++)if(r[o]!==a[o]){l=o;break}var d=[];for(o=l;o<r.length;o++)d.push("..");return(d=d.concat(a.slice(l))).join("/")},e.sep="/",e.delimiter=":",e.dirname=function(n){if("string"!=typeof n&&(n+=""),0===n.length)return".";for(var e=n.charCodeAt(0),t=47===e,i=-1,r=!0,a=n.length-1;a>=1;--a)if(47===(e=n.charCodeAt(a))){if(!r){i=a;break}}else r=!1;return-1===i?t?"/":".":t&&1===i?"/":n.slice(0,i)},e.basename=function(n,e){var t=function(n){"string"!=typeof n&&(n+="");var e,t=0,i=-1,r=!0;for(e=n.length-1;e>=0;--e)if(47===n.charCodeAt(e)){if(!r){t=e+1;break}}else-1===i&&(r=!1,i=e+1);return-1===i?"":n.slice(t,i)}(n);return e&&t.substr(-1*e.length)===e&&(t=t.substr(0,t.length-e.length)),t},e.extname=function(n){"string"!=typeof n&&(n+="");for(var e=-1,t=0,i=-1,r=!0,a=0,s=n.length-1;s>=0;--s){var l=n.charCodeAt(s);if(47!==l)-1===i&&(r=!1,i=s+1),46===l?-1===e?e=s:1!==a&&(a=1):-1!==e&&(a=-1);else if(!r){t=s+1;break}}return-1===e||-1===i||0===a||1===a&&e===i-1&&e===t+1?"":n.slice(e,i)};var r="b"==="ab".substr(-1)?function(n,e,t){return n.substr(e,t)}:function(n,e,t){return e<0&&(e=n.length+e),n.substr(e,t)}},function(n,e,t){"use strict";var i=/[|\\{}()[\]^$+*?.]/g;e.escapeRegExpChars=function(n){return n?String(n).replace(i,"\\$&"):""};var r={"&":"&amp;","<":"&lt;",">":"&gt;",'"':"&#34;","'":"&#39;"},a=/[&<>'"]/g;function s(n){return r[n]||n}e.escapeXML=function(n){return null==n?"":String(n).replace(a,s)},e.escapeXML.toString=function(){return Function.prototype.toString.call(this)+';\nvar _ENCODE_HTML_RULES = {\n      "&": "&amp;"\n    , "<": "&lt;"\n    , ">": "&gt;"\n    , \'"\': "&#34;"\n    , "\'": "&#39;"\n    }\n  , _MATCH_HTML = /[&<>\'"]/g;\nfunction encode_char(c) {\n  return _ENCODE_HTML_RULES[c] || c;\n};\n'},e.shallowCopy=function(n,e){for(var t in e=e||{})n[t]=e[t];return n},e.shallowCopyFromList=function(n,e,t){for(var i=0;i<t.length;i++){var r=t[i];void 0!==e[r]&&(n[r]=e[r])}return n},e.cache={_data:{},set:function(n,e){this._data[n]=e},get:function(n){return this._data[n]},remove:function(n){delete this._data[n]},reset:function(){this._data={}}}},function(n){n.exports=JSON.parse('{"name":"ejs","description":"Embedded JavaScript templates","keywords":["template","engine","ejs"],"version":"2.7.4","author":"Matthew Eernisse <mde@fleegix.org> (http://fleegix.org)","license":"Apache-2.0","main":"./lib/ejs.js","repository":{"type":"git","url":"git://github.com/mde/ejs.git"},"bugs":"https://github.com/mde/ejs/issues","homepage":"https://github.com/mde/ejs","dependencies":{},"devDependencies":{"browserify":"^13.1.1","eslint":"^4.14.0","git-directory-deploy":"^1.5.1","jake":"^10.3.1","jsdoc":"^3.4.0","lru-cache":"^4.0.1","mocha":"^5.0.5","uglify-js":"^3.3.16"},"engines":{"node":">=0.10.0"},"scripts":{"test":"mocha","postinstall":"node ./postinstall.js"}}')},function(n,e,t){"use strict";t(91)},function(n,e,t){"use strict";t(92)},function(n,e,t){"use strict";t.r(e);
/*!
 * Vue.js v2.7.14
 * (c) 2014-2022 Evan You
 * Released under the MIT License.
 */
var i=Object.freeze({}),r=Array.isArray;function a(n){return null==n}function s(n){return null!=n}function l(n){return!0===n}function o(n){return"string"==typeof n||"number"==typeof n||"symbol"==typeof n||"boolean"==typeof n}function d(n){return"function"==typeof n}function c(n){return null!==n&&"object"==typeof n}var u=Object.prototype.toString;function p(n){return"[object Object]"===u.call(n)}function m(n){return"[object RegExp]"===u.call(n)}function h(n){var e=parseFloat(String(n));return e>=0&&Math.floor(e)===e&&isFinite(n)}function g(n){return s(n)&&"function"==typeof n.then&&"function"==typeof n.catch}function f(n){return null==n?"":Array.isArray(n)||p(n)&&n.toString===u?JSON.stringify(n,null,2):String(n)}function b(n){var e=parseFloat(n);return isNaN(e)?n:e}function v(n,e){for(var t=Object.create(null),i=n.split(","),r=0;r<i.length;r++)t[i[r]]=!0;return e?function(n){return t[n.toLowerCase()]}:function(n){return t[n]}}v("slot,component",!0);var y=v("key,ref,slot,slot-scope,is");function x(n,e){var t=n.length;if(t){if(e===n[t-1])return void(n.length=t-1);var i=n.indexOf(e);if(i>-1)return n.splice(i,1)}}var k=Object.prototype.hasOwnProperty;function _(n,e){return k.call(n,e)}function E(n){var e=Object.create(null);return function(t){return e[t]||(e[t]=n(t))}}var S=/-(\w)/g,R=E((function(n){return n.replace(S,(function(n,e){return e?e.toUpperCase():""}))})),T=E((function(n){return n.charAt(0).toUpperCase()+n.slice(1)})),w=/\B([A-Z])/g,I=E((function(n){return n.replace(w,"-$1").toLowerCase()}));var A=Function.prototype.bind?function(n,e){return n.bind(e)}:function(n,e){function t(t){var i=arguments.length;return i?i>1?n.apply(e,arguments):n.call(e,t):n.call(e)}return t._length=n.length,t};function L(n,e){e=e||0;for(var t=n.length-e,i=new Array(t);t--;)i[t]=n[t+e];return i}function B(n,e){for(var t in e)n[t]=e[t];return n}function C(n){for(var e={},t=0;t<n.length;t++)n[t]&&B(e,n[t]);return e}function z(n,e,t){}var D=function(n,e,t){return!1},P=function(n){return n};function O(n,e){if(n===e)return!0;var t=c(n),i=c(e);if(!t||!i)return!t&&!i&&String(n)===String(e);try{var r=Array.isArray(n),a=Array.isArray(e);if(r&&a)return n.length===e.length&&n.every((function(n,t){return O(n,e[t])}));if(n instanceof Date&&e instanceof Date)return n.getTime()===e.getTime();if(r||a)return!1;var s=Object.keys(n),l=Object.keys(e);return s.length===l.length&&s.every((function(t){return O(n[t],e[t])}))}catch(n){return!1}}function M(n,e){for(var t=0;t<n.length;t++)if(O(n[t],e))return t;return-1}function j(n){var e=!1;return function(){e||(e=!0,n.apply(this,arguments))}}function U(n,e){return n===e?0===n&&1/n!=1/e:n==n||e==e}var $=["component","directive","filter"],F=["beforeCreate","created","beforeMount","mounted","beforeUpdate","updated","beforeDestroy","destroyed","activated","deactivated","errorCaptured","serverPrefetch","renderTracked","renderTriggered"],N={optionMergeStrategies:Object.create(null),silent:!1,productionTip:!1,devtools:!1,performance:!1,errorHandler:null,warnHandler:null,ignoredElements:[],keyCodes:Object.create(null),isReservedTag:D,isReservedAttr:D,isUnknownElement:D,getTagNamespace:z,parsePlatformTagName:P,mustUseProp:D,async:!0,_lifecycleHooks:F},q=/a-zA-Z\u00B7\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u037D\u037F-\u1FFF\u200C-\u200D\u203F-\u2040\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD/;function G(n){var e=(n+"").charCodeAt(0);return 36===e||95===e}function K(n,e,t,i){Object.defineProperty(n,e,{value:t,enumerable:!!i,writable:!0,configurable:!0})}var H=new RegExp("[^".concat(q.source,".$_\\d]"));var J="__proto__"in{},V="undefined"!=typeof window,Q=V&&window.navigator.userAgent.toLowerCase(),X=Q&&/msie|trident/.test(Q),W=Q&&Q.indexOf("msie 9.0")>0,Y=Q&&Q.indexOf("edge/")>0;Q&&Q.indexOf("android");var Z=Q&&/iphone|ipad|ipod|ios/.test(Q);Q&&/chrome\/\d+/.test(Q),Q&&/phantomjs/.test(Q);var nn,en=Q&&Q.match(/firefox\/(\d+)/),tn={}.watch,rn=!1;if(V)try{var an={};Object.defineProperty(an,"passive",{get:function(){rn=!0}}),window.addEventListener("test-passive",null,an)}catch(n){}var sn=function(){return void 0===nn&&(nn=!V&&"undefined"!=typeof global&&(global.process&&"server"===global.process.env.VUE_ENV)),nn},ln=V&&window.__VUE_DEVTOOLS_GLOBAL_HOOK__;function on(n){return"function"==typeof n&&/native code/.test(n.toString())}var dn,cn="undefined"!=typeof Symbol&&on(Symbol)&&"undefined"!=typeof Reflect&&on(Reflect.ownKeys);dn="undefined"!=typeof Set&&on(Set)?Set:function(){function n(){this.set=Object.create(null)}return n.prototype.has=function(n){return!0===this.set[n]},n.prototype.add=function(n){this.set[n]=!0},n.prototype.clear=function(){this.set=Object.create(null)},n}();var un=null;function pn(n){void 0===n&&(n=null),n||un&&un._scope.off(),un=n,n&&n._scope.on()}var mn=function(){function n(n,e,t,i,r,a,s,l){this.tag=n,this.data=e,this.children=t,this.text=i,this.elm=r,this.ns=void 0,this.context=a,this.fnContext=void 0,this.fnOptions=void 0,this.fnScopeId=void 0,this.key=e&&e.key,this.componentOptions=s,this.componentInstance=void 0,this.parent=void 0,this.raw=!1,this.isStatic=!1,this.isRootInsert=!0,this.isComment=!1,this.isCloned=!1,this.isOnce=!1,this.asyncFactory=l,this.asyncMeta=void 0,this.isAsyncPlaceholder=!1}return Object.defineProperty(n.prototype,"child",{get:function(){return this.componentInstance},enumerable:!1,configurable:!0}),n}(),hn=function(n){void 0===n&&(n="");var e=new mn;return e.text=n,e.isComment=!0,e};function gn(n){return new mn(void 0,void 0,void 0,String(n))}function fn(n){var e=new mn(n.tag,n.data,n.children&&n.children.slice(),n.text,n.elm,n.context,n.componentOptions,n.asyncFactory);return e.ns=n.ns,e.isStatic=n.isStatic,e.key=n.key,e.isComment=n.isComment,e.fnContext=n.fnContext,e.fnOptions=n.fnOptions,e.fnScopeId=n.fnScopeId,e.asyncMeta=n.asyncMeta,e.isCloned=!0,e}var bn=0,vn=[],yn=function(){function n(){this._pending=!1,this.id=bn++,this.subs=[]}return n.prototype.addSub=function(n){this.subs.push(n)},n.prototype.removeSub=function(n){this.subs[this.subs.indexOf(n)]=null,this._pending||(this._pending=!0,vn.push(this))},n.prototype.depend=function(e){n.target&&n.target.addDep(this)},n.prototype.notify=function(n){var e=this.subs.filter((function(n){return n}));for(var t=0,i=e.length;t<i;t++){0,e[t].update()}},n}();yn.target=null;var xn=[];function kn(n){xn.push(n),yn.target=n}function _n(){xn.pop(),yn.target=xn[xn.length-1]}var En=Array.prototype,Sn=Object.create(En);["push","pop","shift","unshift","splice","sort","reverse"].forEach((function(n){var e=En[n];K(Sn,n,(function(){for(var t=[],i=0;i<arguments.length;i++)t[i]=arguments[i];var r,a=e.apply(this,t),s=this.__ob__;switch(n){case"push":case"unshift":r=t;break;case"splice":r=t.slice(2)}return r&&s.observeArray(r),s.dep.notify(),a}))}));var Rn=Object.getOwnPropertyNames(Sn),Tn={},wn=!0;function In(n){wn=n}var An={notify:z,depend:z,addSub:z,removeSub:z},Ln=function(){function n(n,e,t){if(void 0===e&&(e=!1),void 0===t&&(t=!1),this.value=n,this.shallow=e,this.mock=t,this.dep=t?An:new yn,this.vmCount=0,K(n,"__ob__",this),r(n)){if(!t)if(J)n.__proto__=Sn;else for(var i=0,a=Rn.length;i<a;i++){K(n,l=Rn[i],Sn[l])}e||this.observeArray(n)}else{var s=Object.keys(n);for(i=0;i<s.length;i++){var l;Cn(n,l=s[i],Tn,void 0,e,t)}}}return n.prototype.observeArray=function(n){for(var e=0,t=n.length;e<t;e++)Bn(n[e],!1,this.mock)},n}();function Bn(n,e,t){return n&&_(n,"__ob__")&&n.__ob__ instanceof Ln?n.__ob__:!wn||!t&&sn()||!r(n)&&!p(n)||!Object.isExtensible(n)||n.__v_skip||Un(n)||n instanceof mn?void 0:new Ln(n,e,t)}function Cn(n,e,t,i,a,s){var l=new yn,o=Object.getOwnPropertyDescriptor(n,e);if(!o||!1!==o.configurable){var d=o&&o.get,c=o&&o.set;d&&!c||t!==Tn&&2!==arguments.length||(t=n[e]);var u=!a&&Bn(t,!1,s);return Object.defineProperty(n,e,{enumerable:!0,configurable:!0,get:function(){var e=d?d.call(n):t;return yn.target&&(l.depend(),u&&(u.dep.depend(),r(e)&&Pn(e))),Un(e)&&!a?e.value:e},set:function(e){var i=d?d.call(n):t;if(U(i,e)){if(c)c.call(n,e);else{if(d)return;if(!a&&Un(i)&&!Un(e))return void(i.value=e);t=e}u=!a&&Bn(e,!1,s),l.notify()}}}),l}}function zn(n,e,t){if(!jn(n)){var i=n.__ob__;return r(n)&&h(e)?(n.length=Math.max(n.length,e),n.splice(e,1,t),i&&!i.shallow&&i.mock&&Bn(t,!1,!0),t):e in n&&!(e in Object.prototype)?(n[e]=t,t):n._isVue||i&&i.vmCount?t:i?(Cn(i.value,e,t,void 0,i.shallow,i.mock),i.dep.notify(),t):(n[e]=t,t)}}function Dn(n,e){if(r(n)&&h(e))n.splice(e,1);else{var t=n.__ob__;n._isVue||t&&t.vmCount||jn(n)||_(n,e)&&(delete n[e],t&&t.dep.notify())}}function Pn(n){for(var e=void 0,t=0,i=n.length;t<i;t++)(e=n[t])&&e.__ob__&&e.__ob__.dep.depend(),r(e)&&Pn(e)}function On(n){return Mn(n,!0),K(n,"__v_isShallow",!0),n}function Mn(n,e){if(!jn(n)){Bn(n,e,sn());0}}function jn(n){return!(!n||!n.__v_isReadonly)}function Un(n){return!(!n||!0!==n.__v_isRef)}function $n(n,e,t){Object.defineProperty(n,t,{enumerable:!0,configurable:!0,get:function(){var n=e[t];if(Un(n))return n.value;var i=n&&n.__ob__;return i&&i.dep.depend(),n},set:function(n){var i=e[t];Un(i)&&!Un(n)?i.value=n:e[t]=n}})}"".concat("watcher"," callback"),"".concat("watcher"," getter"),"".concat("watcher"," cleanup");var Fn;var Nn=function(){function n(n){void 0===n&&(n=!1),this.detached=n,this.active=!0,this.effects=[],this.cleanups=[],this.parent=Fn,!n&&Fn&&(this.index=(Fn.scopes||(Fn.scopes=[])).push(this)-1)}return n.prototype.run=function(n){if(this.active){var e=Fn;try{return Fn=this,n()}finally{Fn=e}}else 0},n.prototype.on=function(){Fn=this},n.prototype.off=function(){Fn=this.parent},n.prototype.stop=function(n){if(this.active){var e=void 0,t=void 0;for(e=0,t=this.effects.length;e<t;e++)this.effects[e].teardown();for(e=0,t=this.cleanups.length;e<t;e++)this.cleanups[e]();if(this.scopes)for(e=0,t=this.scopes.length;e<t;e++)this.scopes[e].stop(!0);if(!this.detached&&this.parent&&!n){var i=this.parent.scopes.pop();i&&i!==this&&(this.parent.scopes[this.index]=i,i.index=this.index)}this.parent=void 0,this.active=!1}},n}();function qn(n){var e=n._provided,t=n.$parent&&n.$parent._provided;return t===e?n._provided=Object.create(t):e}var Gn=E((function(n){var e="&"===n.charAt(0),t="~"===(n=e?n.slice(1):n).charAt(0),i="!"===(n=t?n.slice(1):n).charAt(0);return{name:n=i?n.slice(1):n,once:t,capture:i,passive:e}}));function Kn(n,e){function t(){var n=t.fns;if(!r(n))return we(n,null,arguments,e,"v-on handler");for(var i=n.slice(),a=0;a<i.length;a++)we(i[a],null,arguments,e,"v-on handler")}return t.fns=n,t}function Hn(n,e,t,i,r,s){var o,d,c,u;for(o in n)d=n[o],c=e[o],u=Gn(o),a(d)||(a(c)?(a(d.fns)&&(d=n[o]=Kn(d,s)),l(u.once)&&(d=n[o]=r(u.name,d,u.capture)),t(u.name,d,u.capture,u.passive,u.params)):d!==c&&(c.fns=d,n[o]=c));for(o in e)a(n[o])&&i((u=Gn(o)).name,e[o],u.capture)}function Jn(n,e,t){var i;n instanceof mn&&(n=n.data.hook||(n.data.hook={}));var r=n[e];function o(){t.apply(this,arguments),x(i.fns,o)}a(r)?i=Kn([o]):s(r.fns)&&l(r.merged)?(i=r).fns.push(o):i=Kn([r,o]),i.merged=!0,n[e]=i}function Vn(n,e,t,i,r){if(s(e)){if(_(e,t))return n[t]=e[t],r||delete e[t],!0;if(_(e,i))return n[t]=e[i],r||delete e[i],!0}return!1}function Qn(n){return o(n)?[gn(n)]:r(n)?function n(e,t){var i,d,c,u,p=[];for(i=0;i<e.length;i++)a(d=e[i])||"boolean"==typeof d||(c=p.length-1,u=p[c],r(d)?d.length>0&&(Xn((d=n(d,"".concat(t||"","_").concat(i)))[0])&&Xn(u)&&(p[c]=gn(u.text+d[0].text),d.shift()),p.push.apply(p,d)):o(d)?Xn(u)?p[c]=gn(u.text+d):""!==d&&p.push(gn(d)):Xn(d)&&Xn(u)?p[c]=gn(u.text+d.text):(l(e._isVList)&&s(d.tag)&&a(d.key)&&s(t)&&(d.key="__vlist".concat(t,"_").concat(i,"__")),p.push(d)));return p}(n):void 0}function Xn(n){return s(n)&&s(n.text)&&!1===n.isComment}function Wn(n,e){var t,i,a,l,o=null;if(r(n)||"string"==typeof n)for(o=new Array(n.length),t=0,i=n.length;t<i;t++)o[t]=e(n[t],t);else if("number"==typeof n)for(o=new Array(n),t=0;t<n;t++)o[t]=e(t+1,t);else if(c(n))if(cn&&n[Symbol.iterator]){o=[];for(var d=n[Symbol.iterator](),u=d.next();!u.done;)o.push(e(u.value,o.length)),u=d.next()}else for(a=Object.keys(n),o=new Array(a.length),t=0,i=a.length;t<i;t++)l=a[t],o[t]=e(n[l],l,t);return s(o)||(o=[]),o._isVList=!0,o}function Yn(n,e,t,i){var r,a=this.$scopedSlots[n];a?(t=t||{},i&&(t=B(B({},i),t)),r=a(t)||(d(e)?e():e)):r=this.$slots[n]||(d(e)?e():e);var s=t&&t.slot;return s?this.$createElement("template",{slot:s},r):r}function Zn(n){return Lt(this.$options,"filters",n,!0)||P}function ne(n,e){return r(n)?-1===n.indexOf(e):n!==e}function ee(n,e,t,i,r){var a=N.keyCodes[e]||t;return r&&i&&!N.keyCodes[e]?ne(r,i):a?ne(a,n):i?I(i)!==e:void 0===n}function te(n,e,t,i,a){if(t)if(c(t)){r(t)&&(t=C(t));var s=void 0,l=function(r){if("class"===r||"style"===r||y(r))s=n;else{var l=n.attrs&&n.attrs.type;s=i||N.mustUseProp(e,l,r)?n.domProps||(n.domProps={}):n.attrs||(n.attrs={})}var o=R(r),d=I(r);o in s||d in s||(s[r]=t[r],a&&((n.on||(n.on={}))["update:".concat(r)]=function(n){t[r]=n}))};for(var o in t)l(o)}else;return n}function ie(n,e){var t=this._staticTrees||(this._staticTrees=[]),i=t[n];return i&&!e||ae(i=t[n]=this.$options.staticRenderFns[n].call(this._renderProxy,this._c,this),"__static__".concat(n),!1),i}function re(n,e,t){return ae(n,"__once__".concat(e).concat(t?"_".concat(t):""),!0),n}function ae(n,e,t){if(r(n))for(var i=0;i<n.length;i++)n[i]&&"string"!=typeof n[i]&&se(n[i],"".concat(e,"_").concat(i),t);else se(n,e,t)}function se(n,e,t){n.isStatic=!0,n.key=e,n.isOnce=t}function le(n,e){if(e)if(p(e)){var t=n.on=n.on?B({},n.on):{};for(var i in e){var r=t[i],a=e[i];t[i]=r?[].concat(r,a):a}}else;return n}function oe(n,e,t,i){e=e||{$stable:!t};for(var a=0;a<n.length;a++){var s=n[a];r(s)?oe(s,e,t):s&&(s.proxy&&(s.fn.proxy=!0),e[s.key]=s.fn)}return i&&(e.$key=i),e}function de(n,e){for(var t=0;t<e.length;t+=2){var i=e[t];"string"==typeof i&&i&&(n[e[t]]=e[t+1])}return n}function ce(n,e){return"string"==typeof n?e+n:n}function ue(n){n._o=re,n._n=b,n._s=f,n._l=Wn,n._t=Yn,n._q=O,n._i=M,n._m=ie,n._f=Zn,n._k=ee,n._b=te,n._v=gn,n._e=hn,n._u=oe,n._g=le,n._d=de,n._p=ce}function pe(n,e){if(!n||!n.length)return{};for(var t={},i=0,r=n.length;i<r;i++){var a=n[i],s=a.data;if(s&&s.attrs&&s.attrs.slot&&delete s.attrs.slot,a.context!==e&&a.fnContext!==e||!s||null==s.slot)(t.default||(t.default=[])).push(a);else{var l=s.slot,o=t[l]||(t[l]=[]);"template"===a.tag?o.push.apply(o,a.children||[]):o.push(a)}}for(var d in t)t[d].every(me)&&delete t[d];return t}function me(n){return n.isComment&&!n.asyncFactory||" "===n.text}function he(n){return n.isComment&&n.asyncFactory}function ge(n,e,t,r){var a,s=Object.keys(t).length>0,l=e?!!e.$stable:!s,o=e&&e.$key;if(e){if(e._normalized)return e._normalized;if(l&&r&&r!==i&&o===r.$key&&!s&&!r.$hasNormal)return r;for(var d in a={},e)e[d]&&"$"!==d[0]&&(a[d]=fe(n,t,d,e[d]))}else a={};for(var c in t)c in a||(a[c]=be(t,c));return e&&Object.isExtensible(e)&&(e._normalized=a),K(a,"$stable",l),K(a,"$key",o),K(a,"$hasNormal",s),a}function fe(n,e,t,i){var a=function(){var e=un;pn(n);var t=arguments.length?i.apply(null,arguments):i({}),a=(t=t&&"object"==typeof t&&!r(t)?[t]:Qn(t))&&t[0];return pn(e),t&&(!a||1===t.length&&a.isComment&&!he(a))?void 0:t};return i.proxy&&Object.defineProperty(e,t,{get:a,enumerable:!0,configurable:!0}),a}function be(n,e){return function(){return n[e]}}function ve(n){return{get attrs(){if(!n._attrsProxy){var e=n._attrsProxy={};K(e,"_v_attr_proxy",!0),ye(e,n.$attrs,i,n,"$attrs")}return n._attrsProxy},get listeners(){n._listenersProxy||ye(n._listenersProxy={},n.$listeners,i,n,"$listeners");return n._listenersProxy},get slots(){return function(n){n._slotsProxy||ke(n._slotsProxy={},n.$scopedSlots);return n._slotsProxy}(n)},emit:A(n.$emit,n),expose:function(e){e&&Object.keys(e).forEach((function(t){return $n(n,e,t)}))}}}function ye(n,e,t,i,r){var a=!1;for(var s in e)s in n?e[s]!==t[s]&&(a=!0):(a=!0,xe(n,s,i,r));for(var s in n)s in e||(a=!0,delete n[s]);return a}function xe(n,e,t,i){Object.defineProperty(n,e,{enumerable:!0,configurable:!0,get:function(){return t[i][e]}})}function ke(n,e){for(var t in e)n[t]=e[t];for(var t in n)t in e||delete n[t]}var _e=null;function Ee(n,e){return(n.__esModule||cn&&"Module"===n[Symbol.toStringTag])&&(n=n.default),c(n)?e.extend(n):n}function Se(n){if(r(n))for(var e=0;e<n.length;e++){var t=n[e];if(s(t)&&(s(t.componentOptions)||he(t)))return t}}function Re(n,e,t,i,u,p){return(r(t)||o(t))&&(u=i,i=t,t=void 0),l(p)&&(u=2),function(n,e,t,i,o){if(s(t)&&s(t.__ob__))return hn();s(t)&&s(t.is)&&(e=t.is);if(!e)return hn();0;r(i)&&d(i[0])&&((t=t||{}).scopedSlots={default:i[0]},i.length=0);2===o?i=Qn(i):1===o&&(i=function(n){for(var e=0;e<n.length;e++)if(r(n[e]))return Array.prototype.concat.apply([],n);return n}(i));var u,p;if("string"==typeof e){var m=void 0;p=n.$vnode&&n.$vnode.ns||N.getTagNamespace(e),u=N.isReservedTag(e)?new mn(N.parsePlatformTagName(e),t,i,void 0,void 0,n):t&&t.pre||!s(m=Lt(n.$options,"components",e))?new mn(e,t,i,void 0,void 0,n):xt(m,t,n,i,e)}else u=xt(e,t,n,i);return r(u)?u:s(u)?(s(p)&&function n(e,t,i){e.ns=t,"foreignObject"===e.tag&&(t=void 0,i=!0);if(s(e.children))for(var r=0,o=e.children.length;r<o;r++){var d=e.children[r];s(d.tag)&&(a(d.ns)||l(i)&&"svg"!==d.tag)&&n(d,t,i)}}(u,p),s(t)&&function(n){c(n.style)&&Ne(n.style);c(n.class)&&Ne(n.class)}(t),u):hn()}(n,e,t,i,u)}function Te(n,e,t){kn();try{if(e)for(var i=e;i=i.$parent;){var r=i.$options.errorCaptured;if(r)for(var a=0;a<r.length;a++)try{if(!1===r[a].call(i,n,e,t))return}catch(n){Ie(n,i,"errorCaptured hook")}}Ie(n,e,t)}finally{_n()}}function we(n,e,t,i,r){var a;try{(a=t?n.apply(e,t):n.call(e))&&!a._isVue&&g(a)&&!a._handled&&(a.catch((function(n){return Te(n,i,r+" (Promise/async)")})),a._handled=!0)}catch(n){Te(n,i,r)}return a}function Ie(n,e,t){if(N.errorHandler)try{return N.errorHandler.call(null,n,e,t)}catch(e){e!==n&&Ae(e,null,"config.errorHandler")}Ae(n,e,t)}function Ae(n,e,t){if(!V||"undefined"==typeof console)throw n;console.error(n)}var Le,Be=!1,Ce=[],ze=!1;function De(){ze=!1;var n=Ce.slice(0);Ce.length=0;for(var e=0;e<n.length;e++)n[e]()}if("undefined"!=typeof Promise&&on(Promise)){var Pe=Promise.resolve();Le=function(){Pe.then(De),Z&&setTimeout(z)},Be=!0}else if(X||"undefined"==typeof MutationObserver||!on(MutationObserver)&&"[object MutationObserverConstructor]"!==MutationObserver.toString())Le="undefined"!=typeof setImmediate&&on(setImmediate)?function(){setImmediate(De)}:function(){setTimeout(De,0)};else{var Oe=1,Me=new MutationObserver(De),je=document.createTextNode(String(Oe));Me.observe(je,{characterData:!0}),Le=function(){Oe=(Oe+1)%2,je.data=String(Oe)},Be=!0}function Ue(n,e){var t;if(Ce.push((function(){if(n)try{n.call(e)}catch(n){Te(n,e,"nextTick")}else t&&t(e)})),ze||(ze=!0,Le()),!n&&"undefined"!=typeof Promise)return new Promise((function(n){t=n}))}function $e(n){return function(e,t){if(void 0===t&&(t=un),t)return function(n,e,t){var i=n.$options;i[e]=Tt(i[e],t)}(t,n,e)}}$e("beforeMount"),$e("mounted"),$e("beforeUpdate"),$e("updated"),$e("beforeDestroy"),$e("destroyed"),$e("activated"),$e("deactivated"),$e("serverPrefetch"),$e("renderTracked"),$e("renderTriggered"),$e("errorCaptured");var Fe=new dn;function Ne(n){return function n(e,t){var i,a,s=r(e);if(!s&&!c(e)||e.__v_skip||Object.isFrozen(e)||e instanceof mn)return;if(e.__ob__){var l=e.__ob__.dep.id;if(t.has(l))return;t.add(l)}if(s)for(i=e.length;i--;)n(e[i],t);else if(Un(e))n(e.value,t);else for(a=Object.keys(e),i=a.length;i--;)n(e[a[i]],t)}(n,Fe),Fe.clear(),n}var qe,Ge=0,Ke=function(){function n(n,e,t,i,r){var a,s;a=this,void 0===(s=Fn&&!Fn._vm?Fn:n?n._scope:void 0)&&(s=Fn),s&&s.active&&s.effects.push(a),(this.vm=n)&&r&&(n._watcher=this),i?(this.deep=!!i.deep,this.user=!!i.user,this.lazy=!!i.lazy,this.sync=!!i.sync,this.before=i.before):this.deep=this.user=this.lazy=this.sync=!1,this.cb=t,this.id=++Ge,this.active=!0,this.post=!1,this.dirty=this.lazy,this.deps=[],this.newDeps=[],this.depIds=new dn,this.newDepIds=new dn,this.expression="",d(e)?this.getter=e:(this.getter=function(n){if(!H.test(n)){var e=n.split(".");return function(n){for(var t=0;t<e.length;t++){if(!n)return;n=n[e[t]]}return n}}}(e),this.getter||(this.getter=z)),this.value=this.lazy?void 0:this.get()}return n.prototype.get=function(){var n;kn(this);var e=this.vm;try{n=this.getter.call(e,e)}catch(n){if(!this.user)throw n;Te(n,e,'getter for watcher "'.concat(this.expression,'"'))}finally{this.deep&&Ne(n),_n(),this.cleanupDeps()}return n},n.prototype.addDep=function(n){var e=n.id;this.newDepIds.has(e)||(this.newDepIds.add(e),this.newDeps.push(n),this.depIds.has(e)||n.addSub(this))},n.prototype.cleanupDeps=function(){for(var n=this.deps.length;n--;){var e=this.deps[n];this.newDepIds.has(e.id)||e.removeSub(this)}var t=this.depIds;this.depIds=this.newDepIds,this.newDepIds=t,this.newDepIds.clear(),t=this.deps,this.deps=this.newDeps,this.newDeps=t,this.newDeps.length=0},n.prototype.update=function(){this.lazy?this.dirty=!0:this.sync?this.run():pt(this)},n.prototype.run=function(){if(this.active){var n=this.get();if(n!==this.value||c(n)||this.deep){var e=this.value;if(this.value=n,this.user){var t='callback for watcher "'.concat(this.expression,'"');we(this.cb,this.vm,[n,e],this.vm,t)}else this.cb.call(this.vm,n,e)}}},n.prototype.evaluate=function(){this.value=this.get(),this.dirty=!1},n.prototype.depend=function(){for(var n=this.deps.length;n--;)this.deps[n].depend()},n.prototype.teardown=function(){if(this.vm&&!this.vm._isBeingDestroyed&&x(this.vm._scope.effects,this),this.active){for(var n=this.deps.length;n--;)this.deps[n].removeSub(this);this.active=!1,this.onStop&&this.onStop()}},n}();function He(n,e){qe.$on(n,e)}function Je(n,e){qe.$off(n,e)}function Ve(n,e){var t=qe;return function i(){var r=e.apply(null,arguments);null!==r&&t.$off(n,i)}}function Qe(n,e,t){qe=n,Hn(e,t||{},He,Je,Ve,n),qe=void 0}var Xe=null;function We(n){var e=Xe;return Xe=n,function(){Xe=e}}function Ye(n){for(;n&&(n=n.$parent);)if(n._inactive)return!0;return!1}function Ze(n,e){if(e){if(n._directInactive=!1,Ye(n))return}else if(n._directInactive)return;if(n._inactive||null===n._inactive){n._inactive=!1;for(var t=0;t<n.$children.length;t++)Ze(n.$children[t]);nt(n,"activated")}}function nt(n,e,t,i){void 0===i&&(i=!0),kn();var r=un;i&&pn(n);var a=n.$options[e],s="".concat(e," hook");if(a)for(var l=0,o=a.length;l<o;l++)we(a[l],n,t||null,n,s);n._hasHookEvent&&n.$emit("hook:"+e),i&&pn(r),_n()}var et=[],tt=[],it={},rt=!1,at=!1,st=0;var lt=0,ot=Date.now;if(V&&!X){var dt=window.performance;dt&&"function"==typeof dt.now&&ot()>document.createEvent("Event").timeStamp&&(ot=function(){return dt.now()})}var ct=function(n,e){if(n.post){if(!e.post)return 1}else if(e.post)return-1;return n.id-e.id};function ut(){var n,e;for(lt=ot(),at=!0,et.sort(ct),st=0;st<et.length;st++)(n=et[st]).before&&n.before(),e=n.id,it[e]=null,n.run();var t=tt.slice(),i=et.slice();st=et.length=tt.length=0,it={},rt=at=!1,function(n){for(var e=0;e<n.length;e++)n[e]._inactive=!0,Ze(n[e],!0)}(t),function(n){var e=n.length;for(;e--;){var t=n[e],i=t.vm;i&&i._watcher===t&&i._isMounted&&!i._isDestroyed&&nt(i,"updated")}}(i),function(){for(var n=0;n<vn.length;n++){var e=vn[n];e.subs=e.subs.filter((function(n){return n})),e._pending=!1}vn.length=0}(),ln&&N.devtools&&ln.emit("flush")}function pt(n){var e=n.id;if(null==it[e]&&(n!==yn.target||!n.noRecurse)){if(it[e]=!0,at){for(var t=et.length-1;t>st&&et[t].id>n.id;)t--;et.splice(t+1,0,n)}else et.push(n);rt||(rt=!0,Ue(ut))}}function mt(n,e){if(n){for(var t=Object.create(null),i=cn?Reflect.ownKeys(n):Object.keys(n),r=0;r<i.length;r++){var a=i[r];if("__ob__"!==a){var s=n[a].from;if(s in e._provided)t[a]=e._provided[s];else if("default"in n[a]){var l=n[a].default;t[a]=d(l)?l.call(e):l}else 0}}return t}}function ht(n,e,t,a,s){var o,d=this,c=s.options;_(a,"_uid")?(o=Object.create(a))._original=a:(o=a,a=a._original);var u=l(c._compiled),p=!u;this.data=n,this.props=e,this.children=t,this.parent=a,this.listeners=n.on||i,this.injections=mt(c.inject,a),this.slots=function(){return d.$slots||ge(a,n.scopedSlots,d.$slots=pe(t,a)),d.$slots},Object.defineProperty(this,"scopedSlots",{enumerable:!0,get:function(){return ge(a,n.scopedSlots,this.slots())}}),u&&(this.$options=c,this.$slots=this.slots(),this.$scopedSlots=ge(a,n.scopedSlots,this.$slots)),c._scopeId?this._c=function(n,e,t,i){var s=Re(o,n,e,t,i,p);return s&&!r(s)&&(s.fnScopeId=c._scopeId,s.fnContext=a),s}:this._c=function(n,e,t,i){return Re(o,n,e,t,i,p)}}function gt(n,e,t,i,r){var a=fn(n);return a.fnContext=t,a.fnOptions=i,e.slot&&((a.data||(a.data={})).slot=e.slot),a}function ft(n,e){for(var t in e)n[R(t)]=e[t]}function bt(n){return n.name||n.__name||n._componentTag}ue(ht.prototype);var vt={init:function(n,e){if(n.componentInstance&&!n.componentInstance._isDestroyed&&n.data.keepAlive){var t=n;vt.prepatch(t,t)}else{(n.componentInstance=function(n,e){var t={_isComponent:!0,_parentVnode:n,parent:e},i=n.data.inlineTemplate;s(i)&&(t.render=i.render,t.staticRenderFns=i.staticRenderFns);return new n.componentOptions.Ctor(t)}(n,Xe)).$mount(e?n.elm:void 0,e)}},prepatch:function(n,e){var t=e.componentOptions;!function(n,e,t,r,a){var s=r.data.scopedSlots,l=n.$scopedSlots,o=!!(s&&!s.$stable||l!==i&&!l.$stable||s&&n.$scopedSlots.$key!==s.$key||!s&&n.$scopedSlots.$key),d=!!(a||n.$options._renderChildren||o),c=n.$vnode;n.$options._parentVnode=r,n.$vnode=r,n._vnode&&(n._vnode.parent=r),n.$options._renderChildren=a;var u=r.data.attrs||i;n._attrsProxy&&ye(n._attrsProxy,u,c.data&&c.data.attrs||i,n,"$attrs")&&(d=!0),n.$attrs=u,t=t||i;var p=n.$options._parentListeners;if(n._listenersProxy&&ye(n._listenersProxy,t,p||i,n,"$listeners"),n.$listeners=n.$options._parentListeners=t,Qe(n,t,p),e&&n.$options.props){In(!1);for(var m=n._props,h=n.$options._propKeys||[],g=0;g<h.length;g++){var f=h[g],b=n.$options.props;m[f]=Bt(f,b,e,n)}In(!0),n.$options.propsData=e}d&&(n.$slots=pe(a,r.context),n.$forceUpdate())}(e.componentInstance=n.componentInstance,t.propsData,t.listeners,e,t.children)},insert:function(n){var e,t=n.context,i=n.componentInstance;i._isMounted||(i._isMounted=!0,nt(i,"mounted")),n.data.keepAlive&&(t._isMounted?((e=i)._inactive=!1,tt.push(e)):Ze(i,!0))},destroy:function(n){var e=n.componentInstance;e._isDestroyed||(n.data.keepAlive?function n(e,t){if(!(t&&(e._directInactive=!0,Ye(e))||e._inactive)){e._inactive=!0;for(var i=0;i<e.$children.length;i++)n(e.$children[i]);nt(e,"deactivated")}}(e,!0):e.$destroy())}},yt=Object.keys(vt);function xt(n,e,t,o,d){if(!a(n)){var u=t.$options._base;if(c(n)&&(n=u.extend(n)),"function"==typeof n){var p;if(a(n.cid)&&void 0===(n=function(n,e){if(l(n.error)&&s(n.errorComp))return n.errorComp;if(s(n.resolved))return n.resolved;var t=_e;if(t&&s(n.owners)&&-1===n.owners.indexOf(t)&&n.owners.push(t),l(n.loading)&&s(n.loadingComp))return n.loadingComp;if(t&&!s(n.owners)){var i=n.owners=[t],r=!0,o=null,d=null;t.$on("hook:destroyed",(function(){return x(i,t)}));var u=function(n){for(var e=0,t=i.length;e<t;e++)i[e].$forceUpdate();n&&(i.length=0,null!==o&&(clearTimeout(o),o=null),null!==d&&(clearTimeout(d),d=null))},p=j((function(t){n.resolved=Ee(t,e),r?i.length=0:u(!0)})),m=j((function(e){s(n.errorComp)&&(n.error=!0,u(!0))})),h=n(p,m);return c(h)&&(g(h)?a(n.resolved)&&h.then(p,m):g(h.component)&&(h.component.then(p,m),s(h.error)&&(n.errorComp=Ee(h.error,e)),s(h.loading)&&(n.loadingComp=Ee(h.loading,e),0===h.delay?n.loading=!0:o=setTimeout((function(){o=null,a(n.resolved)&&a(n.error)&&(n.loading=!0,u(!1))}),h.delay||200)),s(h.timeout)&&(d=setTimeout((function(){d=null,a(n.resolved)&&m(null)}),h.timeout)))),r=!1,n.loading?n.loadingComp:n.resolved}}(p=n,u)))return function(n,e,t,i,r){var a=hn();return a.asyncFactory=n,a.asyncMeta={data:e,context:t,children:i,tag:r},a}(p,e,t,o,d);e=e||{},Kt(n),s(e.model)&&function(n,e){var t=n.model&&n.model.prop||"value",i=n.model&&n.model.event||"input";(e.attrs||(e.attrs={}))[t]=e.model.value;var a=e.on||(e.on={}),l=a[i],o=e.model.callback;s(l)?(r(l)?-1===l.indexOf(o):l!==o)&&(a[i]=[o].concat(l)):a[i]=o}(n.options,e);var m=function(n,e,t){var i=e.options.props;if(!a(i)){var r={},l=n.attrs,o=n.props;if(s(l)||s(o))for(var d in i){var c=I(d);Vn(r,o,d,c,!0)||Vn(r,l,d,c,!1)}return r}}(e,n);if(l(n.options.functional))return function(n,e,t,a,l){var o=n.options,d={},c=o.props;if(s(c))for(var u in c)d[u]=Bt(u,c,e||i);else s(t.attrs)&&ft(d,t.attrs),s(t.props)&&ft(d,t.props);var p=new ht(t,d,l,a,n),m=o.render.call(null,p._c,p);if(m instanceof mn)return gt(m,t,p.parent,o,p);if(r(m)){for(var h=Qn(m)||[],g=new Array(h.length),f=0;f<h.length;f++)g[f]=gt(h[f],t,p.parent,o,p);return g}}(n,m,e,t,o);var h=e.on;if(e.on=e.nativeOn,l(n.options.abstract)){var f=e.slot;e={},f&&(e.slot=f)}!function(n){for(var e=n.hook||(n.hook={}),t=0;t<yt.length;t++){var i=yt[t],r=e[i],a=vt[i];r===a||r&&r._merged||(e[i]=r?kt(a,r):a)}}(e);var b=bt(n.options)||d;return new mn("vue-component-".concat(n.cid).concat(b?"-".concat(b):""),e,void 0,void 0,void 0,t,{Ctor:n,propsData:m,listeners:h,tag:d,children:o},p)}}}function kt(n,e){var t=function(t,i){n(t,i),e(t,i)};return t._merged=!0,t}var _t=z,Et=N.optionMergeStrategies;function St(n,e,t){if(void 0===t&&(t=!0),!e)return n;for(var i,r,a,s=cn?Reflect.ownKeys(e):Object.keys(e),l=0;l<s.length;l++)"__ob__"!==(i=s[l])&&(r=n[i],a=e[i],t&&_(n,i)?r!==a&&p(r)&&p(a)&&St(r,a):zn(n,i,a));return n}function Rt(n,e,t){return t?function(){var i=d(e)?e.call(t,t):e,r=d(n)?n.call(t,t):n;return i?St(i,r):r}:e?n?function(){return St(d(e)?e.call(this,this):e,d(n)?n.call(this,this):n)}:e:n}function Tt(n,e){var t=e?n?n.concat(e):r(e)?e:[e]:n;return t?function(n){for(var e=[],t=0;t<n.length;t++)-1===e.indexOf(n[t])&&e.push(n[t]);return e}(t):t}function wt(n,e,t,i){var r=Object.create(n||null);return e?B(r,e):r}Et.data=function(n,e,t){return t?Rt(n,e,t):e&&"function"!=typeof e?n:Rt(n,e)},F.forEach((function(n){Et[n]=Tt})),$.forEach((function(n){Et[n+"s"]=wt})),Et.watch=function(n,e,t,i){if(n===tn&&(n=void 0),e===tn&&(e=void 0),!e)return Object.create(n||null);if(!n)return e;var a={};for(var s in B(a,n),e){var l=a[s],o=e[s];l&&!r(l)&&(l=[l]),a[s]=l?l.concat(o):r(o)?o:[o]}return a},Et.props=Et.methods=Et.inject=Et.computed=function(n,e,t,i){if(!n)return e;var r=Object.create(null);return B(r,n),e&&B(r,e),r},Et.provide=function(n,e){return n?function(){var t=Object.create(null);return St(t,d(n)?n.call(this):n),e&&St(t,d(e)?e.call(this):e,!1),t}:e};var It=function(n,e){return void 0===e?n:e};function At(n,e,t){if(d(e)&&(e=e.options),function(n,e){var t=n.props;if(t){var i,a,s={};if(r(t))for(i=t.length;i--;)"string"==typeof(a=t[i])&&(s[R(a)]={type:null});else if(p(t))for(var l in t)a=t[l],s[R(l)]=p(a)?a:{type:a};else 0;n.props=s}}(e),function(n,e){var t=n.inject;if(t){var i=n.inject={};if(r(t))for(var a=0;a<t.length;a++)i[t[a]]={from:t[a]};else if(p(t))for(var s in t){var l=t[s];i[s]=p(l)?B({from:s},l):{from:l}}else 0}}(e),function(n){var e=n.directives;if(e)for(var t in e){var i=e[t];d(i)&&(e[t]={bind:i,update:i})}}(e),!e._base&&(e.extends&&(n=At(n,e.extends,t)),e.mixins))for(var i=0,a=e.mixins.length;i<a;i++)n=At(n,e.mixins[i],t);var s,l={};for(s in n)o(s);for(s in e)_(n,s)||o(s);function o(i){var r=Et[i]||It;l[i]=r(n[i],e[i],t,i)}return l}function Lt(n,e,t,i){if("string"==typeof t){var r=n[e];if(_(r,t))return r[t];var a=R(t);if(_(r,a))return r[a];var s=T(a);return _(r,s)?r[s]:r[t]||r[a]||r[s]}}function Bt(n,e,t,i){var r=e[n],a=!_(t,n),s=t[n],l=Pt(Boolean,r.type);if(l>-1)if(a&&!_(r,"default"))s=!1;else if(""===s||s===I(n)){var o=Pt(String,r.type);(o<0||l<o)&&(s=!0)}if(void 0===s){s=function(n,e,t){if(!_(e,"default"))return;var i=e.default;0;if(n&&n.$options.propsData&&void 0===n.$options.propsData[t]&&void 0!==n._props[t])return n._props[t];return d(i)&&"Function"!==zt(e.type)?i.call(n):i}(i,r,n);var c=wn;In(!0),Bn(s),In(c)}return s}var Ct=/^\s*function (\w+)/;function zt(n){var e=n&&n.toString().match(Ct);return e?e[1]:""}function Dt(n,e){return zt(n)===zt(e)}function Pt(n,e){if(!r(e))return Dt(e,n)?0:-1;for(var t=0,i=e.length;t<i;t++)if(Dt(e[t],n))return t;return-1}var Ot={enumerable:!0,configurable:!0,get:z,set:z};function Mt(n,e,t){Ot.get=function(){return this[e][t]},Ot.set=function(n){this[e][t]=n},Object.defineProperty(n,t,Ot)}function jt(n){var e=n.$options;if(e.props&&function(n,e){var t=n.$options.propsData||{},i=n._props=On({}),r=n.$options._propKeys=[];n.$parent&&In(!1);var a=function(a){r.push(a);var s=Bt(a,e,t,n);Cn(i,a,s),a in n||Mt(n,"_props",a)};for(var s in e)a(s);In(!0)}(n,e.props),function(n){var e=n.$options,t=e.setup;if(t){var i=n._setupContext=ve(n);pn(n),kn();var r=we(t,null,[n._props||On({}),i],n,"setup");if(_n(),pn(),d(r))e.render=r;else if(c(r))if(n._setupState=r,r.__sfc){var a=n._setupProxy={};for(var s in r)"__sfc"!==s&&$n(a,r,s)}else for(var s in r)G(s)||$n(n,r,s);else 0}}(n),e.methods&&function(n,e){n.$options.props;for(var t in e)n[t]="function"!=typeof e[t]?z:A(e[t],n)}(n,e.methods),e.data)!function(n){var e=n.$options.data;p(e=n._data=d(e)?function(n,e){kn();try{return n.call(e,e)}catch(n){return Te(n,e,"data()"),{}}finally{_n()}}(e,n):e||{})||(e={});var t=Object.keys(e),i=n.$options.props,r=(n.$options.methods,t.length);for(;r--;){var a=t[r];0,i&&_(i,a)||G(a)||Mt(n,"_data",a)}var s=Bn(e);s&&s.vmCount++}(n);else{var t=Bn(n._data={});t&&t.vmCount++}e.computed&&function(n,e){var t=n._computedWatchers=Object.create(null),i=sn();for(var r in e){var a=e[r],s=d(a)?a:a.get;0,i||(t[r]=new Ke(n,s||z,z,Ut)),r in n||$t(n,r,a)}}(n,e.computed),e.watch&&e.watch!==tn&&function(n,e){for(var t in e){var i=e[t];if(r(i))for(var a=0;a<i.length;a++)qt(n,t,i[a]);else qt(n,t,i)}}(n,e.watch)}var Ut={lazy:!0};function $t(n,e,t){var i=!sn();d(t)?(Ot.get=i?Ft(e):Nt(t),Ot.set=z):(Ot.get=t.get?i&&!1!==t.cache?Ft(e):Nt(t.get):z,Ot.set=t.set||z),Object.defineProperty(n,e,Ot)}function Ft(n){return function(){var e=this._computedWatchers&&this._computedWatchers[n];if(e)return e.dirty&&e.evaluate(),yn.target&&e.depend(),e.value}}function Nt(n){return function(){return n.call(this,this)}}function qt(n,e,t,i){return p(t)&&(i=t,t=t.handler),"string"==typeof t&&(t=n[t]),n.$watch(e,t,i)}var Gt=0;function Kt(n){var e=n.options;if(n.super){var t=Kt(n.super);if(t!==n.superOptions){n.superOptions=t;var i=function(n){var e,t=n.options,i=n.sealedOptions;for(var r in t)t[r]!==i[r]&&(e||(e={}),e[r]=t[r]);return e}(n);i&&B(n.extendOptions,i),(e=n.options=At(t,n.extendOptions)).name&&(e.components[e.name]=n)}}return e}function Ht(n){this._init(n)}function Jt(n){n.cid=0;var e=1;n.extend=function(n){n=n||{};var t=this,i=t.cid,r=n._Ctor||(n._Ctor={});if(r[i])return r[i];var a=bt(n)||bt(t.options);var s=function(n){this._init(n)};return(s.prototype=Object.create(t.prototype)).constructor=s,s.cid=e++,s.options=At(t.options,n),s.super=t,s.options.props&&function(n){var e=n.options.props;for(var t in e)Mt(n.prototype,"_props",t)}(s),s.options.computed&&function(n){var e=n.options.computed;for(var t in e)$t(n.prototype,t,e[t])}(s),s.extend=t.extend,s.mixin=t.mixin,s.use=t.use,$.forEach((function(n){s[n]=t[n]})),a&&(s.options.components[a]=s),s.superOptions=t.options,s.extendOptions=n,s.sealedOptions=B({},s.options),r[i]=s,s}}function Vt(n){return n&&(bt(n.Ctor.options)||n.tag)}function Qt(n,e){return r(n)?n.indexOf(e)>-1:"string"==typeof n?n.split(",").indexOf(e)>-1:!!m(n)&&n.test(e)}function Xt(n,e){var t=n.cache,i=n.keys,r=n._vnode;for(var a in t){var s=t[a];if(s){var l=s.name;l&&!e(l)&&Wt(t,a,i,r)}}}function Wt(n,e,t,i){var r=n[e];!r||i&&r.tag===i.tag||r.componentInstance.$destroy(),n[e]=null,x(t,e)}!function(n){n.prototype._init=function(n){var e=this;e._uid=Gt++,e._isVue=!0,e.__v_skip=!0,e._scope=new Nn(!0),e._scope._vm=!0,n&&n._isComponent?function(n,e){var t=n.$options=Object.create(n.constructor.options),i=e._parentVnode;t.parent=e.parent,t._parentVnode=i;var r=i.componentOptions;t.propsData=r.propsData,t._parentListeners=r.listeners,t._renderChildren=r.children,t._componentTag=r.tag,e.render&&(t.render=e.render,t.staticRenderFns=e.staticRenderFns)}(e,n):e.$options=At(Kt(e.constructor),n||{},e),e._renderProxy=e,e._self=e,function(n){var e=n.$options,t=e.parent;if(t&&!e.abstract){for(;t.$options.abstract&&t.$parent;)t=t.$parent;t.$children.push(n)}n.$parent=t,n.$root=t?t.$root:n,n.$children=[],n.$refs={},n._provided=t?t._provided:Object.create(null),n._watcher=null,n._inactive=null,n._directInactive=!1,n._isMounted=!1,n._isDestroyed=!1,n._isBeingDestroyed=!1}(e),function(n){n._events=Object.create(null),n._hasHookEvent=!1;var e=n.$options._parentListeners;e&&Qe(n,e)}(e),function(n){n._vnode=null,n._staticTrees=null;var e=n.$options,t=n.$vnode=e._parentVnode,r=t&&t.context;n.$slots=pe(e._renderChildren,r),n.$scopedSlots=t?ge(n.$parent,t.data.scopedSlots,n.$slots):i,n._c=function(e,t,i,r){return Re(n,e,t,i,r,!1)},n.$createElement=function(e,t,i,r){return Re(n,e,t,i,r,!0)};var a=t&&t.data;Cn(n,"$attrs",a&&a.attrs||i,null,!0),Cn(n,"$listeners",e._parentListeners||i,null,!0)}(e),nt(e,"beforeCreate",void 0,!1),function(n){var e=mt(n.$options.inject,n);e&&(In(!1),Object.keys(e).forEach((function(t){Cn(n,t,e[t])})),In(!0))}(e),jt(e),function(n){var e=n.$options.provide;if(e){var t=d(e)?e.call(n):e;if(!c(t))return;for(var i=qn(n),r=cn?Reflect.ownKeys(t):Object.keys(t),a=0;a<r.length;a++){var s=r[a];Object.defineProperty(i,s,Object.getOwnPropertyDescriptor(t,s))}}}(e),nt(e,"created"),e.$options.el&&e.$mount(e.$options.el)}}(Ht),function(n){var e={get:function(){return this._data}},t={get:function(){return this._props}};Object.defineProperty(n.prototype,"$data",e),Object.defineProperty(n.prototype,"$props",t),n.prototype.$set=zn,n.prototype.$delete=Dn,n.prototype.$watch=function(n,e,t){if(p(e))return qt(this,n,e,t);(t=t||{}).user=!0;var i=new Ke(this,n,e,t);if(t.immediate){var r='callback for immediate watcher "'.concat(i.expression,'"');kn(),we(e,this,[i.value],this,r),_n()}return function(){i.teardown()}}}(Ht),function(n){var e=/^hook:/;n.prototype.$on=function(n,t){var i=this;if(r(n))for(var a=0,s=n.length;a<s;a++)i.$on(n[a],t);else(i._events[n]||(i._events[n]=[])).push(t),e.test(n)&&(i._hasHookEvent=!0);return i},n.prototype.$once=function(n,e){var t=this;function i(){t.$off(n,i),e.apply(t,arguments)}return i.fn=e,t.$on(n,i),t},n.prototype.$off=function(n,e){var t=this;if(!arguments.length)return t._events=Object.create(null),t;if(r(n)){for(var i=0,a=n.length;i<a;i++)t.$off(n[i],e);return t}var s,l=t._events[n];if(!l)return t;if(!e)return t._events[n]=null,t;for(var o=l.length;o--;)if((s=l[o])===e||s.fn===e){l.splice(o,1);break}return t},n.prototype.$emit=function(n){var e=this,t=e._events[n];if(t){t=t.length>1?L(t):t;for(var i=L(arguments,1),r='event handler for "'.concat(n,'"'),a=0,s=t.length;a<s;a++)we(t[a],e,i,e,r)}return e}}(Ht),function(n){n.prototype._update=function(n,e){var t=this,i=t.$el,r=t._vnode,a=We(t);t._vnode=n,t.$el=r?t.__patch__(r,n):t.__patch__(t.$el,n,e,!1),a(),i&&(i.__vue__=null),t.$el&&(t.$el.__vue__=t);for(var s=t;s&&s.$vnode&&s.$parent&&s.$vnode===s.$parent._vnode;)s.$parent.$el=s.$el,s=s.$parent},n.prototype.$forceUpdate=function(){this._watcher&&this._watcher.update()},n.prototype.$destroy=function(){var n=this;if(!n._isBeingDestroyed){nt(n,"beforeDestroy"),n._isBeingDestroyed=!0;var e=n.$parent;!e||e._isBeingDestroyed||n.$options.abstract||x(e.$children,n),n._scope.stop(),n._data.__ob__&&n._data.__ob__.vmCount--,n._isDestroyed=!0,n.__patch__(n._vnode,null),nt(n,"destroyed"),n.$off(),n.$el&&(n.$el.__vue__=null),n.$vnode&&(n.$vnode.parent=null)}}}(Ht),function(n){ue(n.prototype),n.prototype.$nextTick=function(n){return Ue(n,this)},n.prototype._render=function(){var n,e=this,t=e.$options,i=t.render,a=t._parentVnode;a&&e._isMounted&&(e.$scopedSlots=ge(e.$parent,a.data.scopedSlots,e.$slots,e.$scopedSlots),e._slotsProxy&&ke(e._slotsProxy,e.$scopedSlots)),e.$vnode=a;try{pn(e),_e=e,n=i.call(e._renderProxy,e.$createElement)}catch(t){Te(t,e,"render"),n=e._vnode}finally{_e=null,pn()}return r(n)&&1===n.length&&(n=n[0]),n instanceof mn||(n=hn()),n.parent=a,n}}(Ht);var Yt=[String,RegExp,Array],Zt={KeepAlive:{name:"keep-alive",abstract:!0,props:{include:Yt,exclude:Yt,max:[String,Number]},methods:{cacheVNode:function(){var n=this.cache,e=this.keys,t=this.vnodeToCache,i=this.keyToCache;if(t){var r=t.tag,a=t.componentInstance,s=t.componentOptions;n[i]={name:Vt(s),tag:r,componentInstance:a},e.push(i),this.max&&e.length>parseInt(this.max)&&Wt(n,e[0],e,this._vnode),this.vnodeToCache=null}}},created:function(){this.cache=Object.create(null),this.keys=[]},destroyed:function(){for(var n in this.cache)Wt(this.cache,n,this.keys)},mounted:function(){var n=this;this.cacheVNode(),this.$watch("include",(function(e){Xt(n,(function(n){return Qt(e,n)}))})),this.$watch("exclude",(function(e){Xt(n,(function(n){return!Qt(e,n)}))}))},updated:function(){this.cacheVNode()},render:function(){var n=this.$slots.default,e=Se(n),t=e&&e.componentOptions;if(t){var i=Vt(t),r=this.include,a=this.exclude;if(r&&(!i||!Qt(r,i))||a&&i&&Qt(a,i))return e;var s=this.cache,l=this.keys,o=null==e.key?t.Ctor.cid+(t.tag?"::".concat(t.tag):""):e.key;s[o]?(e.componentInstance=s[o].componentInstance,x(l,o),l.push(o)):(this.vnodeToCache=e,this.keyToCache=o),e.data.keepAlive=!0}return e||n&&n[0]}}};!function(n){var e={get:function(){return N}};Object.defineProperty(n,"config",e),n.util={warn:_t,extend:B,mergeOptions:At,defineReactive:Cn},n.set=zn,n.delete=Dn,n.nextTick=Ue,n.observable=function(n){return Bn(n),n},n.options=Object.create(null),$.forEach((function(e){n.options[e+"s"]=Object.create(null)})),n.options._base=n,B(n.options.components,Zt),function(n){n.use=function(n){var e=this._installedPlugins||(this._installedPlugins=[]);if(e.indexOf(n)>-1)return this;var t=L(arguments,1);return t.unshift(this),d(n.install)?n.install.apply(n,t):d(n)&&n.apply(null,t),e.push(n),this}}(n),function(n){n.mixin=function(n){return this.options=At(this.options,n),this}}(n),Jt(n),function(n){$.forEach((function(e){n[e]=function(n,t){return t?("component"===e&&p(t)&&(t.name=t.name||n,t=this.options._base.extend(t)),"directive"===e&&d(t)&&(t={bind:t,update:t}),this.options[e+"s"][n]=t,t):this.options[e+"s"][n]}}))}(n)}(Ht),Object.defineProperty(Ht.prototype,"$isServer",{get:sn}),Object.defineProperty(Ht.prototype,"$ssrContext",{get:function(){return this.$vnode&&this.$vnode.ssrContext}}),Object.defineProperty(Ht,"FunctionalRenderContext",{value:ht}),Ht.version="2.7.14";var ni=v("style,class"),ei=v("input,textarea,option,select,progress"),ti=v("contenteditable,draggable,spellcheck"),ii=v("events,caret,typing,plaintext-only"),ri=v("allowfullscreen,async,autofocus,autoplay,checked,compact,controls,declare,default,defaultchecked,defaultmuted,defaultselected,defer,disabled,enabled,formnovalidate,hidden,indeterminate,inert,ismap,itemscope,loop,multiple,muted,nohref,noresize,noshade,novalidate,nowrap,open,pauseonexit,readonly,required,reversed,scoped,seamless,selected,sortable,truespeed,typemustmatch,visible"),ai="http://www.w3.org/1999/xlink",si=function(n){return":"===n.charAt(5)&&"xlink"===n.slice(0,5)},li=function(n){return si(n)?n.slice(6,n.length):""},oi=function(n){return null==n||!1===n};function di(n){for(var e=n.data,t=n,i=n;s(i.componentInstance);)(i=i.componentInstance._vnode)&&i.data&&(e=ci(i.data,e));for(;s(t=t.parent);)t&&t.data&&(e=ci(e,t.data));return function(n,e){if(s(n)||s(e))return ui(n,pi(e));return""}(e.staticClass,e.class)}function ci(n,e){return{staticClass:ui(n.staticClass,e.staticClass),class:s(n.class)?[n.class,e.class]:e.class}}function ui(n,e){return n?e?n+" "+e:n:e||""}function pi(n){return Array.isArray(n)?function(n){for(var e,t="",i=0,r=n.length;i<r;i++)s(e=pi(n[i]))&&""!==e&&(t&&(t+=" "),t+=e);return t}(n):c(n)?function(n){var e="";for(var t in n)n[t]&&(e&&(e+=" "),e+=t);return e}(n):"string"==typeof n?n:""}var mi={svg:"http://www.w3.org/2000/svg",math:"http://www.w3.org/1998/Math/MathML"},hi=v("html,body,base,head,link,meta,style,title,address,article,aside,footer,header,h1,h2,h3,h4,h5,h6,hgroup,nav,section,div,dd,dl,dt,figcaption,figure,picture,hr,img,li,main,ol,p,pre,ul,a,b,abbr,bdi,bdo,br,cite,code,data,dfn,em,i,kbd,mark,q,rp,rt,rtc,ruby,s,samp,small,span,strong,sub,sup,time,u,var,wbr,area,audio,map,track,video,embed,object,param,source,canvas,script,noscript,del,ins,caption,col,colgroup,table,thead,tbody,td,th,tr,button,datalist,fieldset,form,input,label,legend,meter,optgroup,option,output,progress,select,textarea,details,dialog,menu,menuitem,summary,content,element,shadow,template,blockquote,iframe,tfoot"),gi=v("svg,animate,circle,clippath,cursor,defs,desc,ellipse,filter,font-face,foreignobject,g,glyph,image,line,marker,mask,missing-glyph,path,pattern,polygon,polyline,rect,switch,symbol,text,textpath,tspan,use,view",!0),fi=function(n){return hi(n)||gi(n)};var bi=Object.create(null);var vi=v("text,number,password,search,email,tel,url");var yi=Object.freeze({__proto__:null,createElement:function(n,e){var t=document.createElement(n);return"select"!==n||e.data&&e.data.attrs&&void 0!==e.data.attrs.multiple&&t.setAttribute("multiple","multiple"),t},createElementNS:function(n,e){return document.createElementNS(mi[n],e)},createTextNode:function(n){return document.createTextNode(n)},createComment:function(n){return document.createComment(n)},insertBefore:function(n,e,t){n.insertBefore(e,t)},removeChild:function(n,e){n.removeChild(e)},appendChild:function(n,e){n.appendChild(e)},parentNode:function(n){return n.parentNode},nextSibling:function(n){return n.nextSibling},tagName:function(n){return n.tagName},setTextContent:function(n,e){n.textContent=e},setStyleScope:function(n,e){n.setAttribute(e,"")}}),xi={create:function(n,e){ki(e)},update:function(n,e){n.data.ref!==e.data.ref&&(ki(n,!0),ki(e))},destroy:function(n){ki(n,!0)}};function ki(n,e){var t=n.data.ref;if(s(t)){var i=n.context,a=n.componentInstance||n.elm,l=e?null:a,o=e?void 0:a;if(d(t))we(t,i,[l],i,"template ref function");else{var c=n.data.refInFor,u="string"==typeof t||"number"==typeof t,p=Un(t),m=i.$refs;if(u||p)if(c){var h=u?m[t]:t.value;e?r(h)&&x(h,a):r(h)?h.includes(a)||h.push(a):u?(m[t]=[a],_i(i,t,m[t])):t.value=[a]}else if(u){if(e&&m[t]!==a)return;m[t]=o,_i(i,t,l)}else if(p){if(e&&t.value!==a)return;t.value=l}else 0}}}function _i(n,e,t){var i=n._setupState;i&&_(i,e)&&(Un(i[e])?i[e].value=t:i[e]=t)}var Ei=new mn("",{},[]),Si=["create","activate","update","remove","destroy"];function Ri(n,e){return n.key===e.key&&n.asyncFactory===e.asyncFactory&&(n.tag===e.tag&&n.isComment===e.isComment&&s(n.data)===s(e.data)&&function(n,e){if("input"!==n.tag)return!0;var t,i=s(t=n.data)&&s(t=t.attrs)&&t.type,r=s(t=e.data)&&s(t=t.attrs)&&t.type;return i===r||vi(i)&&vi(r)}(n,e)||l(n.isAsyncPlaceholder)&&a(e.asyncFactory.error))}function Ti(n,e,t){var i,r,a={};for(i=e;i<=t;++i)s(r=n[i].key)&&(a[r]=i);return a}var wi={create:Ii,update:Ii,destroy:function(n){Ii(n,Ei)}};function Ii(n,e){(n.data.directives||e.data.directives)&&function(n,e){var t,i,r,a=n===Ei,s=e===Ei,l=Li(n.data.directives,n.context),o=Li(e.data.directives,e.context),d=[],c=[];for(t in o)i=l[t],r=o[t],i?(r.oldValue=i.value,r.oldArg=i.arg,Ci(r,"update",e,n),r.def&&r.def.componentUpdated&&c.push(r)):(Ci(r,"bind",e,n),r.def&&r.def.inserted&&d.push(r));if(d.length){var u=function(){for(var t=0;t<d.length;t++)Ci(d[t],"inserted",e,n)};a?Jn(e,"insert",u):u()}c.length&&Jn(e,"postpatch",(function(){for(var t=0;t<c.length;t++)Ci(c[t],"componentUpdated",e,n)}));if(!a)for(t in l)o[t]||Ci(l[t],"unbind",n,n,s)}(n,e)}var Ai=Object.create(null);function Li(n,e){var t,i,r=Object.create(null);if(!n)return r;for(t=0;t<n.length;t++){if((i=n[t]).modifiers||(i.modifiers=Ai),r[Bi(i)]=i,e._setupState&&e._setupState.__sfc){var a=i.def||Lt(e,"_setupState","v-"+i.name);i.def="function"==typeof a?{bind:a,update:a}:a}i.def=i.def||Lt(e.$options,"directives",i.name)}return r}function Bi(n){return n.rawName||"".concat(n.name,".").concat(Object.keys(n.modifiers||{}).join("."))}function Ci(n,e,t,i,r){var a=n.def&&n.def[e];if(a)try{a(t.elm,n,t,i,r)}catch(i){Te(i,t.context,"directive ".concat(n.name," ").concat(e," hook"))}}var zi=[xi,wi];function Di(n,e){var t=e.componentOptions;if(!(s(t)&&!1===t.Ctor.options.inheritAttrs||a(n.data.attrs)&&a(e.data.attrs))){var i,r,o=e.elm,d=n.data.attrs||{},c=e.data.attrs||{};for(i in(s(c.__ob__)||l(c._v_attr_proxy))&&(c=e.data.attrs=B({},c)),c)r=c[i],d[i]!==r&&Pi(o,i,r,e.data.pre);for(i in(X||Y)&&c.value!==d.value&&Pi(o,"value",c.value),d)a(c[i])&&(si(i)?o.removeAttributeNS(ai,li(i)):ti(i)||o.removeAttribute(i))}}function Pi(n,e,t,i){i||n.tagName.indexOf("-")>-1?Oi(n,e,t):ri(e)?oi(t)?n.removeAttribute(e):(t="allowfullscreen"===e&&"EMBED"===n.tagName?"true":e,n.setAttribute(e,t)):ti(e)?n.setAttribute(e,function(n,e){return oi(e)||"false"===e?"false":"contenteditable"===n&&ii(e)?e:"true"}(e,t)):si(e)?oi(t)?n.removeAttributeNS(ai,li(e)):n.setAttributeNS(ai,e,t):Oi(n,e,t)}function Oi(n,e,t){if(oi(t))n.removeAttribute(e);else{if(X&&!W&&"TEXTAREA"===n.tagName&&"placeholder"===e&&""!==t&&!n.__ieph){var i=function(e){e.stopImmediatePropagation(),n.removeEventListener("input",i)};n.addEventListener("input",i),n.__ieph=!0}n.setAttribute(e,t)}}var Mi={create:Di,update:Di};function ji(n,e){var t=e.elm,i=e.data,r=n.data;if(!(a(i.staticClass)&&a(i.class)&&(a(r)||a(r.staticClass)&&a(r.class)))){var l=di(e),o=t._transitionClasses;s(o)&&(l=ui(l,pi(o))),l!==t._prevClass&&(t.setAttribute("class",l),t._prevClass=l)}}var Ui,$i={create:ji,update:ji};function Fi(n,e,t){var i=Ui;return function r(){var a=e.apply(null,arguments);null!==a&&Gi(n,r,t,i)}}var Ni=Be&&!(en&&Number(en[1])<=53);function qi(n,e,t,i){if(Ni){var r=lt,a=e;e=a._wrapper=function(n){if(n.target===n.currentTarget||n.timeStamp>=r||n.timeStamp<=0||n.target.ownerDocument!==document)return a.apply(this,arguments)}}Ui.addEventListener(n,e,rn?{capture:t,passive:i}:t)}function Gi(n,e,t,i){(i||Ui).removeEventListener(n,e._wrapper||e,t)}function Ki(n,e){if(!a(n.data.on)||!a(e.data.on)){var t=e.data.on||{},i=n.data.on||{};Ui=e.elm||n.elm,function(n){if(s(n.__r)){var e=X?"change":"input";n[e]=[].concat(n.__r,n[e]||[]),delete n.__r}s(n.__c)&&(n.change=[].concat(n.__c,n.change||[]),delete n.__c)}(t),Hn(t,i,qi,Gi,Fi,e.context),Ui=void 0}}var Hi,Ji={create:Ki,update:Ki,destroy:function(n){return Ki(n,Ei)}};function Vi(n,e){if(!a(n.data.domProps)||!a(e.data.domProps)){var t,i,r=e.elm,o=n.data.domProps||{},d=e.data.domProps||{};for(t in(s(d.__ob__)||l(d._v_attr_proxy))&&(d=e.data.domProps=B({},d)),o)t in d||(r[t]="");for(t in d){if(i=d[t],"textContent"===t||"innerHTML"===t){if(e.children&&(e.children.length=0),i===o[t])continue;1===r.childNodes.length&&r.removeChild(r.childNodes[0])}if("value"===t&&"PROGRESS"!==r.tagName){r._value=i;var c=a(i)?"":String(i);Qi(r,c)&&(r.value=c)}else if("innerHTML"===t&&gi(r.tagName)&&a(r.innerHTML)){(Hi=Hi||document.createElement("div")).innerHTML="<svg>".concat(i,"</svg>");for(var u=Hi.firstChild;r.firstChild;)r.removeChild(r.firstChild);for(;u.firstChild;)r.appendChild(u.firstChild)}else if(i!==o[t])try{r[t]=i}catch(n){}}}}function Qi(n,e){return!n.composing&&("OPTION"===n.tagName||function(n,e){var t=!0;try{t=document.activeElement!==n}catch(n){}return t&&n.value!==e}(n,e)||function(n,e){var t=n.value,i=n._vModifiers;if(s(i)){if(i.number)return b(t)!==b(e);if(i.trim)return t.trim()!==e.trim()}return t!==e}(n,e))}var Xi={create:Vi,update:Vi},Wi=E((function(n){var e={},t=/:(.+)/;return n.split(/;(?![^(]*\))/g).forEach((function(n){if(n){var i=n.split(t);i.length>1&&(e[i[0].trim()]=i[1].trim())}})),e}));function Yi(n){var e=Zi(n.style);return n.staticStyle?B(n.staticStyle,e):e}function Zi(n){return Array.isArray(n)?C(n):"string"==typeof n?Wi(n):n}var nr,er=/^--/,tr=/\s*!important$/,ir=function(n,e,t){if(er.test(e))n.style.setProperty(e,t);else if(tr.test(t))n.style.setProperty(I(e),t.replace(tr,""),"important");else{var i=ar(e);if(Array.isArray(t))for(var r=0,a=t.length;r<a;r++)n.style[i]=t[r];else n.style[i]=t}},rr=["Webkit","Moz","ms"],ar=E((function(n){if(nr=nr||document.createElement("div").style,"filter"!==(n=R(n))&&n in nr)return n;for(var e=n.charAt(0).toUpperCase()+n.slice(1),t=0;t<rr.length;t++){var i=rr[t]+e;if(i in nr)return i}}));function sr(n,e){var t=e.data,i=n.data;if(!(a(t.staticStyle)&&a(t.style)&&a(i.staticStyle)&&a(i.style))){var r,l,o=e.elm,d=i.staticStyle,c=i.normalizedStyle||i.style||{},u=d||c,p=Zi(e.data.style)||{};e.data.normalizedStyle=s(p.__ob__)?B({},p):p;var m=function(n,e){var t,i={};if(e)for(var r=n;r.componentInstance;)(r=r.componentInstance._vnode)&&r.data&&(t=Yi(r.data))&&B(i,t);(t=Yi(n.data))&&B(i,t);for(var a=n;a=a.parent;)a.data&&(t=Yi(a.data))&&B(i,t);return i}(e,!0);for(l in u)a(m[l])&&ir(o,l,"");for(l in m)(r=m[l])!==u[l]&&ir(o,l,null==r?"":r)}}var lr={create:sr,update:sr},or=/\s+/;function dr(n,e){if(e&&(e=e.trim()))if(n.classList)e.indexOf(" ")>-1?e.split(or).forEach((function(e){return n.classList.add(e)})):n.classList.add(e);else{var t=" ".concat(n.getAttribute("class")||""," ");t.indexOf(" "+e+" ")<0&&n.setAttribute("class",(t+e).trim())}}function cr(n,e){if(e&&(e=e.trim()))if(n.classList)e.indexOf(" ")>-1?e.split(or).forEach((function(e){return n.classList.remove(e)})):n.classList.remove(e),n.classList.length||n.removeAttribute("class");else{for(var t=" ".concat(n.getAttribute("class")||""," "),i=" "+e+" ";t.indexOf(i)>=0;)t=t.replace(i," ");(t=t.trim())?n.setAttribute("class",t):n.removeAttribute("class")}}function ur(n){if(n){if("object"==typeof n){var e={};return!1!==n.css&&B(e,pr(n.name||"v")),B(e,n),e}return"string"==typeof n?pr(n):void 0}}var pr=E((function(n){return{enterClass:"".concat(n,"-enter"),enterToClass:"".concat(n,"-enter-to"),enterActiveClass:"".concat(n,"-enter-active"),leaveClass:"".concat(n,"-leave"),leaveToClass:"".concat(n,"-leave-to"),leaveActiveClass:"".concat(n,"-leave-active")}})),mr=V&&!W,hr="transition",gr="transitionend",fr="animation",br="animationend";mr&&(void 0===window.ontransitionend&&void 0!==window.onwebkittransitionend&&(hr="WebkitTransition",gr="webkitTransitionEnd"),void 0===window.onanimationend&&void 0!==window.onwebkitanimationend&&(fr="WebkitAnimation",br="webkitAnimationEnd"));var vr=V?window.requestAnimationFrame?window.requestAnimationFrame.bind(window):setTimeout:function(n){return n()};function yr(n){vr((function(){vr(n)}))}function xr(n,e){var t=n._transitionClasses||(n._transitionClasses=[]);t.indexOf(e)<0&&(t.push(e),dr(n,e))}function kr(n,e){n._transitionClasses&&x(n._transitionClasses,e),cr(n,e)}function _r(n,e,t){var i=Sr(n,e),r=i.type,a=i.timeout,s=i.propCount;if(!r)return t();var l="transition"===r?gr:br,o=0,d=function(){n.removeEventListener(l,c),t()},c=function(e){e.target===n&&++o>=s&&d()};setTimeout((function(){o<s&&d()}),a+1),n.addEventListener(l,c)}var Er=/\b(transform|all)(,|$)/;function Sr(n,e){var t,i=window.getComputedStyle(n),r=(i[hr+"Delay"]||"").split(", "),a=(i[hr+"Duration"]||"").split(", "),s=Rr(r,a),l=(i[fr+"Delay"]||"").split(", "),o=(i[fr+"Duration"]||"").split(", "),d=Rr(l,o),c=0,u=0;return"transition"===e?s>0&&(t="transition",c=s,u=a.length):"animation"===e?d>0&&(t="animation",c=d,u=o.length):u=(t=(c=Math.max(s,d))>0?s>d?"transition":"animation":null)?"transition"===t?a.length:o.length:0,{type:t,timeout:c,propCount:u,hasTransform:"transition"===t&&Er.test(i[hr+"Property"])}}function Rr(n,e){for(;n.length<e.length;)n=n.concat(n);return Math.max.apply(null,e.map((function(e,t){return Tr(e)+Tr(n[t])})))}function Tr(n){return 1e3*Number(n.slice(0,-1).replace(",","."))}function wr(n,e){var t=n.elm;s(t._leaveCb)&&(t._leaveCb.cancelled=!0,t._leaveCb());var i=ur(n.data.transition);if(!a(i)&&!s(t._enterCb)&&1===t.nodeType){for(var r=i.css,l=i.type,o=i.enterClass,u=i.enterToClass,p=i.enterActiveClass,m=i.appearClass,h=i.appearToClass,g=i.appearActiveClass,f=i.beforeEnter,v=i.enter,y=i.afterEnter,x=i.enterCancelled,k=i.beforeAppear,_=i.appear,E=i.afterAppear,S=i.appearCancelled,R=i.duration,T=Xe,w=Xe.$vnode;w&&w.parent;)T=w.context,w=w.parent;var I=!T._isMounted||!n.isRootInsert;if(!I||_||""===_){var A=I&&m?m:o,L=I&&g?g:p,B=I&&h?h:u,C=I&&k||f,z=I&&d(_)?_:v,D=I&&E||y,P=I&&S||x,O=b(c(R)?R.enter:R);0;var M=!1!==r&&!W,U=Lr(z),$=t._enterCb=j((function(){M&&(kr(t,B),kr(t,L)),$.cancelled?(M&&kr(t,A),P&&P(t)):D&&D(t),t._enterCb=null}));n.data.show||Jn(n,"insert",(function(){var e=t.parentNode,i=e&&e._pending&&e._pending[n.key];i&&i.tag===n.tag&&i.elm._leaveCb&&i.elm._leaveCb(),z&&z(t,$)})),C&&C(t),M&&(xr(t,A),xr(t,L),yr((function(){kr(t,A),$.cancelled||(xr(t,B),U||(Ar(O)?setTimeout($,O):_r(t,l,$)))}))),n.data.show&&(e&&e(),z&&z(t,$)),M||U||$()}}}function Ir(n,e){var t=n.elm;s(t._enterCb)&&(t._enterCb.cancelled=!0,t._enterCb());var i=ur(n.data.transition);if(a(i)||1!==t.nodeType)return e();if(!s(t._leaveCb)){var r=i.css,l=i.type,o=i.leaveClass,d=i.leaveToClass,u=i.leaveActiveClass,p=i.beforeLeave,m=i.leave,h=i.afterLeave,g=i.leaveCancelled,f=i.delayLeave,v=i.duration,y=!1!==r&&!W,x=Lr(m),k=b(c(v)?v.leave:v);0;var _=t._leaveCb=j((function(){t.parentNode&&t.parentNode._pending&&(t.parentNode._pending[n.key]=null),y&&(kr(t,d),kr(t,u)),_.cancelled?(y&&kr(t,o),g&&g(t)):(e(),h&&h(t)),t._leaveCb=null}));f?f(E):E()}function E(){_.cancelled||(!n.data.show&&t.parentNode&&((t.parentNode._pending||(t.parentNode._pending={}))[n.key]=n),p&&p(t),y&&(xr(t,o),xr(t,u),yr((function(){kr(t,o),_.cancelled||(xr(t,d),x||(Ar(k)?setTimeout(_,k):_r(t,l,_)))}))),m&&m(t,_),y||x||_())}}function Ar(n){return"number"==typeof n&&!isNaN(n)}function Lr(n){if(a(n))return!1;var e=n.fns;return s(e)?Lr(Array.isArray(e)?e[0]:e):(n._length||n.length)>1}function Br(n,e){!0!==e.data.show&&wr(e)}var Cr=function(n){var e,t,i={},d=n.modules,c=n.nodeOps;for(e=0;e<Si.length;++e)for(i[Si[e]]=[],t=0;t<d.length;++t)s(d[t][Si[e]])&&i[Si[e]].push(d[t][Si[e]]);function u(n){var e=c.parentNode(n);s(e)&&c.removeChild(e,n)}function p(n,e,t,r,a,o,d){if(s(n.elm)&&s(o)&&(n=o[d]=fn(n)),n.isRootInsert=!a,!function(n,e,t,r){var a=n.data;if(s(a)){var o=s(n.componentInstance)&&a.keepAlive;if(s(a=a.hook)&&s(a=a.init)&&a(n,!1),s(n.componentInstance))return m(n,e),h(t,n.elm,r),l(o)&&function(n,e,t,r){var a,l=n;for(;l.componentInstance;)if(l=l.componentInstance._vnode,s(a=l.data)&&s(a=a.transition)){for(a=0;a<i.activate.length;++a)i.activate[a](Ei,l);e.push(l);break}h(t,n.elm,r)}(n,e,t,r),!0}}(n,e,t,r)){var u=n.data,p=n.children,f=n.tag;s(f)?(n.elm=n.ns?c.createElementNS(n.ns,f):c.createElement(f,n),y(n),g(n,p,e),s(u)&&b(n,e),h(t,n.elm,r)):l(n.isComment)?(n.elm=c.createComment(n.text),h(t,n.elm,r)):(n.elm=c.createTextNode(n.text),h(t,n.elm,r))}}function m(n,e){s(n.data.pendingInsert)&&(e.push.apply(e,n.data.pendingInsert),n.data.pendingInsert=null),n.elm=n.componentInstance.$el,f(n)?(b(n,e),y(n)):(ki(n),e.push(n))}function h(n,e,t){s(n)&&(s(t)?c.parentNode(t)===n&&c.insertBefore(n,e,t):c.appendChild(n,e))}function g(n,e,t){if(r(e)){0;for(var i=0;i<e.length;++i)p(e[i],t,n.elm,null,!0,e,i)}else o(n.text)&&c.appendChild(n.elm,c.createTextNode(String(n.text)))}function f(n){for(;n.componentInstance;)n=n.componentInstance._vnode;return s(n.tag)}function b(n,t){for(var r=0;r<i.create.length;++r)i.create[r](Ei,n);s(e=n.data.hook)&&(s(e.create)&&e.create(Ei,n),s(e.insert)&&t.push(n))}function y(n){var e;if(s(e=n.fnScopeId))c.setStyleScope(n.elm,e);else for(var t=n;t;)s(e=t.context)&&s(e=e.$options._scopeId)&&c.setStyleScope(n.elm,e),t=t.parent;s(e=Xe)&&e!==n.context&&e!==n.fnContext&&s(e=e.$options._scopeId)&&c.setStyleScope(n.elm,e)}function x(n,e,t,i,r,a){for(;i<=r;++i)p(t[i],a,n,e,!1,t,i)}function k(n){var e,t,r=n.data;if(s(r))for(s(e=r.hook)&&s(e=e.destroy)&&e(n),e=0;e<i.destroy.length;++e)i.destroy[e](n);if(s(e=n.children))for(t=0;t<n.children.length;++t)k(n.children[t])}function _(n,e,t){for(;e<=t;++e){var i=n[e];s(i)&&(s(i.tag)?(E(i),k(i)):u(i.elm))}}function E(n,e){if(s(e)||s(n.data)){var t,r=i.remove.length+1;for(s(e)?e.listeners+=r:e=function(n,e){function t(){0==--t.listeners&&u(n)}return t.listeners=e,t}(n.elm,r),s(t=n.componentInstance)&&s(t=t._vnode)&&s(t.data)&&E(t,e),t=0;t<i.remove.length;++t)i.remove[t](n,e);s(t=n.data.hook)&&s(t=t.remove)?t(n,e):e()}else u(n.elm)}function S(n,e,t,i){for(var r=t;r<i;r++){var a=e[r];if(s(a)&&Ri(n,a))return r}}function R(n,e,t,r,o,d){if(n!==e){s(e.elm)&&s(r)&&(e=r[o]=fn(e));var u=e.elm=n.elm;if(l(n.isAsyncPlaceholder))s(e.asyncFactory.resolved)?I(n.elm,e,t):e.isAsyncPlaceholder=!0;else if(l(e.isStatic)&&l(n.isStatic)&&e.key===n.key&&(l(e.isCloned)||l(e.isOnce)))e.componentInstance=n.componentInstance;else{var m,h=e.data;s(h)&&s(m=h.hook)&&s(m=m.prepatch)&&m(n,e);var g=n.children,b=e.children;if(s(h)&&f(e)){for(m=0;m<i.update.length;++m)i.update[m](n,e);s(m=h.hook)&&s(m=m.update)&&m(n,e)}a(e.text)?s(g)&&s(b)?g!==b&&function(n,e,t,i,r){var l,o,d,u=0,m=0,h=e.length-1,g=e[0],f=e[h],b=t.length-1,v=t[0],y=t[b],k=!r;for(0;u<=h&&m<=b;)a(g)?g=e[++u]:a(f)?f=e[--h]:Ri(g,v)?(R(g,v,i,t,m),g=e[++u],v=t[++m]):Ri(f,y)?(R(f,y,i,t,b),f=e[--h],y=t[--b]):Ri(g,y)?(R(g,y,i,t,b),k&&c.insertBefore(n,g.elm,c.nextSibling(f.elm)),g=e[++u],y=t[--b]):Ri(f,v)?(R(f,v,i,t,m),k&&c.insertBefore(n,f.elm,g.elm),f=e[--h],v=t[++m]):(a(l)&&(l=Ti(e,u,h)),a(o=s(v.key)?l[v.key]:S(v,e,u,h))?p(v,i,n,g.elm,!1,t,m):Ri(d=e[o],v)?(R(d,v,i,t,m),e[o]=void 0,k&&c.insertBefore(n,d.elm,g.elm)):p(v,i,n,g.elm,!1,t,m),v=t[++m]);u>h?x(n,a(t[b+1])?null:t[b+1].elm,t,m,b,i):m>b&&_(e,u,h)}(u,g,b,t,d):s(b)?(s(n.text)&&c.setTextContent(u,""),x(u,null,b,0,b.length-1,t)):s(g)?_(g,0,g.length-1):s(n.text)&&c.setTextContent(u,""):n.text!==e.text&&c.setTextContent(u,e.text),s(h)&&s(m=h.hook)&&s(m=m.postpatch)&&m(n,e)}}}function T(n,e,t){if(l(t)&&s(n.parent))n.parent.data.pendingInsert=e;else for(var i=0;i<e.length;++i)e[i].data.hook.insert(e[i])}var w=v("attrs,class,staticClass,staticStyle,key");function I(n,e,t,i){var r,a=e.tag,o=e.data,d=e.children;if(i=i||o&&o.pre,e.elm=n,l(e.isComment)&&s(e.asyncFactory))return e.isAsyncPlaceholder=!0,!0;if(s(o)&&(s(r=o.hook)&&s(r=r.init)&&r(e,!0),s(r=e.componentInstance)))return m(e,t),!0;if(s(a)){if(s(d))if(n.hasChildNodes())if(s(r=o)&&s(r=r.domProps)&&s(r=r.innerHTML)){if(r!==n.innerHTML)return!1}else{for(var c=!0,u=n.firstChild,p=0;p<d.length;p++){if(!u||!I(u,d[p],t,i)){c=!1;break}u=u.nextSibling}if(!c||u)return!1}else g(e,d,t);if(s(o)){var h=!1;for(var f in o)if(!w(f)){h=!0,b(e,t);break}!h&&o.class&&Ne(o.class)}}else n.data!==e.text&&(n.data=e.text);return!0}return function(n,e,t,r){if(!a(e)){var o,d=!1,u=[];if(a(n))d=!0,p(e,u);else{var m=s(n.nodeType);if(!m&&Ri(n,e))R(n,e,u,null,null,r);else{if(m){if(1===n.nodeType&&n.hasAttribute("data-server-rendered")&&(n.removeAttribute("data-server-rendered"),t=!0),l(t)&&I(n,e,u))return T(e,u,!0),n;o=n,n=new mn(c.tagName(o).toLowerCase(),{},[],void 0,o)}var h=n.elm,g=c.parentNode(h);if(p(e,u,h._leaveCb?null:g,c.nextSibling(h)),s(e.parent))for(var b=e.parent,v=f(e);b;){for(var y=0;y<i.destroy.length;++y)i.destroy[y](b);if(b.elm=e.elm,v){for(var x=0;x<i.create.length;++x)i.create[x](Ei,b);var E=b.data.hook.insert;if(E.merged)for(var S=1;S<E.fns.length;S++)E.fns[S]()}else ki(b);b=b.parent}s(g)?_([n],0,0):s(n.tag)&&k(n)}}return T(e,u,d),e.elm}s(n)&&k(n)}}({nodeOps:yi,modules:[Mi,$i,Ji,Xi,lr,V?{create:Br,activate:Br,remove:function(n,e){!0!==n.data.show?Ir(n,e):e()}}:{}].concat(zi)});W&&document.addEventListener("selectionchange",(function(){var n=document.activeElement;n&&n.vmodel&&$r(n,"input")}));var zr={inserted:function(n,e,t,i){"select"===t.tag?(i.elm&&!i.elm._vOptions?Jn(t,"postpatch",(function(){zr.componentUpdated(n,e,t)})):Dr(n,e,t.context),n._vOptions=[].map.call(n.options,Mr)):("textarea"===t.tag||vi(n.type))&&(n._vModifiers=e.modifiers,e.modifiers.lazy||(n.addEventListener("compositionstart",jr),n.addEventListener("compositionend",Ur),n.addEventListener("change",Ur),W&&(n.vmodel=!0)))},componentUpdated:function(n,e,t){if("select"===t.tag){Dr(n,e,t.context);var i=n._vOptions,r=n._vOptions=[].map.call(n.options,Mr);if(r.some((function(n,e){return!O(n,i[e])})))(n.multiple?e.value.some((function(n){return Or(n,r)})):e.value!==e.oldValue&&Or(e.value,r))&&$r(n,"change")}}};function Dr(n,e,t){Pr(n,e,t),(X||Y)&&setTimeout((function(){Pr(n,e,t)}),0)}function Pr(n,e,t){var i=e.value,r=n.multiple;if(!r||Array.isArray(i)){for(var a,s,l=0,o=n.options.length;l<o;l++)if(s=n.options[l],r)a=M(i,Mr(s))>-1,s.selected!==a&&(s.selected=a);else if(O(Mr(s),i))return void(n.selectedIndex!==l&&(n.selectedIndex=l));r||(n.selectedIndex=-1)}}function Or(n,e){return e.every((function(e){return!O(e,n)}))}function Mr(n){return"_value"in n?n._value:n.value}function jr(n){n.target.composing=!0}function Ur(n){n.target.composing&&(n.target.composing=!1,$r(n.target,"input"))}function $r(n,e){var t=document.createEvent("HTMLEvents");t.initEvent(e,!0,!0),n.dispatchEvent(t)}function Fr(n){return!n.componentInstance||n.data&&n.data.transition?n:Fr(n.componentInstance._vnode)}var Nr={model:zr,show:{bind:function(n,e,t){var i=e.value,r=(t=Fr(t)).data&&t.data.transition,a=n.__vOriginalDisplay="none"===n.style.display?"":n.style.display;i&&r?(t.data.show=!0,wr(t,(function(){n.style.display=a}))):n.style.display=i?a:"none"},update:function(n,e,t){var i=e.value;!i!=!e.oldValue&&((t=Fr(t)).data&&t.data.transition?(t.data.show=!0,i?wr(t,(function(){n.style.display=n.__vOriginalDisplay})):Ir(t,(function(){n.style.display="none"}))):n.style.display=i?n.__vOriginalDisplay:"none")},unbind:function(n,e,t,i,r){r||(n.style.display=n.__vOriginalDisplay)}}},qr={name:String,appear:Boolean,css:Boolean,mode:String,type:String,enterClass:String,leaveClass:String,enterToClass:String,leaveToClass:String,enterActiveClass:String,leaveActiveClass:String,appearClass:String,appearActiveClass:String,appearToClass:String,duration:[Number,String,Object]};function Gr(n){var e=n&&n.componentOptions;return e&&e.Ctor.options.abstract?Gr(Se(e.children)):n}function Kr(n){var e={},t=n.$options;for(var i in t.propsData)e[i]=n[i];var r=t._parentListeners;for(var i in r)e[R(i)]=r[i];return e}function Hr(n,e){if(/\d-keep-alive$/.test(e.tag))return n("keep-alive",{props:e.componentOptions.propsData})}var Jr=function(n){return n.tag||he(n)},Vr=function(n){return"show"===n.name},Qr={name:"transition",props:qr,abstract:!0,render:function(n){var e=this,t=this.$slots.default;if(t&&(t=t.filter(Jr)).length){0;var i=this.mode;0;var r=t[0];if(function(n){for(;n=n.parent;)if(n.data.transition)return!0}(this.$vnode))return r;var a=Gr(r);if(!a)return r;if(this._leaving)return Hr(n,r);var s="__transition-".concat(this._uid,"-");a.key=null==a.key?a.isComment?s+"comment":s+a.tag:o(a.key)?0===String(a.key).indexOf(s)?a.key:s+a.key:a.key;var l=(a.data||(a.data={})).transition=Kr(this),d=this._vnode,c=Gr(d);if(a.data.directives&&a.data.directives.some(Vr)&&(a.data.show=!0),c&&c.data&&!function(n,e){return e.key===n.key&&e.tag===n.tag}(a,c)&&!he(c)&&(!c.componentInstance||!c.componentInstance._vnode.isComment)){var u=c.data.transition=B({},l);if("out-in"===i)return this._leaving=!0,Jn(u,"afterLeave",(function(){e._leaving=!1,e.$forceUpdate()})),Hr(n,r);if("in-out"===i){if(he(a))return d;var p,m=function(){p()};Jn(l,"afterEnter",m),Jn(l,"enterCancelled",m),Jn(u,"delayLeave",(function(n){p=n}))}}return r}}},Xr=B({tag:String,moveClass:String},qr);function Wr(n){n.elm._moveCb&&n.elm._moveCb(),n.elm._enterCb&&n.elm._enterCb()}function Yr(n){n.data.newPos=n.elm.getBoundingClientRect()}function Zr(n){var e=n.data.pos,t=n.data.newPos,i=e.left-t.left,r=e.top-t.top;if(i||r){n.data.moved=!0;var a=n.elm.style;a.transform=a.WebkitTransform="translate(".concat(i,"px,").concat(r,"px)"),a.transitionDuration="0s"}}delete Xr.mode;var na={Transition:Qr,TransitionGroup:{props:Xr,beforeMount:function(){var n=this,e=this._update;this._update=function(t,i){var r=We(n);n.__patch__(n._vnode,n.kept,!1,!0),n._vnode=n.kept,r(),e.call(n,t,i)}},render:function(n){for(var e=this.tag||this.$vnode.data.tag||"span",t=Object.create(null),i=this.prevChildren=this.children,r=this.$slots.default||[],a=this.children=[],s=Kr(this),l=0;l<r.length;l++){if((c=r[l]).tag)if(null!=c.key&&0!==String(c.key).indexOf("__vlist"))a.push(c),t[c.key]=c,(c.data||(c.data={})).transition=s;else;}if(i){var o=[],d=[];for(l=0;l<i.length;l++){var c;(c=i[l]).data.transition=s,c.data.pos=c.elm.getBoundingClientRect(),t[c.key]?o.push(c):d.push(c)}this.kept=n(e,null,o),this.removed=d}return n(e,null,a)},updated:function(){var n=this.prevChildren,e=this.moveClass||(this.name||"v")+"-move";n.length&&this.hasMove(n[0].elm,e)&&(n.forEach(Wr),n.forEach(Yr),n.forEach(Zr),this._reflow=document.body.offsetHeight,n.forEach((function(n){if(n.data.moved){var t=n.elm,i=t.style;xr(t,e),i.transform=i.WebkitTransform=i.transitionDuration="",t.addEventListener(gr,t._moveCb=function n(i){i&&i.target!==t||i&&!/transform$/.test(i.propertyName)||(t.removeEventListener(gr,n),t._moveCb=null,kr(t,e))})}})))},methods:{hasMove:function(n,e){if(!mr)return!1;if(this._hasMove)return this._hasMove;var t=n.cloneNode();n._transitionClasses&&n._transitionClasses.forEach((function(n){cr(t,n)})),dr(t,e),t.style.display="none",this.$el.appendChild(t);var i=Sr(t);return this.$el.removeChild(t),this._hasMove=i.hasTransform}}}};function ea(n,e){for(var t in e)n[t]=e[t];return n}Ht.config.mustUseProp=function(n,e,t){return"value"===t&&ei(n)&&"button"!==e||"selected"===t&&"option"===n||"checked"===t&&"input"===n||"muted"===t&&"video"===n},Ht.config.isReservedTag=fi,Ht.config.isReservedAttr=ni,Ht.config.getTagNamespace=function(n){return gi(n)?"svg":"math"===n?"math":void 0},Ht.config.isUnknownElement=function(n){if(!V)return!0;if(fi(n))return!1;if(n=n.toLowerCase(),null!=bi[n])return bi[n];var e=document.createElement(n);return n.indexOf("-")>-1?bi[n]=e.constructor===window.HTMLUnknownElement||e.constructor===window.HTMLElement:bi[n]=/HTMLUnknownElement/.test(e.toString())},B(Ht.options.directives,Nr),B(Ht.options.components,na),Ht.prototype.__patch__=V?Cr:z,Ht.prototype.$mount=function(n,e){return function(n,e,t){var i;n.$el=e,n.$options.render||(n.$options.render=hn),nt(n,"beforeMount"),i=function(){n._update(n._render(),t)},new Ke(n,i,z,{before:function(){n._isMounted&&!n._isDestroyed&&nt(n,"beforeUpdate")}},!0),t=!1;var r=n._preWatchers;if(r)for(var a=0;a<r.length;a++)r[a].run();return null==n.$vnode&&(n._isMounted=!0,nt(n,"mounted")),n}(this,n=n&&V?function(n){if("string"==typeof n){var e=document.querySelector(n);return e||document.createElement("div")}return n}(n):void 0,e)},V&&setTimeout((function(){N.devtools&&ln&&ln.emit("init",Ht)}),0);var ta=/[!'()*]/g,ia=function(n){return"%"+n.charCodeAt(0).toString(16)},ra=/%2C/g,aa=function(n){return encodeURIComponent(n).replace(ta,ia).replace(ra,",")};function sa(n){try{return decodeURIComponent(n)}catch(n){0}return n}var la=function(n){return null==n||"object"==typeof n?n:String(n)};function oa(n){var e={};return(n=n.trim().replace(/^(\?|#|&)/,""))?(n.split("&").forEach((function(n){var t=n.replace(/\+/g," ").split("="),i=sa(t.shift()),r=t.length>0?sa(t.join("=")):null;void 0===e[i]?e[i]=r:Array.isArray(e[i])?e[i].push(r):e[i]=[e[i],r]})),e):e}function da(n){var e=n?Object.keys(n).map((function(e){var t=n[e];if(void 0===t)return"";if(null===t)return aa(e);if(Array.isArray(t)){var i=[];return t.forEach((function(n){void 0!==n&&(null===n?i.push(aa(e)):i.push(aa(e)+"="+aa(n)))})),i.join("&")}return aa(e)+"="+aa(t)})).filter((function(n){return n.length>0})).join("&"):null;return e?"?"+e:""}var ca=/\/?$/;function ua(n,e,t,i){var r=i&&i.options.stringifyQuery,a=e.query||{};try{a=pa(a)}catch(n){}var s={name:e.name||n&&n.name,meta:n&&n.meta||{},path:e.path||"/",hash:e.hash||"",query:a,params:e.params||{},fullPath:ga(e,r),matched:n?ha(n):[]};return t&&(s.redirectedFrom=ga(t,r)),Object.freeze(s)}function pa(n){if(Array.isArray(n))return n.map(pa);if(n&&"object"==typeof n){var e={};for(var t in n)e[t]=pa(n[t]);return e}return n}var ma=ua(null,{path:"/"});function ha(n){for(var e=[];n;)e.unshift(n),n=n.parent;return e}function ga(n,e){var t=n.path,i=n.query;void 0===i&&(i={});var r=n.hash;return void 0===r&&(r=""),(t||"/")+(e||da)(i)+r}function fa(n,e,t){return e===ma?n===e:!!e&&(n.path&&e.path?n.path.replace(ca,"")===e.path.replace(ca,"")&&(t||n.hash===e.hash&&ba(n.query,e.query)):!(!n.name||!e.name)&&(n.name===e.name&&(t||n.hash===e.hash&&ba(n.query,e.query)&&ba(n.params,e.params))))}function ba(n,e){if(void 0===n&&(n={}),void 0===e&&(e={}),!n||!e)return n===e;var t=Object.keys(n).sort(),i=Object.keys(e).sort();return t.length===i.length&&t.every((function(t,r){var a=n[t];if(i[r]!==t)return!1;var s=e[t];return null==a||null==s?a===s:"object"==typeof a&&"object"==typeof s?ba(a,s):String(a)===String(s)}))}function va(n){for(var e=0;e<n.matched.length;e++){var t=n.matched[e];for(var i in t.instances){var r=t.instances[i],a=t.enteredCbs[i];if(r&&a){delete t.enteredCbs[i];for(var s=0;s<a.length;s++)r._isBeingDestroyed||a[s](r)}}}}var ya={name:"RouterView",functional:!0,props:{name:{type:String,default:"default"}},render:function(n,e){var t=e.props,i=e.children,r=e.parent,a=e.data;a.routerView=!0;for(var s=r.$createElement,l=t.name,o=r.$route,d=r._routerViewCache||(r._routerViewCache={}),c=0,u=!1;r&&r._routerRoot!==r;){var p=r.$vnode?r.$vnode.data:{};p.routerView&&c++,p.keepAlive&&r._directInactive&&r._inactive&&(u=!0),r=r.$parent}if(a.routerViewDepth=c,u){var m=d[l],h=m&&m.component;return h?(m.configProps&&xa(h,a,m.route,m.configProps),s(h,a,i)):s()}var g=o.matched[c],f=g&&g.components[l];if(!g||!f)return d[l]=null,s();d[l]={component:f},a.registerRouteInstance=function(n,e){var t=g.instances[l];(e&&t!==n||!e&&t===n)&&(g.instances[l]=e)},(a.hook||(a.hook={})).prepatch=function(n,e){g.instances[l]=e.componentInstance},a.hook.init=function(n){n.data.keepAlive&&n.componentInstance&&n.componentInstance!==g.instances[l]&&(g.instances[l]=n.componentInstance),va(o)};var b=g.props&&g.props[l];return b&&(ea(d[l],{route:o,configProps:b}),xa(f,a,o,b)),s(f,a,i)}};function xa(n,e,t,i){var r=e.props=function(n,e){switch(typeof e){case"undefined":return;case"object":return e;case"function":return e(n);case"boolean":return e?n.params:void 0;default:0}}(t,i);if(r){r=e.props=ea({},r);var a=e.attrs=e.attrs||{};for(var s in r)n.props&&s in n.props||(a[s]=r[s],delete r[s])}}function ka(n,e,t){var i=n.charAt(0);if("/"===i)return n;if("?"===i||"#"===i)return e+n;var r=e.split("/");t&&r[r.length-1]||r.pop();for(var a=n.replace(/^\//,"").split("/"),s=0;s<a.length;s++){var l=a[s];".."===l?r.pop():"."!==l&&r.push(l)}return""!==r[0]&&r.unshift(""),r.join("/")}function _a(n){return n.replace(/\/(?:\s*\/)+/g,"/")}var Ea=Array.isArray||function(n){return"[object Array]"==Object.prototype.toString.call(n)},Sa=ja,Ra=La,Ta=function(n,e){return Ca(La(n,e),e)},wa=Ca,Ia=Ma,Aa=new RegExp(["(\\\\.)","([\\/.])?(?:(?:\\:(\\w+)(?:\\(((?:\\\\.|[^\\\\()])+)\\))?|\\(((?:\\\\.|[^\\\\()])+)\\))([+*?])?|(\\*))"].join("|"),"g");function La(n,e){for(var t,i=[],r=0,a=0,s="",l=e&&e.delimiter||"/";null!=(t=Aa.exec(n));){var o=t[0],d=t[1],c=t.index;if(s+=n.slice(a,c),a=c+o.length,d)s+=d[1];else{var u=n[a],p=t[2],m=t[3],h=t[4],g=t[5],f=t[6],b=t[7];s&&(i.push(s),s="");var v=null!=p&&null!=u&&u!==p,y="+"===f||"*"===f,x="?"===f||"*"===f,k=t[2]||l,_=h||g;i.push({name:m||r++,prefix:p||"",delimiter:k,optional:x,repeat:y,partial:v,asterisk:!!b,pattern:_?Da(_):b?".*":"[^"+za(k)+"]+?"})}}return a<n.length&&(s+=n.substr(a)),s&&i.push(s),i}function Ba(n){return encodeURI(n).replace(/[\/?#]/g,(function(n){return"%"+n.charCodeAt(0).toString(16).toUpperCase()}))}function Ca(n,e){for(var t=new Array(n.length),i=0;i<n.length;i++)"object"==typeof n[i]&&(t[i]=new RegExp("^(?:"+n[i].pattern+")$",Oa(e)));return function(e,i){for(var r="",a=e||{},s=(i||{}).pretty?Ba:encodeURIComponent,l=0;l<n.length;l++){var o=n[l];if("string"!=typeof o){var d,c=a[o.name];if(null==c){if(o.optional){o.partial&&(r+=o.prefix);continue}throw new TypeError('Expected "'+o.name+'" to be defined')}if(Ea(c)){if(!o.repeat)throw new TypeError('Expected "'+o.name+'" to not repeat, but received `'+JSON.stringify(c)+"`");if(0===c.length){if(o.optional)continue;throw new TypeError('Expected "'+o.name+'" to not be empty')}for(var u=0;u<c.length;u++){if(d=s(c[u]),!t[l].test(d))throw new TypeError('Expected all "'+o.name+'" to match "'+o.pattern+'", but received `'+JSON.stringify(d)+"`");r+=(0===u?o.prefix:o.delimiter)+d}}else{if(d=o.asterisk?encodeURI(c).replace(/[?#]/g,(function(n){return"%"+n.charCodeAt(0).toString(16).toUpperCase()})):s(c),!t[l].test(d))throw new TypeError('Expected "'+o.name+'" to match "'+o.pattern+'", but received "'+d+'"');r+=o.prefix+d}}else r+=o}return r}}function za(n){return n.replace(/([.+*?=^!:${}()[\]|\/\\])/g,"\\$1")}function Da(n){return n.replace(/([=!:$\/()])/g,"\\$1")}function Pa(n,e){return n.keys=e,n}function Oa(n){return n&&n.sensitive?"":"i"}function Ma(n,e,t){Ea(e)||(t=e||t,e=[]);for(var i=(t=t||{}).strict,r=!1!==t.end,a="",s=0;s<n.length;s++){var l=n[s];if("string"==typeof l)a+=za(l);else{var o=za(l.prefix),d="(?:"+l.pattern+")";e.push(l),l.repeat&&(d+="(?:"+o+d+")*"),a+=d=l.optional?l.partial?o+"("+d+")?":"(?:"+o+"("+d+"))?":o+"("+d+")"}}var c=za(t.delimiter||"/"),u=a.slice(-c.length)===c;return i||(a=(u?a.slice(0,-c.length):a)+"(?:"+c+"(?=$))?"),a+=r?"$":i&&u?"":"(?="+c+"|$)",Pa(new RegExp("^"+a,Oa(t)),e)}function ja(n,e,t){return Ea(e)||(t=e||t,e=[]),t=t||{},n instanceof RegExp?function(n,e){var t=n.source.match(/\((?!\?)/g);if(t)for(var i=0;i<t.length;i++)e.push({name:i,prefix:null,delimiter:null,optional:!1,repeat:!1,partial:!1,asterisk:!1,pattern:null});return Pa(n,e)}(n,e):Ea(n)?function(n,e,t){for(var i=[],r=0;r<n.length;r++)i.push(ja(n[r],e,t).source);return Pa(new RegExp("(?:"+i.join("|")+")",Oa(t)),e)}(n,e,t):function(n,e,t){return Ma(La(n,t),e,t)}(n,e,t)}Sa.parse=Ra,Sa.compile=Ta,Sa.tokensToFunction=wa,Sa.tokensToRegExp=Ia;var Ua=Object.create(null);function $a(n,e,t){e=e||{};try{var i=Ua[n]||(Ua[n]=Sa.compile(n));return"string"==typeof e.pathMatch&&(e[0]=e.pathMatch),i(e,{pretty:!0})}catch(n){return""}finally{delete e[0]}}function Fa(n,e,t,i){var r="string"==typeof n?{path:n}:n;if(r._normalized)return r;if(r.name){var a=(r=ea({},n)).params;return a&&"object"==typeof a&&(r.params=ea({},a)),r}if(!r.path&&r.params&&e){(r=ea({},r))._normalized=!0;var s=ea(ea({},e.params),r.params);if(e.name)r.name=e.name,r.params=s;else if(e.matched.length){var l=e.matched[e.matched.length-1].path;r.path=$a(l,s,e.path)}else 0;return r}var o=function(n){var e="",t="",i=n.indexOf("#");i>=0&&(e=n.slice(i),n=n.slice(0,i));var r=n.indexOf("?");return r>=0&&(t=n.slice(r+1),n=n.slice(0,r)),{path:n,query:t,hash:e}}(r.path||""),d=e&&e.path||"/",c=o.path?ka(o.path,d,t||r.append):d,u=function(n,e,t){void 0===e&&(e={});var i,r=t||oa;try{i=r(n||"")}catch(n){i={}}for(var a in e){var s=e[a];i[a]=Array.isArray(s)?s.map(la):la(s)}return i}(o.query,r.query,i&&i.options.parseQuery),p=r.hash||o.hash;return p&&"#"!==p.charAt(0)&&(p="#"+p),{_normalized:!0,path:c,query:u,hash:p}}var Na,qa=function(){},Ga={name:"RouterLink",props:{to:{type:[String,Object],required:!0},tag:{type:String,default:"a"},custom:Boolean,exact:Boolean,exactPath:Boolean,append:Boolean,replace:Boolean,activeClass:String,exactActiveClass:String,ariaCurrentValue:{type:String,default:"page"},event:{type:[String,Array],default:"click"}},render:function(n){var e=this,t=this.$router,i=this.$route,r=t.resolve(this.to,i,this.append),a=r.location,s=r.route,l=r.href,o={},d=t.options.linkActiveClass,c=t.options.linkExactActiveClass,u=null==d?"router-link-active":d,p=null==c?"router-link-exact-active":c,m=null==this.activeClass?u:this.activeClass,h=null==this.exactActiveClass?p:this.exactActiveClass,g=s.redirectedFrom?ua(null,Fa(s.redirectedFrom),null,t):s;o[h]=fa(i,g,this.exactPath),o[m]=this.exact||this.exactPath?o[h]:function(n,e){return 0===n.path.replace(ca,"/").indexOf(e.path.replace(ca,"/"))&&(!e.hash||n.hash===e.hash)&&function(n,e){for(var t in e)if(!(t in n))return!1;return!0}(n.query,e.query)}(i,g);var f=o[h]?this.ariaCurrentValue:null,b=function(n){Ka(n)&&(e.replace?t.replace(a,qa):t.push(a,qa))},v={click:Ka};Array.isArray(this.event)?this.event.forEach((function(n){v[n]=b})):v[this.event]=b;var y={class:o},x=!this.$scopedSlots.$hasNormal&&this.$scopedSlots.default&&this.$scopedSlots.default({href:l,route:s,navigate:b,isActive:o[m],isExactActive:o[h]});if(x){if(1===x.length)return x[0];if(x.length>1||!x.length)return 0===x.length?n():n("span",{},x)}if("a"===this.tag)y.on=v,y.attrs={href:l,"aria-current":f};else{var k=function n(e){var t;if(e)for(var i=0;i<e.length;i++){if("a"===(t=e[i]).tag)return t;if(t.children&&(t=n(t.children)))return t}}(this.$slots.default);if(k){k.isStatic=!1;var _=k.data=ea({},k.data);for(var E in _.on=_.on||{},_.on){var S=_.on[E];E in v&&(_.on[E]=Array.isArray(S)?S:[S])}for(var R in v)R in _.on?_.on[R].push(v[R]):_.on[R]=b;var T=k.data.attrs=ea({},k.data.attrs);T.href=l,T["aria-current"]=f}else y.on=v}return n(this.tag,y,this.$slots.default)}};function Ka(n){if(!(n.metaKey||n.altKey||n.ctrlKey||n.shiftKey||n.defaultPrevented||void 0!==n.button&&0!==n.button)){if(n.currentTarget&&n.currentTarget.getAttribute){var e=n.currentTarget.getAttribute("target");if(/\b_blank\b/i.test(e))return}return n.preventDefault&&n.preventDefault(),!0}}var Ha="undefined"!=typeof window;function Ja(n,e,t,i,r){var a=e||[],s=t||Object.create(null),l=i||Object.create(null);n.forEach((function(n){!function n(e,t,i,r,a,s){var l=r.path,o=r.name;0;var d=r.pathToRegexpOptions||{},c=function(n,e,t){t||(n=n.replace(/\/$/,""));if("/"===n[0])return n;if(null==e)return n;return _a(e.path+"/"+n)}(l,a,d.strict);"boolean"==typeof r.caseSensitive&&(d.sensitive=r.caseSensitive);var u={path:c,regex:Va(c,d),components:r.components||{default:r.component},alias:r.alias?"string"==typeof r.alias?[r.alias]:r.alias:[],instances:{},enteredCbs:{},name:o,parent:a,matchAs:s,redirect:r.redirect,beforeEnter:r.beforeEnter,meta:r.meta||{},props:null==r.props?{}:r.components?r.props:{default:r.props}};r.children&&r.children.forEach((function(r){var a=s?_a(s+"/"+r.path):void 0;n(e,t,i,r,u,a)}));t[u.path]||(e.push(u.path),t[u.path]=u);if(void 0!==r.alias)for(var p=Array.isArray(r.alias)?r.alias:[r.alias],m=0;m<p.length;++m){0;var h={path:p[m],children:r.children};n(e,t,i,h,a,u.path||"/")}o&&(i[o]||(i[o]=u))}(a,s,l,n,r)}));for(var o=0,d=a.length;o<d;o++)"*"===a[o]&&(a.push(a.splice(o,1)[0]),d--,o--);return{pathList:a,pathMap:s,nameMap:l}}function Va(n,e){return Sa(n,[],e)}function Qa(n,e){var t=Ja(n),i=t.pathList,r=t.pathMap,a=t.nameMap;function s(n,t,s){var l=Fa(n,t,!1,e),d=l.name;if(d){var c=a[d];if(!c)return o(null,l);var u=c.regex.keys.filter((function(n){return!n.optional})).map((function(n){return n.name}));if("object"!=typeof l.params&&(l.params={}),t&&"object"==typeof t.params)for(var p in t.params)!(p in l.params)&&u.indexOf(p)>-1&&(l.params[p]=t.params[p]);return l.path=$a(c.path,l.params),o(c,l,s)}if(l.path){l.params={};for(var m=0;m<i.length;m++){var h=i[m],g=r[h];if(Xa(g.regex,l.path,l.params))return o(g,l,s)}}return o(null,l)}function l(n,t){var i=n.redirect,r="function"==typeof i?i(ua(n,t,null,e)):i;if("string"==typeof r&&(r={path:r}),!r||"object"!=typeof r)return o(null,t);var l=r,d=l.name,c=l.path,u=t.query,p=t.hash,m=t.params;if(u=l.hasOwnProperty("query")?l.query:u,p=l.hasOwnProperty("hash")?l.hash:p,m=l.hasOwnProperty("params")?l.params:m,d){a[d];return s({_normalized:!0,name:d,query:u,hash:p,params:m},void 0,t)}if(c){var h=function(n,e){return ka(n,e.parent?e.parent.path:"/",!0)}(c,n);return s({_normalized:!0,path:$a(h,m),query:u,hash:p},void 0,t)}return o(null,t)}function o(n,t,i){return n&&n.redirect?l(n,i||t):n&&n.matchAs?function(n,e,t){var i=s({_normalized:!0,path:$a(t,e.params)});if(i){var r=i.matched,a=r[r.length-1];return e.params=i.params,o(a,e)}return o(null,e)}(0,t,n.matchAs):ua(n,t,i,e)}return{match:s,addRoute:function(n,e){var t="object"!=typeof n?a[n]:void 0;Ja([e||n],i,r,a,t),t&&t.alias.length&&Ja(t.alias.map((function(n){return{path:n,children:[e]}})),i,r,a,t)},getRoutes:function(){return i.map((function(n){return r[n]}))},addRoutes:function(n){Ja(n,i,r,a)}}}function Xa(n,e,t){var i=e.match(n);if(!i)return!1;if(!t)return!0;for(var r=1,a=i.length;r<a;++r){var s=n.keys[r-1];s&&(t[s.name||"pathMatch"]="string"==typeof i[r]?sa(i[r]):i[r])}return!0}var Wa=Ha&&window.performance&&window.performance.now?window.performance:Date;function Ya(){return Wa.now().toFixed(3)}var Za=Ya();function ns(){return Za}function es(n){return Za=n}var ts=Object.create(null);function is(){"scrollRestoration"in window.history&&(window.history.scrollRestoration="manual");var n=window.location.protocol+"//"+window.location.host,e=window.location.href.replace(n,""),t=ea({},window.history.state);return t.key=ns(),window.history.replaceState(t,"",e),window.addEventListener("popstate",ss),function(){window.removeEventListener("popstate",ss)}}function rs(n,e,t,i){if(n.app){var r=n.options.scrollBehavior;r&&n.app.$nextTick((function(){var a=function(){var n=ns();if(n)return ts[n]}(),s=r.call(n,e,t,i?a:null);s&&("function"==typeof s.then?s.then((function(n){us(n,a)})).catch((function(n){0})):us(s,a))}))}}function as(){var n=ns();n&&(ts[n]={x:window.pageXOffset,y:window.pageYOffset})}function ss(n){as(),n.state&&n.state.key&&es(n.state.key)}function ls(n){return ds(n.x)||ds(n.y)}function os(n){return{x:ds(n.x)?n.x:window.pageXOffset,y:ds(n.y)?n.y:window.pageYOffset}}function ds(n){return"number"==typeof n}var cs=/^#\d/;function us(n,e){var t,i="object"==typeof n;if(i&&"string"==typeof n.selector){var r=cs.test(n.selector)?document.getElementById(n.selector.slice(1)):document.querySelector(n.selector);if(r){var a=n.offset&&"object"==typeof n.offset?n.offset:{};e=function(n,e){var t=document.documentElement.getBoundingClientRect(),i=n.getBoundingClientRect();return{x:i.left-t.left-e.x,y:i.top-t.top-e.y}}(r,a={x:ds((t=a).x)?t.x:0,y:ds(t.y)?t.y:0})}else ls(n)&&(e=os(n))}else i&&ls(n)&&(e=os(n));e&&("scrollBehavior"in document.documentElement.style?window.scrollTo({left:e.x,top:e.y,behavior:n.behavior}):window.scrollTo(e.x,e.y))}var ps,ms=Ha&&((-1===(ps=window.navigator.userAgent).indexOf("Android 2.")&&-1===ps.indexOf("Android 4.0")||-1===ps.indexOf("Mobile Safari")||-1!==ps.indexOf("Chrome")||-1!==ps.indexOf("Windows Phone"))&&window.history&&"function"==typeof window.history.pushState);function hs(n,e){as();var t=window.history;try{if(e){var i=ea({},t.state);i.key=ns(),t.replaceState(i,"",n)}else t.pushState({key:es(Ya())},"",n)}catch(t){window.location[e?"replace":"assign"](n)}}function gs(n){hs(n,!0)}var fs={redirected:2,aborted:4,cancelled:8,duplicated:16};function bs(n,e){return ys(n,e,fs.redirected,'Redirected when going from "'+n.fullPath+'" to "'+function(n){if("string"==typeof n)return n;if("path"in n)return n.path;var e={};return xs.forEach((function(t){t in n&&(e[t]=n[t])})),JSON.stringify(e,null,2)}(e)+'" via a navigation guard.')}function vs(n,e){return ys(n,e,fs.cancelled,'Navigation cancelled from "'+n.fullPath+'" to "'+e.fullPath+'" with a new navigation.')}function ys(n,e,t,i){var r=new Error(i);return r._isRouter=!0,r.from=n,r.to=e,r.type=t,r}var xs=["params","query","hash"];function ks(n){return Object.prototype.toString.call(n).indexOf("Error")>-1}function _s(n,e){return ks(n)&&n._isRouter&&(null==e||n.type===e)}function Es(n,e,t){var i=function(r){r>=n.length?t():n[r]?e(n[r],(function(){i(r+1)})):i(r+1)};i(0)}function Ss(n){return function(e,t,i){var r=!1,a=0,s=null;Rs(n,(function(n,e,t,l){if("function"==typeof n&&void 0===n.cid){r=!0,a++;var o,d=Is((function(e){var r;((r=e).__esModule||ws&&"Module"===r[Symbol.toStringTag])&&(e=e.default),n.resolved="function"==typeof e?e:Na.extend(e),t.components[l]=e,--a<=0&&i()})),c=Is((function(n){var e="Failed to resolve async component "+l+": "+n;s||(s=ks(n)?n:new Error(e),i(s))}));try{o=n(d,c)}catch(n){c(n)}if(o)if("function"==typeof o.then)o.then(d,c);else{var u=o.component;u&&"function"==typeof u.then&&u.then(d,c)}}})),r||i()}}function Rs(n,e){return Ts(n.map((function(n){return Object.keys(n.components).map((function(t){return e(n.components[t],n.instances[t],n,t)}))})))}function Ts(n){return Array.prototype.concat.apply([],n)}var ws="function"==typeof Symbol&&"symbol"==typeof Symbol.toStringTag;function Is(n){var e=!1;return function(){for(var t=[],i=arguments.length;i--;)t[i]=arguments[i];if(!e)return e=!0,n.apply(this,t)}}var As=function(n,e){this.router=n,this.base=function(n){if(!n)if(Ha){var e=document.querySelector("base");n=(n=e&&e.getAttribute("href")||"/").replace(/^https?:\/\/[^\/]+/,"")}else n="/";"/"!==n.charAt(0)&&(n="/"+n);return n.replace(/\/$/,"")}(e),this.current=ma,this.pending=null,this.ready=!1,this.readyCbs=[],this.readyErrorCbs=[],this.errorCbs=[],this.listeners=[]};function Ls(n,e,t,i){var r=Rs(n,(function(n,i,r,a){var s=function(n,e){"function"!=typeof n&&(n=Na.extend(n));return n.options[e]}(n,e);if(s)return Array.isArray(s)?s.map((function(n){return t(n,i,r,a)})):t(s,i,r,a)}));return Ts(i?r.reverse():r)}function Bs(n,e){if(e)return function(){return n.apply(e,arguments)}}As.prototype.listen=function(n){this.cb=n},As.prototype.onReady=function(n,e){this.ready?n():(this.readyCbs.push(n),e&&this.readyErrorCbs.push(e))},As.prototype.onError=function(n){this.errorCbs.push(n)},As.prototype.transitionTo=function(n,e,t){var i,r=this;try{i=this.router.match(n,this.current)}catch(n){throw this.errorCbs.forEach((function(e){e(n)})),n}var a=this.current;this.confirmTransition(i,(function(){r.updateRoute(i),e&&e(i),r.ensureURL(),r.router.afterHooks.forEach((function(n){n&&n(i,a)})),r.ready||(r.ready=!0,r.readyCbs.forEach((function(n){n(i)})))}),(function(n){t&&t(n),n&&!r.ready&&(_s(n,fs.redirected)&&a===ma||(r.ready=!0,r.readyErrorCbs.forEach((function(e){e(n)}))))}))},As.prototype.confirmTransition=function(n,e,t){var i=this,r=this.current;this.pending=n;var a,s,l=function(n){!_s(n)&&ks(n)&&(i.errorCbs.length?i.errorCbs.forEach((function(e){e(n)})):console.error(n)),t&&t(n)},o=n.matched.length-1,d=r.matched.length-1;if(fa(n,r)&&o===d&&n.matched[o]===r.matched[d])return this.ensureURL(),n.hash&&rs(this.router,r,n,!1),l(((s=ys(a=r,n,fs.duplicated,'Avoided redundant navigation to current location: "'+a.fullPath+'".')).name="NavigationDuplicated",s));var c=function(n,e){var t,i=Math.max(n.length,e.length);for(t=0;t<i&&n[t]===e[t];t++);return{updated:e.slice(0,t),activated:e.slice(t),deactivated:n.slice(t)}}(this.current.matched,n.matched),u=c.updated,p=c.deactivated,m=c.activated,h=[].concat(function(n){return Ls(n,"beforeRouteLeave",Bs,!0)}(p),this.router.beforeHooks,function(n){return Ls(n,"beforeRouteUpdate",Bs)}(u),m.map((function(n){return n.beforeEnter})),Ss(m)),g=function(e,t){if(i.pending!==n)return l(vs(r,n));try{e(n,r,(function(e){!1===e?(i.ensureURL(!0),l(function(n,e){return ys(n,e,fs.aborted,'Navigation aborted from "'+n.fullPath+'" to "'+e.fullPath+'" via a navigation guard.')}(r,n))):ks(e)?(i.ensureURL(!0),l(e)):"string"==typeof e||"object"==typeof e&&("string"==typeof e.path||"string"==typeof e.name)?(l(bs(r,n)),"object"==typeof e&&e.replace?i.replace(e):i.push(e)):t(e)}))}catch(n){l(n)}};Es(h,g,(function(){Es(function(n){return Ls(n,"beforeRouteEnter",(function(n,e,t,i){return function(n,e,t){return function(i,r,a){return n(i,r,(function(n){"function"==typeof n&&(e.enteredCbs[t]||(e.enteredCbs[t]=[]),e.enteredCbs[t].push(n)),a(n)}))}}(n,t,i)}))}(m).concat(i.router.resolveHooks),g,(function(){if(i.pending!==n)return l(vs(r,n));i.pending=null,e(n),i.router.app&&i.router.app.$nextTick((function(){va(n)}))}))}))},As.prototype.updateRoute=function(n){this.current=n,this.cb&&this.cb(n)},As.prototype.setupListeners=function(){},As.prototype.teardown=function(){this.listeners.forEach((function(n){n()})),this.listeners=[],this.current=ma,this.pending=null};var Cs=function(n){function e(e,t){n.call(this,e,t),this._startLocation=zs(this.base)}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.setupListeners=function(){var n=this;if(!(this.listeners.length>0)){var e=this.router,t=e.options.scrollBehavior,i=ms&&t;i&&this.listeners.push(is());var r=function(){var t=n.current,r=zs(n.base);n.current===ma&&r===n._startLocation||n.transitionTo(r,(function(n){i&&rs(e,n,t,!0)}))};window.addEventListener("popstate",r),this.listeners.push((function(){window.removeEventListener("popstate",r)}))}},e.prototype.go=function(n){window.history.go(n)},e.prototype.push=function(n,e,t){var i=this,r=this.current;this.transitionTo(n,(function(n){hs(_a(i.base+n.fullPath)),rs(i.router,n,r,!1),e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var i=this,r=this.current;this.transitionTo(n,(function(n){gs(_a(i.base+n.fullPath)),rs(i.router,n,r,!1),e&&e(n)}),t)},e.prototype.ensureURL=function(n){if(zs(this.base)!==this.current.fullPath){var e=_a(this.base+this.current.fullPath);n?hs(e):gs(e)}},e.prototype.getCurrentLocation=function(){return zs(this.base)},e}(As);function zs(n){var e=window.location.pathname,t=e.toLowerCase(),i=n.toLowerCase();return!n||t!==i&&0!==t.indexOf(_a(i+"/"))||(e=e.slice(n.length)),(e||"/")+window.location.search+window.location.hash}var Ds=function(n){function e(e,t,i){n.call(this,e,t),i&&function(n){var e=zs(n);if(!/^\/#/.test(e))return window.location.replace(_a(n+"/#"+e)),!0}(this.base)||Ps()}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.setupListeners=function(){var n=this;if(!(this.listeners.length>0)){var e=this.router.options.scrollBehavior,t=ms&&e;t&&this.listeners.push(is());var i=function(){var e=n.current;Ps()&&n.transitionTo(Os(),(function(i){t&&rs(n.router,i,e,!0),ms||Us(i.fullPath)}))},r=ms?"popstate":"hashchange";window.addEventListener(r,i),this.listeners.push((function(){window.removeEventListener(r,i)}))}},e.prototype.push=function(n,e,t){var i=this,r=this.current;this.transitionTo(n,(function(n){js(n.fullPath),rs(i.router,n,r,!1),e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var i=this,r=this.current;this.transitionTo(n,(function(n){Us(n.fullPath),rs(i.router,n,r,!1),e&&e(n)}),t)},e.prototype.go=function(n){window.history.go(n)},e.prototype.ensureURL=function(n){var e=this.current.fullPath;Os()!==e&&(n?js(e):Us(e))},e.prototype.getCurrentLocation=function(){return Os()},e}(As);function Ps(){var n=Os();return"/"===n.charAt(0)||(Us("/"+n),!1)}function Os(){var n=window.location.href,e=n.indexOf("#");return e<0?"":n=n.slice(e+1)}function Ms(n){var e=window.location.href,t=e.indexOf("#");return(t>=0?e.slice(0,t):e)+"#"+n}function js(n){ms?hs(Ms(n)):window.location.hash=n}function Us(n){ms?gs(Ms(n)):window.location.replace(Ms(n))}var $s=function(n){function e(e,t){n.call(this,e,t),this.stack=[],this.index=-1}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.push=function(n,e,t){var i=this;this.transitionTo(n,(function(n){i.stack=i.stack.slice(0,i.index+1).concat(n),i.index++,e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var i=this;this.transitionTo(n,(function(n){i.stack=i.stack.slice(0,i.index).concat(n),e&&e(n)}),t)},e.prototype.go=function(n){var e=this,t=this.index+n;if(!(t<0||t>=this.stack.length)){var i=this.stack[t];this.confirmTransition(i,(function(){var n=e.current;e.index=t,e.updateRoute(i),e.router.afterHooks.forEach((function(e){e&&e(i,n)}))}),(function(n){_s(n,fs.duplicated)&&(e.index=t)}))}},e.prototype.getCurrentLocation=function(){var n=this.stack[this.stack.length-1];return n?n.fullPath:"/"},e.prototype.ensureURL=function(){},e}(As),Fs=function(n){void 0===n&&(n={}),this.app=null,this.apps=[],this.options=n,this.beforeHooks=[],this.resolveHooks=[],this.afterHooks=[],this.matcher=Qa(n.routes||[],this);var e=n.mode||"hash";switch(this.fallback="history"===e&&!ms&&!1!==n.fallback,this.fallback&&(e="hash"),Ha||(e="abstract"),this.mode=e,e){case"history":this.history=new Cs(this,n.base);break;case"hash":this.history=new Ds(this,n.base,this.fallback);break;case"abstract":this.history=new $s(this,n.base);break;default:0}},Ns={currentRoute:{configurable:!0}};Fs.prototype.match=function(n,e,t){return this.matcher.match(n,e,t)},Ns.currentRoute.get=function(){return this.history&&this.history.current},Fs.prototype.init=function(n){var e=this;if(this.apps.push(n),n.$once("hook:destroyed",(function(){var t=e.apps.indexOf(n);t>-1&&e.apps.splice(t,1),e.app===n&&(e.app=e.apps[0]||null),e.app||e.history.teardown()})),!this.app){this.app=n;var t=this.history;if(t instanceof Cs||t instanceof Ds){var i=function(n){t.setupListeners(),function(n){var i=t.current,r=e.options.scrollBehavior;ms&&r&&"fullPath"in n&&rs(e,n,i,!1)}(n)};t.transitionTo(t.getCurrentLocation(),i,i)}t.listen((function(n){e.apps.forEach((function(e){e._route=n}))}))}},Fs.prototype.beforeEach=function(n){return Gs(this.beforeHooks,n)},Fs.prototype.beforeResolve=function(n){return Gs(this.resolveHooks,n)},Fs.prototype.afterEach=function(n){return Gs(this.afterHooks,n)},Fs.prototype.onReady=function(n,e){this.history.onReady(n,e)},Fs.prototype.onError=function(n){this.history.onError(n)},Fs.prototype.push=function(n,e,t){var i=this;if(!e&&!t&&"undefined"!=typeof Promise)return new Promise((function(e,t){i.history.push(n,e,t)}));this.history.push(n,e,t)},Fs.prototype.replace=function(n,e,t){var i=this;if(!e&&!t&&"undefined"!=typeof Promise)return new Promise((function(e,t){i.history.replace(n,e,t)}));this.history.replace(n,e,t)},Fs.prototype.go=function(n){this.history.go(n)},Fs.prototype.back=function(){this.go(-1)},Fs.prototype.forward=function(){this.go(1)},Fs.prototype.getMatchedComponents=function(n){var e=n?n.matched?n:this.resolve(n).route:this.currentRoute;return e?[].concat.apply([],e.matched.map((function(n){return Object.keys(n.components).map((function(e){return n.components[e]}))}))):[]},Fs.prototype.resolve=function(n,e,t){var i=Fa(n,e=e||this.history.current,t,this),r=this.match(i,e),a=r.redirectedFrom||r.fullPath;return{location:i,route:r,href:function(n,e,t){var i="hash"===t?"#"+e:e;return n?_a(n+"/"+i):i}(this.history.base,a,this.mode),normalizedTo:i,resolved:r}},Fs.prototype.getRoutes=function(){return this.matcher.getRoutes()},Fs.prototype.addRoute=function(n,e){this.matcher.addRoute(n,e),this.history.current!==ma&&this.history.transitionTo(this.history.getCurrentLocation())},Fs.prototype.addRoutes=function(n){this.matcher.addRoutes(n),this.history.current!==ma&&this.history.transitionTo(this.history.getCurrentLocation())},Object.defineProperties(Fs.prototype,Ns);var qs=Fs;function Gs(n,e){return n.push(e),function(){var t=n.indexOf(e);t>-1&&n.splice(t,1)}}Fs.install=function n(e){if(!n.installed||Na!==e){n.installed=!0,Na=e;var t=function(n){return void 0!==n},i=function(n,e){var i=n.$options._parentVnode;t(i)&&t(i=i.data)&&t(i=i.registerRouteInstance)&&i(n,e)};e.mixin({beforeCreate:function(){t(this.$options.router)?(this._routerRoot=this,this._router=this.$options.router,this._router.init(this),e.util.defineReactive(this,"_route",this._router.history.current)):this._routerRoot=this.$parent&&this.$parent._routerRoot||this,i(this,this)},destroyed:function(){i(this)}}),Object.defineProperty(e.prototype,"$router",{get:function(){return this._routerRoot._router}}),Object.defineProperty(e.prototype,"$route",{get:function(){return this._routerRoot._route}}),e.component("RouterView",ya),e.component("RouterLink",Ga);var r=e.config.optionMergeStrategies;r.beforeRouteEnter=r.beforeRouteLeave=r.beforeRouteUpdate=r.created}},Fs.version="3.6.5",Fs.isNavigationFailure=_s,Fs.NavigationFailureType=fs,Fs.START_LOCATION=ma,Ha&&window.Vue&&window.Vue.use(Fs);t(105);t(17),t(132);var Ks={NotFound:()=>Promise.all([t.e(0),t.e(4)]).then(t.bind(null,339)),Layout:()=>Promise.all([t.e(0),t.e(2)]).then(t.bind(null,338))},Hs={"v-6933ae78":()=>t.e(5).then(t.bind(null,340)),"v-6629cfe6":()=>t.e(6).then(t.bind(null,341)),"v-2969cc26":()=>t.e(7).then(t.bind(null,342)),"v-eaab9570":()=>t.e(8).then(t.bind(null,343)),"v-007ca368":()=>t.e(9).then(t.bind(null,344)),"v-36d5ec98":()=>t.e(10).then(t.bind(null,345)),"v-18e88d58":()=>t.e(11).then(t.bind(null,346)),"v-60064de7":()=>t.e(12).then(t.bind(null,347)),"v-179fad57":()=>t.e(13).then(t.bind(null,348)),"v-3fdec0bd":()=>t.e(14).then(t.bind(null,349)),"v-53104ef6":()=>t.e(15).then(t.bind(null,350)),"v-1a9d53e5":()=>t.e(16).then(t.bind(null,351)),"v-150b83f6":()=>t.e(17).then(t.bind(null,352)),"v-517069f0":()=>t.e(18).then(t.bind(null,353)),"v-74cfb0b2":()=>t.e(19).then(t.bind(null,354)),"v-a113e2c4":()=>t.e(20).then(t.bind(null,355)),"v-6962c4c2":()=>t.e(21).then(t.bind(null,356)),"v-a6ed5612":()=>t.e(22).then(t.bind(null,357)),"v-2778bd58":()=>t.e(23).then(t.bind(null,358)),"v-31581127":()=>t.e(24).then(t.bind(null,359)),"v-c2ced796":()=>t.e(25).then(t.bind(null,360)),"v-3fe17966":()=>t.e(26).then(t.bind(null,361)),"v-0b361225":()=>t.e(27).then(t.bind(null,362)),"v-68306418":()=>t.e(28).then(t.bind(null,363)),"v-6c981036":()=>t.e(29).then(t.bind(null,364)),"v-1a140cfc":()=>t.e(30).then(t.bind(null,365)),"v-29b8baff":()=>t.e(31).then(t.bind(null,366)),"v-2a85a268":()=>t.e(32).then(t.bind(null,367)),"v-ad649dc2":()=>t.e(33).then(t.bind(null,368)),"v-3aa5fefb":()=>t.e(34).then(t.bind(null,369)),"v-35ef0b3a":()=>t.e(35).then(t.bind(null,370)),"v-2f859720":()=>t.e(36).then(t.bind(null,371)),"v-3622e3e6":()=>t.e(37).then(t.bind(null,372)),"v-c6d294b8":()=>t.e(38).then(t.bind(null,373)),"v-aa603976":()=>t.e(39).then(t.bind(null,374)),"v-1823a466":()=>t.e(40).then(t.bind(null,375)),"v-55200187":()=>t.e(41).then(t.bind(null,376)),"v-66f73835":()=>t.e(42).then(t.bind(null,377)),"v-7482ba20":()=>t.e(43).then(t.bind(null,378)),"v-2c529f3a":()=>t.e(44).then(t.bind(null,379)),"v-76fe5474":()=>t.e(45).then(t.bind(null,380)),"v-24aa3866":()=>t.e(46).then(t.bind(null,381)),"v-18bc1557":()=>t.e(47).then(t.bind(null,382)),"v-4fda8213":()=>t.e(48).then(t.bind(null,383)),"v-c45fcee4":()=>t.e(49).then(t.bind(null,384)),"v-e36601e4":()=>t.e(50).then(t.bind(null,385)),"v-1ae0a658":()=>t.e(51).then(t.bind(null,386)),"v-97c51d34":()=>t.e(52).then(t.bind(null,387)),"v-02285212":()=>t.e(53).then(t.bind(null,388)),"v-2bcd0941":()=>t.e(54).then(t.bind(null,389)),"v-6e3c4c48":()=>t.e(55).then(t.bind(null,390)),"v-2d5f867f":()=>t.e(56).then(t.bind(null,391)),"v-7a34202e":()=>t.e(57).then(t.bind(null,392)),"v-ac009106":()=>t.e(58).then(t.bind(null,393)),"v-31ed6925":()=>t.e(59).then(t.bind(null,394)),"v-45526b4e":()=>t.e(60).then(t.bind(null,395)),"v-11669a46":()=>t.e(61).then(t.bind(null,396)),"v-2c0bb97b":()=>t.e(62).then(t.bind(null,397)),"v-43f0e09d":()=>t.e(63).then(t.bind(null,398)),"v-2b382624":()=>t.e(64).then(t.bind(null,399)),"v-36c9cb62":()=>t.e(65).then(t.bind(null,400)),"v-7e68add3":()=>t.e(66).then(t.bind(null,401)),"v-087079a8":()=>t.e(67).then(t.bind(null,402)),"v-b1a79552":()=>t.e(68).then(t.bind(null,403)),"v-433c42bb":()=>t.e(69).then(t.bind(null,404)),"v-4f80c998":()=>t.e(70).then(t.bind(null,405)),"v-3161e9d4":()=>t.e(71).then(t.bind(null,406)),"v-78a8ae4e":()=>t.e(72).then(t.bind(null,407)),"v-147908a9":()=>t.e(73).then(t.bind(null,408)),"v-f49e53d6":()=>t.e(74).then(t.bind(null,409)),"v-00a73f02":()=>t.e(75).then(t.bind(null,410)),"v-cafc5bfe":()=>t.e(76).then(t.bind(null,411)),"v-53b20642":()=>t.e(77).then(t.bind(null,412)),"v-623e7b3d":()=>t.e(78).then(t.bind(null,413)),"v-551cf7ff":()=>t.e(79).then(t.bind(null,414))};function Js(n){const e=Object.create(null);return function(t){return e[t]||(e[t]=n(t))}}const Vs=/-(\w)/g,Qs=Js(n=>n.replace(Vs,(n,e)=>e?e.toUpperCase():"")),Xs=/\B([A-Z])/g,Ws=Js(n=>n.replace(Xs,"-$1").toLowerCase()),Ys=Js(n=>n.charAt(0).toUpperCase()+n.slice(1));function Zs(n,e){if(!e)return;if(n(e))return n(e);return e.includes("-")?n(Ys(Qs(e))):n(Ys(e))||n(Ws(e))}const nl=Object.assign({},Ks,Hs),el=n=>nl[n],tl=n=>Hs[n],il=n=>Ks[n],rl=n=>Ht.component(n);function al(n){return Zs(tl,n)}function sl(n){return Zs(il,n)}function ll(n){return Zs(el,n)}function ol(n){return Zs(rl,n)}function dl(...n){return Promise.all(n.filter(n=>n).map(async n=>{if(!ol(n)&&ll(n)){const e=await ll(n)();Ht.component(n,e.default)}}))}function cl(n,e){"undefined"!=typeof window&&window.__VUEPRESS__&&(window.__VUEPRESS__[n]=e)}var ul=t(93),pl=t.n(ul),ml=t(94),hl=t.n(ml),gl={created(){if(this.siteMeta=this.$site.headTags.filter(([n])=>"meta"===n).map(([n,e])=>e),this.$ssrContext){const e=this.getMergedMetaTags();this.$ssrContext.title=this.$title,this.$ssrContext.lang=this.$lang,this.$ssrContext.pageMeta=(n=e)?n.map(n=>{let e="<meta";return Object.keys(n).forEach(t=>{e+=` ${t}="${hl()(n[t])}"`}),e+">"}).join("\n    "):"",this.$ssrContext.canonicalLink=bl(this.$canonicalUrl)}var n},mounted(){this.currentMetaTags=[...document.querySelectorAll("meta")],this.updateMeta(),this.updateCanonicalLink()},methods:{updateMeta(){document.title=this.$title,document.documentElement.lang=this.$lang;const n=this.getMergedMetaTags();this.currentMetaTags=vl(n,this.currentMetaTags)},getMergedMetaTags(){const n=this.$page.frontmatter.meta||[];return pl()([{name:"description",content:this.$description}],n,this.siteMeta,yl)},updateCanonicalLink(){fl(),this.$canonicalUrl&&document.head.insertAdjacentHTML("beforeend",bl(this.$canonicalUrl))}},watch:{$page(){this.updateMeta(),this.updateCanonicalLink()}},beforeDestroy(){vl(null,this.currentMetaTags),fl()}};function fl(){const n=document.querySelector("link[rel='canonical']");n&&n.remove()}function bl(n=""){return n?`<link href="${n}" rel="canonical" />`:""}function vl(n,e){if(e&&[...e].filter(n=>n.parentNode===document.head).forEach(n=>document.head.removeChild(n)),n)return n.map(n=>{const e=document.createElement("meta");return Object.keys(n).forEach(t=>{e.setAttribute(t,n[t])}),document.head.appendChild(e),e})}function yl(n){for(const e of["name","property","itemprop"])if(n.hasOwnProperty(e))return n[e]+e;return JSON.stringify(n)}var xl=t(51),kl={mounted(){window.addEventListener("scroll",this.onScroll)},methods:{onScroll:t.n(xl)()((function(){this.setActiveHash()}),300),setActiveHash(){const n=[].slice.call(document.querySelectorAll(".sidebar-link")),e=[].slice.call(document.querySelectorAll(".header-anchor")).filter(e=>n.some(n=>n.hash===e.hash)),t=Math.max(window.pageYOffset,document.documentElement.scrollTop,document.body.scrollTop),i=Math.max(document.documentElement.scrollHeight,document.body.scrollHeight),r=window.innerHeight+t;for(let n=0;n<e.length;n++){const a=e[n],s=e[n+1],l=0===n&&0===t||t>=a.parentElement.offsetTop+10&&(!s||t<s.parentElement.offsetTop-10),o=decodeURIComponent(this.$route.hash);if(l&&o!==decodeURIComponent(a.hash)){const t=a;if(r===i)for(let t=n+1;t<e.length;t++)if(o===decodeURIComponent(e[t].hash))return;return this.$vuepress.$set("disableScrollBehavior",!0),void this.$router.replace(decodeURIComponent(t.hash),()=>{this.$nextTick(()=>{this.$vuepress.$set("disableScrollBehavior",!1)})})}}}},beforeDestroy(){window.removeEventListener("scroll",this.onScroll)}},_l=t(26),El=t.n(_l),Sl={mounted(){El.a.configure({showSpinner:!1}),this.$router.beforeEach((n,e,t)=>{n.path===e.path||Ht.component(n.name)||El.a.start(),t()}),this.$router.afterEach(()=>{El.a.done(),this.isSidebarOpen=!1})}};t(241),t(242);class Rl{constructor(){this.containerEl=document.getElementById("message-container"),this.containerEl||(this.containerEl=document.createElement("div"),this.containerEl.id="message-container",document.body.appendChild(this.containerEl))}show({text:n="",duration:e=3e3}){let t=document.createElement("div");t.className="message move-in",t.innerHTML=`\n      <i style="fill: #06a35a;font-size: 14px;display:inline-flex;align-items: center;">\n        <svg style="fill: #06a35a;font-size: 14px;" t="1572421810237" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2323" width="16" height="16"><path d="M822.811993 824.617989c-83.075838 81.99224-188.546032 124.613757-316.049383 127.86455-122.085362-3.250794-223.943563-45.87231-305.935802-127.86455s-124.613757-184.21164-127.86455-305.935802c3.250794-127.503351 45.87231-232.973545 127.86455-316.049383 81.99224-83.075838 184.21164-126.058554 305.935802-129.309347 127.503351 3.250794 232.973545 46.23351 316.049383 129.309347 83.075838 83.075838 126.058554 188.546032 129.309347 316.049383C949.231746 640.406349 905.887831 742.62575 822.811993 824.617989zM432.716755 684.111464c3.973192 3.973192 8.307584 5.779189 13.364374 6.140388 5.05679 0.361199 9.752381-1.444797 13.364374-5.417989l292.571429-287.514638c3.973192-3.973192 5.779189-8.307584 5.779189-13.364374 0-5.05679-1.805996-9.752381-5.779189-13.364374l1.805996 1.805996c-3.973192-3.973192-8.668783-5.779189-14.086772-6.140388-5.417989-0.361199-10.47478 1.444797-14.809171 5.417989l-264.397884 220.33157c-3.973192 3.250794-8.668783 4.695591-14.447972 4.695591-5.779189 0-10.835979-1.444797-15.53157-3.973192l-94.273016-72.962257c-4.334392-3.250794-9.391182-4.334392-14.447972-3.973192s-9.391182 3.250794-12.641975 7.585185l-2.889594 3.973192c-3.250794 4.334392-4.334392 9.391182-3.973192 14.809171 0.722399 5.417989 2.528395 10.11358 5.779189 14.086772L432.716755 684.111464z" p-id="2324"></path></svg>\n      </i>\n      <div class="text">${n}</div>\n    `,this.containerEl.appendChild(t),e>0&&setTimeout(()=>{this.close(t)},e)}close(n){n.className=n.className.replace("move-in",""),n.className+="move-out",n.addEventListener("animationend",()=>{n.remove()})}}var Tl={mounted(){!!/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)||this.updateCopy()},updated(){!!/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)||this.updateCopy()},methods:{updateCopy(){setTimeout(()=>{(['div[class*="language-"] pre','div[class*="aside-code"] aside']instanceof Array||Array.isArray(['div[class*="language-"] pre','div[class*="aside-code"] aside']))&&['div[class*="language-"] pre','div[class*="aside-code"] aside'].forEach(n=>{document.querySelectorAll(n).forEach(this.generateCopyButton)})},1e3)},generateCopyButton(n){if(n.classList.contains("codecopy-enabled"))return;const e=document.createElement("i");e.className="code-copy",e.innerHTML='<svg  style="color:#aaa;font-size:14px" t="1572422231464" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3201" width="14" height="14"><path d="M866.461538 39.384615H354.461538c-43.323077 0-78.769231 35.446154-78.76923 78.769231v39.384616h472.615384c43.323077 0 78.769231 35.446154 78.769231 78.76923v551.384616h39.384615c43.323077 0 78.769231-35.446154 78.769231-78.769231V118.153846c0-43.323077-35.446154-78.769231-78.769231-78.769231z m-118.153846 275.692308c0-43.323077-35.446154-78.769231-78.76923-78.769231H157.538462c-43.323077 0-78.769231 35.446154-78.769231 78.769231v590.769231c0 43.323077 35.446154 78.769231 78.769231 78.769231h512c43.323077 0 78.769231-35.446154 78.76923-78.769231V315.076923z m-354.461538 137.846154c0 11.815385-7.876923 19.692308-19.692308 19.692308h-157.538461c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h157.538461c11.815385 0 19.692308 7.876923 19.692308 19.692308v39.384615z m157.538461 315.076923c0 11.815385-7.876923 19.692308-19.692307 19.692308H216.615385c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h315.076923c11.815385 0 19.692308 7.876923 19.692307 19.692308v39.384615z m78.769231-157.538462c0 11.815385-7.876923 19.692308-19.692308 19.692308H216.615385c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h393.846153c11.815385 0 19.692308 7.876923 19.692308 19.692308v39.384615z" p-id="3202"></path></svg>',e.title="Copy to clipboard",e.addEventListener("click",()=>{this.copyToClipboard(n.innerText)}),n.appendChild(e),n.classList.add("codecopy-enabled")},copyToClipboard(n){const e=document.createElement("textarea");e.value=n,e.setAttribute("readonly",""),e.style.position="absolute",e.style.left="-9999px",document.body.appendChild(e);const t=document.getSelection().rangeCount>0&&document.getSelection().getRangeAt(0);e.select(),document.execCommand("copy");(new Rl).show({text:"复制成功",duration:1e3}),document.body.removeChild(e),t&&(document.getSelection().removeAllRanges(),document.getSelection().addRange(t))}}};!function(n,e){void 0===e&&(e={});var t=e.insertAt;if(n&&"undefined"!=typeof document){var i=document.head||document.getElementsByTagName("head")[0],r=document.createElement("style");r.type="text/css","top"===t&&i.firstChild?i.insertBefore(r,i.firstChild):i.appendChild(r),r.styleSheet?r.styleSheet.cssText=n:r.appendChild(document.createTextNode(n))}}("@media (max-width: 1000px) {\n  .vuepress-plugin-demo-block__h_code {\n    display: none;\n  }\n  .vuepress-plugin-demo-block__app {\n    margin-left: auto !important;\n    margin-right: auto !important;\n  }\n}\n.vuepress-plugin-demo-block__wrapper {\n  margin-top: 10px;\n  border: 1px solid #ebebeb;\n  border-radius: 4px;\n  transition: all 0.2s;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display {\n  height: 400px;\n  display: flex;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__app {\n  width: 300px;\n  border: 1px solid #ebebeb;\n  box-shadow: 1px 1px 3px #ebebeb;\n  margin-right: 5px;\n  overflow: auto;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__h_code {\n  flex: 1;\n  overflow: auto;\n  height: 100%;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__h_code > pre {\n  overflow: visible;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__display {\n  max-height: 400px;\n  overflow: auto;\n}\n.vuepress-plugin-demo-block__wrapper div {\n  box-sizing: border-box;\n}\n.vuepress-plugin-demo-block__wrapper:hover {\n  box-shadow: 0 0 11px rgba(33, 33, 33, 0.2);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__code {\n  overflow: hidden;\n  height: 0;\n  padding: 0 !important;\n  background-color: #282c34;\n  border-radius: 0 !important;\n  transition: height 0.5s;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__code pre {\n  margin: 0 !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__display {\n  padding: 20px;\n  border-bottom: 1px solid #ebebeb;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer {\n  position: relative;\n  text-align: center;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__codepen {\n  opacity: 1;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__expand::before {\n  border-top: none;\n  border-right: 6px solid transparent;\n  border-bottom: 6px solid #ccc;\n  border-left: 6px solid transparent;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__codepen,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand span,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand {\n  opacity: 1;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand::before {\n  border-top-color: #3eaf7c !important;\n  border-bottom-color: #3eaf7c !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover svg {\n  fill: #3eaf7c !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand-text {\n  transition: all 0.5s;\n  opacity: 0;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer form:nth-last-child(2) {\n  right: 50px;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer form:last-child {\n  right: 10px;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button {\n  border-color: transparent;\n  background-color: transparent;\n  font-size: 14px;\n  color: #3eaf7c;\n  cursor: pointer;\n  outline: none;\n  margin: 0;\n  width: 46px;\n  position: relative;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button:hover::before {\n  content: attr(data-tip);\n  white-space: nowrap;\n  position: absolute;\n  top: -30px;\n  left: 50%;\n  color: #eee;\n  line-height: 1;\n  z-index: 1000;\n  border-radius: 4px;\n  padding: 6px;\n  -webkit-transform: translateX(-50%);\n          transform: translateX(-50%);\n  background-color: rgba(0, 0, 0, 0.8);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button:hover::after {\n  content: '' !important;\n  display: block;\n  position: absolute;\n  left: 50%;\n  top: -5px;\n  -webkit-transform: translateX(-50%);\n          transform: translateX(-50%);\n  border: 5px solid transparent;\n  border-top-color: rgba(0, 0, 0, 0.8);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button svg {\n  width: 34px;\n  height: 20px;\n  fill: #ccc;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__codepen {\n  position: absolute;\n  top: 10px;\n  transition: all 0.5s;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand {\n  position: relative;\n  width: 100px;\n  height: 40px;\n  margin: 0;\n  color: #3eaf7c;\n  font-size: 14px;\n  background-color: transparent;\n  border-color: transparent;\n  outline: none;\n  transition: all 0.5s;\n  cursor: pointer;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand::before {\n  content: \"\";\n  position: absolute;\n  top: 50%;\n  left: 50%;\n  width: 0;\n  height: 0;\n  border-top: 6px solid #ccc;\n  border-right: 6px solid transparent;\n  border-left: 6px solid transparent;\n  -webkit-transform: translate(-50%, -50%);\n          transform: translate(-50%, -50%);\n}\n");var wl={jsLib:[],cssLib:[],jsfiddle:!0,codepen:!0,codepenLayout:"left",codepenJsProcessor:"babel",codepenEditors:"101",horizontal:!1,vue:"https://cdn.jsdelivr.net/npm/vue/dist/vue.min.js",react:"https://cdn.jsdelivr.net/npm/react/umd/react.production.min.js",reactDOM:"https://cdn.jsdelivr.net/npm/react-dom/umd/react-dom.production.min.js"},Il={},Al=function(n){return'<div id="app">\n'.concat(n,"\n</div>")},Ll=function(n){return window.$VUEPRESS_DEMO_BLOCK&&void 0!==window.$VUEPRESS_DEMO_BLOCK[n]?window.$VUEPRESS_DEMO_BLOCK[n]:wl[n]},Bl=function n(e,t,i){var r=document.createElement(e);return t&&Object.keys(t).forEach((function(n){if(n.indexOf("data"))r[n]=t[n];else{var e=n.replace("data","");r.dataset[e]=t[n]}})),i&&i.forEach((function(e){var t=e.tag,i=e.attrs,a=e.children;r.appendChild(n(t,i,a))})),r},Cl=function(n,e,t){var i,r=(i=n.querySelectorAll(".".concat(e)),Array.prototype.slice.call(i));return 1!==r.length||t?r:r[0]},zl=function(n,e){var t,i,r=n.match(/<style>([\s\S]+)<\/style>/),a=n.match(/<template>([\s\S]+)<\/template>/),s=n.match(/<script>([\s\S]+)<\/script>/),l={css:r&&r[1].replace(/^\n|\n$/g,""),html:a&&a[1].replace(/^\n|\n$/g,""),js:s&&s[1].replace(/^\n|\n$/g,""),jsLib:e.jsLib||[],cssLib:e.cssLib||[]};l.htmlTpl=Al(l.html),l.jsTpl=(t=l.js,i=t.replace(/export\s+default\s*?\{\n*/,"").replace(/\n*\}\s*$/,"").trim(),"new Vue({\n  el: '#app',\n  ".concat(i,"\n})")),l.script=function(n,e){var t=n.split(/export\s+default/),i="(function() {".concat(t[0]," ; return ").concat(t[1],"})()"),r=window.Babel?window.Babel.transform(i,{presets:["es2015"]}).code:i,a=[eval][0](r);return a.template=e,a}(l.js,l.html);var o=Ll("vue");return l.jsLib.unshift(o),l},Dl=function(n,e){var t,i=n.match(/<style>([\s\S]+)<\/style>/),r=n.match(/<html>([\s\S]+)<\/html>/),a=n.match(/<script>([\s\S]+)<\/script>/),s={css:i&&i[1].replace(/^\n|\n$/g,""),html:r&&r[1].replace(/^\n|\n$/g,""),js:a&&a[1].replace(/^\n|\n$/g,""),jsLib:e.jsLib||[],cssLib:e.cssLib||[]};return s.htmlTpl=s.html,s.jsTpl=s.js,s.script=(t=s.js,window.Babel?window.Babel.transform(t,{presets:["es2015"]}).code:t),s},Pl=function(n){return n=n.replace("export default ","").replace(/App\.__style__(\s*)=(\s*)`([\s\S]*)?`/,""),n+='ReactDOM.render(React.createElement(App), document.getElementById("app"))'};function Ol(){var n=Cl(document,"vuepress-plugin-demo-block__wrapper",!0);n.length?n.forEach((function(n){if("true"!==n.dataset.created){n.style.display="block";var e=Cl(n,"vuepress-plugin-demo-block__code"),t=Cl(n,"vuepress-plugin-demo-block__display"),i=Cl(n,"vuepress-plugin-demo-block__footer"),r=Cl(t,"vuepress-plugin-demo-block__app"),a=decodeURIComponent(n.dataset.code),s=decodeURIComponent(n.dataset.config),l=decodeURIComponent(n.dataset.type);s=s?JSON.parse(s):{};var o=e.querySelector("div").clientHeight,d="react"===l?function(n,e){var t=(0,window.Babel.transform)(n,{presets:["es2015","react"]}).code,i="(function(exports){var module={};module.exports=exports;".concat(t,";return module.exports.__esModule?module.exports.default:module.exports;})({})"),r=new Function("return ".concat(i))(),a={js:r,css:r.__style__||"",jsLib:e.jsLib||[],cssLib:e.cssLib||[],jsTpl:Pl(n),htmlTpl:Al("")},s=Ll("react"),l=Ll("reactDOM");return a.jsLib.unshift(s,l),a}(a,s):"vanilla"===l?Dl(a,s):zl(a,s),c=Bl("button",{className:"".concat("vuepress-plugin-demo-block__expand")});if(i.appendChild(c),c.addEventListener("click",Ml.bind(null,c,o,e,i)),Ll("jsfiddle")&&i.appendChild(function(n){var e=n.css,t=n.htmlTpl,i=n.jsTpl,r=n.jsLib,a=n.cssLib,s=r.concat(a).concat(Ll("cssLib")).concat(Ll("jsLib")).join(",");return Bl("form",{className:"vuepress-plugin-demo-block__jsfiddle",target:"_blank",action:"https://jsfiddle.net/api/post/library/pure/",method:"post"},[{tag:"input",attrs:{type:"hidden",name:"css",value:e}},{tag:"input",attrs:{type:"hidden",name:"html",value:t}},{tag:"input",attrs:{type:"hidden",name:"js",value:i}},{tag:"input",attrs:{type:"hidden",name:"panel_js",value:3}},{tag:"input",attrs:{type:"hidden",name:"wrap",value:1}},{tag:"input",attrs:{type:"hidden",name:"resources",value:s}},{tag:"button",attrs:{type:"submit",className:"vuepress-plugin-demo-block__button",innerHTML:'<?xml version="1.0" standalone="no"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg t="1547088289967" class="icon" style="" viewBox="0 0 1170 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1952" xmlns:xlink="http://www.w3.org/1999/xlink" width="228.515625" height="200"><defs><style type="text/css"></style></defs><path d="M1028.571429 441.142857q63.428571 26.285714 102.571428 83.142857T1170.285714 650.857143q0 93.714286-67.428571 160.285714T940 877.714286q-2.285714 0-6.571429-0.285715t-6-0.285714H232q-97.142857-5.714286-164.571429-71.714286T0 645.142857q0-62.857143 31.428571-116t84-84q-6.857143-22.285714-6.857142-46.857143 0-65.714286 46.857142-112t113.714286-46.285714q54.285714 0 98.285714 33.142857 42.857143-88 127.142858-141.714286t186.571428-53.714285q94.857143 0 174.857143 46T982.571429 248.571429t46.571428 172q0 3.428571-0.285714 10.285714t-0.285714 10.285714zM267.428571 593.142857q0 69.714286 48 110.285714t118.857143 40.571429q78.285714 0 137.142857-56.571429-9.142857-11.428571-27.142857-32.285714T519.428571 626.285714q-38.285714 37.142857-82.285714 37.142857-31.428571 0-53.428571-19.142857T361.714286 594.285714q0-30.285714 22-49.714285t52.285714-19.428572q25.142857 0 48.285714 12t41.714286 31.428572 37.142857 42.857142 39.428572 46.857143 44 42.857143 55.428571 31.428572 69.428571 12q69.142857 0 116.857143-40.857143T936 594.857143q0-69.142857-48-109.714286t-118.285714-40.571428q-81.714286 0-137.714286 55.428571l53.142857 61.714286q37.714286-36.571429 81.142857-36.571429 29.714286 0 52.571429 18.857143t22.857143 48q0 32.571429-21.142857 52.285714t-53.714286 19.714286q-24.571429 0-47.142857-12t-41.142857-31.428571-37.428572-42.857143-39.714286-46.857143-44.285714-42.857143-55.142857-31.428571T434.285714 444.571429q-69.714286 0-118.285714 40.285714T267.428571 593.142857z" p-id="1953"></path></svg>',datatip:"JSFiddle"}}])}(d)),Ll("codepen")&&i.appendChild(function(n){var e=n.css,t=n.htmlTpl,i=n.jsTpl,r=n.jsLib,a=n.cssLib,s=JSON.stringify({css:e,html:t,js:i,js_external:r.concat(Ll("jsLib")).join(";"),css_external:a.concat(Ll("cssLib")).join(";"),layout:Ll("codepenLayout"),js_pre_processor:Ll("codepenJsProcessor"),editors:Ll("codepenEditors")});return Bl("form",{className:"vuepress-plugin-demo-block__codepen",target:"_blank",action:"https://codepen.io/pen/define",method:"post"},[{tag:"input",attrs:{type:"hidden",name:"data",value:s}},{tag:"button",attrs:{type:"submit",innerHTML:'<?xml version="1.0" standalone="no"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg t="1547088271207" class="icon" style="" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1737" xmlns:xlink="http://www.w3.org/1999/xlink" width="200" height="200"><defs><style type="text/css"></style></defs><path d="M123.428571 668l344.571429 229.714286v-205.142857L277.142857 565.142857z m-35.428571-82.285714l110.285714-73.714286-110.285714-73.714286v147.428572z m468 312l344.571429-229.714286-153.714286-102.857143-190.857143 127.428572v205.142857z m-44-281.714286l155.428571-104-155.428571-104-155.428571 104zM277.142857 458.857143l190.857143-127.428572V126.285714L123.428571 356z m548.571429 53.142857l110.285714 73.714286V438.285714z m-78.857143-53.142857l153.714286-102.857143-344.571429-229.714286v205.142857z m277.142857-102.857143v312q0 23.428571-19.428571 36.571429l-468 312q-12 7.428571-24.571429 7.428571t-24.571429-7.428571L19.428571 704.571429q-19.428571-13.142857-19.428571-36.571429V356q0-23.428571 19.428571-36.571429L487.428571 7.428571q12-7.428571 24.571429-7.428571t24.571429 7.428571l468 312q19.428571 13.142857 19.428571 36.571429z" p-id="1738"></path></svg>',className:"vuepress-plugin-demo-block__button",datatip:"Codepen"}}])}(d)),void 0!==s.horizontal?s.horizontal:Ll("horizontal")){n.classList.add("vuepress-plugin-demo-block__horizontal");var u=e.firstChild.cloneNode(!0);u.classList.add("vuepress-plugin-demo-block__h_code"),t.appendChild(u)}if(d.css&&function(n){if(!Il[n]){var e=Bl("style",{innerHTML:n});document.body.appendChild(e),Il[n]=!0}}(d.css),"react"===l)ReactDOM.render(React.createElement(d.js),r);else if("vue"===l){var p=(new(Vue.extend(d.script))).$mount();r.appendChild(p.$el)}else"vanilla"===l&&(r.innerHTML=d.html,new Function("return (function(){".concat(d.script,"})()"))());n.dataset.created="true"}})):setTimeout((function(n){Ol()}),300)}function Ml(n,e,t,i){var r="1"!==n.dataset.isExpand;t.style.height=r?"".concat(e,"px"):0,r?i.classList.add("vuepress-plugin-demo-block__show-link"):i.classList.remove("vuepress-plugin-demo-block__show-link"),n.dataset.isExpand=r?"1":"0"}var jl={mounted:function(){window.$VUEPRESS_DEMO_BLOCK={jsfiddle:!1,codepen:!0,horizontal:!1},Ol()},updated:function(){Ol()}},Ul="auto",$l="zoom-in",Fl="zoom-out",Nl="grab",ql="move";function Gl(n,e,t){var i=!(arguments.length>3&&void 0!==arguments[3])||arguments[3],r={passive:!1};i?n.addEventListener(e,t,r):n.removeEventListener(e,t,r)}function Kl(n,e){if(n){var t=new Image;t.onload=function(){e&&e(t)},t.src=n}}function Hl(n){return n.dataset.original?n.dataset.original:"A"===n.parentNode.tagName?n.parentNode.getAttribute("href"):null}function Jl(n,e,t){!function(n){var e=Vl,t=Ql;if(n.transition){var i=n.transition;delete n.transition,n[e]=i}if(n.transform){var r=n.transform;delete n.transform,n[t]=r}}(e);var i=n.style,r={};for(var a in e)t&&(r[a]=i[a]||""),i[a]=e[a];return r}var Vl="transition",Ql="transform",Xl="transform",Wl="transitionend";var Yl=function(){},Zl={enableGrab:!0,preloadImage:!1,closeOnWindowResize:!0,transitionDuration:.4,transitionTimingFunction:"cubic-bezier(0.4, 0, 0, 1)",bgColor:"rgb(255, 255, 255)",bgOpacity:1,scaleBase:1,scaleExtra:.5,scrollThreshold:40,zIndex:998,customSize:null,onOpen:Yl,onClose:Yl,onGrab:Yl,onMove:Yl,onRelease:Yl,onBeforeOpen:Yl,onBeforeClose:Yl,onBeforeGrab:Yl,onBeforeRelease:Yl,onImageLoading:Yl,onImageLoaded:Yl},no={init:function(n){var e,t;e=this,t=n,Object.getOwnPropertyNames(Object.getPrototypeOf(e)).forEach((function(n){e[n]=e[n].bind(t)}))},click:function(n){if(n.preventDefault(),to(n))return window.open(this.target.srcOriginal||n.currentTarget.src,"_blank");this.shown?this.released?this.close():this.release():this.open(n.currentTarget)},scroll:function(){var n=document.documentElement||document.body.parentNode||document.body,e=window.pageXOffset||n.scrollLeft,t=window.pageYOffset||n.scrollTop;null===this.lastScrollPosition&&(this.lastScrollPosition={x:e,y:t});var i=this.lastScrollPosition.x-e,r=this.lastScrollPosition.y-t,a=this.options.scrollThreshold;(Math.abs(r)>=a||Math.abs(i)>=a)&&(this.lastScrollPosition=null,this.close())},keydown:function(n){(function(n){return"Escape"===(n.key||n.code)||27===n.keyCode})(n)&&(this.released?this.close():this.release(this.close))},mousedown:function(n){if(eo(n)&&!to(n)){n.preventDefault();var e=n.clientX,t=n.clientY;this.pressTimer=setTimeout(function(){this.grab(e,t)}.bind(this),200)}},mousemove:function(n){this.released||this.move(n.clientX,n.clientY)},mouseup:function(n){eo(n)&&!to(n)&&(clearTimeout(this.pressTimer),this.released?this.close():this.release())},touchstart:function(n){n.preventDefault();var e=n.touches[0],t=e.clientX,i=e.clientY;this.pressTimer=setTimeout(function(){this.grab(t,i)}.bind(this),200)},touchmove:function(n){if(!this.released){var e=n.touches[0],t=e.clientX,i=e.clientY;this.move(t,i)}},touchend:function(n){(function(n){n.targetTouches.length})(n)||(clearTimeout(this.pressTimer),this.released?this.close():this.release())},clickOverlay:function(){this.close()},resizeWindow:function(){this.close()}};function eo(n){return 0===n.button}function to(n){return n.metaKey||n.ctrlKey}var io={init:function(n){this.el=document.createElement("div"),this.instance=n,this.parent=document.body,Jl(this.el,{position:"fixed",top:0,left:0,right:0,bottom:0,opacity:0}),this.updateStyle(n.options),Gl(this.el,"click",n.handler.clickOverlay.bind(n))},updateStyle:function(n){Jl(this.el,{zIndex:n.zIndex,backgroundColor:n.bgColor,transition:"opacity\n        "+n.transitionDuration+"s\n        "+n.transitionTimingFunction})},insert:function(){this.parent.appendChild(this.el)},remove:function(){this.parent.removeChild(this.el)},fadeIn:function(){this.el.offsetWidth,this.el.style.opacity=this.instance.options.bgOpacity},fadeOut:function(){this.el.style.opacity=0}},ro="function"==typeof Symbol&&"symbol"==typeof Symbol.iterator?function(n){return typeof n}:function(n){return n&&"function"==typeof Symbol&&n.constructor===Symbol&&n!==Symbol.prototype?"symbol":typeof n},ao=function(){function n(n,e){for(var t=0;t<e.length;t++){var i=e[t];i.enumerable=i.enumerable||!1,i.configurable=!0,"value"in i&&(i.writable=!0),Object.defineProperty(n,i.key,i)}}return function(e,t,i){return t&&n(e.prototype,t),i&&n(e,i),e}}(),so=Object.assign||function(n){for(var e=1;e<arguments.length;e++){var t=arguments[e];for(var i in t)Object.prototype.hasOwnProperty.call(t,i)&&(n[i]=t[i])}return n},lo={init:function(n,e){this.el=n,this.instance=e,this.srcThumbnail=this.el.getAttribute("src"),this.srcset=this.el.getAttribute("srcset"),this.srcOriginal=Hl(this.el),this.rect=this.el.getBoundingClientRect(),this.translate=null,this.scale=null,this.styleOpen=null,this.styleClose=null},zoomIn:function(){var n=this.instance.options,e=n.zIndex,t=n.enableGrab,i=n.transitionDuration,r=n.transitionTimingFunction;this.translate=this.calculateTranslate(),this.scale=this.calculateScale(),this.styleOpen={position:"relative",zIndex:e+1,cursor:t?Nl:Fl,transition:Xl+"\n        "+i+"s\n        "+r,transform:"translate3d("+this.translate.x+"px, "+this.translate.y+"px, 0px)\n        scale("+this.scale.x+","+this.scale.y+")",height:this.rect.height+"px",width:this.rect.width+"px"},this.el.offsetWidth,this.styleClose=Jl(this.el,this.styleOpen,!0)},zoomOut:function(){this.el.offsetWidth,Jl(this.el,{transform:"none"})},grab:function(n,e,t){var i=oo(),r=i.x-n,a=i.y-e;Jl(this.el,{cursor:ql,transform:"translate3d(\n        "+(this.translate.x+r)+"px, "+(this.translate.y+a)+"px, 0px)\n        scale("+(this.scale.x+t)+","+(this.scale.y+t)+")"})},move:function(n,e,t){var i=oo(),r=i.x-n,a=i.y-e;Jl(this.el,{transition:Xl,transform:"translate3d(\n        "+(this.translate.x+r)+"px, "+(this.translate.y+a)+"px, 0px)\n        scale("+(this.scale.x+t)+","+(this.scale.y+t)+")"})},restoreCloseStyle:function(){Jl(this.el,this.styleClose)},restoreOpenStyle:function(){Jl(this.el,this.styleOpen)},upgradeSource:function(){if(this.srcOriginal){var n=this.el.parentNode;this.srcset&&this.el.removeAttribute("srcset");var e=this.el.cloneNode(!1);e.setAttribute("src",this.srcOriginal),e.style.position="fixed",e.style.visibility="hidden",n.appendChild(e),setTimeout(function(){this.el.setAttribute("src",this.srcOriginal),n.removeChild(e)}.bind(this),50)}},downgradeSource:function(){this.srcOriginal&&(this.srcset&&this.el.setAttribute("srcset",this.srcset),this.el.setAttribute("src",this.srcThumbnail))},calculateTranslate:function(){var n=oo(),e=this.rect.left+this.rect.width/2,t=this.rect.top+this.rect.height/2;return{x:n.x-e,y:n.y-t}},calculateScale:function(){var n=this.el.dataset,e=n.zoomingHeight,t=n.zoomingWidth,i=this.instance.options,r=i.customSize,a=i.scaleBase;if(!r&&e&&t)return{x:t/this.rect.width,y:e/this.rect.height};if(r&&"object"===(void 0===r?"undefined":ro(r)))return{x:r.width/this.rect.width,y:r.height/this.rect.height};var s=this.rect.width/2,l=this.rect.height/2,o=oo(),d={x:o.x-s,y:o.y-l},c=d.x/s,u=d.y/l,p=a+Math.min(c,u);if(r&&"string"==typeof r){var m=t||this.el.naturalWidth,h=e||this.el.naturalHeight,g=parseFloat(r)*m/(100*this.rect.width),f=parseFloat(r)*h/(100*this.rect.height);if(p>g||p>f)return{x:g,y:f}}return{x:p,y:p}}};function oo(){var n=document.documentElement;return{x:Math.min(n.clientWidth,window.innerWidth)/2,y:Math.min(n.clientHeight,window.innerHeight)/2}}function co(n,e,t){["mousedown","mousemove","mouseup","touchstart","touchmove","touchend"].forEach((function(i){Gl(n,i,e[i],t)}))}var uo=function(){function n(e){!function(n,e){if(!(n instanceof e))throw new TypeError("Cannot call a class as a function")}(this,n),this.target=Object.create(lo),this.overlay=Object.create(io),this.handler=Object.create(no),this.body=document.body,this.shown=!1,this.lock=!1,this.released=!0,this.lastScrollPosition=null,this.pressTimer=null,this.options=so({},Zl,e),this.overlay.init(this),this.handler.init(this)}return ao(n,[{key:"listen",value:function(n){if("string"==typeof n)for(var e=document.querySelectorAll(n),t=e.length;t--;)this.listen(e[t]);else"IMG"===n.tagName&&(n.style.cursor=$l,Gl(n,"click",this.handler.click),this.options.preloadImage&&Kl(Hl(n)));return this}},{key:"config",value:function(n){return n?(so(this.options,n),this.overlay.updateStyle(this.options),this):this.options}},{key:"open",value:function(n){var e=this,t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:this.options.onOpen;if(!this.shown&&!this.lock){var i="string"==typeof n?document.querySelector(n):n;if("IMG"===i.tagName){if(this.options.onBeforeOpen(i),this.target.init(i,this),!this.options.preloadImage){var r=this.target.srcOriginal;null!=r&&(this.options.onImageLoading(i),Kl(r,this.options.onImageLoaded))}this.shown=!0,this.lock=!0,this.target.zoomIn(),this.overlay.insert(),this.overlay.fadeIn(),Gl(document,"scroll",this.handler.scroll),Gl(document,"keydown",this.handler.keydown),this.options.closeOnWindowResize&&Gl(window,"resize",this.handler.resizeWindow);var a=function n(){Gl(i,Wl,n,!1),e.lock=!1,e.target.upgradeSource(),e.options.enableGrab&&co(document,e.handler,!0),t(i)};return Gl(i,Wl,a),this}}}},{key:"close",value:function(){var n=this,e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:this.options.onClose;if(this.shown&&!this.lock){var t=this.target.el;this.options.onBeforeClose(t),this.lock=!0,this.body.style.cursor=Ul,this.overlay.fadeOut(),this.target.zoomOut(),Gl(document,"scroll",this.handler.scroll,!1),Gl(document,"keydown",this.handler.keydown,!1),this.options.closeOnWindowResize&&Gl(window,"resize",this.handler.resizeWindow,!1);var i=function i(){Gl(t,Wl,i,!1),n.shown=!1,n.lock=!1,n.target.downgradeSource(),n.options.enableGrab&&co(document,n.handler,!1),n.target.restoreCloseStyle(),n.overlay.remove(),e(t)};return Gl(t,Wl,i),this}}},{key:"grab",value:function(n,e){var t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this.options.scaleExtra,i=arguments.length>3&&void 0!==arguments[3]?arguments[3]:this.options.onGrab;if(this.shown&&!this.lock){var r=this.target.el;this.options.onBeforeGrab(r),this.released=!1,this.target.grab(n,e,t);var a=function n(){Gl(r,Wl,n,!1),i(r)};return Gl(r,Wl,a),this}}},{key:"move",value:function(n,e){var t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this.options.scaleExtra,i=arguments.length>3&&void 0!==arguments[3]?arguments[3]:this.options.onMove;if(this.shown&&!this.lock){this.released=!1,this.body.style.cursor=ql,this.target.move(n,e,t);var r=this.target.el,a=function n(){Gl(r,Wl,n,!1),i(r)};return Gl(r,Wl,a),this}}},{key:"release",value:function(){var n=this,e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:this.options.onRelease;if(this.shown&&!this.lock){var t=this.target.el;this.options.onBeforeRelease(t),this.lock=!0,this.body.style.cursor=Ul,this.target.restoreOpenStyle();var i=function i(){Gl(t,Wl,i,!1),n.lock=!1,n.released=!0,e(t)};return Gl(t,Wl,i),this}}}]),n}();const po=JSON.parse('{"bgColor":"rgba(0,0,0,0.6)"}'),mo=Number("500");class ho{constructor(){this.instance=new uo(po)}update(n=".theme-vdoing-content img:not(.no-zoom)"){"undefined"!=typeof window&&this.instance.listen(n)}updateDelay(n=".theme-vdoing-content img:not(.no-zoom)",e=mo){setTimeout(()=>this.update(n),e)}}var go=[gl,kl,Sl,Tl,jl,{watch:{"$page.path"(){void 0!==this.$vuepress.zooming&&this.$vuepress.zooming.updateDelay()}},mounted(){this.$vuepress.zooming=new ho,this.$vuepress.zooming.updateDelay()}}],fo={name:"GlobalLayout",computed:{layout(){const n=this.getLayout();return cl("layout",n),Ht.component(n)}},methods:{getLayout(){if(this.$page.path){const n=this.$page.frontmatter.layout;return n&&(this.$vuepress.getLayoutAsyncComponent(n)||this.$vuepress.getVueComponent(n))?n:"Layout"}return"NotFound"}}},bo=t(4),vo=Object(bo.a)(fo,(function(){return(0,this._self._c)(this.layout,{tag:"component"})}),[],!1,null,null,null).exports;!function(n,e,t){switch(e){case"components":n[e]||(n[e]={}),Object.assign(n[e],t);break;case"mixins":n[e]||(n[e]=[]),n[e].push(...t);break;default:throw new Error("Unknown option name.")}}(vo,"mixins",go);const yo=[{name:"v-6933ae78",path:"/java/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-6933ae78").then(t)}},{path:"/java/index.html",redirect:"/java/"},{path:"/00.目录页/05.开发/10.Java.html",redirect:"/java/"},{name:"v-6629cfe6",path:"/go/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-6629cfe6").then(t)}},{path:"/go/index.html",redirect:"/go/"},{path:"/00.目录页/05.开发/15.GoLang.html",redirect:"/go/"},{name:"v-2969cc26",path:"/deep-learning/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-2969cc26").then(t)}},{path:"/deep-learning/index.html",redirect:"/deep-learning/"},{path:"/00.目录页/10.AI/05.深度学习.html",redirect:"/deep-learning/"},{name:"v-eaab9570",path:"/linux/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-eaab9570").then(t)}},{path:"/linux/index.html",redirect:"/linux/"},{path:"/00.目录页/15.基础/10.Linux.html",redirect:"/linux/"},{name:"v-007ca368",path:"/datastructure/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-007ca368").then(t)}},{path:"/datastructure/index.html",redirect:"/datastructure/"},{path:"/00.目录页/15.基础/15.数据结构.html",redirect:"/datastructure/"},{name:"v-36d5ec98",path:"/cloudnative/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-36d5ec98").then(t)}},{path:"/cloudnative/index.html",redirect:"/cloudnative/"},{path:"/00.目录页/15.基础/20.云原生.html",redirect:"/cloudnative/"},{name:"v-18e88d58",path:"/git/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-18e88d58").then(t)}},{path:"/git/index.html",redirect:"/git/"},{path:"/00.目录页/15.基础/5.Git.html",redirect:"/git/"},{name:"v-60064de7",path:"/redis/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-60064de7").then(t)}},{path:"/redis/index.html",redirect:"/redis/"},{path:"/00.目录页/20.中间件/05.Redis.html",redirect:"/redis/"},{name:"v-179fad57",path:"/mysql/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-179fad57").then(t)}},{path:"/mysql/index.html",redirect:"/mysql/"},{path:"/00.目录页/20.中间件/06.MySQL.html",redirect:"/mysql/"},{name:"v-3fdec0bd",path:"/route-hijack/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-3fdec0bd").then(t)}},{path:"/route-hijack/index.html",redirect:"/route-hijack/"},{path:"/00.目录页/25.网络/5.路由劫持.html",redirect:"/route-hijack/"},{name:"v-53104ef6",path:"/archives/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-53104ef6").then(t)}},{path:"/archives/index.html",redirect:"/archives/"},{path:"/@pages/archivesPage.html",redirect:"/archives/"},{name:"v-1a9d53e5",path:"/categories/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-1a9d53e5").then(t)}},{path:"/categories/index.html",redirect:"/categories/"},{path:"/@pages/categoriesPage.html",redirect:"/categories/"},{name:"v-150b83f6",path:"/tags/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-150b83f6").then(t)}},{path:"/tags/index.html",redirect:"/tags/"},{path:"/@pages/tagsPage.html",redirect:"/tags/"},{name:"v-517069f0",path:"/pages/3a4ae9/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-517069f0").then(t)}},{path:"/pages/3a4ae9/index.html",redirect:"/pages/3a4ae9/"},{path:"/AI/05.深度学习/05.李宏毅/01.基本概念.html",redirect:"/pages/3a4ae9/"},{name:"v-74cfb0b2",path:"/pages/e6f457/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-74cfb0b2").then(t)}},{path:"/pages/e6f457/index.html",redirect:"/pages/e6f457/"},{path:"/AI/05.深度学习/05.李宏毅/05.神经网络训练不起来怎么办.html",redirect:"/pages/e6f457/"},{name:"v-a113e2c4",path:"/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-a113e2c4").then(t)}},{path:"/index.html",redirect:"/"},{name:"v-6962c4c2",path:"/pages/271391/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-6962c4c2").then(t)}},{path:"/pages/271391/index.html",redirect:"/pages/271391/"},{path:"/中间件/05.Redis/05.专栏：Redis 核心技术与实战/01.基础架构、数据结构与 IO 模型.html",redirect:"/pages/271391/"},{name:"v-a6ed5612",path:"/pages/d1a6d3/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-a6ed5612").then(t)}},{path:"/pages/d1a6d3/index.html",redirect:"/pages/d1a6d3/"},{path:"/中间件/05.Redis/05.专栏：Redis 核心技术与实战/04.持久化机制：AOF日志和RDB快照.html",redirect:"/pages/d1a6d3/"},{name:"v-2778bd58",path:"/pages/348567/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-2778bd58").then(t)}},{path:"/pages/348567/index.html",redirect:"/pages/348567/"},{path:"/中间件/05.Redis/05.专栏：Redis 核心技术与实战/06.主从复制与哨兵机制.html",redirect:"/pages/348567/"},{name:"v-31581127",path:"/pages/71b166/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-31581127").then(t)}},{path:"/pages/71b166/index.html",redirect:"/pages/71b166/"},{path:"/中间件/05.Redis/05.专栏：Redis 核心技术与实战/09.切片集群.html",redirect:"/pages/71b166/"},{name:"v-c2ced796",path:"/pages/2029a8/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-c2ced796").then(t)}},{path:"/pages/2029a8/index.html",redirect:"/pages/2029a8/"},{path:"/中间件/05.Redis/05.专栏：Redis 核心技术与实战/11.Redis 中的数据结构.html",redirect:"/pages/2029a8/"},{name:"v-3fe17966",path:"/pages/a3ed18/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-3fe17966").then(t)}},{path:"/pages/a3ed18/index.html",redirect:"/pages/a3ed18/"},{path:"/中间件/05.Redis/05.专栏：Redis 核心技术与实战/14.时间序列数据的保存.html",redirect:"/pages/a3ed18/"},{name:"v-0b361225",path:"/pages/5d636a/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-0b361225").then(t)}},{path:"/pages/5d636a/index.html",redirect:"/pages/5d636a/"},{path:"/中间件/05.Redis/05.专栏：Redis 核心技术与实战/15.Redis 的消息队列方案.html",redirect:"/pages/5d636a/"},{name:"v-68306418",path:"/pages/ca62e3/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-68306418").then(t)}},{path:"/pages/ca62e3/index.html",redirect:"/pages/ca62e3/"},{path:"/中间件/05.Redis/05.专栏：Redis 核心技术与实战/16.异步机制、CPU 架构对性能的影响.html",redirect:"/pages/ca62e3/"},{name:"v-6c981036",path:"/pages/f111bf/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-6c981036").then(t)}},{path:"/pages/f111bf/index.html",redirect:"/pages/f111bf/"},{path:"/中间件/05.Redis/05.专栏：Redis 核心技术与实战/18.如何应对变慢的 Redis.html",redirect:"/pages/f111bf/"},{name:"v-1a140cfc",path:"/pages/6135bf/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-1a140cfc").then(t)}},{path:"/pages/6135bf/index.html",redirect:"/pages/6135bf/"},{path:"/中间件/05.Redis/05.专栏：Redis 核心技术与实战/20.Redis 的内存碎片、缓冲区.html",redirect:"/pages/6135bf/"},{name:"v-29b8baff",path:"/pages/d403e5/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-29b8baff").then(t)}},{path:"/pages/d403e5/index.html",redirect:"/pages/d403e5/"},{path:"/中间件/05.Redis/05.专栏：Redis 核心技术与实战/23.Redis 用作缓存.html",redirect:"/pages/d403e5/"},{name:"v-2a85a268",path:"/pages/cbe81b/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-2a85a268").then(t)}},{path:"/pages/cbe81b/index.html",redirect:"/pages/cbe81b/"},{path:"/中间件/05.Redis/05.专栏：Redis 核心技术与实战/25.Redis 用作缓存之缓存异常.html",redirect:"/pages/cbe81b/"},{name:"v-ad649dc2",path:"/pages/ea52c5/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-ad649dc2").then(t)}},{path:"/pages/ea52c5/index.html",redirect:"/pages/ea52c5/"},{path:"/中间件/05.Redis/05.专栏：Redis 核心技术与实战/27.Redis 用作缓存之缓存污染.html",redirect:"/pages/ea52c5/"},{name:"v-3aa5fefb",path:"/pages/8f7740/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-3aa5fefb").then(t)}},{path:"/pages/8f7740/index.html",redirect:"/pages/8f7740/"},{path:"/中间件/05.Redis/05.专栏：Redis 核心技术与实战/28.Pika：基于SSD实现大容量Redis.html",redirect:"/pages/8f7740/"},{name:"v-35ef0b3a",path:"/pages/5a1b01/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-35ef0b3a").then(t)}},{path:"/pages/5a1b01/index.html",redirect:"/pages/5a1b01/"},{path:"/中间件/05.Redis/05.专栏：Redis 核心技术与实战/29.无锁的原子操作和分布式锁.html",redirect:"/pages/5a1b01/"},{name:"v-2f859720",path:"/pages/932816/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-2f859720").then(t)}},{path:"/pages/932816/index.html",redirect:"/pages/932816/"},{path:"/中间件/05.Redis/05.专栏：Redis 核心技术与实战/31.Redis 的事务机制.html",redirect:"/pages/932816/"},{name:"v-3622e3e6",path:"/pages/4140fe/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-3622e3e6").then(t)}},{path:"/pages/4140fe/index.html",redirect:"/pages/4140fe/"},{path:"/中间件/05.Redis/05.专栏：Redis 核心技术与实战/32.Redis 主从同步的坑.html",redirect:"/pages/4140fe/"},{name:"v-c6d294b8",path:"/pages/b6efd0/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-c6d294b8").then(t)}},{path:"/pages/b6efd0/index.html",redirect:"/pages/b6efd0/"},{path:"/中间件/05.Redis/05.专栏：Redis 核心技术与实战/36.秒杀场景下的应用.html",redirect:"/pages/b6efd0/"},{name:"v-aa603976",path:"/pages/d3d97d/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-aa603976").then(t)}},{path:"/pages/d3d97d/index.html",redirect:"/pages/d3d97d/"},{path:"/中间件/05.Redis/05.专栏：Redis 核心技术与实战/37.集群的数据倾斜和通信开销问题.html",redirect:"/pages/d3d97d/"},{name:"v-1823a466",path:"/pages/473452/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-1823a466").then(t)}},{path:"/pages/473452/index.html",redirect:"/pages/473452/"},{path:"/中间件/06.MySQL/05.专栏：MySQL 实战 45 讲/01.基础架构：一条SQL查询语句是如何执行的？.html",redirect:"/pages/473452/"},{name:"v-55200187",path:"/pages/38bad9/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-55200187").then(t)}},{path:"/pages/38bad9/index.html",redirect:"/pages/38bad9/"},{path:"/中间件/06.MySQL/05.专栏：MySQL 实战 45 讲/02.日志系统：一条SQL更新语句是如何执行的？.html",redirect:"/pages/38bad9/"},{name:"v-66f73835",path:"/pages/b99352/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-66f73835").then(t)}},{path:"/pages/b99352/index.html",redirect:"/pages/b99352/"},{path:"/中间件/06.MySQL/05.专栏：MySQL 实战 45 讲/03.事务隔离.html",redirect:"/pages/b99352/"},{name:"v-7482ba20",path:"/pages/1ea58b/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-7482ba20").then(t)}},{path:"/pages/1ea58b/index.html",redirect:"/pages/1ea58b/"},{path:"/中间件/06.MySQL/05.专栏：MySQL 实战 45 讲/04.深入浅出索引.html",redirect:"/pages/1ea58b/"},{name:"v-2c529f3a",path:"/pages/376254/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-2c529f3a").then(t)}},{path:"/pages/376254/index.html",redirect:"/pages/376254/"},{path:"/中间件/06.MySQL/05.专栏：MySQL 实战 45 讲/05.全局锁、表级锁和行锁.html",redirect:"/pages/376254/"},{name:"v-76fe5474",path:"/pages/02bb58/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-76fe5474").then(t)}},{path:"/pages/02bb58/index.html",redirect:"/pages/02bb58/"},{path:"/中间件/06.MySQL/05.专栏：MySQL 实战 45 讲/06.change buffer.html",redirect:"/pages/02bb58/"},{name:"v-24aa3866",path:"/pages/c4cff3/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-24aa3866").then(t)}},{path:"/pages/c4cff3/index.html",redirect:"/pages/c4cff3/"},{path:"/中间件/06.MySQL/05.专栏：MySQL 实战 45 讲/07.MySQL为什么有时候会加错索引.html",redirect:"/pages/c4cff3/"},{name:"v-18bc1557",path:"/pages/fa9ec1/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-18bc1557").then(t)}},{path:"/pages/fa9ec1/index.html",redirect:"/pages/fa9ec1/"},{path:"/中间件/06.MySQL/05.专栏：MySQL 实战 45 讲/08.怎么给字符串字段加索引.html",redirect:"/pages/fa9ec1/"},{name:"v-4fda8213",path:"/pages/c774f5/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-4fda8213").then(t)}},{path:"/pages/c774f5/index.html",redirect:"/pages/c774f5/"},{path:"/基础/10.Linux/05.韩顺平2021课程笔记/05.Linux基础篇.html",redirect:"/pages/c774f5/"},{name:"v-c45fcee4",path:"/pages/4a5b75/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-c45fcee4").then(t)}},{path:"/pages/4a5b75/index.html",redirect:"/pages/4a5b75/"},{path:"/基础/10.Linux/05.韩顺平2021课程笔记/10.Linux实操篇（上）.html",redirect:"/pages/4a5b75/"},{name:"v-e36601e4",path:"/pages/16468e/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-e36601e4").then(t)}},{path:"/pages/16468e/index.html",redirect:"/pages/16468e/"},{path:"/基础/10.Linux/05.韩顺平2021课程笔记/15.Linux实操篇（下）.html",redirect:"/pages/16468e/"},{name:"v-1ae0a658",path:"/pages/1e98d9/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-1ae0a658").then(t)}},{path:"/pages/1e98d9/index.html",redirect:"/pages/1e98d9/"},{path:"/基础/10.Linux/05.韩顺平2021课程笔记/20.JavaEE与Python定制篇.html",redirect:"/pages/1e98d9/"},{name:"v-97c51d34",path:"/pages/338288/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-97c51d34").then(t)}},{path:"/pages/338288/index.html",redirect:"/pages/338288/"},{path:"/基础/10.Linux/05.韩顺平2021课程笔记/25.大数据定制篇-Shell编程.html",redirect:"/pages/338288/"},{name:"v-02285212",path:"/pages/dd2e0e/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-02285212").then(t)}},{path:"/pages/dd2e0e/index.html",redirect:"/pages/dd2e0e/"},{path:"/基础/10.Linux/10.From公众号/5.带你实现Linux命令自由.html",redirect:"/pages/dd2e0e/"},{name:"v-2bcd0941",path:"/pages/c2aef8/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-2bcd0941").then(t)}},{path:"/pages/c2aef8/index.html",redirect:"/pages/c2aef8/"},{path:"/基础/15.数据结构/05.常见数据结构/05.LSM 树.html",redirect:"/pages/c2aef8/"},{name:"v-6e3c4c48",path:"/pages/850e00/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-6e3c4c48").then(t)}},{path:"/pages/850e00/index.html",redirect:"/pages/850e00/"},{path:"/基础/20.云原生/15.Kubernetes入门实战课-罗剑锋/01.开篇词.html",redirect:"/pages/850e00/"},{name:"v-2d5f867f",path:"/pages/1cc8db/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-2d5f867f").then(t)}},{path:"/pages/1cc8db/index.html",redirect:"/pages/1cc8db/"},{path:"/基础/20.云原生/15.Kubernetes入门实战课-罗剑锋/02.初识容器.html",redirect:"/pages/1cc8db/"},{name:"v-7a34202e",path:"/pages/757154/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-7a34202e").then(t)}},{path:"/pages/757154/index.html",redirect:"/pages/757154/"},{path:"/基础/20.云原生/15.Kubernetes入门实战课-罗剑锋/09.Kubernetes 的安装与基本架构.html",redirect:"/pages/757154/"},{name:"v-ac009106",path:"/pages/c0d84b/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-ac009106").then(t)}},{path:"/pages/c0d84b/index.html",redirect:"/pages/c0d84b/"},{path:"/基础/20.云原生/15.Kubernetes入门实战课-罗剑锋/11.YAML、Pod、Job、CronJob、ConfigMap、Secret.html",redirect:"/pages/c0d84b/"},{name:"v-31ed6925",path:"/pages/0d79ac/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-31ed6925").then(t)}},{path:"/pages/0d79ac/index.html",redirect:"/pages/0d79ac/"},{path:"/基础/5.Git/05.Git基础.html",redirect:"/pages/0d79ac/"},{name:"v-45526b4e",path:"/pages/dc4ebe/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-45526b4e").then(t)}},{path:"/pages/dc4ebe/index.html",redirect:"/pages/dc4ebe/"},{path:"/基础/5.Git/10.Git的使用.html",redirect:"/pages/dc4ebe/"},{name:"v-11669a46",path:"/pages/483565/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-11669a46").then(t)}},{path:"/pages/483565/index.html",redirect:"/pages/483565/"},{path:"/开发/10.Java/05.黑马Java入门基础-学习笔记/05.Java基础语法.html",redirect:"/pages/483565/"},{name:"v-2c0bb97b",path:"/pages/a6522a/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-2c0bb97b").then(t)}},{path:"/pages/a6522a/index.html",redirect:"/pages/a6522a/"},{path:"/开发/10.Java/05.黑马Java入门基础-学习笔记/10.数组.html",redirect:"/pages/a6522a/"},{name:"v-43f0e09d",path:"/pages/615479/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-43f0e09d").then(t)}},{path:"/pages/615479/index.html",redirect:"/pages/615479/"},{path:"/开发/10.Java/05.黑马Java入门基础-学习笔记/15.方法.html",redirect:"/pages/615479/"},{name:"v-2b382624",path:"/pages/d4e408/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-2b382624").then(t)}},{path:"/pages/d4e408/index.html",redirect:"/pages/d4e408/"},{path:"/开发/10.Java/05.黑马Java入门基础-学习笔记/20.面向对象基础.html",redirect:"/pages/d4e408/"},{name:"v-36c9cb62",path:"/pages/8f676c/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-36c9cb62").then(t)}},{path:"/pages/8f676c/index.html",redirect:"/pages/8f676c/"},{path:"/开发/10.Java/05.黑马Java入门基础-学习笔记/25.常用API(String、ArrayList).html",redirect:"/pages/8f676c/"},{name:"v-7e68add3",path:"/pages/46cfbb/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-7e68add3").then(t)}},{path:"/pages/46cfbb/index.html",redirect:"/pages/46cfbb/"},{path:"/开发/10.Java/05.黑马Java入门基础-学习笔记/30.面向对象进阶1（static、单例、代码块、继承）.html",redirect:"/pages/46cfbb/"},{name:"v-087079a8",path:"/pages/b127ae/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-087079a8").then(t)}},{path:"/pages/b127ae/index.html",redirect:"/pages/b127ae/"},{path:"/开发/10.Java/05.黑马Java入门基础-学习笔记/31.面向对象进阶2（包、权限修饰符、抽象类、接口）.html",redirect:"/pages/b127ae/"},{name:"v-b1a79552",path:"/pages/a4fc75/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-b1a79552").then(t)}},{path:"/pages/a4fc75/index.html",redirect:"/pages/a4fc75/"},{path:"/开发/10.Java/05.黑马Java入门基础-学习笔记/32.面向对象进阶3（多态、内部类、常用API）.html",redirect:"/pages/a4fc75/"},{name:"v-433c42bb",path:"/pages/4cb625/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-433c42bb").then(t)}},{path:"/pages/4cb625/index.html",redirect:"/pages/4cb625/"},{path:"/开发/10.Java/05.黑马Java入门基础-学习笔记/33.面向对象进阶4（常用日期API、正则、Arrays类、Lambda）.html",redirect:"/pages/4cb625/"},{name:"v-4f80c998",path:"/pages/6013df/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-4f80c998").then(t)}},{path:"/pages/6013df/index.html",redirect:"/pages/6013df/"},{path:"/开发/10.Java/05.黑马Java入门基础-学习笔记/34.面向对象进阶5（集合体系）.html",redirect:"/pages/6013df/"},{name:"v-3161e9d4",path:"/pages/134c54/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-3161e9d4").then(t)}},{path:"/pages/134c54/index.html",redirect:"/pages/134c54/"},{path:"/开发/10.Java/05.黑马Java入门基础-学习笔记/35.面向对象进阶6（集合体系之Map）.html",redirect:"/pages/134c54/"},{name:"v-78a8ae4e",path:"/pages/e64834/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-78a8ae4e").then(t)}},{path:"/pages/e64834/index.html",redirect:"/pages/e64834/"},{path:"/开发/10.Java/05.黑马Java入门基础-学习笔记/40.面向对象进阶-补充（可变参数）.html",redirect:"/pages/e64834/"},{name:"v-147908a9",path:"/pages/017edb/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-147908a9").then(t)}},{path:"/pages/017edb/index.html",redirect:"/pages/017edb/"},{path:"/开发/10.Java/10.面向对象.html",redirect:"/pages/017edb/"},{name:"v-f49e53d6",path:"/pages/e76788/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-f49e53d6").then(t)}},{path:"/pages/e76788/index.html",redirect:"/pages/e76788/"},{path:"/开发/10.Java/15.常用API.html",redirect:"/pages/e76788/"},{name:"v-00a73f02",path:"/pages/5de326/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-00a73f02").then(t)}},{path:"/pages/5de326/index.html",redirect:"/pages/5de326/"},{path:"/开发/10.Java/20.并发、并行、异步、同步（暂存）.html",redirect:"/pages/5de326/"},{name:"v-cafc5bfe",path:"/pages/0fc51e/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-cafc5bfe").then(t)}},{path:"/pages/0fc51e/index.html",redirect:"/pages/0fc51e/"},{path:"/开发/10.Java/30.《Spring Boot 进阶-郑天民》/05.Spring依赖注入的原理分析.html",redirect:"/pages/0fc51e/"},{name:"v-53b20642",path:"/pages/a53eb3/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-53b20642").then(t)}},{path:"/pages/a53eb3/index.html",redirect:"/pages/a53eb3/"},{path:"/开发/15.GoLang/05.码神之路-学习笔记/05.基础.html",redirect:"/pages/a53eb3/"},{name:"v-623e7b3d",path:"/pages/83009c/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-623e7b3d").then(t)}},{path:"/pages/83009c/index.html",redirect:"/pages/83009c/"},{path:"/网络/5.路由劫持/5.《深入浅出详解RPKI》/05.前言.html",redirect:"/pages/83009c/"},{name:"v-551cf7ff",path:"/pages/b6c83c/",component:vo,beforeEnter:(n,e,t)=>{dl("Layout","v-551cf7ff").then(t)}},{path:"/pages/b6c83c/index.html",redirect:"/pages/b6c83c/"},{path:"/网络/5.路由劫持/5.《深入浅出详解RPKI》/10.简介.html",redirect:"/pages/b6c83c/"},{path:"*",component:vo}],xo={title:"",description:"",base:"/blog/",headTags:[["link",{rel:"icon",href:"/blog/img/bitbug_favicon.ico"}],["meta",{name:"keywords",content:"前端博客,个人技术博客,前端,前端开发,前端框架,web前端,前端面试题,技术文档,学习,面试,JavaScript,js,ES6,TypeScript,vue,python,css3,html5,Node,git,github,markdown"}],["meta",{name:"theme-color",content:"#11a8cd"}]],pages:[{title:"Java",frontmatter:{pageComponent:{name:"Catalogue",data:{key:"开发/10.Java",imgUrl:"/img/more.png",description:"学习、面试、在线工具等更多文章和页面"}},title:"Java",date:"2020-03-11T21:50:56.000Z",permalink:"/java"},regularPath:"/00.%E7%9B%AE%E5%BD%95%E9%A1%B5/05.%E5%BC%80%E5%8F%91/10.Java.html",relativePath:"00.目录页/05.开发/10.Java.md",key:"v-6933ae78",path:"/java/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/03/28, 02:58:11",lastUpdatedTimestamp:1648436291e3},{title:"GoLang",frontmatter:{pageComponent:{name:"Catalogue",data:{key:"开发/15.GoLang",imgUrl:"/img/more.png",description:"GoLang 学习笔记"}},title:"GoLang",date:"2022-05-15T21:06:15.000Z",permalink:"/go"},regularPath:"/00.%E7%9B%AE%E5%BD%95%E9%A1%B5/05.%E5%BC%80%E5%8F%91/15.GoLang.html",relativePath:"00.目录页/05.开发/15.GoLang.md",key:"v-6629cfe6",path:"/go/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/07/27, 11:28:29",lastUpdatedTimestamp:1658921309e3},{title:"深度学习",frontmatter:{pageComponent:{name:"Catalogue",data:{key:"AI/05.深度学习",imgUrl:"/img/more.png",description:null}},title:"深度学习",permalink:"/deep-learning",date:"2022-03-28T10:12:09.000Z"},regularPath:"/00.%E7%9B%AE%E5%BD%95%E9%A1%B5/10.AI/05.%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.html",relativePath:"00.目录页/10.AI/05.深度学习.md",key:"v-2969cc26",path:"/deep-learning/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/03/28, 02:58:11",lastUpdatedTimestamp:1648436291e3},{title:"Linux",frontmatter:{pageComponent:{name:"Catalogue",data:{key:"基础/10.Linux",imgUrl:"/img/more.png",description:"Linux 学习"}},title:"Linux",date:"2022-04-09T09:57:56.000Z",permalink:"/linux"},regularPath:"/00.%E7%9B%AE%E5%BD%95%E9%A1%B5/15.%E5%9F%BA%E7%A1%80/10.Linux.html",relativePath:"00.目录页/15.基础/10.Linux.md",key:"v-eaab9570",path:"/linux/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/04/09, 07:49:44",lastUpdatedTimestamp:1649490584e3},{title:"DataStructure",frontmatter:{pageComponent:{name:"Catalogue",data:{key:"基础/15.数据结构",imgUrl:"/img/more.png",description:"记录常见数据结构的知识"}},title:"DataStructure",date:"2022-05-24T09:57:56.000Z",permalink:"/datastructure"},regularPath:"/00.%E7%9B%AE%E5%BD%95%E9%A1%B5/15.%E5%9F%BA%E7%A1%80/15.%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.html",relativePath:"00.目录页/15.基础/15.数据结构.md",key:"v-007ca368",path:"/datastructure/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2023/05/24, 09:11:54",lastUpdatedTimestamp:1684919514e3},{title:"CloudNative",frontmatter:{pageComponent:{name:"Catalogue",data:{key:"基础/20.云原生",imgUrl:"/img/more.png",description:"学习云原生相关内容的笔记"}},title:"CloudNative",date:"2022-06-07T09:57:56.000Z",permalink:"/cloudnative"},regularPath:"/00.%E7%9B%AE%E5%BD%95%E9%A1%B5/15.%E5%9F%BA%E7%A1%80/20.%E4%BA%91%E5%8E%9F%E7%94%9F.html",relativePath:"00.目录页/15.基础/20.云原生.md",key:"v-36d5ec98",path:"/cloudnative/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2023/06/07, 00:44:58",lastUpdatedTimestamp:1686098698e3},{title:"Git",frontmatter:{pageComponent:{name:"Catalogue",data:{key:"基础/5.Git",imgUrl:"/img/more.png",description:"Git 使用"}},title:"Git",date:"2022-04-09T09:57:56.000Z",permalink:"/git"},regularPath:"/00.%E7%9B%AE%E5%BD%95%E9%A1%B5/15.%E5%9F%BA%E7%A1%80/5.Git.html",relativePath:"00.目录页/15.基础/5.Git.md",key:"v-18e88d58",path:"/git/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/04/09, 07:49:44",lastUpdatedTimestamp:1649490584e3},{title:"Redis",frontmatter:{pageComponent:{name:"Catalogue",data:{key:"中间件/05.Redis",imgUrl:"/img/more.png",description:"Redis 学习笔记"}},title:"Redis",date:"2023-03-19T22:11:56.000Z",permalink:"/redis"},regularPath:"/00.%E7%9B%AE%E5%BD%95%E9%A1%B5/20.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.Redis.html",relativePath:"00.目录页/20.中间件/05.Redis.md",key:"v-60064de7",path:"/redis/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2023/03/19, 14:17:32",lastUpdatedTimestamp:1679235452e3},{title:"MySQL",frontmatter:{pageComponent:{name:"Catalogue",data:{key:"中间件/06.MySQL",imgUrl:"/img/more.png",description:"MySQL 学习笔记"}},title:"MySQL",date:"2023-05-17T09:35:08.000Z",permalink:"/mysql"},regularPath:"/00.%E7%9B%AE%E5%BD%95%E9%A1%B5/20.%E4%B8%AD%E9%97%B4%E4%BB%B6/06.MySQL.html",relativePath:"00.目录页/20.中间件/06.MySQL.md",key:"v-179fad57",path:"/mysql/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2023/05/17, 02:42:28",lastUpdatedTimestamp:1684291348e3},{title:"路由劫持",frontmatter:{pageComponent:{name:"Catalogue",data:{key:"网络/5.路由劫持",imgUrl:"/img/more.png",description:"路由劫持学习记录"}},title:"路由劫持",date:"2022-04-12T19:01:56.000Z",permalink:"/route-hijack"},regularPath:"/00.%E7%9B%AE%E5%BD%95%E9%A1%B5/25.%E7%BD%91%E7%BB%9C/5.%E8%B7%AF%E7%94%B1%E5%8A%AB%E6%8C%81.html",relativePath:"00.目录页/25.网络/5.路由劫持.md",key:"v-3fdec0bd",path:"/route-hijack/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2023/03/19, 14:17:32",lastUpdatedTimestamp:1679235452e3},{title:"归档",frontmatter:{archivesPage:!0,title:"归档",permalink:"/archives/",article:!1},regularPath:"/@pages/archivesPage.html",relativePath:"@pages/archivesPage.md",key:"v-53104ef6",path:"/archives/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/03/27, 01:31:04",lastUpdatedTimestamp:1648344664e3},{title:"分类",frontmatter:{categoriesPage:!0,title:"分类",permalink:"/categories/",article:!1},regularPath:"/@pages/categoriesPage.html",relativePath:"@pages/categoriesPage.md",key:"v-1a9d53e5",path:"/categories/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/03/27, 01:31:04",lastUpdatedTimestamp:1648344664e3},{title:"标签",frontmatter:{tagsPage:!0,title:"标签",permalink:"/tags/",article:!1},regularPath:"/@pages/tagsPage.html",relativePath:"@pages/tagsPage.md",key:"v-150b83f6",path:"/tags/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/03/27, 01:31:04",lastUpdatedTimestamp:1648344664e3},{title:"基本概念",frontmatter:{title:"基本概念",date:"2022-01-21T19:04:11.000Z",permalink:"/pages/3a4ae9/",categories:["AI","深度学习","李宏毅"],tags:[null]},regularPath:"/AI/05.%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/05.%E6%9D%8E%E5%AE%8F%E6%AF%85/01.%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5.html",relativePath:"AI/05.深度学习/05.李宏毅/01.基本概念.md",key:"v-517069f0",path:"/pages/3a4ae9/",headers:[{level:3,title:"1. Function with Unknown Parameters",slug:"_1-function-with-unknown-parameters",normalizedTitle:"1. function with unknown parameters",charIndex:829},{level:3,title:"2. Define Loss from Training Data",slug:"_2-define-loss-from-training-data",normalizedTitle:"2. define loss from training data",charIndex:1083},{level:4,title:"(1) Loss 函数",slug:"_1-loss-函数",normalizedTitle:"(1) loss 函数",charIndex:1120},{level:4,title:"(2) 计算误差e",slug:"_2-计算误差e",normalizedTitle:"(2) 计算误差e",charIndex:1415},{level:4,title:"(3) Error Surface",slug:"_3-error-surface",normalizedTitle:"(3) error surface",charIndex:1487},{level:3,title:"3. Optimization",slug:"_3-optimization",normalizedTitle:"3. optimization",charIndex:1660},{level:3,title:"1. 红色曲线怎么表达",slug:"_1-红色曲线怎么表达",normalizedTitle:"1. 红色曲线怎么表达",charIndex:2698},{level:3,title:"2. 蓝色 Function （Hard Sigmoid）怎么写出来",slug:"_2-蓝色-function-hard-sigmoid-怎么写出来",normalizedTitle:"2. 蓝色 function （hard sigmoid）怎么写出来",charIndex:3103},{level:4,title:"（1）Sigmoid Function（S型曲线)",slug:"_1-sigmoid-function-s型曲线",normalizedTitle:"（1）sigmoid function（s型曲线)",charIndex:3141},{level:4,title:"(2) 各式各样的蓝色 Function 怎样制造出来",slug:"_2-各式各样的蓝色-function-怎样制造出来",normalizedTitle:"(2) 各式各样的蓝色 function 怎样制造出来",charIndex:3258},{level:3,title:"3. 红色 Function 长什么样子",slug:"_3-红色-function-长什么样子",normalizedTitle:"3. 红色 function 长什么样子",charIndex:3488},{level:4,title:"如何减少 Model 的Bias",slug:"如何减少-model-的bias",normalizedTitle:"如何减少 model 的bias",charIndex:3532},{level:3,title:"模型变型",slug:"模型变型",normalizedTitle:"模型变型",charIndex:4676},{level:4,title:"Activation Function",slug:"activation-function",normalizedTitle:"activation function",charIndex:4684},{level:4,title:"模型改进——多做几次",slug:"模型改进-多做几次",normalizedTitle:"模型改进——多做几次",charIndex:4881}],headersStr:"1. Function with Unknown Parameters 2. Define Loss from Training Data (1) Loss 函数 (2) 计算误差e (3) Error Surface 3. Optimization 1. 红色曲线怎么表达 2. 蓝色 Function （Hard Sigmoid）怎么写出来 （1）Sigmoid Function（S型曲线) (2) 各式各样的蓝色 Function 怎样制造出来 3. 红色 Function 长什么样子 如何减少 Model 的Bias 模型变型 Activation Function 模型改进——多做几次",content:"机器学习概括来说，机器学习就是让机器具备找一个函式的能力。\n\n\n# Different types of Functions\n\n * Regression（回归）\n   \n   * 输出是一个数值（scalar）\n     \n     > 例如，今天要机器做的事情,是预测未来某一个时间的,PM2.5的数值。输入可能是种种跟预测PM2.5,有关的指数,这一个函式可以拿这些数值当作输入,输出明天中午的PM2.5的数值,那这一个找这个函式的任务,叫作Regression。\n\n * Classification（分类）\n   \n   * 要机器做选择题。人类先备好一些选项（也叫类别）（classes），从设定好的选项中选择一个当做输出，这个任务就叫做 Classification。\n     \n     > 例如，gmail account裡面有一个函式,帮我们侦测一封邮件,是不是垃圾邮件。\n     > \n     > alpha go本身也是一个 Classification 的问题。\n\n * Structured Learning\n   \n   * 机器今天不只是要做选择题，不只是输出一个数字，还要产生一个有结构的物件。机器画一张图 写一篇文章,这种叫机器产生有结构的东西的问题,就叫作Structured Learning。即要机器学会创造。\n\n\n# Case Study\n\n举例说明机器怎么找一个函式。\n\n找一个函式,这个函式的输入是youtube上面一个频道过往所有的资讯，输出就是预测明天这个频道可能的总观看次数。\n\n找这个函式的过程，分为三步：\n\n 1. 写出一个带有未知参数的函式；2. 定义一个叫做Loss的function；3. 解一个Optimization的问题找到一组参数使loss值最小。<本质是训练，用已知的数据来“预测”>\n\n----------------------------------------\n\n\n# 1. Function with Unknown Parameters\n\n假设函式为 $ y=b+w*x_{1} $，这个带有Unknown的Parameter的Function叫做Model。这个猜测往往就来自于你对这个问题本质上的了解，也就是 Domain knowledge\n\n * y 为预测值，本例中为明天观看此频道的总人数\n * $x_{1}$为已知的东西，叫做Feature，本例中为今天观看的人数\n * b (bias) 和 w (weight)是未知的参数，要从数据资料中学习得到\n\n\n# 2. Define Loss from Training Data\n\n# (1) Loss 函数\n\n定义一个 Loss 函数，输入为 Model 中的未知参数 b 和 w（Parameter），输出的值表示若把这组值传给未知参数，对于计算出的预测值是好还是不好。\n\n对于 Loss 的计算，要从训练资料来进行。所以对于一个预测值，可以从训练资料中知道真实的结果，因而可以计算预估结果和真正结果（Label）之间的误差 e ：$e_{i} = 计算差距(y，\\hat{y} )$。可以以此方法计算训练集中的每一天的误差，从而可得 Loss 值:$L=\\frac{1}{n}\\sum_{n}e_{_n}$\n\nL越大,代表这组参数越不好，L越小,代表这组参数越好\n\n# (2) 计算误差e\n\n如上图，计算误差 e 有多种方法：MAE、MSN 、Cross-entropy（y 和 ŷ 机率分布时使用） 等。\n\n# (3) Error Surface\n\n我们可以调整不同的 w 和 b ，為不同的w跟b的组合计算它的Loss,然后就可以画出以下这一个等高线图.（尝试不同的参数，计算Loss，画出来的图）\n\n在这个等高线图上面,越偏红色系,代表计算出来的Loss越大,就代表这一组w跟b越差,如果越偏蓝色系,就代表Loss越小,就代表这一组w跟b越好。\n\n\n# 3. Optimization\n\n解一个最佳化的问题：找一组未知参数，让 Loss 最小。本例中是找让 Loss 最小的 w* 和 b*。一个Optimization 方法：Gradient Descent。\n\n怎样找一个 w 让这个 loss 的值最小呢？随机选取一个初始的点，这个初始的点,我们叫做 w0-> 求参数对 Loss 的微分 -> 更新参数值。朝低的地方跨一步，那更新时这一步要跨多大呢？这一步的步伐的大小取决于这个地方的斜率和学习率 ($\\eta $)（自己设定的）。这种你在做机器学习,需要自己设定的东西,叫做hyperparameters （超参数）。\n\n什么时候停下来呢？往往有两种状况：\n\n * 第一种状况是你失去耐心了，你一开始会设定说，我今天在调整我的参数的时候，我最多计算几次；\n * 那还有另外一种理想上停下来的可能是，今天当我们不断调整参数时调整到一个地方，它的微分的值算出来正好是 0 的时候，如果这一项正好算出来是0.0乘上 learning rate 还是 0，所以你的参数就不会再移动位置，那参数的位置就不会再更新。\n\n\n\n你可能会发现 Gradient Descent 这个方法有一个巨大的问题，我们没有找到真正最好的解，我们只是找到的 local minima 而不是 global minima。其实，local minima 是一个假问题，我们在做 Gradient Descent 的时候真正面对的难题不是 local minima，之后会讲到它的真正痛点在哪。\n\n刚刚只有一个参数 w，将其扩展至二维乃至多维是同理。\n\noptimization\n\n\n# Linear Model\n\n上文中的模型即线性模型。\n\n观察真实数据，发现每隔七天一个循环，因此可以修改模型（模型的修改通常来自于对问题的理解，即 Domain Knowledge）。因而模型从$y=b+wx_1$ --\x3e $y=b+ \\sum_{j=1}^{7}w_jx_j$，前七天的观看人数都被列入考虑。\n\n\n# Piecewise Linear Curves(分段线性曲线)\n\n不管怎麼摆弄w 跟 b,你永远製造不出红色那一条线,你永远无法用 Linear 的 Model,製造红色这一条线。因为 model 的限制而使得永远无法模拟真实状况，这种来自 Model 的限制，叫做Model 的 Bias（≠上文中 Model 中的 Bias b）。\n\n\n# 1. 红色曲线怎么表达\n\n图中红色的这一条曲线，可以看作是一个常数，加上一群蓝色这样的 Function。\n\n这个蓝色的 Function 叫做 Hard Sigmoid，它的特性是\n\n * 当输入的值,当 x 轴的值小於某一个这个 Flash Hold 的时候,它是某一个定值,\n * 大於另外一个 Flash Hold 的时候,又是另外一个定值,\n * 中间有一个斜坡\n\nPiecewise Linear 的 Curves 越复杂,也就是这个转折的点越多啊,那你需要的这个蓝色的 Function 就越多。可以用 Piecewise Linear 的 Curves,去逼近任何的连续的曲线,而每一个 Piecewise Linear 的 Curves,又都可以用一大堆蓝色的 Function 组合起来,也就是说,我只要有足够的蓝色 Function 把它加起来,我也许就可以变成任何连续的曲线。\n\n\n# 2. 蓝色 Function （Hard Sigmoid）怎么写出来\n\n# （1）Sigmoid Function（S型曲线)\n\n用 sigmoid Function 来逼近蓝色 Function。公式：\n\n$y=c\\frac{1}{1+e^{b+wx_1}} =c*sigmoid(b+wx_1) $\n\n# (2) 各式各样的蓝色 Function 怎样制造出来\n\n调整 b 、w 和 c ：\n\n * 如果你今天改 w 你就会改变斜率你就会改变斜坡的坡度\n\n * 如果你动了 b 你就可以把这一个 Sigmoid Function 左右移动\n\n * 如果你改 c 你就可以改变它的高度\n   \n   不同的 Sigmoid Function 叠起来以后，可以去逼近各种Piecewise Linear 的 Function，然后可以用来来近似不同的连续函数。\n\n\n# 3. 红色 Function 长什么样子\n\n红色曲线 = 蓝色0+1+2+3，即\n\n# 如何减少 Model 的Bias\n\n写一个更有弹性的,有未知参数的 Function：\n\n此时，用了多个Feature，即$X_1$。 j 来代表 Feature 的编号.\n\n我们先考虑一下 j 就是 1 2 3 的状况,就是我们只考虑三个 Feature。举例来说 我们只考虑前一、二、三天的 Case，\n\n * 所以 j 等於 1 2 3,那所以输入就是 x1 代表前一天的观看人数,x2 两天前观看人数,x3 三天前的观看人数\n\n * 每一个 i 就代表了一个蓝色的 Function,只是我们现在每一个蓝色的 Function,都用一个 Sigmoid Function 来比近似它，1 2 3 代表有三个 Sigmoid Function,\n   \n   这个括号裡面做的事情是什麼：\n\n表达成矩阵形式：\n\n这个蓝色方框做的事情：\n\n接下来：\n\n整个过程做的事情为：\n\n**重新定义符号：**各个列向量拼在一起，统称为$\\theta$.\n\n\n# Back to ML_Step 2 :define loss from training data\n\n直接用 θ 来统设所有的参数,所以我们现在的 Loss Function 就变成 $L(\\theta)$.\n\n\n# Back to ML_Step 3: Optimization\n\n一直按照这个图计算下去，直到 Gradient=0 向量的结果或者不想做了。\n\n但是实际上，我们的数据集通常会很大，假设为 N ，我们把这 N 笔资料分成一个个组，一组叫 Batch，并且只拿一个 Batch 里的 Data 算一个 Loss，把他叫做 L1。假设这个 B 够大,也许 L 跟 L1 会很接近 也说不定,所以实作上的时候,每次我们会先选一个 Batch,用这个 Batch 来算 L,根据这个 L1 来算 Gradient,用这个 Gradient 来更新参数,接下来再选下一个 Batch 算出 L2,根据 L2 算出 Gradient,然后再更新参数,再取下一个 Batch 算出 L3,根据 L3 算出 Gradient,再用 L3 算出来的 Gradient 来更新参数，如下图： 所以我们并不是拿 L 来算 Gradient，实际上我们是拿一个 Batch 算出来的 L1 L2 L3，来计算 Gradient，那把所有的 Batch 都看过一次，叫做一个 Epoch，每一次更新参数叫做一次 Update，Update 跟 Epoch 是不一样的东西。Batch Size 也是一个 HyperParameter。 每次更新一次参数叫做一次 Update,把所有的 Batch 都过一遍,叫做一个 Epoch。\n\n\n# 模型变型\n\n# Activation Function\n\n * Sigmoid（S型）\n * ReLU（Rectified Linear Unit）\n\n把两个 ReLU 叠起来,就可以变成 Hard 的 Sigmoid,你想要用 ReLU 的话,就把 Sigmoid 的地方,换成$max(0, b_i+w_{ij}x_j)$.\n\n接下来的实验都选择用了 ReLU,显然 ReLU 比较好.原因下回分解\n\n# 模型改进——多做几次\n\nDeep Learning：Neural Network换个了名字，重振雄风。如下图：\n\nOver Fitting：更深层次之后，在训练集上效果更好，但是预测的效果更差了。",normalizedContent:"机器学习概括来说，机器学习就是让机器具备找一个函式的能力。\n\n\n# different types of functions\n\n * regression（回归）\n   \n   * 输出是一个数值（scalar）\n     \n     > 例如，今天要机器做的事情,是预测未来某一个时间的,pm2.5的数值。输入可能是种种跟预测pm2.5,有关的指数,这一个函式可以拿这些数值当作输入,输出明天中午的pm2.5的数值,那这一个找这个函式的任务,叫作regression。\n\n * classification（分类）\n   \n   * 要机器做选择题。人类先备好一些选项（也叫类别）（classes），从设定好的选项中选择一个当做输出，这个任务就叫做 classification。\n     \n     > 例如，gmail account裡面有一个函式,帮我们侦测一封邮件,是不是垃圾邮件。\n     > \n     > alpha go本身也是一个 classification 的问题。\n\n * structured learning\n   \n   * 机器今天不只是要做选择题，不只是输出一个数字，还要产生一个有结构的物件。机器画一张图 写一篇文章,这种叫机器产生有结构的东西的问题,就叫作structured learning。即要机器学会创造。\n\n\n# case study\n\n举例说明机器怎么找一个函式。\n\n找一个函式,这个函式的输入是youtube上面一个频道过往所有的资讯，输出就是预测明天这个频道可能的总观看次数。\n\n找这个函式的过程，分为三步：\n\n 1. 写出一个带有未知参数的函式；2. 定义一个叫做loss的function；3. 解一个optimization的问题找到一组参数使loss值最小。<本质是训练，用已知的数据来“预测”>\n\n----------------------------------------\n\n\n# 1. function with unknown parameters\n\n假设函式为 $ y=b+w*x_{1} $，这个带有unknown的parameter的function叫做model。这个猜测往往就来自于你对这个问题本质上的了解，也就是 domain knowledge\n\n * y 为预测值，本例中为明天观看此频道的总人数\n * $x_{1}$为已知的东西，叫做feature，本例中为今天观看的人数\n * b (bias) 和 w (weight)是未知的参数，要从数据资料中学习得到\n\n\n# 2. define loss from training data\n\n# (1) loss 函数\n\n定义一个 loss 函数，输入为 model 中的未知参数 b 和 w（parameter），输出的值表示若把这组值传给未知参数，对于计算出的预测值是好还是不好。\n\n对于 loss 的计算，要从训练资料来进行。所以对于一个预测值，可以从训练资料中知道真实的结果，因而可以计算预估结果和真正结果（label）之间的误差 e ：$e_{i} = 计算差距(y，\\hat{y} )$。可以以此方法计算训练集中的每一天的误差，从而可得 loss 值:$l=\\frac{1}{n}\\sum_{n}e_{_n}$\n\nl越大,代表这组参数越不好，l越小,代表这组参数越好\n\n# (2) 计算误差e\n\n如上图，计算误差 e 有多种方法：mae、msn 、cross-entropy（y 和 y 机率分布时使用） 等。\n\n# (3) error surface\n\n我们可以调整不同的 w 和 b ，為不同的w跟b的组合计算它的loss,然后就可以画出以下这一个等高线图.（尝试不同的参数，计算loss，画出来的图）\n\n在这个等高线图上面,越偏红色系,代表计算出来的loss越大,就代表这一组w跟b越差,如果越偏蓝色系,就代表loss越小,就代表这一组w跟b越好。\n\n\n# 3. optimization\n\n解一个最佳化的问题：找一组未知参数，让 loss 最小。本例中是找让 loss 最小的 w* 和 b*。一个optimization 方法：gradient descent。\n\n怎样找一个 w 让这个 loss 的值最小呢？随机选取一个初始的点，这个初始的点,我们叫做 w0-> 求参数对 loss 的微分 -> 更新参数值。朝低的地方跨一步，那更新时这一步要跨多大呢？这一步的步伐的大小取决于这个地方的斜率和学习率 ($\\eta $)（自己设定的）。这种你在做机器学习,需要自己设定的东西,叫做hyperparameters （超参数）。\n\n什么时候停下来呢？往往有两种状况：\n\n * 第一种状况是你失去耐心了，你一开始会设定说，我今天在调整我的参数的时候，我最多计算几次；\n * 那还有另外一种理想上停下来的可能是，今天当我们不断调整参数时调整到一个地方，它的微分的值算出来正好是 0 的时候，如果这一项正好算出来是0.0乘上 learning rate 还是 0，所以你的参数就不会再移动位置，那参数的位置就不会再更新。\n\n\n\n你可能会发现 gradient descent 这个方法有一个巨大的问题，我们没有找到真正最好的解，我们只是找到的 local minima 而不是 global minima。其实，local minima 是一个假问题，我们在做 gradient descent 的时候真正面对的难题不是 local minima，之后会讲到它的真正痛点在哪。\n\n刚刚只有一个参数 w，将其扩展至二维乃至多维是同理。\n\noptimization\n\n\n# linear model\n\n上文中的模型即线性模型。\n\n观察真实数据，发现每隔七天一个循环，因此可以修改模型（模型的修改通常来自于对问题的理解，即 domain knowledge）。因而模型从$y=b+wx_1$ --\x3e $y=b+ \\sum_{j=1}^{7}w_jx_j$，前七天的观看人数都被列入考虑。\n\n\n# piecewise linear curves(分段线性曲线)\n\n不管怎麼摆弄w 跟 b,你永远製造不出红色那一条线,你永远无法用 linear 的 model,製造红色这一条线。因为 model 的限制而使得永远无法模拟真实状况，这种来自 model 的限制，叫做model 的 bias（=上文中 model 中的 bias b）。\n\n\n# 1. 红色曲线怎么表达\n\n图中红色的这一条曲线，可以看作是一个常数，加上一群蓝色这样的 function。\n\n这个蓝色的 function 叫做 hard sigmoid，它的特性是\n\n * 当输入的值,当 x 轴的值小於某一个这个 flash hold 的时候,它是某一个定值,\n * 大於另外一个 flash hold 的时候,又是另外一个定值,\n * 中间有一个斜坡\n\npiecewise linear 的 curves 越复杂,也就是这个转折的点越多啊,那你需要的这个蓝色的 function 就越多。可以用 piecewise linear 的 curves,去逼近任何的连续的曲线,而每一个 piecewise linear 的 curves,又都可以用一大堆蓝色的 function 组合起来,也就是说,我只要有足够的蓝色 function 把它加起来,我也许就可以变成任何连续的曲线。\n\n\n# 2. 蓝色 function （hard sigmoid）怎么写出来\n\n# （1）sigmoid function（s型曲线)\n\n用 sigmoid function 来逼近蓝色 function。公式：\n\n$y=c\\frac{1}{1+e^{b+wx_1}} =c*sigmoid(b+wx_1) $\n\n# (2) 各式各样的蓝色 function 怎样制造出来\n\n调整 b 、w 和 c ：\n\n * 如果你今天改 w 你就会改变斜率你就会改变斜坡的坡度\n\n * 如果你动了 b 你就可以把这一个 sigmoid function 左右移动\n\n * 如果你改 c 你就可以改变它的高度\n   \n   不同的 sigmoid function 叠起来以后，可以去逼近各种piecewise linear 的 function，然后可以用来来近似不同的连续函数。\n\n\n# 3. 红色 function 长什么样子\n\n红色曲线 = 蓝色0+1+2+3，即\n\n# 如何减少 model 的bias\n\n写一个更有弹性的,有未知参数的 function：\n\n此时，用了多个feature，即$x_1$。 j 来代表 feature 的编号.\n\n我们先考虑一下 j 就是 1 2 3 的状况,就是我们只考虑三个 feature。举例来说 我们只考虑前一、二、三天的 case，\n\n * 所以 j 等於 1 2 3,那所以输入就是 x1 代表前一天的观看人数,x2 两天前观看人数,x3 三天前的观看人数\n\n * 每一个 i 就代表了一个蓝色的 function,只是我们现在每一个蓝色的 function,都用一个 sigmoid function 来比近似它，1 2 3 代表有三个 sigmoid function,\n   \n   这个括号裡面做的事情是什麼：\n\n表达成矩阵形式：\n\n这个蓝色方框做的事情：\n\n接下来：\n\n整个过程做的事情为：\n\n**重新定义符号：**各个列向量拼在一起，统称为$\\theta$.\n\n\n# back to ml_step 2 :define loss from training data\n\n直接用 θ 来统设所有的参数,所以我们现在的 loss function 就变成 $l(\\theta)$.\n\n\n# back to ml_step 3: optimization\n\n一直按照这个图计算下去，直到 gradient=0 向量的结果或者不想做了。\n\n但是实际上，我们的数据集通常会很大，假设为 n ，我们把这 n 笔资料分成一个个组，一组叫 batch，并且只拿一个 batch 里的 data 算一个 loss，把他叫做 l1。假设这个 b 够大,也许 l 跟 l1 会很接近 也说不定,所以实作上的时候,每次我们会先选一个 batch,用这个 batch 来算 l,根据这个 l1 来算 gradient,用这个 gradient 来更新参数,接下来再选下一个 batch 算出 l2,根据 l2 算出 gradient,然后再更新参数,再取下一个 batch 算出 l3,根据 l3 算出 gradient,再用 l3 算出来的 gradient 来更新参数，如下图： 所以我们并不是拿 l 来算 gradient，实际上我们是拿一个 batch 算出来的 l1 l2 l3，来计算 gradient，那把所有的 batch 都看过一次，叫做一个 epoch，每一次更新参数叫做一次 update，update 跟 epoch 是不一样的东西。batch size 也是一个 hyperparameter。 每次更新一次参数叫做一次 update,把所有的 batch 都过一遍,叫做一个 epoch。\n\n\n# 模型变型\n\n# activation function\n\n * sigmoid（s型）\n * relu（rectified linear unit）\n\n把两个 relu 叠起来,就可以变成 hard 的 sigmoid,你想要用 relu 的话,就把 sigmoid 的地方,换成$max(0, b_i+w_{ij}x_j)$.\n\n接下来的实验都选择用了 relu,显然 relu 比较好.原因下回分解\n\n# 模型改进——多做几次\n\ndeep learning：neural network换个了名字，重振雄风。如下图：\n\nover fitting：更深层次之后，在训练集上效果更好，但是预测的效果更差了。",charsets:{cjk:!0},lastUpdated:"2022/03/28, 03:20:10",lastUpdatedTimestamp:164843761e4},{title:"神经网络训练不起来怎么办",frontmatter:{title:"神经网络训练不起来怎么办",date:"2022-10-12T09:52:10.000Z",permalink:"/pages/e6f457/",categories:["AI","深度学习","李宏毅"],tags:[null]},regularPath:"/AI/05.%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/05.%E6%9D%8E%E5%AE%8F%E6%AF%85/05.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83%E4%B8%8D%E8%B5%B7%E6%9D%A5%E6%80%8E%E4%B9%88%E5%8A%9E.html",relativePath:"AI/05.深度学习/05.李宏毅/05.神经网络训练不起来怎么办.md",key:"v-74cfb0b2",path:"/pages/e6f457/",headersStr:null,content:"通常 local minimum 并不常见，更常见的是 saddle point，大部分时候都还有路可以让 Loss 下降。\n\n",normalizedContent:"通常 local minimum 并不常见，更常见的是 saddle point，大部分时候都还有路可以让 loss 下降。\n\n",charsets:{cjk:!0},lastUpdated:"2023/01/24, 08:14:58",lastUpdatedTimestamp:1674548098e3},{title:"Home",frontmatter:{home:!0,heroText:"Nrich's blog",tagline:"积跬步以至千里，致敬每个爱学习的你。",features:[{title:"开发",details:"java等后端技术",imgUrl:"/img/milkdragon.jpeg"},{title:"AI",details:"深度学习等学习笔记",imgUrl:"/img/ui.png"},{title:"技术",details:"技术文档、教程、技巧、总结等文章",imgUrl:"/img/other.png"}]},regularPath:"/",relativePath:"index.md",key:"v-a113e2c4",path:"/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/03/28, 03:20:10",lastUpdatedTimestamp:164843761e4},{title:"基础架构、数据结构与 IO 模型",frontmatter:{title:"基础架构、数据结构与 IO 模型",date:"2023-03-20T14:37:36.000Z",permalink:"/pages/271391/",categories:["中间件","Redis","专栏：Redis 核心技术与实战"],tags:[null]},regularPath:"/%E4%B8%AD%E9%97%B4%E4%BB%B6/05.Redis/05.%E4%B8%93%E6%A0%8F%EF%BC%9ARedis%20%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/01.%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84%E3%80%81%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%20IO%20%E6%A8%A1%E5%9E%8B.html",relativePath:"中间件/05.Redis/05.专栏：Redis 核心技术与实战/01.基础架构、数据结构与 IO 模型.md",key:"v-6962c4c2",path:"/pages/271391/",headers:[{level:2,title:"1. 基础架构：一个键值数据库包含什么？",slug:"_1-基础架构-一个键值数据库包含什么",normalizedTitle:"1. 基础架构：一个键值数据库包含什么？",charIndex:53},{level:3,title:"1.1 可以存哪些数据？",slug:"_1-1-可以存哪些数据",normalizedTitle:"1.1 可以存哪些数据？",charIndex:417},{level:3,title:"1.2 可以对数据做什么操作？",slug:"_1-2-可以对数据做什么操作",normalizedTitle:"1.2 可以对数据做什么操作？",charIndex:824},{level:3,title:"1.3 采用什么访问模式？",slug:"_1-3-采用什么访问模式",normalizedTitle:"1.3 采用什么访问模式？",charIndex:1674},{level:3,title:"1.4 如何定位键值对的位置？",slug:"_1-4-如何定位键值对的位置",normalizedTitle:"1.4 如何定位键值对的位置？",charIndex:2330},{level:3,title:"1.5 不同操作的具体逻辑是怎样的？",slug:"_1-5-不同操作的具体逻辑是怎样的",normalizedTitle:"1.5 不同操作的具体逻辑是怎样的？",charIndex:2810},{level:3,title:"1.6 如何实现重启后快速提供服务？",slug:"_1-6-如何实现重启后快速提供服务",normalizedTitle:"1.6 如何实现重启后快速提供服务？",charIndex:3069},{level:3,title:"1.7 小结",slug:"_1-7-小结",normalizedTitle:"1.7 小结",charIndex:3694},{level:2,title:"2. 数据结构：快速的Redis有哪些慢操作？",slug:"_2-数据结构-快速的redis有哪些慢操作",normalizedTitle:"2. 数据结构：快速的redis有哪些慢操作？",charIndex:4039},{level:3,title:"2.1 key 和 value 用什么结构组织？",slug:"_2-1-key-和-value-用什么结构组织",normalizedTitle:"2.1 key 和 value 用什么结构组织？",charIndex:4694},{level:3,title:"2.2 为什么哈希表操作变慢了——哈希冲突",slug:"_2-2-为什么哈希表操作变慢了-哈希冲突",normalizedTitle:"2.2 为什么哈希表操作变慢了——哈希冲突",charIndex:5180},{level:3,title:"2.3 集合数据的操作效率",slug:"_2-3-集合数据的操作效率",normalizedTitle:"2.3 集合数据的操作效率",charIndex:6259},{level:4,title:"2.3.1 有哪些底层数据结构",slug:"_2-3-1-有哪些底层数据结构",normalizedTitle:"2.3.1 有哪些底层数据结构",charIndex:6425},{level:4,title:"2.3.2 不同操作的复杂度",slug:"_2-3-2-不同操作的复杂度",normalizedTitle:"2.3.2 不同操作的复杂度",charIndex:7426},{level:3,title:"2.4 小结",slug:"_2-4-小结",normalizedTitle:"2.4 小结",charIndex:8641},{level:2,title:"3. 高性能 IO 模型：为什么单线程还能这么快？",slug:"_3-高性能-io-模型-为什么单线程还能这么快",normalizedTitle:"3. 高性能 io 模型：为什么单线程还能这么快？",charIndex:10048},{level:3,title:"3.1 Redis 为什么用单线程——多线程的并发访问控制问题",slug:"_3-1-redis-为什么用单线程-多线程的并发访问控制问题",normalizedTitle:"3.1 redis 为什么用单线程——多线程的并发访问控制问题",charIndex:10427},{level:3,title:"3.2 单线程 Redis 为什么那么快——多路复用机制",slug:"_3-2-单线程-redis-为什么那么快-多路复用机制",normalizedTitle:"3.2 单线程 redis 为什么那么快——多路复用机制",charIndex:10972},{level:4,title:"3.2.1 基本 IO 模型与阻塞点",slug:"_3-2-1-基本-io-模型与阻塞点",normalizedTitle:"3.2.1 基本 io 模型与阻塞点",charIndex:11235},{level:4,title:"3.2.2 非阻塞模式",slug:"_3-2-2-非阻塞模式",normalizedTitle:"3.2.2 非阻塞模式",charIndex:11552},{level:4,title:"3.2.3 基于多路复用的高性能 I/O 模型",slug:"_3-2-3-基于多路复用的高性能-i-o-模型",normalizedTitle:"3.2.3 基于多路复用的高性能 i/o 模型",charIndex:12219},{level:3,title:"3.3 小结",slug:"_3-3-小结",normalizedTitle:"3.3 小结",charIndex:13554}],headersStr:"1. 基础架构：一个键值数据库包含什么？ 1.1 可以存哪些数据？ 1.2 可以对数据做什么操作？ 1.3 采用什么访问模式？ 1.4 如何定位键值对的位置？ 1.5 不同操作的具体逻辑是怎样的？ 1.6 如何实现重启后快速提供服务？ 1.7 小结 2. 数据结构：快速的Redis有哪些慢操作？ 2.1 key 和 value 用什么结构组织？ 2.2 为什么哈希表操作变慢了——哈希冲突 2.3 集合数据的操作效率 2.3.1 有哪些底层数据结构 2.3.2 不同操作的复杂度 2.4 小结 3. 高性能 IO 模型：为什么单线程还能这么快？ 3.1 Redis 为什么用单线程——多线程的并发访问控制问题 3.2 单线程 Redis 为什么那么快——多路复用机制 3.2.1 基本 IO 模型与阻塞点 3.2.2 非阻塞模式 3.2.3 基于多路复用的高性能 I/O 模型 3.3 小结",content:"# 基础架构、数据结构与 IO 模型\n\n> 参考： 01 | 基本架构：一个键值数据库包含什么？\n\n\n# 1. 基础架构：一个键值数据库包含什么？\n\nRedis是典型的键值数据库。\n\n我们先建立起”系统观“，再深入理解和优化 Redis。 即先对它的总体架构和关键模块有一个全局的认知，然后再深入到具体的技术点。\n\n今天，先构造一个简单的 KV 数据库，我们只需要关注整体架构和核心模块，并对其进行剖析。我把这个简单的键值数据库称为SimpleKV，它只是一个具有关键组件的 KV 数据库架构。\n\n> 这里的 SimpleKV 与 GitHub 上同名的项目并不是一个东西。\n\n开始构造 SimpleKV 时，首先就要考虑里面可以存什么样的数据，对数据可以做什么样的操作，也就是数据模型和操作接口。\n\n对于Redis来说，它到底能做什么，不能做什么呢？只有先搞懂它的数据模型和操作接口，我们才能真正把“这块好钢用在刀刃上”。\n\n\n# 1.1 可以存哪些数据？\n\n对于键值数据库而言，基本的数据模型是 key-value 模型。SimpleKV 中：\n\n * key 为 String 类型\n * value 为基本数据类型，如 String、整型等。\n\n对于实际生产环境中的键值数据库来说，value 类型还可以是复杂类型。\n\n不同键值数据库支持的key类型一般差异不大，而value类型则有较大差别。我们在对键值数据库进行选型时，一个重要的考虑因素是它支持的value类型。例如，Memcached 支持的 value 类型仅为 String 类型，而 Redis 支持的 value 类型包括了 String、哈希表、列表、集合等。Redis能够在实际业务场景中得到广泛的应用，就是得益于支持多样化类型的 value。\n\n不同 value 类型的实现存在各种性能、效率等方面的差异，因此用于满足不同业务的需求。明白这些原理才能去选择。\n\n\n# 1.2 可以对数据做什么操作？\n\nSimpleKV是一个简单的键值数据库，因此，基本操作无外乎增删改查：\n\n * PUT：新写入或更新一个 key-value 对；\n * GET：根据一个 key 读取相应的value值；\n * DELETE：根据一个 key 删除整个 key-value 对。\n\n需要注意的是， 有些键值数据库的新写/更新操作叫 SET。新写入和更新虽然是用一个操作接口，但在实际执行时，会根据 key 是否存在而执行相应的新写或更新流程。\n\n在实际的业务场景中，我们经常会碰到这种情况：查询一个用户在一段时间内的访问记录。这种操作在键值数据库中属于SCAN 操作，即 根据一段 key 的范围返回相应的 value 值。因此， PUT/GET/DELETE/SCAN 是一个键值数据库的基本操作集合。\n\n此外，实际业务场景通常还有更加丰富的需求，比如 EXISTS 接口。对于一个具体的键值数据库而言，你可以通过查看操作文档，了解其详细的操作接口。\n\n现在，数据模型和操作接口我们就构造完成了，这是我们的基础工作。接下来更进一步，需要考虑一个非常重要的设计问题： 键值对保存在内存还是外存？\n\n * 保存在内存的好处是读写很快，潜在风险是一旦掉电，所有的数据都会丢失。\n * 保存在外存虽可以避免数据丢失，但受限于磁盘性能，整体数据库的性能就会被拉低。\n\n因此， 如何进行设计选择，我们通常需要考虑键值数据库的主要应用场景。比如，缓存场景下的数据需要能快速访问但允许丢失，那么，用于此场景的键值数据库通常采用内存保存键值数据。Memcached 和 Redis 都是属于内存键值数据库。\n\n为了和Redis保持一致，我们的 SimpleKV 就采用内存保存键值数据。接下来，我们来了解下 SimpleKV 的基本组件。大体来说，一个键值数据库包括了访问框架、索引模块、操作模块和存储模块四部分：\n\n\n\n接下来，我们就从这四个部分入手，继续构建我们的 SimpleKV。\n\n\n# 1.3 采用什么访问模式？\n\n访问模式通常有两种：\n\n * 一种是通过函数库调用的方式供外部应用使用。比如上图的 libsimplekv.so，以动态链接库的形式链接到程序中\n * 一种是通过网络框架以 Socket 通信的形式对外提供 KV 操作\n\n实际的键值数据库也基本采用上述两种方式，例如，RocksDB 以动态链接库的形式使用，而 Memcached 和 Redis 则是通过网络框架访问。\n\n通过网络框架提供键值存储服务，一方面扩大了键值数据库的受用面，但另一方面，也给键值数据库的性能、运行模型提供了不同的设计选择，带来了一些潜在的问题。\n\nKV 数据库通过接收网络数据包，并按照协议进行解析得到操作，然后执行。此时，我们会遇到一个系统设计上的问题，简单来说，就是网络连接的处理、网络请求的解析，以及数据存取的处理，是用一个线程、多个线程，还是多个进程来交互处理呢？该如何进行设计和取舍呢？我们一般把这个问题称为 I/O 模型设计。不同的 I/O 模型对键值数据库的性能和可扩展性会有不同的影响：\n\n * 如果使用单线程，那一个线程既要处理网络连接、解析请求，又要完成数据存取，一旦某一步操作发生阻塞，整个线程就会阻塞住，这就降低了系统响应速度。\n * 如果使用多线程，那不同线程间如果需要访问共享资源，那又会产生线程竞争，也会影响系统效率。\n\n因此我们需要进行精心的设计来面对这个两难的问题。\n\n> 也许你听说过 Redis 是单线程，那 Redis 是如何做到“单线程、高性能”的呢？\n\n\n# 1.4 如何定位键值对的位置？\n\nSimpleKV 查找某个 KV 对的操作依赖于 KV 数据库的索引模型。索引的作用是让键值数据库根据 key 找到相应 value 的存储位置，进而执行操作。\n\n索引的类型有很多，常见的有哈希表、B+树、字典树等。不同的索引结构在性能、空间消耗、并发控制等方面具有不同的特征。Memcached 和 Redis 采用哈希表作为 key-value 索引，而 RocksDB 则采用跳表作为内存中 key-value 的索引。\n\nSimpleKV的索引根据 key 找到 value 的存储位置即可。但是，和 SimpleKV 不同，对 Redis 而言，它的 value 支持多种类型，当我们通过索引找到一个 key 所对应的 value 后，仍然需要从 value 的复杂结构（例如集合和列表）中进一步找到我们实际需要的数据，这个操作的效率本身就依赖于它们的实现结构。\n\nRedis 采用一些常见的高效索引结构作为某些 value 类型的底层数据结构，这一技术路线为 Redis 实现高性能访问提供了良好的支撑。\n\n\n# 1.5 不同操作的具体逻辑是怎样的？\n\nSimpleKV 找到数据的存储位置后，对于不同的操作，其进一步执行的操作逻辑也有所差异。\n\nSimpleKV 的操作模块就实现了不同操作的具体逻辑：\n\n * GET/SCAN：立刻返回当前位置的 value 即可；\n * PUT：为新 KV pair 分配内存空间；\n * DELETE：删除 KV pair，并释放相应内存空间，这个过程由分配器完成。\n\n对于 PUT 或 DELETE 操作，涉及到了分配和释放内存，这就需要 SimpleKV 数据库的存储模块了。\n\n\n# 1.6 如何实现重启后快速提供服务？\n\nSimpleKV 采用了常用的内存分配器 glibc 的 malloc 和 free，因此，SimpleKV 并不需要特别考虑内存空间的管理问题。\n\n但是，KV 数据库的 KV pair 通常大小不一，glibc 的分配器在处理随机的大小内存块分配时表现并不好。一旦保存的键值对数据规模过大，就可能会造成较严重的内存碎片问题。\n\n因此，分配器是 KV 数据库的一个关键因素。Redis 的内存分配器提供了多种选择，分配效率也不一样，后面会对此展开讲述。\n\nSimpleKV 虽然依赖于内存保存数据，提供快速访问，但是，我也希望 SimpleKV 重启后能快速重新提供服务，所以，我在 SimpleKV 的存储模块中增加了持久化功能。不过，鉴于磁盘管理要比内存管理复杂，SimpleKV 就直接采用了文件形式，将键值数据通过调用本地文件系统的操作接口保存在磁盘上。\n\n此时，SimpleKV 只需要考虑何时将内存中的键值数据保存到文件中：\n\n * 一种方式是，每次 KV pair 的修改都进行落盘操作。虽然这更可靠，但性能会受到很大影响。\n * 一种方式是，周期性地把内存中的 KV pair 同步到文件中。但这面临数据丢失的风险。\n\nRedis 也提供了持久化功能。不过，为了适应不同的业务场景，Redis 为持久化提供了诸多的执行机制和优化改进。后面会对 Redis 的持久化机制的设计进行讨论。\n\n\n# 1.7 小结\n\n在了解了这个 SimpleKV 的基本组件后，再学习 Redis 这个丰富版的 SimpleKV 时就会轻松很多。为了支持更加丰富的业务场景，Redis对这些组件或者功能进行了扩展，或者说是进行了精细优化，从而满足了功能和性能等方面的要求。\n\n\n\n从 SimpleKV 到 Redis，主要有以下重要变化：\n\n * Redis 主要通过网络框架进行访问，而不再是动态库了。\n * value 的类型更加丰富，因此可支持的操作也更加丰富。\n * Redis的持久化模块能支持两种方式：日志（AOF）和快照（RDB）。\n * SimpleKV 是个简单的单机键值数据库，但是，Redis 支持高可靠集群和高可扩展集群，因此，Redis 中包含了相应的集群功能支撑模块。\n\n\n# 2. 数据结构：快速的Redis有哪些慢操作？\n\nRedis 的“快”有一个重要表现：它接收到一个键值对操作后，能以微秒级别的速度找到数据，并快速完成操作。\n\n数据库这么多，为啥 Redis 能有这么突出的表现呢：\n\n * 一方面，操作在内存中完成\n * 另一方面，归功于它的数据结构，高效的数据结构是 Redis 快速处理数据的基础。\n\n> 这里说的数据结构是指数据库中 value 的数据类型（图中绿色的块块）的底层实现方式\n\n简单来说，底层数据结构一共有 6 种：简单动态字符串、双向链表、压缩列表、哈希表、跳表和整数数组。它们和数据类型的对应关系如下图所示：\n\n\n\n可以看到，String 类型的底层实现只有一种数据结构，也就是简单动态字符串。而 List、Hash、Set 和 Sorted Set 这四种数据类型，都有两种底层实现结构。通常情况下，我们会把这四种类型称为集合类型，它们的特点是一个键对应了一个集合的数据。\n\n看到这里，其实有些问题已经值得我们去考虑了：\n\n * 这些数据结构都是值的底层实现，键和值本身之间用什么结构组织？\n * 为什么集合类型有那么多的底层结构，它们都是怎么组织数据的，都很快吗？\n * 什么是简单动态字符串，和常用的字符串是一回事吗？\n\n接下来，我就和你聊聊前两个问题。这样，你不仅可以知道 Redis“快”的基本原理，还可以借此理解 Redis 中有哪些潜在的“慢操作”，最大化 Redis 的性能优势。而关于简单动态字符串，会在后面的课程继续讨论。\n\n\n# 2.1 key 和 value 用什么结构组织？\n\n为了实现从 key 到 value 的快速访问，Redis 使用了一个哈希表来保存所有键值对。\n\n一个哈希表，其实就是一个数组，数组的每个元素称为一个哈希桶。所以，我们常说，一个哈希表是由多个哈希桶组成的，每个哈希桶中保存了键值对数据。哈希桶中的元素保存的不是值本身，而是一个 pointer，这样不管 value 是 String 还是 collection 类型，哈希桶中的元素都是指向它们的 pointer。\n\n如下图所示，哈希桶中的 entry 元素中保存了 key 和 value 的 pointer：\n\n\n\n因为这个哈希表保存了所有的键值对，所以，我也把它称为全局哈希表。使用 hash table 可以在 O(1) 时间复杂度下访问到相应的 entry 元素。——通过计算 key 的哈希值，得到哈希桶的位置，就可以访问到 KV pair 了。\n\n但是，随着往 Redis 写入大量数据后，会发现操作有时候突然变慢了，因为有一个潜在的风险点：哈希表的冲突问题和 rehash 可能带来的操作阻塞。\n\n\n# 2.2 为什么哈希表操作变慢了——哈希冲突\n\n当数据增多，哈希冲突是不可避免的问题。\n\nRedis 解决哈希冲突的方式，就是链式哈希：同一个哈希桶中的多个元素用一个链表来保存，它们之间依次用指针连接。\n\n如下图所示，冲突的元素形成的链表，叫做哈希冲突链。\n\n\n\n但随着哈希冲突越来越多，一条哈希冲突链的逐 entry 查找会降低性能。所以，Redis 会对哈希表做 rehash 操作：增加现有的哈希桶数量，让逐渐增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突。\n\nrehash 具体怎么做呢？\n\n为了使 rehash 操作更高效，Redis 默认使用了两个全局哈希表：哈希表 1 和哈希表 2。一开始，当你刚插入数据时，默认使用哈希表 1，此时的哈希表 2 并没有被分配空间。随着数据逐步增多，Redis 开始执行 rehash，这个过程分为三步：\n\n 1. 给哈希表 2 分配更大的空间，例如是当前哈希表 1 大小的两倍；\n 2. 把哈希表 1 中的数据重新映射并拷贝到哈希表 2 中；\n 3. 释放哈希表 1 的空间。\n\n到此，我们就可以从哈希表 1 切换到哈希表 2，用增大的哈希表 2 保存更多数据，而原来的哈希表 1 留作下一次 rehash 扩容备用。\n\n这个过程看似简单，但是第二步涉及大量的数据拷贝，如果一次性把哈希表 1 中的数据都迁移完，会造成 Redis 线程阻塞，无法服务其他请求。此时，Redis 就无法快速访问数据了。为了避免这个问题，Redis 采用了渐进式 rehash：\n\n简单来说就是在第二步拷贝数据时，Redis 仍然正常处理客户端请求，每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries。如下图所示：\n\n\n\n这样就巧妙地把一次性大量拷贝的开销，分摊到了多次处理请求的过程中，避免了耗时操作，保证了数据的快速访问。\n\n到这里，你就能理解 Redis 的 key 和 value 是怎么通过哈希表来组织的了。\n\n * 对于 value 为 String 类型的来说，找到 entry 就可以直接 CRUD 了，操作复杂度 O(1)。\n * 对于 value 为 collection 类型的来说，找到 entry 后还要在集合中进一步操作。\n\n接下来来看在 collection 类型中的操作效率又是怎样的。\n\n\n# 2.3 集合数据的操作效率\n\n和 String 类型不同，一个集合类型的 value，第一步是通过全局哈希表找到对应的哈希桶位置，第二步是在集合中再增删改查。那么，集合的操作效率和哪些因素相关呢？\n\n 1. 与底层的数据结构有关\n 2. 与操作本身的执行特点有关\n\n接下来，我们就分别聊聊集合类型的底层数据结构和操作复杂度。\n\n# 2.3.1 有哪些底层数据结构\n\n集合类型的底层数据结构主要有 5 种：整数数组、双向链表、哈希表、压缩列表和跳表：\n\n * 哈希表的操作我们已经了解了；\n * 整数数组和双向链表平时很常见，其操作特征是顺序读写，通过数组下标或者链表的指针逐个元素访问，操作复杂度往往是 O(N)；\n * 压缩跳表和跳表平时接触不多，但也是 Redis 的重要数据结构，下面重点解释这部分。\n\n----------------------------------------\n\n压缩列表：\n\n压缩列表实际上类似于一个数组，数组中的每一个元素都对应保存一个数据。和数组不同的是，压缩列表在表头有三个字段：\n\n * zlbytes：列表长度\n * zltail：列表尾的偏移量\n * zllen：列表中的 entry 的个数\n\n\n\n在压缩列表中，定位第一个和最后一个元素，可以通过表头三个字段的长度直接定位，复杂度是O(1)。而查找其他元素时，只能逐个查找，此时的复杂度就是O(N)了。\n\n----------------------------------------\n\n跳表：\n\n有序链表只能逐一查找元素，导致操作起来非常缓慢，于是就出现了跳表。具体来说，跳表在链表的基础上，增加了多级索引，通过索引位置的几个跳转，实现数据的快速定位，如下图所示：\n\n\n\n如果我们要在链表中查找 33 这个元素，只能从头开始遍历链表，查找 6 次，直到找到 33 为止。此时，复杂度是 O(N)，查找效率很低。\n\n为了提高查找速度，我们来增加一级索引：从第一个元素开始，每两个元素选一个出来作为索引。这些索引再通过指针指向原始的链表。例如，从前两个元素中抽取元素 1 作为一级索引，从第三、四个元素中抽取元素 11 作为一级索引。此时，我们只需要 4 次查找就能定位到元素 33 了。\n\n如果我们还想再快，可以再增加二级索引：从一级索引中，再抽取部分元素作为二级索引。例如，从一级索引中抽取 1、27、100 作为二级索引，二级索引指向一级索引。这样，我们只需要 3 次查找，就能定位到元素 33 了。\n\n可以看到，这个查找过程就是在多级索引上跳来跳去，最后定位到元素。这也正好符合“跳”表的叫法。当数据量很大时，跳表的查找复杂度就是 $O(logN)$。\n\n好了，我们现在可以按照查找的时间复杂度给这些数据结构分下类了：\n\n\n\n# 2.3.2 不同操作的复杂度\n\n集合类型的操作类型很多，有读写单个集合元素的，例如 HGET、HSET，也有操作多个元素的，例如 SADD，还有对整个集合进行遍历操作的，例如 SMEMBERS。这么多操作，它们的复杂度也各不相同。而复杂度的高低又是我们选择集合类型的重要依据。\n\n我总结了一个“四句口诀”，希望能帮助你快速记住集合常见操作的复杂度。这样你在使用过程中，就可以提前规避高复杂度操作了：\n\n * 单元素操作是基础；\n * 范围操作非常耗时；\n * 统计操作通常高效；\n * 例外情况只有几个。\n\n第一，单元素操作，是指每一种集合类型对单个数据实现的增删改查操作。例如，Hash 类型的 HGET、HSET 和 HDEL，Set 类型的 SADD、SREM、SRANDMEMBER 等。这些操作的复杂度由集合采用的数据结构决定，例如，HGET、HSET 和 HDEL 是对哈希表做操作，所以它们的复杂度都是 O(1)；Set 类型用哈希表作为底层数据结构时，它的 SADD、SREM、SRANDMEMBER 复杂度也是 O(1)。\n\n这里，有个地方你需要注意一下，集合类型支持同时对多个元素进行增删改查，例如 Hash 类型的 HMGET 和 HMSET，Set 类型的 SADD 也支持同时增加多个元素。此时，这些操作的复杂度，就是由单个元素操作复杂度和元素个数决定的。例如，HMSET 增加 M 个元素时，复杂度就从 O(1) 变成 O(M) 了。\n\n第二，范围操作，是指集合类型中的遍历操作，可以返回集合中的所有数据，比如 Hash 类型的 HGETALL 和 Set 类型的 SMEMBERS，或者返回一个范围内的部分数据，比如 List 类型的 LRANGE 和 ZSet 类型的 ZRANGE。这类操作的复杂度一般是 O(N)，比较耗时，我们应该尽量避免。\n\n不过，Redis 从 2.8 版本开始提供了 SCAN 系列操作（包括 HSCAN，SSCAN 和 ZSCAN），这类操作实现了渐进式遍历，每次只返回有限数量的数据。这样一来，相比于 HGETALL、SMEMBERS 这类操作来说，就避免了一次性返回所有元素而导致的 Redis 阻塞。\n\n第三，统计操作，是指集合类型对集合中所有元素个数的记录，例如 LLEN 和 SCARD。这类操作复杂度只有 O(1)，这是因为当集合类型采用压缩列表、双向链表、整数数组这些数据结构时，这些结构中专门记录了元素的个数统计，因此可以高效地完成相关操作。\n\n第四，例外情况，是指某些数据结构的特殊记录，例如压缩列表和双向链表都会记录表头和表尾的偏移量。这样一来，对于 List 类型的 LPOP、RPOP、LPUSH、RPUSH 这四个操作来说，它们是在列表的头尾增删元素，这就可以通过偏移量直接定位，所以它们的复杂度也只有 O(1)，可以实现快速操作。\n\n\n# 2.4 小结\n\n这一大节学习了 Redis 的底层数据结构，包括 Redis 整体的用来保存每个 KV 的全局哈希表结构，也包括支持集合类型实现的双向链表、压缩列表、整数数组、哈希表和跳表这五大底层结构。\n\nRedis 之所以能快速操作键值对，一方面是因为 O(1) 复杂度的哈希表被广泛使用，包括 String、Hash 和 Set，它们的操作复杂度基本由哈希表决定，另一方面，Sorted Set 也采用了 O(logN) 复杂度的跳表。不过，集合类型的范围操作，因为要遍历底层数据结构，复杂度通常是 O(N)。这里，我的建议是：用其他命令来替代，例如可以用 SCAN 来代替，避免在 Redis 内部产生费时的全集合遍历操作。\n\n当然，我们不能忘了复杂度较高的 List 类型，它的两种底层实现结构：双向链表和压缩列表的操作复杂度都是 O(N)。因此，我的建议是：因地制宜地使用 List 类型。例如，既然它的 POP/PUSH 效率很高，那么就将它主要用于 FIFO 队列场景，而不是作为一个可以随机读写的集合。\n\nRedis 数据类型丰富，最好的办法就是掌握原理，从原理上推断不同操作的复杂度，从而快速合理地做出选择\n\n----------------------------------------\n\n本节问题 1：Redis什么时候做 rehash？\n\nRedis会使用装载因子（load factor）来判断是否需要做 rehash。装载因子的计算方式是，哈希表中所有 entry 的个数除以哈希表的哈希桶个数。Redis会根据装载因子的两种情况，来触发 rehash 操作：\n\n * 装载因子≥1，同时，哈希表被允许进行 rehash；\n * 装载因子≥5。\n\n在第一种情况下，如果装载因子等于1，同时我们假设，所有键值对是平均分布在哈希表的各个桶中的，那么，此时，哈希表可以不用链式哈希，因为一个哈希桶正好保存了一个键值对。\n\n但是，如果此时再有新的数据写入，哈希表就要使用链式哈希了，这会对查询性能产生影响。在进行RDB生成和AOF重写时，哈希表的rehash是被禁止的，这是为了避免对RDB和AOF重写造成影响。如果此时，Redis没有在生成RDB和重写AOF，那么，就可以进行rehash。否则的话，再有数据写入时，哈希表就要开始使用查询较慢的链式哈希了。\n\n在第二种情况下，也就是装载因子大于等于5时，就表明当前保存的数据量已经远远大于哈希桶的个数，哈希桶里会有大量的链式哈希存在，性能会受到严重影响，此时，就立马开始做rehash。\n\n刚刚说的是触发rehash的情况，如果装载因子小于1，或者装载因子大于1但是小于5，同时哈希表暂时不被允许进行rehash（例如，实例正在生成RDB或者重写AOF），此时，哈希表是不会进行rehash操作的。\n\n本节问题 2： 渐进式 rehash 的执行机制——采用渐进式hash时，如果实例暂时没有收到新请求，是不是就不做rehash了？\n\n其实不是的。Redis会执行定时任务，定时任务中就包含了rehash操作。所谓的定时任务，就是按照一定频率（例如每100ms/次）执行的任务。\n\n在rehash被触发后，即使没有收到新请求，Redis也会定时执行一次rehash操作，而且，每次执行时长不会超过1ms，以免对其他任务造成影响。\n\n\n# 3. 高性能 IO 模型：为什么单线程还能这么快？\n\n这一大节探讨：为什么单线程的 Redis 能那么快？\n\n首先要厘清一个事实，我们通常说的 Redis 是单线程，主要是指 Redis 的网络 IO 和键值对读写是由一个线程来完成的，这也是 Redis 对外提供键值存储服务的主要流程。但 Redis 的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。\n\n所以，严格来说，Redis 并不是单线程，但是我们一般把 Redis 称为单线程高性能，这样显得“酷”些。因此接下来我们也称 Redis 为单线程模式。\n\n要弄明白这节提出的问题，我们就要深入地学习下 Redis 的单线程设计机制以及多路复用机制。之后你在调优 Redis 性能时，也能更有针对性地避免会导致 Redis 单线程阻塞的操作，例如执行复杂度高的命令。\n\n\n# 3.1 Redis 为什么用单线程——多线程的并发访问控制问题\n\n要更好地理解 Redis 为什么用单线程，我们就要先了解多线程的开销。\n\n对于一个多线程的系统来说，在有合理的资源分配的情况下，可以增加系统中处理请求操作的资源实体，进而提升系统能够同时处理的请求数，即吞吐率。但通常情况下如果没有良好的设计，实际多线程的表现可能并不好，如下图，左边是我们的期望，右边是可能的实际表现：\n\n\n\n出现这种情况的一个关键瓶颈就是：系统通常会存在被多线程同时访问的共享资源，为保证正确性的额外机制会带来额外的开销。这就是多线程编程模式面临的共享资源的并发访问控制问题。\n\n并发访问控制一直是多线程开发中的一个难点问题，如果没有精细的设计，比如说，只是简单地采用一个粗粒度互斥锁，就会出现不理想的结果：即使增加了线程，大部分线程也在等待获取访问共享资源的互斥锁，并行变串行，系统吞吐率并没有随着线程的增加而增加。而且，采用多线程开发一般会引入同步原语来保护共享资源的并发访问，这也会降低系统代码的易调试性和可维护性。为了避免这些问题，Redis 直接采用了单线程模式。\n\n到这里，你应该已经明白了“Redis为什么用单线程”，那么，接下来，我们就来看看，为什么单线程Redis能获得高性能。\n\n\n# 3.2 单线程 Redis 为什么那么快——多路复用机制\n\nRedis 使用单线程模型却达到了每秒数十万级别的处理能力，这是为什么呢？其实，这是 Redis 多方面设计选择的一个综合结果：\n\n * 一方面，大部分操作在内存上完成，再加上采用了高效的数据结构。\n * 另一方面，Redis 采用了多路复用机制，使其在网络 IO 操作中能并发处理大量的客户端请求，实现高吞吐率。\n\n首先，我们要弄明白网络操作的基本 IO 模型和潜在的阻塞点。毕竟，Redis 采用单线程进行 IO，如果线程被阻塞了，就无法进行多路复用了。\n\n# 3.2.1 基本 IO 模型与阻塞点\n\n一次网络交互的过程：以 Get 请求为例，第一节中的 SimpleKV 为了处理一个 Get 请求，需要监听客户端请求（bind/listen），和客户端建立连接（accept），从 socket 中读取请求（recv），解析客户端发送请求（parse），根据请求类型读取键值数据（get），最后给客户端返回结果，即向 socket 中写回数据（send）。下图显示了这一过程：\n\n\n\n由于 Redis 是单线程，而这里的网络 IO 有潜在的阻塞点，分别是 accept() 和 recv()，从而可能导致 Redis 整个线程阻塞。幸运的是，socket 网络模型本身支持非阻塞模式。\n\n# 3.2.2 非阻塞模式\n\nSocket 网络模型的非阻塞模式设置，主要体现在三个关键的函数调用上，如果想要使用 socket 非阻塞模式，就必须要了解这三个函数的调用返回类型和设置模式。接下来，我们就重点学习下它们。\n\n在 socket 模型中，不同操作调用后会返回不同的套接字类型：\n\n * socket() 方法会返回主动套接字；\n * 然后调用 listen() 方法，将主动套接字转化为监听套接字，此时，可以监听来自客户端的连接请求；\n * 最后，调用 accept() 方法接收到达的客户端连接，并返回已连接套接字。\n\n\n\n针对监听套接字，我们可以设置非阻塞模式：当 Redis 调用 accept() 但一直未有连接请求到达时，Redis 线程可以返回处理其他操作，而不用一直等待。但是，你要注意的是，调用 accept() 时，已经存在监听套接字了。\n\n虽然 Redis 线程可以不用继续等待，但是总得有机制继续在监听套接字上等待后续连接请求，并在有请求时通知 Redis。\n\n类似的，我们也可以针对已连接套接字设置非阻塞模式：Redis 调用 recv() 后，如果已连接套接字上一直没有数据到达，Redis 线程同样可以返回处理其他操作。我们也需要有机制继续监听该已连接套接字，并在有数据达到时通知 Redis。\n\n这样才能保证 Redis 线程，既不会像基本 IO 模型中一直在阻塞点等待，也不会导致 Redis 无法处理实际到达的连接请求或数据。\n\n到此，Linux 中的 IO 多路复用机制就要登场了。\n\n# 3.2.3 基于多路复用的高性能 I/O 模型\n\nLinux 中的 IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听套接字和已连接套接字。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。\n\n> 所以其实 3.2.2 节中需要有请求或者数据到达时通知 Redis 的机制就是 Linux 内核。另外，此机制也成为 Redis 通常是在 Linux 下使用的原因之一。\n\n下图就是基于多路复用的 Redis IO 模型。图中的多个 FD 就是刚才所说的多个套接字。Redis 网络框架调用 epoll 机制，让内核监听这些套接字。此时，Redis 线程不会阻塞在某一个特定的监听或已连接套接字上，也就是说，不会阻塞在某一个特定的客户端请求处理上。正因为此，Redis 可以同时和多个客户端连接并处理请求，从而提升并发性。\n\n\n\n为了在请求到达时能通知到 Redis 线程，select/epoll 提供了基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数。\n\n那么，回调机制是怎么工作的呢？其实，select/epoll 一旦监测到 FD 上有请求到达时，就会触发相应的事件。\n\n这些事件会被放进一个事件队列，Redis 单线程对该事件队列不断进行处理。这样一来，Redis 无需一直轮询是否有请求实际发生，这就可以避免造成 CPU 资源浪费。同时，Redis 在对事件队列中的事件进行处理时，会调用相应的处理函数，这就实现了基于事件的回调。因为 Redis 一直在对事件队列进行处理，所以能及时响应客户端请求，提升 Redis 的响应性能。\n\n为了方便你理解，我再以连接请求和读数据请求为例，具体解释一下。这两个请求分别对应 Accept 事件和 Read 事件，Redis 分别对这两个事件注册 accept 和 get 回调函数。当 Linux 内核监听到有连接请求或读数据请求时，就会触发 Accept 事件和 Read 事件，此时，内核就会回调 Redis 相应的 accept 和 get 函数进行处理。\n\n> 这就像病人去医院瞧病。在医生实际诊断前，每个病人（等同于请求）都需要先分诊、测体温、登记等。如果这些工作都由医生来完成，医生的工作效率就会很低。所以，医院都设置了分诊台，分诊台会一直处理这些诊断前的工作（类似于 Linux 内核监听请求），然后再转交给医生做实际诊断。这样即使一个医生（相当于 Redis 单线程），效率也能提升。\n\n不过，需要注意的是，即使你的应用场景中部署了不同的操作系统，多路复用机制也是适用的。因为这个机制的实现有很多种，既有基于 Linux 系统下的 select 和 epoll 实现，也有基于 FreeBSD 的 kqueue 实现，以及基于 Solaris 的 evport 实现，这样，你可以根据 Redis 实际运行的操作系统，选择相应的多路复用实现。\n\n\n# 3.3 小结\n\n我们重点学习了 Redis 线程的三个问题：\n\n * Redis 真的只有单线程吗？\n * 为什么用单线程？\n * 单线程为什么这么快？\n\nRedis 单线程是指它对网络 IO 和数据读写的操作采用了一个线程，而采用单线程的一个核心原因是避免多线程开发的并发控制问题。单线程的 Redis 也能获得高性能，跟多路复用的 IO 模型密切相关，因为这避免了 accept() 和 send()/recv() 潜在的网络 IO 操作阻塞点。\n\n> 另外，我也剧透下，可能你也注意到了，2020 年 5 月，Redis 6.0 的稳定版发布了，Redis 6.0 中提出了多线程模型。那么，这个多线程模型和这节课所说的 IO 模型有什么关联？会引入复杂的并发控制问题吗？会给 Redis 6.0 带来多大提升？关于这些问题，我会在后面的课程中和你具体介绍。\n\n----------------------------------------\n\n问题：Redis 的基本 IO 模型中还有哪些潜在的性能瓶颈？\n\n在主线程执行操作期间，任何耗时的操作都是潜在的性能瓶颈，除了网络 IO 外，还包括 bigkey、全量返回等操作。",normalizedContent:"# 基础架构、数据结构与 io 模型\n\n> 参考： 01 | 基本架构：一个键值数据库包含什么？\n\n\n# 1. 基础架构：一个键值数据库包含什么？\n\nredis是典型的键值数据库。\n\n我们先建立起”系统观“，再深入理解和优化 redis。 即先对它的总体架构和关键模块有一个全局的认知，然后再深入到具体的技术点。\n\n今天，先构造一个简单的 kv 数据库，我们只需要关注整体架构和核心模块，并对其进行剖析。我把这个简单的键值数据库称为simplekv，它只是一个具有关键组件的 kv 数据库架构。\n\n> 这里的 simplekv 与 github 上同名的项目并不是一个东西。\n\n开始构造 simplekv 时，首先就要考虑里面可以存什么样的数据，对数据可以做什么样的操作，也就是数据模型和操作接口。\n\n对于redis来说，它到底能做什么，不能做什么呢？只有先搞懂它的数据模型和操作接口，我们才能真正把“这块好钢用在刀刃上”。\n\n\n# 1.1 可以存哪些数据？\n\n对于键值数据库而言，基本的数据模型是 key-value 模型。simplekv 中：\n\n * key 为 string 类型\n * value 为基本数据类型，如 string、整型等。\n\n对于实际生产环境中的键值数据库来说，value 类型还可以是复杂类型。\n\n不同键值数据库支持的key类型一般差异不大，而value类型则有较大差别。我们在对键值数据库进行选型时，一个重要的考虑因素是它支持的value类型。例如，memcached 支持的 value 类型仅为 string 类型，而 redis 支持的 value 类型包括了 string、哈希表、列表、集合等。redis能够在实际业务场景中得到广泛的应用，就是得益于支持多样化类型的 value。\n\n不同 value 类型的实现存在各种性能、效率等方面的差异，因此用于满足不同业务的需求。明白这些原理才能去选择。\n\n\n# 1.2 可以对数据做什么操作？\n\nsimplekv是一个简单的键值数据库，因此，基本操作无外乎增删改查：\n\n * put：新写入或更新一个 key-value 对；\n * get：根据一个 key 读取相应的value值；\n * delete：根据一个 key 删除整个 key-value 对。\n\n需要注意的是， 有些键值数据库的新写/更新操作叫 set。新写入和更新虽然是用一个操作接口，但在实际执行时，会根据 key 是否存在而执行相应的新写或更新流程。\n\n在实际的业务场景中，我们经常会碰到这种情况：查询一个用户在一段时间内的访问记录。这种操作在键值数据库中属于scan 操作，即 根据一段 key 的范围返回相应的 value 值。因此， put/get/delete/scan 是一个键值数据库的基本操作集合。\n\n此外，实际业务场景通常还有更加丰富的需求，比如 exists 接口。对于一个具体的键值数据库而言，你可以通过查看操作文档，了解其详细的操作接口。\n\n现在，数据模型和操作接口我们就构造完成了，这是我们的基础工作。接下来更进一步，需要考虑一个非常重要的设计问题： 键值对保存在内存还是外存？\n\n * 保存在内存的好处是读写很快，潜在风险是一旦掉电，所有的数据都会丢失。\n * 保存在外存虽可以避免数据丢失，但受限于磁盘性能，整体数据库的性能就会被拉低。\n\n因此， 如何进行设计选择，我们通常需要考虑键值数据库的主要应用场景。比如，缓存场景下的数据需要能快速访问但允许丢失，那么，用于此场景的键值数据库通常采用内存保存键值数据。memcached 和 redis 都是属于内存键值数据库。\n\n为了和redis保持一致，我们的 simplekv 就采用内存保存键值数据。接下来，我们来了解下 simplekv 的基本组件。大体来说，一个键值数据库包括了访问框架、索引模块、操作模块和存储模块四部分：\n\n\n\n接下来，我们就从这四个部分入手，继续构建我们的 simplekv。\n\n\n# 1.3 采用什么访问模式？\n\n访问模式通常有两种：\n\n * 一种是通过函数库调用的方式供外部应用使用。比如上图的 libsimplekv.so，以动态链接库的形式链接到程序中\n * 一种是通过网络框架以 socket 通信的形式对外提供 kv 操作\n\n实际的键值数据库也基本采用上述两种方式，例如，rocksdb 以动态链接库的形式使用，而 memcached 和 redis 则是通过网络框架访问。\n\n通过网络框架提供键值存储服务，一方面扩大了键值数据库的受用面，但另一方面，也给键值数据库的性能、运行模型提供了不同的设计选择，带来了一些潜在的问题。\n\nkv 数据库通过接收网络数据包，并按照协议进行解析得到操作，然后执行。此时，我们会遇到一个系统设计上的问题，简单来说，就是网络连接的处理、网络请求的解析，以及数据存取的处理，是用一个线程、多个线程，还是多个进程来交互处理呢？该如何进行设计和取舍呢？我们一般把这个问题称为 i/o 模型设计。不同的 i/o 模型对键值数据库的性能和可扩展性会有不同的影响：\n\n * 如果使用单线程，那一个线程既要处理网络连接、解析请求，又要完成数据存取，一旦某一步操作发生阻塞，整个线程就会阻塞住，这就降低了系统响应速度。\n * 如果使用多线程，那不同线程间如果需要访问共享资源，那又会产生线程竞争，也会影响系统效率。\n\n因此我们需要进行精心的设计来面对这个两难的问题。\n\n> 也许你听说过 redis 是单线程，那 redis 是如何做到“单线程、高性能”的呢？\n\n\n# 1.4 如何定位键值对的位置？\n\nsimplekv 查找某个 kv 对的操作依赖于 kv 数据库的索引模型。索引的作用是让键值数据库根据 key 找到相应 value 的存储位置，进而执行操作。\n\n索引的类型有很多，常见的有哈希表、b+树、字典树等。不同的索引结构在性能、空间消耗、并发控制等方面具有不同的特征。memcached 和 redis 采用哈希表作为 key-value 索引，而 rocksdb 则采用跳表作为内存中 key-value 的索引。\n\nsimplekv的索引根据 key 找到 value 的存储位置即可。但是，和 simplekv 不同，对 redis 而言，它的 value 支持多种类型，当我们通过索引找到一个 key 所对应的 value 后，仍然需要从 value 的复杂结构（例如集合和列表）中进一步找到我们实际需要的数据，这个操作的效率本身就依赖于它们的实现结构。\n\nredis 采用一些常见的高效索引结构作为某些 value 类型的底层数据结构，这一技术路线为 redis 实现高性能访问提供了良好的支撑。\n\n\n# 1.5 不同操作的具体逻辑是怎样的？\n\nsimplekv 找到数据的存储位置后，对于不同的操作，其进一步执行的操作逻辑也有所差异。\n\nsimplekv 的操作模块就实现了不同操作的具体逻辑：\n\n * get/scan：立刻返回当前位置的 value 即可；\n * put：为新 kv pair 分配内存空间；\n * delete：删除 kv pair，并释放相应内存空间，这个过程由分配器完成。\n\n对于 put 或 delete 操作，涉及到了分配和释放内存，这就需要 simplekv 数据库的存储模块了。\n\n\n# 1.6 如何实现重启后快速提供服务？\n\nsimplekv 采用了常用的内存分配器 glibc 的 malloc 和 free，因此，simplekv 并不需要特别考虑内存空间的管理问题。\n\n但是，kv 数据库的 kv pair 通常大小不一，glibc 的分配器在处理随机的大小内存块分配时表现并不好。一旦保存的键值对数据规模过大，就可能会造成较严重的内存碎片问题。\n\n因此，分配器是 kv 数据库的一个关键因素。redis 的内存分配器提供了多种选择，分配效率也不一样，后面会对此展开讲述。\n\nsimplekv 虽然依赖于内存保存数据，提供快速访问，但是，我也希望 simplekv 重启后能快速重新提供服务，所以，我在 simplekv 的存储模块中增加了持久化功能。不过，鉴于磁盘管理要比内存管理复杂，simplekv 就直接采用了文件形式，将键值数据通过调用本地文件系统的操作接口保存在磁盘上。\n\n此时，simplekv 只需要考虑何时将内存中的键值数据保存到文件中：\n\n * 一种方式是，每次 kv pair 的修改都进行落盘操作。虽然这更可靠，但性能会受到很大影响。\n * 一种方式是，周期性地把内存中的 kv pair 同步到文件中。但这面临数据丢失的风险。\n\nredis 也提供了持久化功能。不过，为了适应不同的业务场景，redis 为持久化提供了诸多的执行机制和优化改进。后面会对 redis 的持久化机制的设计进行讨论。\n\n\n# 1.7 小结\n\n在了解了这个 simplekv 的基本组件后，再学习 redis 这个丰富版的 simplekv 时就会轻松很多。为了支持更加丰富的业务场景，redis对这些组件或者功能进行了扩展，或者说是进行了精细优化，从而满足了功能和性能等方面的要求。\n\n\n\n从 simplekv 到 redis，主要有以下重要变化：\n\n * redis 主要通过网络框架进行访问，而不再是动态库了。\n * value 的类型更加丰富，因此可支持的操作也更加丰富。\n * redis的持久化模块能支持两种方式：日志（aof）和快照（rdb）。\n * simplekv 是个简单的单机键值数据库，但是，redis 支持高可靠集群和高可扩展集群，因此，redis 中包含了相应的集群功能支撑模块。\n\n\n# 2. 数据结构：快速的redis有哪些慢操作？\n\nredis 的“快”有一个重要表现：它接收到一个键值对操作后，能以微秒级别的速度找到数据，并快速完成操作。\n\n数据库这么多，为啥 redis 能有这么突出的表现呢：\n\n * 一方面，操作在内存中完成\n * 另一方面，归功于它的数据结构，高效的数据结构是 redis 快速处理数据的基础。\n\n> 这里说的数据结构是指数据库中 value 的数据类型（图中绿色的块块）的底层实现方式\n\n简单来说，底层数据结构一共有 6 种：简单动态字符串、双向链表、压缩列表、哈希表、跳表和整数数组。它们和数据类型的对应关系如下图所示：\n\n\n\n可以看到，string 类型的底层实现只有一种数据结构，也就是简单动态字符串。而 list、hash、set 和 sorted set 这四种数据类型，都有两种底层实现结构。通常情况下，我们会把这四种类型称为集合类型，它们的特点是一个键对应了一个集合的数据。\n\n看到这里，其实有些问题已经值得我们去考虑了：\n\n * 这些数据结构都是值的底层实现，键和值本身之间用什么结构组织？\n * 为什么集合类型有那么多的底层结构，它们都是怎么组织数据的，都很快吗？\n * 什么是简单动态字符串，和常用的字符串是一回事吗？\n\n接下来，我就和你聊聊前两个问题。这样，你不仅可以知道 redis“快”的基本原理，还可以借此理解 redis 中有哪些潜在的“慢操作”，最大化 redis 的性能优势。而关于简单动态字符串，会在后面的课程继续讨论。\n\n\n# 2.1 key 和 value 用什么结构组织？\n\n为了实现从 key 到 value 的快速访问，redis 使用了一个哈希表来保存所有键值对。\n\n一个哈希表，其实就是一个数组，数组的每个元素称为一个哈希桶。所以，我们常说，一个哈希表是由多个哈希桶组成的，每个哈希桶中保存了键值对数据。哈希桶中的元素保存的不是值本身，而是一个 pointer，这样不管 value 是 string 还是 collection 类型，哈希桶中的元素都是指向它们的 pointer。\n\n如下图所示，哈希桶中的 entry 元素中保存了 key 和 value 的 pointer：\n\n\n\n因为这个哈希表保存了所有的键值对，所以，我也把它称为全局哈希表。使用 hash table 可以在 o(1) 时间复杂度下访问到相应的 entry 元素。——通过计算 key 的哈希值，得到哈希桶的位置，就可以访问到 kv pair 了。\n\n但是，随着往 redis 写入大量数据后，会发现操作有时候突然变慢了，因为有一个潜在的风险点：哈希表的冲突问题和 rehash 可能带来的操作阻塞。\n\n\n# 2.2 为什么哈希表操作变慢了——哈希冲突\n\n当数据增多，哈希冲突是不可避免的问题。\n\nredis 解决哈希冲突的方式，就是链式哈希：同一个哈希桶中的多个元素用一个链表来保存，它们之间依次用指针连接。\n\n如下图所示，冲突的元素形成的链表，叫做哈希冲突链。\n\n\n\n但随着哈希冲突越来越多，一条哈希冲突链的逐 entry 查找会降低性能。所以，redis 会对哈希表做 rehash 操作：增加现有的哈希桶数量，让逐渐增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突。\n\nrehash 具体怎么做呢？\n\n为了使 rehash 操作更高效，redis 默认使用了两个全局哈希表：哈希表 1 和哈希表 2。一开始，当你刚插入数据时，默认使用哈希表 1，此时的哈希表 2 并没有被分配空间。随着数据逐步增多，redis 开始执行 rehash，这个过程分为三步：\n\n 1. 给哈希表 2 分配更大的空间，例如是当前哈希表 1 大小的两倍；\n 2. 把哈希表 1 中的数据重新映射并拷贝到哈希表 2 中；\n 3. 释放哈希表 1 的空间。\n\n到此，我们就可以从哈希表 1 切换到哈希表 2，用增大的哈希表 2 保存更多数据，而原来的哈希表 1 留作下一次 rehash 扩容备用。\n\n这个过程看似简单，但是第二步涉及大量的数据拷贝，如果一次性把哈希表 1 中的数据都迁移完，会造成 redis 线程阻塞，无法服务其他请求。此时，redis 就无法快速访问数据了。为了避免这个问题，redis 采用了渐进式 rehash：\n\n简单来说就是在第二步拷贝数据时，redis 仍然正常处理客户端请求，每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries。如下图所示：\n\n\n\n这样就巧妙地把一次性大量拷贝的开销，分摊到了多次处理请求的过程中，避免了耗时操作，保证了数据的快速访问。\n\n到这里，你就能理解 redis 的 key 和 value 是怎么通过哈希表来组织的了。\n\n * 对于 value 为 string 类型的来说，找到 entry 就可以直接 crud 了，操作复杂度 o(1)。\n * 对于 value 为 collection 类型的来说，找到 entry 后还要在集合中进一步操作。\n\n接下来来看在 collection 类型中的操作效率又是怎样的。\n\n\n# 2.3 集合数据的操作效率\n\n和 string 类型不同，一个集合类型的 value，第一步是通过全局哈希表找到对应的哈希桶位置，第二步是在集合中再增删改查。那么，集合的操作效率和哪些因素相关呢？\n\n 1. 与底层的数据结构有关\n 2. 与操作本身的执行特点有关\n\n接下来，我们就分别聊聊集合类型的底层数据结构和操作复杂度。\n\n# 2.3.1 有哪些底层数据结构\n\n集合类型的底层数据结构主要有 5 种：整数数组、双向链表、哈希表、压缩列表和跳表：\n\n * 哈希表的操作我们已经了解了；\n * 整数数组和双向链表平时很常见，其操作特征是顺序读写，通过数组下标或者链表的指针逐个元素访问，操作复杂度往往是 o(n)；\n * 压缩跳表和跳表平时接触不多，但也是 redis 的重要数据结构，下面重点解释这部分。\n\n----------------------------------------\n\n压缩列表：\n\n压缩列表实际上类似于一个数组，数组中的每一个元素都对应保存一个数据。和数组不同的是，压缩列表在表头有三个字段：\n\n * zlbytes：列表长度\n * zltail：列表尾的偏移量\n * zllen：列表中的 entry 的个数\n\n\n\n在压缩列表中，定位第一个和最后一个元素，可以通过表头三个字段的长度直接定位，复杂度是o(1)。而查找其他元素时，只能逐个查找，此时的复杂度就是o(n)了。\n\n----------------------------------------\n\n跳表：\n\n有序链表只能逐一查找元素，导致操作起来非常缓慢，于是就出现了跳表。具体来说，跳表在链表的基础上，增加了多级索引，通过索引位置的几个跳转，实现数据的快速定位，如下图所示：\n\n\n\n如果我们要在链表中查找 33 这个元素，只能从头开始遍历链表，查找 6 次，直到找到 33 为止。此时，复杂度是 o(n)，查找效率很低。\n\n为了提高查找速度，我们来增加一级索引：从第一个元素开始，每两个元素选一个出来作为索引。这些索引再通过指针指向原始的链表。例如，从前两个元素中抽取元素 1 作为一级索引，从第三、四个元素中抽取元素 11 作为一级索引。此时，我们只需要 4 次查找就能定位到元素 33 了。\n\n如果我们还想再快，可以再增加二级索引：从一级索引中，再抽取部分元素作为二级索引。例如，从一级索引中抽取 1、27、100 作为二级索引，二级索引指向一级索引。这样，我们只需要 3 次查找，就能定位到元素 33 了。\n\n可以看到，这个查找过程就是在多级索引上跳来跳去，最后定位到元素。这也正好符合“跳”表的叫法。当数据量很大时，跳表的查找复杂度就是 $o(logn)$。\n\n好了，我们现在可以按照查找的时间复杂度给这些数据结构分下类了：\n\n\n\n# 2.3.2 不同操作的复杂度\n\n集合类型的操作类型很多，有读写单个集合元素的，例如 hget、hset，也有操作多个元素的，例如 sadd，还有对整个集合进行遍历操作的，例如 smembers。这么多操作，它们的复杂度也各不相同。而复杂度的高低又是我们选择集合类型的重要依据。\n\n我总结了一个“四句口诀”，希望能帮助你快速记住集合常见操作的复杂度。这样你在使用过程中，就可以提前规避高复杂度操作了：\n\n * 单元素操作是基础；\n * 范围操作非常耗时；\n * 统计操作通常高效；\n * 例外情况只有几个。\n\n第一，单元素操作，是指每一种集合类型对单个数据实现的增删改查操作。例如，hash 类型的 hget、hset 和 hdel，set 类型的 sadd、srem、srandmember 等。这些操作的复杂度由集合采用的数据结构决定，例如，hget、hset 和 hdel 是对哈希表做操作，所以它们的复杂度都是 o(1)；set 类型用哈希表作为底层数据结构时，它的 sadd、srem、srandmember 复杂度也是 o(1)。\n\n这里，有个地方你需要注意一下，集合类型支持同时对多个元素进行增删改查，例如 hash 类型的 hmget 和 hmset，set 类型的 sadd 也支持同时增加多个元素。此时，这些操作的复杂度，就是由单个元素操作复杂度和元素个数决定的。例如，hmset 增加 m 个元素时，复杂度就从 o(1) 变成 o(m) 了。\n\n第二，范围操作，是指集合类型中的遍历操作，可以返回集合中的所有数据，比如 hash 类型的 hgetall 和 set 类型的 smembers，或者返回一个范围内的部分数据，比如 list 类型的 lrange 和 zset 类型的 zrange。这类操作的复杂度一般是 o(n)，比较耗时，我们应该尽量避免。\n\n不过，redis 从 2.8 版本开始提供了 scan 系列操作（包括 hscan，sscan 和 zscan），这类操作实现了渐进式遍历，每次只返回有限数量的数据。这样一来，相比于 hgetall、smembers 这类操作来说，就避免了一次性返回所有元素而导致的 redis 阻塞。\n\n第三，统计操作，是指集合类型对集合中所有元素个数的记录，例如 llen 和 scard。这类操作复杂度只有 o(1)，这是因为当集合类型采用压缩列表、双向链表、整数数组这些数据结构时，这些结构中专门记录了元素的个数统计，因此可以高效地完成相关操作。\n\n第四，例外情况，是指某些数据结构的特殊记录，例如压缩列表和双向链表都会记录表头和表尾的偏移量。这样一来，对于 list 类型的 lpop、rpop、lpush、rpush 这四个操作来说，它们是在列表的头尾增删元素，这就可以通过偏移量直接定位，所以它们的复杂度也只有 o(1)，可以实现快速操作。\n\n\n# 2.4 小结\n\n这一大节学习了 redis 的底层数据结构，包括 redis 整体的用来保存每个 kv 的全局哈希表结构，也包括支持集合类型实现的双向链表、压缩列表、整数数组、哈希表和跳表这五大底层结构。\n\nredis 之所以能快速操作键值对，一方面是因为 o(1) 复杂度的哈希表被广泛使用，包括 string、hash 和 set，它们的操作复杂度基本由哈希表决定，另一方面，sorted set 也采用了 o(logn) 复杂度的跳表。不过，集合类型的范围操作，因为要遍历底层数据结构，复杂度通常是 o(n)。这里，我的建议是：用其他命令来替代，例如可以用 scan 来代替，避免在 redis 内部产生费时的全集合遍历操作。\n\n当然，我们不能忘了复杂度较高的 list 类型，它的两种底层实现结构：双向链表和压缩列表的操作复杂度都是 o(n)。因此，我的建议是：因地制宜地使用 list 类型。例如，既然它的 pop/push 效率很高，那么就将它主要用于 fifo 队列场景，而不是作为一个可以随机读写的集合。\n\nredis 数据类型丰富，最好的办法就是掌握原理，从原理上推断不同操作的复杂度，从而快速合理地做出选择\n\n----------------------------------------\n\n本节问题 1：redis什么时候做 rehash？\n\nredis会使用装载因子（load factor）来判断是否需要做 rehash。装载因子的计算方式是，哈希表中所有 entry 的个数除以哈希表的哈希桶个数。redis会根据装载因子的两种情况，来触发 rehash 操作：\n\n * 装载因子≥1，同时，哈希表被允许进行 rehash；\n * 装载因子≥5。\n\n在第一种情况下，如果装载因子等于1，同时我们假设，所有键值对是平均分布在哈希表的各个桶中的，那么，此时，哈希表可以不用链式哈希，因为一个哈希桶正好保存了一个键值对。\n\n但是，如果此时再有新的数据写入，哈希表就要使用链式哈希了，这会对查询性能产生影响。在进行rdb生成和aof重写时，哈希表的rehash是被禁止的，这是为了避免对rdb和aof重写造成影响。如果此时，redis没有在生成rdb和重写aof，那么，就可以进行rehash。否则的话，再有数据写入时，哈希表就要开始使用查询较慢的链式哈希了。\n\n在第二种情况下，也就是装载因子大于等于5时，就表明当前保存的数据量已经远远大于哈希桶的个数，哈希桶里会有大量的链式哈希存在，性能会受到严重影响，此时，就立马开始做rehash。\n\n刚刚说的是触发rehash的情况，如果装载因子小于1，或者装载因子大于1但是小于5，同时哈希表暂时不被允许进行rehash（例如，实例正在生成rdb或者重写aof），此时，哈希表是不会进行rehash操作的。\n\n本节问题 2： 渐进式 rehash 的执行机制——采用渐进式hash时，如果实例暂时没有收到新请求，是不是就不做rehash了？\n\n其实不是的。redis会执行定时任务，定时任务中就包含了rehash操作。所谓的定时任务，就是按照一定频率（例如每100ms/次）执行的任务。\n\n在rehash被触发后，即使没有收到新请求，redis也会定时执行一次rehash操作，而且，每次执行时长不会超过1ms，以免对其他任务造成影响。\n\n\n# 3. 高性能 io 模型：为什么单线程还能这么快？\n\n这一大节探讨：为什么单线程的 redis 能那么快？\n\n首先要厘清一个事实，我们通常说的 redis 是单线程，主要是指 redis 的网络 io 和键值对读写是由一个线程来完成的，这也是 redis 对外提供键值存储服务的主要流程。但 redis 的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。\n\n所以，严格来说，redis 并不是单线程，但是我们一般把 redis 称为单线程高性能，这样显得“酷”些。因此接下来我们也称 redis 为单线程模式。\n\n要弄明白这节提出的问题，我们就要深入地学习下 redis 的单线程设计机制以及多路复用机制。之后你在调优 redis 性能时，也能更有针对性地避免会导致 redis 单线程阻塞的操作，例如执行复杂度高的命令。\n\n\n# 3.1 redis 为什么用单线程——多线程的并发访问控制问题\n\n要更好地理解 redis 为什么用单线程，我们就要先了解多线程的开销。\n\n对于一个多线程的系统来说，在有合理的资源分配的情况下，可以增加系统中处理请求操作的资源实体，进而提升系统能够同时处理的请求数，即吞吐率。但通常情况下如果没有良好的设计，实际多线程的表现可能并不好，如下图，左边是我们的期望，右边是可能的实际表现：\n\n\n\n出现这种情况的一个关键瓶颈就是：系统通常会存在被多线程同时访问的共享资源，为保证正确性的额外机制会带来额外的开销。这就是多线程编程模式面临的共享资源的并发访问控制问题。\n\n并发访问控制一直是多线程开发中的一个难点问题，如果没有精细的设计，比如说，只是简单地采用一个粗粒度互斥锁，就会出现不理想的结果：即使增加了线程，大部分线程也在等待获取访问共享资源的互斥锁，并行变串行，系统吞吐率并没有随着线程的增加而增加。而且，采用多线程开发一般会引入同步原语来保护共享资源的并发访问，这也会降低系统代码的易调试性和可维护性。为了避免这些问题，redis 直接采用了单线程模式。\n\n到这里，你应该已经明白了“redis为什么用单线程”，那么，接下来，我们就来看看，为什么单线程redis能获得高性能。\n\n\n# 3.2 单线程 redis 为什么那么快——多路复用机制\n\nredis 使用单线程模型却达到了每秒数十万级别的处理能力，这是为什么呢？其实，这是 redis 多方面设计选择的一个综合结果：\n\n * 一方面，大部分操作在内存上完成，再加上采用了高效的数据结构。\n * 另一方面，redis 采用了多路复用机制，使其在网络 io 操作中能并发处理大量的客户端请求，实现高吞吐率。\n\n首先，我们要弄明白网络操作的基本 io 模型和潜在的阻塞点。毕竟，redis 采用单线程进行 io，如果线程被阻塞了，就无法进行多路复用了。\n\n# 3.2.1 基本 io 模型与阻塞点\n\n一次网络交互的过程：以 get 请求为例，第一节中的 simplekv 为了处理一个 get 请求，需要监听客户端请求（bind/listen），和客户端建立连接（accept），从 socket 中读取请求（recv），解析客户端发送请求（parse），根据请求类型读取键值数据（get），最后给客户端返回结果，即向 socket 中写回数据（send）。下图显示了这一过程：\n\n\n\n由于 redis 是单线程，而这里的网络 io 有潜在的阻塞点，分别是 accept() 和 recv()，从而可能导致 redis 整个线程阻塞。幸运的是，socket 网络模型本身支持非阻塞模式。\n\n# 3.2.2 非阻塞模式\n\nsocket 网络模型的非阻塞模式设置，主要体现在三个关键的函数调用上，如果想要使用 socket 非阻塞模式，就必须要了解这三个函数的调用返回类型和设置模式。接下来，我们就重点学习下它们。\n\n在 socket 模型中，不同操作调用后会返回不同的套接字类型：\n\n * socket() 方法会返回主动套接字；\n * 然后调用 listen() 方法，将主动套接字转化为监听套接字，此时，可以监听来自客户端的连接请求；\n * 最后，调用 accept() 方法接收到达的客户端连接，并返回已连接套接字。\n\n\n\n针对监听套接字，我们可以设置非阻塞模式：当 redis 调用 accept() 但一直未有连接请求到达时，redis 线程可以返回处理其他操作，而不用一直等待。但是，你要注意的是，调用 accept() 时，已经存在监听套接字了。\n\n虽然 redis 线程可以不用继续等待，但是总得有机制继续在监听套接字上等待后续连接请求，并在有请求时通知 redis。\n\n类似的，我们也可以针对已连接套接字设置非阻塞模式：redis 调用 recv() 后，如果已连接套接字上一直没有数据到达，redis 线程同样可以返回处理其他操作。我们也需要有机制继续监听该已连接套接字，并在有数据达到时通知 redis。\n\n这样才能保证 redis 线程，既不会像基本 io 模型中一直在阻塞点等待，也不会导致 redis 无法处理实际到达的连接请求或数据。\n\n到此，linux 中的 io 多路复用机制就要登场了。\n\n# 3.2.3 基于多路复用的高性能 i/o 模型\n\nlinux 中的 io 多路复用机制是指一个线程处理多个 io 流，就是我们经常听到的 select/epoll 机制。简单来说，在 redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听套接字和已连接套接字。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 redis 线程处理，这就实现了一个 redis 线程处理多个 io 流的效果。\n\n> 所以其实 3.2.2 节中需要有请求或者数据到达时通知 redis 的机制就是 linux 内核。另外，此机制也成为 redis 通常是在 linux 下使用的原因之一。\n\n下图就是基于多路复用的 redis io 模型。图中的多个 fd 就是刚才所说的多个套接字。redis 网络框架调用 epoll 机制，让内核监听这些套接字。此时，redis 线程不会阻塞在某一个特定的监听或已连接套接字上，也就是说，不会阻塞在某一个特定的客户端请求处理上。正因为此，redis 可以同时和多个客户端连接并处理请求，从而提升并发性。\n\n\n\n为了在请求到达时能通知到 redis 线程，select/epoll 提供了基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数。\n\n那么，回调机制是怎么工作的呢？其实，select/epoll 一旦监测到 fd 上有请求到达时，就会触发相应的事件。\n\n这些事件会被放进一个事件队列，redis 单线程对该事件队列不断进行处理。这样一来，redis 无需一直轮询是否有请求实际发生，这就可以避免造成 cpu 资源浪费。同时，redis 在对事件队列中的事件进行处理时，会调用相应的处理函数，这就实现了基于事件的回调。因为 redis 一直在对事件队列进行处理，所以能及时响应客户端请求，提升 redis 的响应性能。\n\n为了方便你理解，我再以连接请求和读数据请求为例，具体解释一下。这两个请求分别对应 accept 事件和 read 事件，redis 分别对这两个事件注册 accept 和 get 回调函数。当 linux 内核监听到有连接请求或读数据请求时，就会触发 accept 事件和 read 事件，此时，内核就会回调 redis 相应的 accept 和 get 函数进行处理。\n\n> 这就像病人去医院瞧病。在医生实际诊断前，每个病人（等同于请求）都需要先分诊、测体温、登记等。如果这些工作都由医生来完成，医生的工作效率就会很低。所以，医院都设置了分诊台，分诊台会一直处理这些诊断前的工作（类似于 linux 内核监听请求），然后再转交给医生做实际诊断。这样即使一个医生（相当于 redis 单线程），效率也能提升。\n\n不过，需要注意的是，即使你的应用场景中部署了不同的操作系统，多路复用机制也是适用的。因为这个机制的实现有很多种，既有基于 linux 系统下的 select 和 epoll 实现，也有基于 freebsd 的 kqueue 实现，以及基于 solaris 的 evport 实现，这样，你可以根据 redis 实际运行的操作系统，选择相应的多路复用实现。\n\n\n# 3.3 小结\n\n我们重点学习了 redis 线程的三个问题：\n\n * redis 真的只有单线程吗？\n * 为什么用单线程？\n * 单线程为什么这么快？\n\nredis 单线程是指它对网络 io 和数据读写的操作采用了一个线程，而采用单线程的一个核心原因是避免多线程开发的并发控制问题。单线程的 redis 也能获得高性能，跟多路复用的 io 模型密切相关，因为这避免了 accept() 和 send()/recv() 潜在的网络 io 操作阻塞点。\n\n> 另外，我也剧透下，可能你也注意到了，2020 年 5 月，redis 6.0 的稳定版发布了，redis 6.0 中提出了多线程模型。那么，这个多线程模型和这节课所说的 io 模型有什么关联？会引入复杂的并发控制问题吗？会给 redis 6.0 带来多大提升？关于这些问题，我会在后面的课程中和你具体介绍。\n\n----------------------------------------\n\n问题：redis 的基本 io 模型中还有哪些潜在的性能瓶颈？\n\n在主线程执行操作期间，任何耗时的操作都是潜在的性能瓶颈，除了网络 io 外，还包括 bigkey、全量返回等操作。",charsets:{cjk:!0},lastUpdated:"2023/03/27, 09:21:08",lastUpdatedTimestamp:1679908868e3},{title:"持久化机制：AOF日志和RDB快照",frontmatter:{title:"持久化机制：AOF日志和RDB快照",date:"2023-03-25T20:55:25.000Z",permalink:"/pages/d1a6d3/",categories:["中间件","Redis","专栏：Redis 核心技术与实战"],tags:[null]},regularPath:"/%E4%B8%AD%E9%97%B4%E4%BB%B6/05.Redis/05.%E4%B8%93%E6%A0%8F%EF%BC%9ARedis%20%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/04.%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6%EF%BC%9AAOF%E6%97%A5%E5%BF%97%E5%92%8CRDB%E5%BF%AB%E7%85%A7.html",relativePath:"中间件/05.Redis/05.专栏：Redis 核心技术与实战/04.持久化机制：AOF日志和RDB快照.md",key:"v-a6ed5612",path:"/pages/d1a6d3/",headers:[{level:2,title:"1. AOF 日志：宕机了，Redis 如何避免数据丢失",slug:"_1-aof-日志-宕机了-redis-如何避免数据丢失",normalizedTitle:"1. aof 日志：宕机了，redis 如何避免数据丢失",charIndex:296},{level:3,title:"1.1 AOF 日志是如何实现的？",slug:"_1-1-aof-日志是如何实现的",normalizedTitle:"1.1 aof 日志是如何实现的？",charIndex:351},{level:3,title:"1.2 三种写回策略",slug:"_1-2-三种写回策略",normalizedTitle:"1.2 三种写回策略",charIndex:1435},{level:3,title:"1.3 AOF 重写机制",slug:"_1-3-aof-重写机制",normalizedTitle:"1.3 aof 重写机制",charIndex:2421},{level:3,title:"1.4 AOF 重写会阻塞吗？—— 不会",slug:"_1-4-aof-重写会阻塞吗-不会",normalizedTitle:"1.4 aof 重写会阻塞吗？—— 不会",charIndex:2886},{level:3,title:"1.5 小结",slug:"_1-5-小结",normalizedTitle:"1.5 小结",charIndex:3571},{level:2,title:"2. RDB 快照：宕机后，Redis如何实现快速恢复？",slug:"_2-rdb-快照-宕机后-redis如何实现快速恢复",normalizedTitle:"2. rdb 快照：宕机后，redis如何实现快速恢复？",charIndex:4510},{level:3,title:"2.1 什么是 RDB",slug:"_2-1-什么是-rdb",normalizedTitle:"2.1 什么是 rdb",charIndex:4543},{level:3,title:"2.2 给哪些数据拍快照？",slug:"_2-2-给哪些数据拍快照",normalizedTitle:"2.2 给哪些数据拍快照？",charIndex:5059},{level:3,title:"2.3 快照时数据能修改吗？",slug:"_2-3-快照时数据能修改吗",normalizedTitle:"2.3 快照时数据能修改吗？",charIndex:5458},{level:3,title:"2.4 拍快照的频率",slug:"_2-4-拍快照的频率",normalizedTitle:"2.4 拍快照的频率",charIndex:6175},{level:3,title:"2.5 小结",slug:"_2-5-小结",normalizedTitle:"2.5 小结",charIndex:7412}],headersStr:"1. AOF 日志：宕机了，Redis 如何避免数据丢失 1.1 AOF 日志是如何实现的？ 1.2 三种写回策略 1.3 AOF 重写机制 1.4 AOF 重写会阻塞吗？—— 不会 1.5 小结 2. RDB 快照：宕机后，Redis如何实现快速恢复？ 2.1 什么是 RDB 2.2 给哪些数据拍快照？ 2.3 快照时数据能修改吗？ 2.4 拍快照的频率 2.5 小结",content:"# 持久化机制：AOF日志和RDB快照\n\n> 参考：\n> \n>  * 04 AOF 日志：宕机了，Redis 如何避免数据丢失？ | 极客时间\n>  * 05 内存快照：宕机后，Redis 如何实现快速恢复？| 极客时间\n\nRedis 用作缓存并将数据存于内存中，就会面对一个问题：一旦服务器宕机，内存中的数据将全部丢失。\n\n也许有个解决方案：从后端数据库恢复这些数据。但这频繁访问数据库会使得性能严重下降。所以对于 Redis 而言，实现数据的持久化，避免从后端中恢复数据，是至关重要的。\n\n目前，Redis 的持久化主要有两大机制：AOF 日志和 RDB 快照。这里讲分别讲解。\n\n\n# 1. AOF 日志：宕机了，Redis 如何避免数据丢失\n\nAOF：Append Only File\n\n\n# 1.1 AOF 日志是如何实现的？\n\n说到日志，我们熟悉的是预写日志（WAL，Write Ahead Log），也就是说，在实际写数据前，先把修改的数据记到日志文件中，以便故障时进行恢复。不过，AOF 日志正好相反，它是写后日志，“写后”的意思是 Redis 是先执行命令，把数据写入内存，然后才记录日志，如下图所示：\n\n那 AOF 为什么要先执行命令再记日志呢？要回答这个问题，我们要先知道 AOF 里记录了什么内容。\n\n传统数据库的日志，例如 redo log（重做日志），记录的是修改后的数据，而 AOF 里记录的是 Redis 收到的每一条命令，这些命令是以文本形式保存的。\n\n我们以Redis收到“set testkey testvalue”命令后记录的日志为例，看看AOF日志的内容。其中，“ *3”表示当前命令有三个部分，每部分都是由“ $+数字”开头，后面紧跟着具体的命令、键或值。这里，“数字”表示这部分中的命令、键或值一共有多少字节。例如，“ $3 set”表示这部分有3个字节，也就是“set”命令。\n\n但是，为了避免额外的检查开销，Redis 在向 AOF 里面记录日志的时候，并不会先去对这些命令进行语法检查。所以，如果先记日志再执行命令的话，日志中就有可能记录了错误的命令，Redis 在使用日志恢复数据时，就可能会出错。\n\n而写后日志这种方式，就是先让系统执行命令，只有命令能执行成功，才会被记录到日志中，否则，系统就会直接向客户端报错。所以，Redis 使用写后日志这一方式的一大好处是，可以避免出现记录错误命令的情况。\n\n除此之外，AOF 还有一个好处：它是在命令执行后才记录日志，所以不会阻塞当前的写操作。\n\n不过，AOF 也有两个潜在的风险:\n\n * 首先，如果刚执行完一个命令，还没有来得及记日志就宕机了，那么这个命令和相应的数据就有丢失的风险。如果此时 Redis 是用作缓存，还可以从后端数据库重新读入数据进行恢复，但是，如果 Redis 是直接用作数据库的话，此时，因为命令没有记入日志，所以就无法用日志进行恢复了。\n * 其次，AOF 虽然避免了对当前命令的阻塞，但可能会给下一个操作带来阻塞风险。这是因为，AOF 日志也是在主线程中执行的，如果在把日志文件写入磁盘时，磁盘写压力大，就会导致写盘很慢，进而导致后续的操作也无法执行了。\n\n仔细分析的话，你就会发现，这两个风险都是和 AOF 写回磁盘的时机相关的。这也就意味着，如果我们能够控制一个写命令执行完后 AOF 日志写回磁盘的时机，这两个风险就解除了。\n\n\n# 1.2 三种写回策略\n\n其实，对于这个问题，AOF 机制给我们提供了三个选择，也就是 AOF 配置项 appendfsync 的三个可选值：\n\n * Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；\n * Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；\n * No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。\n\n针对避免主线程阻塞和减少数据丢失问题，这三种写回策略都无法做到两全其美。我们来分析下其中的原因：\n\n * “同步写回”可以做到基本不丢数据，但是它在每一个写命令后都有一个慢速的落盘操作，不可避免地会影响主线程性能；\n * 虽然“操作系统控制的写回”在写完缓冲区后，就可以继续执行后续的命令，但是落盘的时机已经不在 Redis 手中了，只要 AOF 记录没有写回磁盘，一旦宕机对应的数据就丢失了；\n * “每秒写回”采用一秒写回一次的频率，避免了“同步写回”的性能开销，虽然减少了对系统性能的影响，但是如果发生宕机，上一秒内未落盘的命令操作仍然会丢失。所以，这只能算是，在避免影响主线程性能和避免数据丢失两者间取了个折中。\n\n三种写回策略的对比如下：\n\n选择哪种写回策略，就要在高性能和高可靠性之间做 trade-off 了：\n\n * 想要获得高性能，就选择 No 策略；\n * 如果想要得到高可靠性保证，就选择 Always 策略；\n * 如果允许数据有一点丢失，又希望性能别受太大影响的话，那么就选择 Everysec 策略。\n\n随着 Redis 接收的命令越来越多，AOF 文件也会越来越大，这也就意味着，我们一定要小心 AOF 文件过大带来的性能问题。这里的“性能问题”，主要在于以下三个方面：\n\n 1. 文件系统本身对文件大小有限制，无法保存过大的文件；\n 2. 如果文件太大，之后再往里面追加命令记录的话，效率也会变低；\n 3. 如果发生宕机，AOF 中记录的命令要一个个被重新执行，用于故障恢复，如果日志文件太大，整个恢复过程就会非常缓慢，这就会影响到 Redis 的正常使用。\n\n所以，我们就要采取一定的控制手段，这个时候，**AOF 重写机制**就登场了。\n\n\n# 1.3 AOF 重写机制\n\n当 AOF 日志文件太大了，就需要 AOF 重写机制了。\n\nAOF 重写机制：就是在重写时，Redis 根据数据库的现状创建一个新的 AOF 文件，也就是说，读取数据库中的所有键值对，然后对每一个键值对用一条命令记录它的写入。比如说，当读取了键值对“testkey”: “testvalue”之后，重写机制会记录 set testkey testvalue 这条命令。这样，当需要恢复时，可以重新执行该命令，实现“testkey”: “testvalue”的写入。\n\n为什么重写机制可以把日志文件变小呢? 实际上，重写机制具有“多变一”功能。所谓的“多变一”，也就是说，旧日志文件中的多条命令，在重写后的新日志中变成了一条命令。因为这个过程把一些中间的修改记录给去掉了，只保留了最新的数据库状态。如下图所示：\n\n不过，虽然 AOF 重写后，日志文件会缩小，但是，要把整个数据库的最新数据的操作日志都写回磁盘，仍然是一个非常耗时的过程。这时，我们就要继续关注另一个问题了：重写会不会阻塞主线程？\n\n\n# 1.4 AOF 重写会阻塞吗？—— 不会\n\n和 AOF 日志由主线程写回不同，重写过程是由后台子进程 bgrewriteaof 来完成的，这也是为了避免阻塞主线程，导致数据库性能下降。\n\n我把重写的过程总结为“一个拷贝，两处日志”：\n\n“一个拷贝”就是指，每次执行重写时，主线程 fork 出后台的 bgrewriteaof 子进程。此时，fork 会把主线程的内存拷贝一份给 bgrewriteaof 子进程，这里面就包含了数据库的最新数据。然后，bgrewriteaof 子进程就可以在不影响主线程的情况下，逐一把拷贝的数据写成操作，记入重写日志。\n\n“两处日志”又是什么呢？\n\n因为主线程未阻塞，仍然可以处理新来的操作。此时，如果有写操作，第一处日志就是指正在使用的 AOF 日志，Redis 会把这个操作写到它的缓冲区。这样一来，即使宕机了，这个 AOF 日志的操作仍然是齐全的，可以用于恢复。\n\n而第二处日志，就是指新的 AOF 重写日志。这个操作也会被写到重写日志的缓冲区。这样，重写日志也不会丢失最新的操作。等到拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF 文件，以保证数据库最新状态的记录。此时，我们就可以用新的 AOF 文件替代旧文件了。\n\n因此，AOF 非阻塞的重写过程如下图所示：\n\n总结来说，每次 AOF 重写时，Redis 会先执行一个内存拷贝，用于重写；然后，使用两个日志保证在重写过程中，新写入的数据不会丢失。而且，因为 Redis 采用额外的线程进行数据重写，所以，这个过程并不会阻塞主线程。\n\n\n# 1.5 小结\n\n这一节介绍了 Redis 用于避免数据丢失的 AOF 日志机制。这个方法通过逐一记录操作命令，在恢复时再逐一执行命令的方式，保证了数据的可靠性。\n\nAOF 机制考虑到对 Redis 性能的影响，提供了 AOF 日志的三种写回策略。\n\n此外，为了避免日志文件过大，Redis 提供了 AOF 重写机制，直接根据数据库里数据的最新状态，生成这些数据的插入命令，作为新日志。这个过程通过后台线程完成，避免了对主线程的阻塞。\n\n不过，上面介绍的落盘时机和重写机制都是用于“记日志”的方法，而在”用日志“时，需要对所有的操作记录进行顺序重放，这个重放过程就很慢了。那，有没有既能避免数据丢失，又能更快地恢复的方法呢？当然有，那就是 RDB 快照了。\n\n----------------------------------------\n\n本节问题 1：AOF 重写过程有没有其他潜在的阻塞风险？\n\n这里有两个风险：\n\n 1. Redis 主线程 fork 创建 bgrewriteaof 子进程时，内核需要创建用于管理子进程的相关数据结构，这些数据结构在操作系统中通常叫作进程控制块（Process Control Block，简称为 PCB）。内核要把主线程的 PCB 内容拷贝给子进程。这个创建和拷贝过程由内核执行，是会阻塞主线程的。而且，在拷贝过程中，子进程要拷贝父进程的页表，这个过程的耗时和 Redis 实例的内存大小有关。如果 Redis 实例内存大，页表就会大，fork 执行时间就会长，这就会给主线程带来阻塞风险。\n 2. bgrewriteaof 子进程会和主线程共享内存。当主线程收到新写或修改的操作时，主线程会申请新的内存空间，用来保存新写或修改的数据，如果操作的是 bigkey，也就是数据量大的集合类型数据，那么，主线程会因为申请大空间而面临阻塞风险。因为操作系统在分配内存空间时，有查找和锁的开销，这就会导致阻塞。\n\n本节问题 2：AOF 重写为什么不共享使用 AOF 本身的日志？\n\n如果都用 AOF 日志的话，主线程要写，bgrewriteaof 子进程也要写，这两者会竞争文件系统的锁，这就会对 Redis 主线程的性能造成影响。\n\n\n# 2. RDB 快照：宕机后，Redis如何实现快速恢复？\n\n\n# 2.1 什么是 RDB\n\n上一节讲的 Redis 避免数据丢失的 AOF 方法，好处是每次执行只需要记录操作命令，需要持久化的数据量不大，只要你不是采用的 Always 的持久化策略，就不会对性能造成太大影响。\n\n但由于记录的命令而不是实际数据，因此使用 AOF 日志进行故障恢复时需要重放一遍，如果日志过多会耗费很长时间。那有没有既可以保证可靠性，还能在宕机时实现快速恢复的其他方法呢？这就是这节要学习的持久化方法——内存快照。\n\n内存快照：指内存中的数据在某一个时刻的状态记录。\n\n这就像平时拍照片一样，内存快照把某一时刻的状态以文件的形式写到磁盘上，这样即使宕机，快照文件也不会丢失，数据的可靠性也就得到了保证。这个快照文件就称为 RDB 文件。\n\n> RDB: Redis DataBase\n\n和 AOF 相比，RDB 记录的是某一时刻的数据，并不是操作，所以，在做数据恢复时，我们可以直接把 RDB 文件读入内存，很快地完成恢复。\n\n但内存快照也并不一定是最优选项，拍快照涉及到两个关键问题：\n\n * 给哪些数据拍快照？这涉及到快照的执行效率的问题。\n * 拍快照时还能增删改吗？这涉及 Redis 是否被阻塞。\n\n\n# 2.2 给哪些数据拍快照？\n\nRedis 的数据都在内存中，为了提供所有数据的可靠性保证，它执行的是全量快照，也就是说，把内存中的所有数据都记录到磁盘中。\n\n但全量快照全部写入磁盘会花费很多时间，而 Redis 的单线程模型又决定了我们要尽量避免所有会阻塞主线程的操作。那 RDB 文件的生成是否会阻塞主线程？\n\nRedis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave：\n\n * save：在主线程中执行，会导致阻塞；\n * bgsave：创建一个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞，这也是 Redis RDB 文件生成的默认配置。\n\n此时，我们可以通过bgsave命令来执行全量快照，这既提供了数据的可靠性保证，也避免了对 Redis 的性能影响。\n\n接下来需要考虑，使用 bgsave 来执行全量快照时，Redis 能否正常处理写操作？\n\n\n# 2.3 快照时数据能修改吗？\n\n在拍快照时，如果发生数据改动，则很容易产生数据不一致现象。如果不想让数据发生改动，那拍快照期间 Redis 无法接收写请求，这在生产环境下是不被允许的。这时，Redis 就借助了操作系统提供的写时复制技术（Copy-On-Write，COW），在执行快照的同时，正常处理写操作。\n\n为什么不用 bgsave 避免阻塞来处理拍快照期间不能写的问题呢？\n\n这是一个常见的误区。\n\n避免阻塞和正常处理写操作并不是一回事。用 bgsave 执行全量快照时，主线程的确没有阻塞，可以正常接收请求，但是，为了保证快照完整性，它只能处理读操作，因为不能修改正在执行快照的数据。\n\n简单来说， bgsave 子进程是由主线程 fork 生成的，可以共享主线程的所有内存数据。bgsave 子进程运行后，开始读取主线程的内存数据，并把它们写入 RDB 文件。\n\n * 此时，如果主线程对这些数据都是读操作（如图中的键值对 A），那么，主线程和 bgsave 子进程相互不影响。\n * 但如果主线程要修改一块数据（例如图中的键值对 C），那么，这块数据就会被复制一份，生成该数据的副本（键值对 C’）。然后，主线程在这个数据副本上进行修改。同时，bgsave子进程可以继续把原来的数据（键值对 C）写入 RDB 文件。\n\n这既保证了快照的完整性，也允许主线程同时对数据进行修改，避免了对正常业务的影响。\n\n到这里，我们就解决了对“哪些数据做快照”以及“做快照时数据能否修改”这两大问题：Redis 会使用 bgsave 对当前内存中的所有数据做快照，这个操作是子进程在后台完成的，这就允许主线程同时可以修改数据。\n\n\n# 2.4 拍快照的频率\n\n快照间隔时间也是一个关键问题。\n\n拍快照的间隔越小，发生宕机时丢失的数据也就越少，那能不能每秒拍一次快照？\n\n这种想法是错误的。频繁执行全量快照会带来两方面的开销：\n\n * 一方面，频繁将全量数据写入磁盘，会给磁盘带来很大压力，多个快照竞争有限的磁盘带宽，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。\n * 另一方面，bgsave 子进程需要通过 fork 操作从主线程创建出来。虽然，子进程在创建后不会再阻塞主线程，但是，fork 这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。如果频繁 fork 出 bgsave 子进程，这就会频繁阻塞主线程了（所以，在 Redis 中如果有一个 bgsave 在运行，就不会再启动第二个 bgsave 子进程）。那么，有什么其他好方法吗？\n\n此时，我们可以做增量快照：做了一次全量快照后，后续的快照只对修改的数据进行快照记录，这样可以避免每次全量快照的开销。\n\n在第一次做完全量快照后，T1 和 T2 时刻如果再做快照，我们只需要将被修改的数据写入快照文件就行。但是，这么做的前提是，我们需要记住哪些数据被修改了。这个“记住”需要我们使用额外的元数据信息去记录哪些数据被修改了，这会带来额外的空间开销问题。如下图所示：\n\n如果我们对每一个键值对的修改，都做个记录，那么，如果有 1 万个被修改的键值对，我们就需要有 1 万条额外的记录。而且，有的时候，键值对非常小，比如只有 32 字节，而记录它被修改的元数据信息，可能就需要 8 字节，这样的画，为了“记住”修改，引入的额外空间开销比较大。这对于内存资源宝贵的 Redis 来说，有些得不偿失。\n\n到这里，你可以发现，RDB 快照虽然跟 AOF 相比，快照的恢复速度快，但是，快照的频率不好把握，如果频率太低，两次快照间一旦宕机，就可能有比较多的数据丢失。如果频率太高，又会产生额外开销，那么，还有什么方法既能利用RDB的快速恢复，又能以较小的开销做到尽量少丢数据呢？\n\nRedis 4.0中提出了一个混合使用AOF日志和内存快照的方法。简单来说，内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。\n\n这样一来，快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。而且，AOF 日志也只用记录两次快照间的操作，也就是说，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。\n\n如下图所示，T1和T2时刻的修改，用AOF日志记录，等到第二次做全量快照时，就可以清空AOF日志，因为此时的修改都已经记录到快照中了，恢复时就不再用日志了。\n\n这个方法既能享受到 RDB 文件快速恢复的好处，又能享受到 AOF 只记录操作命令的简单优势，颇有点“鱼和熊掌可以兼得”的感觉，建议你在实践中用起来。\n\n📝 其实最后这个综合的方法没有使用增量快照的办法。\n\n\n# 2.5 小结\n\n这一大节，介绍了 Redis 用于避免数据丢失的 RDB 内存快照的方法，它可以快速恢复数据库。通过直接把 RDB 文件读入内存，避免 AOF 需要顺序、逐一执行操作命令带来的低效性能问题。\n\nRedis 设计 bgsave 和写时复制的方式来尽可能减少了内存快照对正常读写的影响。\n\n但频繁快照又是不可接受的，于是出现了混合使用 RDB 和 AOF 的方式，正好可以取两者之长，避两者之短，以较小的性能开销保证数据可靠性和性能。\n\n最后，关于 AOF 和 RDB 的选择问题，我想提三点建议：\n\n * 数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择；\n * 如果允许分钟级别的数据丢失，可以只使用 RDB；\n * 如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。\n\n----------------------------------------\n\n本节问题 1 ：使用一个 2 核 CPU、4GB 内存、500GB 磁盘的云主机运行 Redis，Redis 数据库的数据量大小差不多是 2GB。当时 Redis主要以修改操作为主，写读比例差不多在 8:2 左右，也就是说，如果有 100 个请求，80 个请求执行的是修改操作。在这个场景下，用 RDB 做持久化有什么风险吗？？\n\n从内存资源和CPU资源两方面分析风险：\n\n 1. 内存不足的风险：Redis fork一个bgsave子进程进行RDB写入，如果主线程再接收到写操作，就会采用写时复制。写时复制需要给写操作的数据分配新的内存空间。本问题中写的比例为80%，那么，在持久化过程中，为了保存80%写操作涉及的数据，写时复制机制会在实例内存中，为这些数据再分配新内存空间，分配的内存量相当于整个实例数据量的80%，大约是1.6GB，这样一来，整个系统内存的使用量就接近饱和了。此时，如果实例还有大量的新key写入或key修改，云主机内存很快就会被吃光。如果云主机开启了Swap机制，就会有一部分数据被换到磁盘上，当访问磁盘上的这部分数据时，性能会急剧下降。如果云主机没有开启Swap，会直接触发OOM，整个Redis实例会面临被系统kill掉的风险。\n 2. 主线程和子进程竞争使用CPU的风险：生成RDB的子进程需要CPU核运行，主线程本身也需要CPU核运行，而且，如果Redis还启用了后台线程，此时，主线程、子进程和后台线程都会竞争CPU资源。由于云主机只有2核CPU，这就会影响到主线程处理请求的速度。\n\n本节问题 2 ：写时复制的底层实现机制？？\n\n写时复制的效果：bgsave子进程相当于复制了原始数据，而主线程仍然可以修改原来的数据。\n\n对Redis来说，主线程fork出bgsave子进程后，bgsave子进程实际是复制了主线程的页表。这些页表中，就保存了在执行bgsave命令时，主线程的所有数据块在内存中的物理地址。这样一来，bgsave子进程生成RDB时，就可以根据页表读取这些数据，再写入磁盘中。如果此时，主线程接收到了新写或修改操作，那么，主线程会使用写时复制机制。具体来说，写时复制就是指，主线程在有写操作时，才会把这个新写或修改后的数据写入到一个新的物理地址中，并修改自己的页表映射。\n\n我来借助下图中的例子，具体展示一下写时复制的底层机制。\n\nbgsave子进程复制主线程的页表以后，假如主线程需要修改虚页7里的数据，那么，主线程就需要新分配一个物理页（假设是物理页53），然后把修改后的虚页7里的数据写到物理页53上，而虚页7里原来的数据仍然保存在物理页33上。这个时候，虚页7到物理页33的映射关系，仍然保留在bgsave子进程中。所以，bgsave子进程可以无误地把虚页7的原始数据写入RDB文件。",normalizedContent:"# 持久化机制：aof日志和rdb快照\n\n> 参考：\n> \n>  * 04 aof 日志：宕机了，redis 如何避免数据丢失？ | 极客时间\n>  * 05 内存快照：宕机后，redis 如何实现快速恢复？| 极客时间\n\nredis 用作缓存并将数据存于内存中，就会面对一个问题：一旦服务器宕机，内存中的数据将全部丢失。\n\n也许有个解决方案：从后端数据库恢复这些数据。但这频繁访问数据库会使得性能严重下降。所以对于 redis 而言，实现数据的持久化，避免从后端中恢复数据，是至关重要的。\n\n目前，redis 的持久化主要有两大机制：aof 日志和 rdb 快照。这里讲分别讲解。\n\n\n# 1. aof 日志：宕机了，redis 如何避免数据丢失\n\naof：append only file\n\n\n# 1.1 aof 日志是如何实现的？\n\n说到日志，我们熟悉的是预写日志（wal，write ahead log），也就是说，在实际写数据前，先把修改的数据记到日志文件中，以便故障时进行恢复。不过，aof 日志正好相反，它是写后日志，“写后”的意思是 redis 是先执行命令，把数据写入内存，然后才记录日志，如下图所示：\n\n那 aof 为什么要先执行命令再记日志呢？要回答这个问题，我们要先知道 aof 里记录了什么内容。\n\n传统数据库的日志，例如 redo log（重做日志），记录的是修改后的数据，而 aof 里记录的是 redis 收到的每一条命令，这些命令是以文本形式保存的。\n\n我们以redis收到“set testkey testvalue”命令后记录的日志为例，看看aof日志的内容。其中，“ *3”表示当前命令有三个部分，每部分都是由“ $+数字”开头，后面紧跟着具体的命令、键或值。这里，“数字”表示这部分中的命令、键或值一共有多少字节。例如，“ $3 set”表示这部分有3个字节，也就是“set”命令。\n\n但是，为了避免额外的检查开销，redis 在向 aof 里面记录日志的时候，并不会先去对这些命令进行语法检查。所以，如果先记日志再执行命令的话，日志中就有可能记录了错误的命令，redis 在使用日志恢复数据时，就可能会出错。\n\n而写后日志这种方式，就是先让系统执行命令，只有命令能执行成功，才会被记录到日志中，否则，系统就会直接向客户端报错。所以，redis 使用写后日志这一方式的一大好处是，可以避免出现记录错误命令的情况。\n\n除此之外，aof 还有一个好处：它是在命令执行后才记录日志，所以不会阻塞当前的写操作。\n\n不过，aof 也有两个潜在的风险:\n\n * 首先，如果刚执行完一个命令，还没有来得及记日志就宕机了，那么这个命令和相应的数据就有丢失的风险。如果此时 redis 是用作缓存，还可以从后端数据库重新读入数据进行恢复，但是，如果 redis 是直接用作数据库的话，此时，因为命令没有记入日志，所以就无法用日志进行恢复了。\n * 其次，aof 虽然避免了对当前命令的阻塞，但可能会给下一个操作带来阻塞风险。这是因为，aof 日志也是在主线程中执行的，如果在把日志文件写入磁盘时，磁盘写压力大，就会导致写盘很慢，进而导致后续的操作也无法执行了。\n\n仔细分析的话，你就会发现，这两个风险都是和 aof 写回磁盘的时机相关的。这也就意味着，如果我们能够控制一个写命令执行完后 aof 日志写回磁盘的时机，这两个风险就解除了。\n\n\n# 1.2 三种写回策略\n\n其实，对于这个问题，aof 机制给我们提供了三个选择，也就是 aof 配置项 appendfsync 的三个可选值：\n\n * always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；\n * everysec，每秒写回：每个写命令执行完，只是先把日志写到 aof 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；\n * no，操作系统控制的写回：每个写命令执行完，只是先把日志写到 aof 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。\n\n针对避免主线程阻塞和减少数据丢失问题，这三种写回策略都无法做到两全其美。我们来分析下其中的原因：\n\n * “同步写回”可以做到基本不丢数据，但是它在每一个写命令后都有一个慢速的落盘操作，不可避免地会影响主线程性能；\n * 虽然“操作系统控制的写回”在写完缓冲区后，就可以继续执行后续的命令，但是落盘的时机已经不在 redis 手中了，只要 aof 记录没有写回磁盘，一旦宕机对应的数据就丢失了；\n * “每秒写回”采用一秒写回一次的频率，避免了“同步写回”的性能开销，虽然减少了对系统性能的影响，但是如果发生宕机，上一秒内未落盘的命令操作仍然会丢失。所以，这只能算是，在避免影响主线程性能和避免数据丢失两者间取了个折中。\n\n三种写回策略的对比如下：\n\n选择哪种写回策略，就要在高性能和高可靠性之间做 trade-off 了：\n\n * 想要获得高性能，就选择 no 策略；\n * 如果想要得到高可靠性保证，就选择 always 策略；\n * 如果允许数据有一点丢失，又希望性能别受太大影响的话，那么就选择 everysec 策略。\n\n随着 redis 接收的命令越来越多，aof 文件也会越来越大，这也就意味着，我们一定要小心 aof 文件过大带来的性能问题。这里的“性能问题”，主要在于以下三个方面：\n\n 1. 文件系统本身对文件大小有限制，无法保存过大的文件；\n 2. 如果文件太大，之后再往里面追加命令记录的话，效率也会变低；\n 3. 如果发生宕机，aof 中记录的命令要一个个被重新执行，用于故障恢复，如果日志文件太大，整个恢复过程就会非常缓慢，这就会影响到 redis 的正常使用。\n\n所以，我们就要采取一定的控制手段，这个时候，**aof 重写机制**就登场了。\n\n\n# 1.3 aof 重写机制\n\n当 aof 日志文件太大了，就需要 aof 重写机制了。\n\naof 重写机制：就是在重写时，redis 根据数据库的现状创建一个新的 aof 文件，也就是说，读取数据库中的所有键值对，然后对每一个键值对用一条命令记录它的写入。比如说，当读取了键值对“testkey”: “testvalue”之后，重写机制会记录 set testkey testvalue 这条命令。这样，当需要恢复时，可以重新执行该命令，实现“testkey”: “testvalue”的写入。\n\n为什么重写机制可以把日志文件变小呢? 实际上，重写机制具有“多变一”功能。所谓的“多变一”，也就是说，旧日志文件中的多条命令，在重写后的新日志中变成了一条命令。因为这个过程把一些中间的修改记录给去掉了，只保留了最新的数据库状态。如下图所示：\n\n不过，虽然 aof 重写后，日志文件会缩小，但是，要把整个数据库的最新数据的操作日志都写回磁盘，仍然是一个非常耗时的过程。这时，我们就要继续关注另一个问题了：重写会不会阻塞主线程？\n\n\n# 1.4 aof 重写会阻塞吗？—— 不会\n\n和 aof 日志由主线程写回不同，重写过程是由后台子进程 bgrewriteaof 来完成的，这也是为了避免阻塞主线程，导致数据库性能下降。\n\n我把重写的过程总结为“一个拷贝，两处日志”：\n\n“一个拷贝”就是指，每次执行重写时，主线程 fork 出后台的 bgrewriteaof 子进程。此时，fork 会把主线程的内存拷贝一份给 bgrewriteaof 子进程，这里面就包含了数据库的最新数据。然后，bgrewriteaof 子进程就可以在不影响主线程的情况下，逐一把拷贝的数据写成操作，记入重写日志。\n\n“两处日志”又是什么呢？\n\n因为主线程未阻塞，仍然可以处理新来的操作。此时，如果有写操作，第一处日志就是指正在使用的 aof 日志，redis 会把这个操作写到它的缓冲区。这样一来，即使宕机了，这个 aof 日志的操作仍然是齐全的，可以用于恢复。\n\n而第二处日志，就是指新的 aof 重写日志。这个操作也会被写到重写日志的缓冲区。这样，重写日志也不会丢失最新的操作。等到拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 aof 文件，以保证数据库最新状态的记录。此时，我们就可以用新的 aof 文件替代旧文件了。\n\n因此，aof 非阻塞的重写过程如下图所示：\n\n总结来说，每次 aof 重写时，redis 会先执行一个内存拷贝，用于重写；然后，使用两个日志保证在重写过程中，新写入的数据不会丢失。而且，因为 redis 采用额外的线程进行数据重写，所以，这个过程并不会阻塞主线程。\n\n\n# 1.5 小结\n\n这一节介绍了 redis 用于避免数据丢失的 aof 日志机制。这个方法通过逐一记录操作命令，在恢复时再逐一执行命令的方式，保证了数据的可靠性。\n\naof 机制考虑到对 redis 性能的影响，提供了 aof 日志的三种写回策略。\n\n此外，为了避免日志文件过大，redis 提供了 aof 重写机制，直接根据数据库里数据的最新状态，生成这些数据的插入命令，作为新日志。这个过程通过后台线程完成，避免了对主线程的阻塞。\n\n不过，上面介绍的落盘时机和重写机制都是用于“记日志”的方法，而在”用日志“时，需要对所有的操作记录进行顺序重放，这个重放过程就很慢了。那，有没有既能避免数据丢失，又能更快地恢复的方法呢？当然有，那就是 rdb 快照了。\n\n----------------------------------------\n\n本节问题 1：aof 重写过程有没有其他潜在的阻塞风险？\n\n这里有两个风险：\n\n 1. redis 主线程 fork 创建 bgrewriteaof 子进程时，内核需要创建用于管理子进程的相关数据结构，这些数据结构在操作系统中通常叫作进程控制块（process control block，简称为 pcb）。内核要把主线程的 pcb 内容拷贝给子进程。这个创建和拷贝过程由内核执行，是会阻塞主线程的。而且，在拷贝过程中，子进程要拷贝父进程的页表，这个过程的耗时和 redis 实例的内存大小有关。如果 redis 实例内存大，页表就会大，fork 执行时间就会长，这就会给主线程带来阻塞风险。\n 2. bgrewriteaof 子进程会和主线程共享内存。当主线程收到新写或修改的操作时，主线程会申请新的内存空间，用来保存新写或修改的数据，如果操作的是 bigkey，也就是数据量大的集合类型数据，那么，主线程会因为申请大空间而面临阻塞风险。因为操作系统在分配内存空间时，有查找和锁的开销，这就会导致阻塞。\n\n本节问题 2：aof 重写为什么不共享使用 aof 本身的日志？\n\n如果都用 aof 日志的话，主线程要写，bgrewriteaof 子进程也要写，这两者会竞争文件系统的锁，这就会对 redis 主线程的性能造成影响。\n\n\n# 2. rdb 快照：宕机后，redis如何实现快速恢复？\n\n\n# 2.1 什么是 rdb\n\n上一节讲的 redis 避免数据丢失的 aof 方法，好处是每次执行只需要记录操作命令，需要持久化的数据量不大，只要你不是采用的 always 的持久化策略，就不会对性能造成太大影响。\n\n但由于记录的命令而不是实际数据，因此使用 aof 日志进行故障恢复时需要重放一遍，如果日志过多会耗费很长时间。那有没有既可以保证可靠性，还能在宕机时实现快速恢复的其他方法呢？这就是这节要学习的持久化方法——内存快照。\n\n内存快照：指内存中的数据在某一个时刻的状态记录。\n\n这就像平时拍照片一样，内存快照把某一时刻的状态以文件的形式写到磁盘上，这样即使宕机，快照文件也不会丢失，数据的可靠性也就得到了保证。这个快照文件就称为 rdb 文件。\n\n> rdb: redis database\n\n和 aof 相比，rdb 记录的是某一时刻的数据，并不是操作，所以，在做数据恢复时，我们可以直接把 rdb 文件读入内存，很快地完成恢复。\n\n但内存快照也并不一定是最优选项，拍快照涉及到两个关键问题：\n\n * 给哪些数据拍快照？这涉及到快照的执行效率的问题。\n * 拍快照时还能增删改吗？这涉及 redis 是否被阻塞。\n\n\n# 2.2 给哪些数据拍快照？\n\nredis 的数据都在内存中，为了提供所有数据的可靠性保证，它执行的是全量快照，也就是说，把内存中的所有数据都记录到磁盘中。\n\n但全量快照全部写入磁盘会花费很多时间，而 redis 的单线程模型又决定了我们要尽量避免所有会阻塞主线程的操作。那 rdb 文件的生成是否会阻塞主线程？\n\nredis 提供了两个命令来生成 rdb 文件，分别是 save 和 bgsave：\n\n * save：在主线程中执行，会导致阻塞；\n * bgsave：创建一个子进程，专门用于写入 rdb 文件，避免了主线程的阻塞，这也是 redis rdb 文件生成的默认配置。\n\n此时，我们可以通过bgsave命令来执行全量快照，这既提供了数据的可靠性保证，也避免了对 redis 的性能影响。\n\n接下来需要考虑，使用 bgsave 来执行全量快照时，redis 能否正常处理写操作？\n\n\n# 2.3 快照时数据能修改吗？\n\n在拍快照时，如果发生数据改动，则很容易产生数据不一致现象。如果不想让数据发生改动，那拍快照期间 redis 无法接收写请求，这在生产环境下是不被允许的。这时，redis 就借助了操作系统提供的写时复制技术（copy-on-write，cow），在执行快照的同时，正常处理写操作。\n\n为什么不用 bgsave 避免阻塞来处理拍快照期间不能写的问题呢？\n\n这是一个常见的误区。\n\n避免阻塞和正常处理写操作并不是一回事。用 bgsave 执行全量快照时，主线程的确没有阻塞，可以正常接收请求，但是，为了保证快照完整性，它只能处理读操作，因为不能修改正在执行快照的数据。\n\n简单来说， bgsave 子进程是由主线程 fork 生成的，可以共享主线程的所有内存数据。bgsave 子进程运行后，开始读取主线程的内存数据，并把它们写入 rdb 文件。\n\n * 此时，如果主线程对这些数据都是读操作（如图中的键值对 a），那么，主线程和 bgsave 子进程相互不影响。\n * 但如果主线程要修改一块数据（例如图中的键值对 c），那么，这块数据就会被复制一份，生成该数据的副本（键值对 c’）。然后，主线程在这个数据副本上进行修改。同时，bgsave子进程可以继续把原来的数据（键值对 c）写入 rdb 文件。\n\n这既保证了快照的完整性，也允许主线程同时对数据进行修改，避免了对正常业务的影响。\n\n到这里，我们就解决了对“哪些数据做快照”以及“做快照时数据能否修改”这两大问题：redis 会使用 bgsave 对当前内存中的所有数据做快照，这个操作是子进程在后台完成的，这就允许主线程同时可以修改数据。\n\n\n# 2.4 拍快照的频率\n\n快照间隔时间也是一个关键问题。\n\n拍快照的间隔越小，发生宕机时丢失的数据也就越少，那能不能每秒拍一次快照？\n\n这种想法是错误的。频繁执行全量快照会带来两方面的开销：\n\n * 一方面，频繁将全量数据写入磁盘，会给磁盘带来很大压力，多个快照竞争有限的磁盘带宽，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。\n * 另一方面，bgsave 子进程需要通过 fork 操作从主线程创建出来。虽然，子进程在创建后不会再阻塞主线程，但是，fork 这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。如果频繁 fork 出 bgsave 子进程，这就会频繁阻塞主线程了（所以，在 redis 中如果有一个 bgsave 在运行，就不会再启动第二个 bgsave 子进程）。那么，有什么其他好方法吗？\n\n此时，我们可以做增量快照：做了一次全量快照后，后续的快照只对修改的数据进行快照记录，这样可以避免每次全量快照的开销。\n\n在第一次做完全量快照后，t1 和 t2 时刻如果再做快照，我们只需要将被修改的数据写入快照文件就行。但是，这么做的前提是，我们需要记住哪些数据被修改了。这个“记住”需要我们使用额外的元数据信息去记录哪些数据被修改了，这会带来额外的空间开销问题。如下图所示：\n\n如果我们对每一个键值对的修改，都做个记录，那么，如果有 1 万个被修改的键值对，我们就需要有 1 万条额外的记录。而且，有的时候，键值对非常小，比如只有 32 字节，而记录它被修改的元数据信息，可能就需要 8 字节，这样的画，为了“记住”修改，引入的额外空间开销比较大。这对于内存资源宝贵的 redis 来说，有些得不偿失。\n\n到这里，你可以发现，rdb 快照虽然跟 aof 相比，快照的恢复速度快，但是，快照的频率不好把握，如果频率太低，两次快照间一旦宕机，就可能有比较多的数据丢失。如果频率太高，又会产生额外开销，那么，还有什么方法既能利用rdb的快速恢复，又能以较小的开销做到尽量少丢数据呢？\n\nredis 4.0中提出了一个混合使用aof日志和内存快照的方法。简单来说，内存快照以一定的频率执行，在两次快照之间，使用 aof 日志记录这期间的所有命令操作。\n\n这样一来，快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。而且，aof 日志也只用记录两次快照间的操作，也就是说，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。\n\n如下图所示，t1和t2时刻的修改，用aof日志记录，等到第二次做全量快照时，就可以清空aof日志，因为此时的修改都已经记录到快照中了，恢复时就不再用日志了。\n\n这个方法既能享受到 rdb 文件快速恢复的好处，又能享受到 aof 只记录操作命令的简单优势，颇有点“鱼和熊掌可以兼得”的感觉，建议你在实践中用起来。\n\n📝 其实最后这个综合的方法没有使用增量快照的办法。\n\n\n# 2.5 小结\n\n这一大节，介绍了 redis 用于避免数据丢失的 rdb 内存快照的方法，它可以快速恢复数据库。通过直接把 rdb 文件读入内存，避免 aof 需要顺序、逐一执行操作命令带来的低效性能问题。\n\nredis 设计 bgsave 和写时复制的方式来尽可能减少了内存快照对正常读写的影响。\n\n但频繁快照又是不可接受的，于是出现了混合使用 rdb 和 aof 的方式，正好可以取两者之长，避两者之短，以较小的性能开销保证数据可靠性和性能。\n\n最后，关于 aof 和 rdb 的选择问题，我想提三点建议：\n\n * 数据不能丢失时，内存快照和 aof 的混合使用是一个很好的选择；\n * 如果允许分钟级别的数据丢失，可以只使用 rdb；\n * 如果只用 aof，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。\n\n----------------------------------------\n\n本节问题 1 ：使用一个 2 核 cpu、4gb 内存、500gb 磁盘的云主机运行 redis，redis 数据库的数据量大小差不多是 2gb。当时 redis主要以修改操作为主，写读比例差不多在 8:2 左右，也就是说，如果有 100 个请求，80 个请求执行的是修改操作。在这个场景下，用 rdb 做持久化有什么风险吗？？\n\n从内存资源和cpu资源两方面分析风险：\n\n 1. 内存不足的风险：redis fork一个bgsave子进程进行rdb写入，如果主线程再接收到写操作，就会采用写时复制。写时复制需要给写操作的数据分配新的内存空间。本问题中写的比例为80%，那么，在持久化过程中，为了保存80%写操作涉及的数据，写时复制机制会在实例内存中，为这些数据再分配新内存空间，分配的内存量相当于整个实例数据量的80%，大约是1.6gb，这样一来，整个系统内存的使用量就接近饱和了。此时，如果实例还有大量的新key写入或key修改，云主机内存很快就会被吃光。如果云主机开启了swap机制，就会有一部分数据被换到磁盘上，当访问磁盘上的这部分数据时，性能会急剧下降。如果云主机没有开启swap，会直接触发oom，整个redis实例会面临被系统kill掉的风险。\n 2. 主线程和子进程竞争使用cpu的风险：生成rdb的子进程需要cpu核运行，主线程本身也需要cpu核运行，而且，如果redis还启用了后台线程，此时，主线程、子进程和后台线程都会竞争cpu资源。由于云主机只有2核cpu，这就会影响到主线程处理请求的速度。\n\n本节问题 2 ：写时复制的底层实现机制？？\n\n写时复制的效果：bgsave子进程相当于复制了原始数据，而主线程仍然可以修改原来的数据。\n\n对redis来说，主线程fork出bgsave子进程后，bgsave子进程实际是复制了主线程的页表。这些页表中，就保存了在执行bgsave命令时，主线程的所有数据块在内存中的物理地址。这样一来，bgsave子进程生成rdb时，就可以根据页表读取这些数据，再写入磁盘中。如果此时，主线程接收到了新写或修改操作，那么，主线程会使用写时复制机制。具体来说，写时复制就是指，主线程在有写操作时，才会把这个新写或修改后的数据写入到一个新的物理地址中，并修改自己的页表映射。\n\n我来借助下图中的例子，具体展示一下写时复制的底层机制。\n\nbgsave子进程复制主线程的页表以后，假如主线程需要修改虚页7里的数据，那么，主线程就需要新分配一个物理页（假设是物理页53），然后把修改后的虚页7里的数据写到物理页53上，而虚页7里原来的数据仍然保存在物理页33上。这个时候，虚页7到物理页33的映射关系，仍然保留在bgsave子进程中。所以，bgsave子进程可以无误地把虚页7的原始数据写入rdb文件。",charsets:{cjk:!0},lastUpdated:"2023/03/27, 09:21:08",lastUpdatedTimestamp:1679908868e3},{title:"主从复制与哨兵机制",frontmatter:{title:"主从复制与哨兵机制",date:"2023-03-25T22:21:29.000Z",permalink:"/pages/348567/",categories:["中间件","Redis","专栏：Redis 核心技术与实战"],tags:[null]},regularPath:"/%E4%B8%AD%E9%97%B4%E4%BB%B6/05.Redis/05.%E4%B8%93%E6%A0%8F%EF%BC%9ARedis%20%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/06.%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E4%B8%8E%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6.html",relativePath:"中间件/05.Redis/05.专栏：Redis 核心技术与实战/06.主从复制与哨兵机制.md",key:"v-2778bd58",path:"/pages/348567/",headers:[{level:2,title:"1. 数据同步：主从库如何实现数据一致？",slug:"_1-数据同步-主从库如何实现数据一致",normalizedTitle:"1. 数据同步：主从库如何实现数据一致？",charIndex:598},{level:3,title:"1.1 主从库间如何进行第一次同步？",slug:"_1-1-主从库间如何进行第一次同步",normalizedTitle:"1.1 主从库间如何进行第一次同步？",charIndex:706},{level:3,title:"1.2 主从级联模式分担全量复制时的主库压力",slug:"_1-2-主从级联模式分担全量复制时的主库压力",normalizedTitle:"1.2 主从级联模式分担全量复制时的主库压力",charIndex:1921},{level:3,title:"1.3 主从库间网络断了怎么办？",slug:"_1-3-主从库间网络断了怎么办",normalizedTitle:"1.3 主从库间网络断了怎么办？",charIndex:2620},{level:3,title:"1.4 小结",slug:"_1-4-小结",normalizedTitle:"1.4 小结",charIndex:4261},{level:2,title:"2. 哨兵机制：主库挂了，如何不间断服务？",slug:"_2-哨兵机制-主库挂了-如何不间断服务",normalizedTitle:"2. 哨兵机制：主库挂了，如何不间断服务？",charIndex:5416},{level:3,title:"2.1 哨兵机制的基本流程",slug:"_2-1-哨兵机制的基本流程",normalizedTitle:"2.1 哨兵机制的基本流程",charIndex:5754},{level:3,title:"2.2 主观下线和客观下线",slug:"_2-2-主观下线和客观下线",normalizedTitle:"2.2 主观下线和客观下线",charIndex:6396},{level:3,title:"2.3 如何选定新主库？",slug:"_2-3-如何选定新主库",normalizedTitle:"2.3 如何选定新主库？",charIndex:7260},{level:4,title:"2.3.1 筛选",slug:"_2-3-1-筛选",normalizedTitle:"2.3.1 筛选",charIndex:7416},{level:4,title:"2.3.2 打分",slug:"_2-3-2-打分",normalizedTitle:"2.3.2 打分",charIndex:7775},{level:3,title:"2.4 小结",slug:"_2-4-小结",normalizedTitle:"2.4 小结",charIndex:8502},{level:2,title:"3. 哨兵集群：哨兵挂了，主从库还能切换吗？",slug:"_3-哨兵集群-哨兵挂了-主从库还能切换吗",normalizedTitle:"3. 哨兵集群：哨兵挂了，主从库还能切换吗？",charIndex:9170},{level:3,title:"3.1 基于 pub/sub 机制的哨兵集群组成",slug:"_3-1-基于-pub-sub-机制的哨兵集群组成",normalizedTitle:"3.1 基于 pub/sub 机制的哨兵集群组成",charIndex:9526},{level:3,title:"3.2 基于 pub/sub 机制的客户端事件通知",slug:"_3-2-基于-pub-sub-机制的客户端事件通知",normalizedTitle:"3.2 基于 pub/sub 机制的客户端事件通知",charIndex:10528},{level:3,title:"3.3 由哪个哨兵执行主从切换？",slug:"_3-3-由哪个哨兵执行主从切换",normalizedTitle:"3.3 由哪个哨兵执行主从切换？",charIndex:11321},{level:3,title:"3.4 小结",slug:"_3-4-小结",normalizedTitle:"3.4 小结",charIndex:12208}],headersStr:"1. 数据同步：主从库如何实现数据一致？ 1.1 主从库间如何进行第一次同步？ 1.2 主从级联模式分担全量复制时的主库压力 1.3 主从库间网络断了怎么办？ 1.4 小结 2. 哨兵机制：主库挂了，如何不间断服务？ 2.1 哨兵机制的基本流程 2.2 主观下线和客观下线 2.3 如何选定新主库？ 2.3.1 筛选 2.3.2 打分 2.4 小结 3. 哨兵集群：哨兵挂了，主从库还能切换吗？ 3.1 基于 pub/sub 机制的哨兵集群组成 3.2 基于 pub/sub 机制的客户端事件通知 3.3 由哪个哨兵执行主从切换？ 3.4 小结",content:"> 参考：\n> \n>  * 06 数据同步：主从库如何实现数据一致？| 极客时间(opens new window)\n>  * 07 哨兵机制：主库挂了，如何不间断服务？| 极客时间(opens new window)\n>  * 08 哨兵集群：哨兵挂了，主从库还能切换吗？| 极客时间\n\n我们使用 AOF 和 RDB，保证尽量少丢失数据，提升可靠性。但依然存在不可用问题。\n\n假设我们的 Redis 只有一个实例，那么当这个实例宕机，那就无法继续提供服务了。我们总说 Redis 具有高可靠性，其实有两层含义：\n\n * 一是数据尽量少丢失。\n * 二是服务尽量少中断。\n\nAOF 和 RDB 保证了前者，而对于后者，Redis 的做法就是增加副本冗余量，这样当一个实例出现故障后，其他实例可以继续提供服务。\n\nRedis 使用了主从复制的模式来做数据复制，主从库之间采用的是“读写分离”的方式：\n\n * 读操作：主库、从库都可以接收；\n * 写操作：首先到主库执行，然后，主库将写操作同步给从库。\n\n主从复制的模式就面临 DDIA 数据复制 中所讨论的一系列问题。下面我们对 Redis 在该模式上的实践进行讨论。\n\n主从库同步是如何完成的呢？主库数据是一次性传给从库，还是分批同步？要是主从库间的网络断连了，数据还能保持一致吗？下面聊聊主从库同步的原理，以及应对网络断连风险的方案。\n\n\n# 1. 数据同步：主从库如何实现数据一致？\n\n这一大节主要讨论主从库同步的原理，以及应对网络断连风险的方案。\n\n首先看一下主从库间的第一次同步是如何进行的，这也是 Redis 实例建立主从库模式后的规定动作。\n\n\n# 1.1 主从库间如何进行第一次同步？\n\n当我们启动多个 Redis 实例的时候，它们相互之间就可以通过 replicaof（Redis 5.0 之前使用 slaveof）命令形成主库和从库的关系，之后会按照三个阶段完成数据的第一次同步。\n\n例如，现在有实例1（ip：172.16.19.3）和实例2（ip：172.16.19.5），我们在实例2上执行以下这个命令后，实例2就变成了实例1的从库，并从实例1上复制数据：\n\nreplicaof  172.16.19.3  6379\n\n\n1\n\n\n接下来，我们就要学习主从库间数据第一次同步的三个阶段了：\n\n第一阶段是主从库间建立连接、协商同步的过程，主要是为全量复制做准备。在这一步，从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复后，主从库间就可以开始同步了。\n\n具体来说，从库给主库发送 psync 命令，表示要进行数据同步，主库根据这个命令的参数来启动复制。psync命令包含了主库的 runID和复制进度 offset 两个参数：\n\n * runID：是每个 Redis 实例启动时都会自动生成的一个随机 ID，用来唯一标记这个实例。当从库和主库第一次复制时，因为不知道主库的 runID，所以将runID设为“?”。\n * offset：此时设为 -1，表示第一次复制。\n\n主库收到 psync 命令后，会用 FULLRESYNC 响应命令带上两个参数：主库 runID 和主库目前的复制进度 offset，返回给从库。从库收到响应后，会记录下这两个参数。\n\n这里有个地方需要注意，FULLRESYNC 响应表示第一次复制采用的全量复制，也就是说，主库会把当前所有的数据都复制给从库。\n\n在第二阶段，主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载。这个过程依赖于内存快照生成的 RDB 文件。\n\n具体来说，主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。从库接收到 RDB 文件后，会先清空当前数据库，然后加载 RDB 文件。这是因为从库在通过 replicaof 命令开始和主库同步前，可能保存了其他数据。为了避免之前数据的影响，从库需要先把当前数据库清空。\n\n在主库将数据同步给从库的过程中，主库不会被阻塞，仍然可以正常接收请求。否则，Redis 的服务就被中断了。但是，这些请求中的写操作并没有记录到刚刚生成的 RDB 文件中。为了保证主从库的数据一致性，主库会在内存中用专门的 replication buffer，记录 RDB 文件生成后收到的所有写操作。\n\n最后，也就是第三阶段，主库会把第二阶段执行过程中新收到的写命令，再发送给从库。具体的操作是，当主库完成 RDB 文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再重新执行这些操作。这样一来，主从库就实现同步了。\n\n\n# 1.2 主从级联模式分担全量复制时的主库压力\n\n在主从同步时，全量复制的阶段需要主库完成两个耗时的操作：生成 RDB 和传输 RDB。\n\n若从库数量很多且都需要进行全量复制，会让主库忙于 fork 子进程生成 RDB，导致主库响应请求速度变慢。同时传输 RDB 也需要占用主库的带宽。那么，有没有好的解决方法来分担主库压力呢？这就是“主-从-从”模式。\n\n刚刚介绍的主从模式中，所有的从库都是从主库同步而来的，现在我们可以通过“主-从-从”的模式将主库生成的 RDB 和传输 RDB 的压力以级联的方式分散到从库上。\n\n简单来说，我们在部署主从集群的时候，可以手动选择一个从库（比如选择内存资源配置较高的从库），用于级联其他的从库。然后，我们可以再选择一些从库（例如三分之一的从库），在这些从库上执行如下命令，让它们和刚才所选的从库，建立起主从关系：\n\nreplicaof  所选从库的IP 6379\n\n\n1\n\n\n这样一来，这些从库就会知道，在进行同步时，不用再和主库进行交互了，只要和级联的从库进行写操作同步就行了，这就可以减轻主库上的压力，如下图所示：\n\n以上就是“主-从-从”模式的同步。一旦主从库完成了全量复制，它们之间就会一直维护一个网络连接，主库会通过这个连接将后续陆续收到的命令操作再同步给从库，这个过程也称为基于长连接的命令传播，可以避免频繁建立连接的开销。\n\n这个数据同步的过程存在一个风险点：网络断连或阻塞。如果网络断连，主从库之间就无法进行命令传播了，从库的数据自然也就没办法和主库保持一致了，客户端就可能从从库读到旧数据。接下来，我们就来聊聊网络断连后的解决办法.\n\n\n# 1.3 主从库间网络断了怎么办？\n\n在 Redis 2.8 之前，如果主从库在命令传播时出现了网络闪断，那么，从库就会和主库重新进行一次全量复制，开销非常大。\n\n从 Redis 2.8 开始，网络断了之后，主从库会采用增量复制的方式继续同步。也就是只会把网络断连期间主库收到的命令，同步给从库。\n\n那么，增量复制时，主从库之间具体是怎么保持同步的呢？这里的奥妙就在于 repl_backlog_buffer 这个缓冲区。我们先来看下它是如何用于增量命令的同步的。\n\n当主从库断连后，主库会把断连期间收到的写操作命令，写入 replication buffer ，同时也会把这些操作命令也写入 repl_backlog_buffer 这个缓冲区。repl_backlog_buffer 是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己已经读到的位置。\n\n刚开始的时候，主库和从库的写读位置在一起，这算是它们的起始位置。随着主库不断接收新的写操作，它在缓冲区中的写位置会逐步偏离起始位置，我们通常用偏移量来衡量这个偏移距离的大小，对主库来说，对应的偏移量就是 master_repl_offset。主库接收的新写操作越多，这个值就会越大。同样，从库在复制完写操作命令后，它在缓冲区中的读位置也开始逐步偏移刚才的起始位置，此时，从库已复制的偏移量 slave_repl_offset 也在不断增加。正常情况下，这两个偏移量基本相等。\n\n主从库的连接恢复之后，从库首先会给主库发送 psync 命令，并把自己当前的 slave_repl_offset 发给主库，主库会判断自己的 master_repl_offset 和 slave_repl_offset 之间的差距。在网络断连阶段，主库可能会收到新的写操作命令，所以，一般来说，master_repl_offset 会大于 slave_repl_offset。此时，主库只用把 master_repl_offset 和 slave_repl_offset 之间的命令操作同步给从库就行。\n\n就像刚刚示意图的中间部分，主库和从库之间相差了 put d e 和 put d f 两个操作，在增量复制时，主库只需要把它们同步给从库就行了。\n\n说到这里，我们再借助一张图，回顾下增量复制的流程：\n\n不过由于 repl_backlog_buffer 是一个环形缓冲区，所以在缓冲区写满后，主库会继续写入，此时，就会覆盖掉之前写入的操作。如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致。因此，我们要想办法避免这一情况，一般而言，我们可以调整 repl_backlog_size 这个参数。这个参数和所需的缓冲空间大小有关：缓冲空间大小 = 主库写入命令速度 * 操作大小 - 主从库间网络传输命令速度 * 操作大小。在实际应用中，考虑到可能存在一些突发的请求压力，我们通常需要把这个缓冲空间扩大一倍，即 repl_backlog_size = 缓冲空间大小 * 2，这也就是 repl_backlog_size 的最终值。\n\n> 举个例子，如果主库每秒写入 2000 个操作，每个操作的大小为 2KB，网络每秒能传输 1000 个操作，那么，有 1000 个操作需要缓冲起来，这就至少需要 2MB 的缓冲空间。否则，新写的命令就会覆盖掉旧操作了。为了应对可能的突发压力，我们最终把 repl_backlog_size 设为 4MB。\n\n这样一来，增量复制时主从库的数据不一致风险就降低了。不过，如果并发请求量非常大，连两倍的缓冲空间都存不下新操作请求的话，此时，主从库数据仍然可能不一致。针对这种情况：\n\n * 一方面，根据服务器的资源继续适当增加 repl_backlog_size 值。\n * 一方面，可以考虑使用切片集群来分担单个主库的请求压力。（后面会讲）\n\n\n# 1.4 小结\n\n这一节主要讲了 Redis 主从同步的三种模式：\n\n 1. 全量复制：第一次同步不可避免，耗时。为减小主库的同步压力，引入了“主-从-从”的级联模式。\n    \n    💡 小建议: 一个Redis实例的数据库不要太大，一个实例大小在几GB级别比较合适，这样可以减少RDB文件生成、传输和重新加载的开销。\n\n 2. 长连接复制：是主从库正常运行后的常规同步阶段，主从之间通过命令传播实现同步。\n\n 3. 增量复制：发生网络断连后，就需要增量复制来保证数据的同步。\n    \n    通过调大 repl_backlog_size 这个参数，可以减少从库在网络断连时全量复制的风险。\n\n不过，主从模式面临主库故障的潜在风险，下面将聊聊主库故障后，保证服务可靠性的解决方案。\n\n----------------------------------------\n\n本节问题 1：AOF记录的操作命令更全，相比于RDB丢失的数据更少。为什么主从库间的复制不使用 AOF？\n\n有两个原因：\n\n 1. RDB 文件是二进制文件，无论是要把 RDB 写入磁盘，还是要通过网络传输 RDB，IO 效率都比记录和传输 AOF 的高。\n 2. 在从库端进行恢复时，用 RDB 的恢复效率要高于用 AOF。\n\n本节问题 2：replication buffer 和 repl_backlog_buffer 的区别？\n\n总的来说，replication buffer 是主从库在进行全量复制时，主库上用于和从库连接的客户端的 buffer，而 repl_backlog_buffer 是为了支持从库增量复制，主库上用于持续保存写操作的一块专用 buffer。\n\nRedis主从库在进行复制时，当主库要把全量复制期间的写操作命令发给从库时，主库的操作：\n\n * 先创建一个客户端，用来连接从库\n * 通过这个客户端，把写操作命令发给从库\n\n在内存中，主库上的客户端就会对应一个 buffer，这个 buffer 就被称为 replication buffer。Redis通过 client_buffer 配置项来控制这个 buffer 的大小。主库会给每个从库建立一个客户端，所以 replication buffer 不是共享的，而是每个从库都有一个对应的客户端。\n\nrepl_backlog_buffer 是一块专用 buffer，在 Redis 服务器启动后，开始一直接收写操作命令，所以 repl_backlog_buffer 是所有从库共享的。主库和从库会各自记录自己的复制进度，所以，不同的从库在进行恢复时，会把自己的复制进度（slave_repl_offset）发给主库，主库就可以和它独立同步。\n\n\n# 2. 哨兵机制：主库挂了，如何不间断服务？\n\n上节学习了主从库的集群模式，在这个模式下，如果从库发生故障了，客户端可以继续向主库或其他从库发送请求，但是如果主库发生故障了，从库就没有主库可以进行数据复制了。如果请求是只读的话还好，但如果有写请求，那么此时就没有实例可以完成这个操作了。这种情况是不可接受的。\n\n所以，如果主库挂了，我们就需要运行一个新主库，比如说把一个从库切换为主库，但这就涉及到三个问题：\n\n 1. 主库真的挂了吗？\n 2. 该选择哪个从库作为主库？\n 3. 怎么把新主库的相关信息通知给从库和客户端呢？\n\n这就要提到哨兵机制了。在 Redis 主从集群中，哨兵机制是实现主从库自动切换的关键机制，它有效地解决了主从复制模式下故障转移的这三个问题。\n\n\n# 2.1 哨兵机制的基本流程\n\n哨兵其实就是一个运行在特殊模式下的 Redis 进程，主从库实例运行的同时，它也在运行。哨兵主要负责的就是三个任务：监控、选主（选择主库）和通知。\n\n * 监控是指哨兵进程在运行时，周期性地给所有的主从库发送 PING 命令，检测它们是否仍然在线运行。如果从库没有在规定时间内响应哨兵的PING命令，哨兵就会把它标记为“下线状态”；同样，如果主库也没有在规定时间内响应哨兵的PING命令，哨兵就会判定主库下线，然后开始自动切换主库的流程。\n * 自动切换主库的流程就是哨兵的选主的任务：主库挂了以后，哨兵就需要从很多个从库里，按照一定的规则选择一个从库实例，把它作为新的主库。这一步完成后，现在的集群里就有了新主库。\n * 然后，哨兵会执行最后一个任务：通知：哨兵把新主库的连接信息发给其他从库，让它们执行 replicaof 命令，和新主库建立连接，并进行数据复制。同时，哨兵会把新主库的连接信息通知给客户端，让它们把请求操作发到新主库上。\n\n在这三个任务中，通知任务相对来说比较简单，哨兵只需要把新主库信息发给从库和客户端，让它们和新主库建立连接就行，并不涉及决策的逻辑。但是，在监控和选主这两个任务中，哨兵需要做出两个决策：\n\n * 在监控任务中，哨兵需要判断主库是否处于下线状态；\n * 在选主任务中，哨兵也要决定选择哪个从库实例作为主库。\n\n接下来先说一下如何判断主库的下线状态。哨兵对主库的下线判断有“主观下线”和“客观下线”两种。\n\n\n# 2.2 主观下线和客观下线\n\n我先解释下什么是“主观下线”。\n\n哨兵进程会使用 PING 命令检测它自己和主、从库的网络连接情况，用来判断实例的状态。如果哨兵发现主库或从库对 PING 命令的响应超时了，那么，哨兵就会先把它标记为“主观下线”：\n\n * 如果检测的是从库，那么哨兵简单地把它标记为主观下线就行了，因为从库的下线影响一般不太大，集群的对外服务不会间断。\n * 但如果检测是主库，那么哨兵在标记为主观下线后，还需要开启主从切换。\n\n但存在哨兵误判主库的下线状态的问题，因为一旦开启主从切换，就会带来额外开销，因此需要特别注意避免误判的情况。误判就是说主库实际没有下线，但哨兵误以为它下线了，这通常发生在集群的网络压力较大的情况下。\n\n误判之后会产生什么开销？\n\n一旦哨兵判断主库下线了，就会开始选择新主库，并让从库和新主库进行数据同步，这个过程本身就会有开销，例如，哨兵要花时间选出新主库，从库也需要花时间和新主库同步。而在误判的情况下，主库本身根本就不需要进行切换的，所以这个过程的开销是没有价值的。\n\n那怎样减少误判呢？哨兵机制通常会由多台实例组成一个哨兵集群，让多个哨兵实例一起来判断，从而避免单个哨兵因网络问题而导致的误判。这样，只有当大多数的哨兵都认为主库已经主观下线了，那主库才被标记为客观下线。这个叫法表明主库下线成为一个客观事实了，判断的原则就是少数服从多数。这时会进一步出发哨兵进行主从切换的流程。\n\n上述标记为“主观下线”和“客观下线”的流程如下图所示：\n\n简单来说，“客观下线”的标准就是，当有 N 个哨兵实例时，最好要有 N/2 + 1 个实例判断主库为“主观下线”，才能最终判定主库为“客观下线”。这样一来，就可以减少误判的概率，也能避免误判带来的无谓的主从库切换。（当然，有多少个实例做出“主观下线”的判断才可以，可以由 Redis 管理员自行设定）\n\n到这里我们可以看到，借助于多个哨兵实例来共同判断主库是否处于下线状态。如果主库的确下线了，哨兵就要开始下一个决策过程：选主。\n\n\n# 2.3 如何选定新主库？\n\n哨兵选择新主库的过程可以称为“筛选+打分”：\n\n * 筛选：在多个从库中按照一定的筛选条件来去掉不符合条件的从库。\n * 打分：再按照一定的规则，给剩下的从库逐个打分，评选得分最高的从库为新主库。\n\n这个过程如下图所示：\n\n在刚刚那段话中，有两个“一定”，我们看看分别是什么：\n\n# 2.3.1 筛选\n\n我们在多个从库中选主的时候，除了要检查从库的当前在线状态，还要判断它之前的网络连接状态，从而选出网络情况最好的实例。如果从库总是和主库断连，而且断连次数超出了一定的阈值，我们就有理由相信，这个从库的网络状况并不是太好，就可以把这个从库筛掉了。\n\n具体怎么判断呢？你使用配置项 down-after-milliseconds * 10。其中，down-after-milliseconds 是我们认定主从库断连的最大连接超时时间。如果在 down-after-milliseconds 毫秒内，主从节点都没有通过网络联系上，我们就可以认为主从节点断连了。如果发生断连的次数超过了 10 次，就说明这个从库的网络状况不好，不适合作为新主库。\n\n由此就过滤掉了不合适做主库的从库，完成了筛选工作。\n\n# 2.3.2 打分\n\n接下来就要给剩余的从库打分了。我们可以分别按照三个规则依次进行三轮打分：\n\n 1. 从库优先级\n 2. 从库复制进度\n 3. 从库 ID 号\n\n只要在某一轮中，有从库得分最高，那么它就是主库了，选主过程到此结束。如果没有出现得分最高的从库，那么就继续进行下一轮。\n\n第一轮：优先级最高的从库得分高。\n\n用户可以通过 slave-priority 配置项，给不同的从库设置不同优先级。比如，你有两个从库，它们的内存大小不一样，你可以手动给内存大的实例设置一个高优先级。在选主时，哨兵会给优先级高的从库打高分，如果有一个从库优先级最高，那么它就是新主库了。如果从库的优先级都一样，那么哨兵开始第二轮打分。\n\n第二轮：和旧主库同步程度最接近的从库得分高。\n\n这个规则的依据是，如果选择和旧主库同步最接近的那个从库作为主库，那么，这个新主库上就有最新的数据。其实也就是哪个从库的 slave_repl_offset 最接近主库的 master_repl_offset 谁就得分高(在 repl_backlog_buffer 中的位置)。如下图所示：\n\n第三轮：ID号小的从库得分高。\n\n每个实例都会有一个ID，这个ID就类似于这里的从库的编号。目前，Redis 在选主库时，有一个默认的规定：在优先级和复制进度都相同的情况下，ID 号最小的从库得分最高，会被选为新主库。\n\n到这里，“选主”这个过程就完成了。我们在回顾一下这个流程：\n\n * 首先，哨兵会按照在线状态、网络状态，筛选过滤掉一部分不符合要求的从库；\n * 然后，依次按照优先级、复制进度、ID 号大小再对剩余的从库进行打分，只要有得分最高的从库出现，就把它选为新主库。\n\n\n# 2.4 小结\n\n哨兵机制是实现 Redis 不间断服务的重要保证，它自动完成了以下三个功能，并实现了主从切换：\n\n * 监控主库运行状态，并判断主库是否客观下线；\n * 在主库客观下线后，选取新主库；\n * 选出新主库后，通知从库和客户端。\n\n为了降低误判率，哨兵机制通常采用多实例部署，通过“少数服从多数”的原则，来判断主库是否客观下线。\n\n但哨兵集群同时也带来了问题：\n\n * 哨兵集群中有实例挂了，怎么办，会影响主库状态判断和选主吗？\n * 哨兵集群多数实例达成共识，判断出主库“客观下线”后，由哪个实例来执行主从切换呢？\n\n为了搞懂这些问题，需要进一步了解哨兵集群。\n\n----------------------------------------\n\n本节问题 1：在主从切换过程中，客户端能否正常地进行请求操作呢？\n\n主从集群一般是采用读写分离模式，当主库故障后，客户端仍然可以把读请求发送给从库，让从库服务。但是，对于写请求操作，客户端就无法执行了。\n\n本节问题 2：如果想要应用程序不感知服务的中断，还需要哨兵或客户端再做些什么吗？\n\n * 一方面，客户端需要能缓存应用发送的写请求。只要不是同步写操作（Redis 应用场景一般也没有同步写），写请求通常不会在应用程序的关键路径上，所以，客户端缓存写请求后，给应用程序返回一个确认就行。\n * 另一方面，主从切换完成后，客户端要能和新主库重新建立连接，哨兵需要提供订阅频道，让客户端能够订阅到新主库的信息。同时，客户端也需要能主动和哨兵通信，询问新主库的信息。\n\n\n# 3. 哨兵集群：哨兵挂了，主从库还能切换吗？\n\n上节讲的哨兵机制实现了主从切换，但如果有哨兵实例在运行时发生了故障，主从库还能正常切换吗？实际上，一旦多个实例组成了哨兵集群，即使有哨兵实例挂掉了，其他哨兵还能继续协作完成主从切换的工作，包括判定主库是不是处于下线状态、选择新主库，以及通知从库和客户端。\n\n如果你部署过哨兵集群的话就会知道，在配置哨兵的信息时，我们只需要用到下面的这个配置项，即设置主库的 IP和端口，并没有配置其他哨兵的连接信息：\n\nsentinel monitor <master-name> <ip> <redis-port> <quorum>\n\n\n1\n\n\n这些哨兵实例既然都不知道彼此的地址，又是怎么组成集群的呢？要弄明白这个问题，我们就需要学习一下哨兵集群的组成和运行机制了。\n\n\n# 3.1 基于 pub/sub 机制的哨兵集群组成\n\n哨兵实例之间可以相互发现，要归功于 Redis 提供的 pub/sub 机制，也就是发布/订阅机制。哨兵只要和主库建立起了连接，就可以在主库上发布消息了，比如说发布它自己的连接信息（IP和端口）。同时，它也可以从主库上订阅消息，获得其他哨兵发布的连接信息。当多个哨兵实例都在主库上做了发布和订阅操作后，它们之间就能知道彼此的 IP 地址和端口。\n\n除了哨兵实例，我们自己编写的应用程序也可以通过Redis进行消息的发布和订阅。所以，为了区分不同应用的消息，Redis 会以频道的形式，对这些消息进行分门别类的管理。所谓的频道，实际上就是消息的类别。当消息类别相同时，它们就属于同一个频道。反之，就属于不同的频道。只有订阅了同一个频道的应用，才能通过发布的消息进行信息交换。\n\n在主从集群中，主库上有一个名为 __sentinel__: hello 的频道，不同哨兵就是通过它来相互发现，实现互相通信的。如下图示例：\n\n借助于上图所示的 pub/sub 机制，哨兵集群就形成了，它们之间可以通过网络连接进行通信，并对主库是否下线的判断进行协商。哨兵除了彼此之间建立起连接形成集群外，还需要和从库建立连接。这是因为，在哨兵的监控任务中，它需要对主从库都进行心跳判断，而且在主从库切换完成后，它还需要通知从库，让它们和新主库进行同步。\n\n那么， 哨兵是如何知道从库的 IP 地址和端口的呢？如下图所示，这是由哨兵向主库发送 INFO 命令来完成的，然后主库会响应给哨兵一个 slave 列表。由此，哨兵就可以与从库建立连接了。\n\n你看，通过 pub/sub 机制，哨兵之间可以组成集群，同时，哨兵又通过 INFO 命令，获得了从库连接信息，也能和从库建立连接，并进行监控了。\n\n但是，哨兵不能只和主、从库连接。因为主从库切换后，客户端也需要知道新主库的连接信息，才能向新主库发送请求操作。所以，哨兵还需要完成把新主库的信息告诉客户端这个任务。而且，在实际使用哨兵时，我们有时会遇到这样的问题：如何在客户端通过监控了解哨兵进行主从切换的过程呢？比如说，主从切换进行到哪一步了？这其实就是要求，客户端能够获取到哨兵集群在监控、选主、切换这个过程中发生的各种事件。\n\n此时，我们仍然可以依赖 pub/sub 机制，来帮助我们完成哨兵和客户端间的信息同步。\n\n\n# 3.2 基于 pub/sub 机制的客户端事件通知\n\n从本质上说，哨兵就是一个运行在特定模式下的 Redis 实例，只不过它并不服务请求操作，只是完成监控、选主和通知的任务。所以，每个哨兵实例也提供 pub/sub 机制，客户端可以从哨兵订阅消息。哨兵提供的消息订阅频道有很多，不同频道包含了主从库切换过程中的不同关键事件。下面列出了一些重要的频道：\n\n知道了这些频道之后，你就可以让客户端从哨兵那里订阅消息了。具体的操作步骤是，客户端读取哨兵的配置文件后，可以获得哨兵的地址和端口，和哨兵建立网络连接。然后，我们可以在客户端执行订阅命令，来获取不同的事件消息。\n\n举个例子，你可以执行 SUBSCRIBE +odown 命令，来订阅“所有实例进入客观下线状态的事件”，也可以执行 PSUBSCRIBE * 来订阅所有的事件。\n\n当哨兵把新主库选择出来后，客户端就会看到下面的 switch-master 事件。这个事件表示主库已经切换了，新主库的 IP 址和端口信息已经有了。这个时候，客户端就可以用这里面的新主库地址和端口进行通信了：\n\nswitch-master <master name> <oldip> <oldport> <newip> <newport>\n\n\n1\n\n\n有了这些事件通知，客户端不仅可以在主从切换后得到新主库的连接信息，还可以监控到主从库切换过程中发生的各个重要事件。这样，客户端就可以知道主从切换进行到哪一步了，有助于了解切换进度。\n\n好了，有了 pub/sub 机制，哨兵和哨兵之间、哨兵和从库之间、哨兵和客户端之间就都能建立起连接了，再加上我们上节课介绍主库下线判断和选主依据，哨兵集群的监控、选主和通知三个任务就基本可以正常工作了。不过，我们还需要考虑一个问题：主库故障以后，哨兵集群有多个实例，那怎么确定由哪个哨兵来进行实际的主从切换呢？\n\n\n# 3.3 由哪个哨兵执行主从切换？\n\n确定由哪个哨兵执行主从切换的过程，和主库“客观下线”的判断过程类似，也是一个“投票仲裁”的过程。在具体了解这个过程前，我们再来看下，判断“客观下线”的仲裁过程。\n\n哨兵集群要判定主库“客观下线”，需要有一定数量的实例都认为该主库已经“主观下线”了。我在上节课向你介绍了判断“客观下线”的原则，接下来，我介绍下具体的判断过程：\n\n任何一个实例只要自身判断主库“主观下线”后，就会给其他实例发送 is-master-down-by-addr 命令。接着，其他实例会根据自己和主库的连接情况，做出 Y 或 N 的响应，Y 相当于赞成票，N 相当于反对票。如下图所示：\n\n一个哨兵获得了仲裁所需的赞成票数后，就可以标记主库为“客观下线”。这个所需的赞成票数是通过哨兵配置文件中的 quorum 配置项设定的。例如，现在有 5 个哨兵，quorum 配置的是 3，那么，一个哨兵需要3张赞成票，就可以标记主库为“客观下线”了。这3张赞成票包括哨兵自己的一张赞成票和另外两个哨兵的赞成票。\n\n此时，这个哨兵就可以再给其他哨兵发送命令，表明希望由自己来执行主从切换，并让所有其他哨兵进行投票。这个投票过程称为“Leader 选举”。因为最终执行主从切换的哨兵称为 Leader，投票过程就是确定 Leader。在投票过程中，任何一个想成为 Leader 的哨兵，要满足两个条件：\n\n 1. 拿到半数以上的赞成票；\n 2. 拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。以3个哨兵为例，假设此时的 quorum 设置为 2，那么，任何一个想成为 Leader 的哨兵只要拿到2张赞成票，就可以了。\n\n下图就展示了 3 个哨兵、quorum=2 的选举过程：\n\n需要注意的是，如果哨兵集群只有 2 个实例，此时，一个哨兵要想成为 Leader，必须获得 2 票，而不是 1 票。所以，如果有个哨兵挂掉了，那么，此时的集群是无法进行主从库切换的。因此，通常我们至少会配置 3 个哨兵实例。这一点很重要，你在实际应用时可不能忽略了。\n\n\n# 3.4 小结\n\n通常，我们在解决一个系统问题的时候，会引入一个新机制，或者设计一层新功能，就像我们在这两节课学习的内容：为了实现主从切换，我们引入了哨兵；为了避免单个哨兵故障后无法进行主从切换，以及为了减少误判率，又引入了哨兵集群；哨兵集群又需要有一些机制来支撑它的正常运行。\n\n这一节主要讲了哨兵集群的一些关键机制：\n\n * 基于 pub/sub 机制的哨兵集群组成过程；\n * 基于 INFO 命令的从库列表，这可以帮助哨兵和从库建立连接；\n * 基于哨兵自身的 pub/sub 功能，这实现了客户端和哨兵之间的事件通知。\n\n对于主从切换，需要哨兵集群在判断了主库“客观下线”后，经过投票仲裁，选举一个 Leader 出来，由它负责实际的主从切换，即由它来完成新主库的选择以及通知从库与客户端。\n\n> 最后，我想再给你分享一个经验：要保证所有哨兵实例的配置是一致的，尤其是主观下线的判断值 down-after-milliseconds。我们曾经就踩过一个“坑”。当时，在我们的项目中，因为这个值在不同的哨兵实例上配置不一致，导致哨兵集群一直没有对有故障的主库形成共识，也就没有及时切换主库，最终的结果就是集群服务不稳定。所以，你一定不要忽略这条看似简单的经验。\n\n----------------------------------------\n\n本节问题 1：有一个Redis集群，是“一主四从”，配置了 5 个哨兵实例的集群，quorum 值设为 2。在运行过程中，如果有 3 个哨兵实例都发生故障了，此时，Redis 主库如果有故障，还能正确地判断主库“客观下线”吗？如果可以的话，还能进行主从库自动切换吗？\n\n因为判定主库“客观下线”的依据是，认为主库“主观下线”的哨兵个数要大于等于quorum值，现在还剩2个哨兵实例，个数正好等于quorum值，所以还能正常判断主库是否处于“客观下线”状态。如果一个哨兵想要执行主从切换，就要获到半数以上的哨兵投票赞成，也就是至少需要3个哨兵投票赞成。但是，现在只有2个哨兵了，所以就无法进行主从切换了。\n\n本节问题 2：哨兵实例是不是越多越好呢？如果同时调大 down-after-milliseconds 值，对减少误判是不是也有好处？\n\n哨兵实例越多，误判率会越低，但是在判定主库下线和选举Leader时，实例需要拿到的赞成票数也越多，等待所有哨兵投完票的时间可能也会相应增加，主从库切换的时间也会变长，客户端容易堆积较多的请求操作，可能会导致客户端请求溢出，从而造成请求丢失。如果业务层对Redis的操作有响应时间要求，就可能会因为新主库一直没有选定，新操作无法执行而发生超时报警。\n\n调大down-after-milliseconds后，可能会导致这样的情况：主库实际已经发生故障了，但是哨兵过了很长时间才判断出来，这就会影响到Redis对业务的可用性。",normalizedContent:"> 参考：\n> \n>  * 06 数据同步：主从库如何实现数据一致？| 极客时间(opens new window)\n>  * 07 哨兵机制：主库挂了，如何不间断服务？| 极客时间(opens new window)\n>  * 08 哨兵集群：哨兵挂了，主从库还能切换吗？| 极客时间\n\n我们使用 aof 和 rdb，保证尽量少丢失数据，提升可靠性。但依然存在不可用问题。\n\n假设我们的 redis 只有一个实例，那么当这个实例宕机，那就无法继续提供服务了。我们总说 redis 具有高可靠性，其实有两层含义：\n\n * 一是数据尽量少丢失。\n * 二是服务尽量少中断。\n\naof 和 rdb 保证了前者，而对于后者，redis 的做法就是增加副本冗余量，这样当一个实例出现故障后，其他实例可以继续提供服务。\n\nredis 使用了主从复制的模式来做数据复制，主从库之间采用的是“读写分离”的方式：\n\n * 读操作：主库、从库都可以接收；\n * 写操作：首先到主库执行，然后，主库将写操作同步给从库。\n\n主从复制的模式就面临 ddia 数据复制 中所讨论的一系列问题。下面我们对 redis 在该模式上的实践进行讨论。\n\n主从库同步是如何完成的呢？主库数据是一次性传给从库，还是分批同步？要是主从库间的网络断连了，数据还能保持一致吗？下面聊聊主从库同步的原理，以及应对网络断连风险的方案。\n\n\n# 1. 数据同步：主从库如何实现数据一致？\n\n这一大节主要讨论主从库同步的原理，以及应对网络断连风险的方案。\n\n首先看一下主从库间的第一次同步是如何进行的，这也是 redis 实例建立主从库模式后的规定动作。\n\n\n# 1.1 主从库间如何进行第一次同步？\n\n当我们启动多个 redis 实例的时候，它们相互之间就可以通过 replicaof（redis 5.0 之前使用 slaveof）命令形成主库和从库的关系，之后会按照三个阶段完成数据的第一次同步。\n\n例如，现在有实例1（ip：172.16.19.3）和实例2（ip：172.16.19.5），我们在实例2上执行以下这个命令后，实例2就变成了实例1的从库，并从实例1上复制数据：\n\nreplicaof  172.16.19.3  6379\n\n\n1\n\n\n接下来，我们就要学习主从库间数据第一次同步的三个阶段了：\n\n第一阶段是主从库间建立连接、协商同步的过程，主要是为全量复制做准备。在这一步，从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复后，主从库间就可以开始同步了。\n\n具体来说，从库给主库发送 psync 命令，表示要进行数据同步，主库根据这个命令的参数来启动复制。psync命令包含了主库的 runid和复制进度 offset 两个参数：\n\n * runid：是每个 redis 实例启动时都会自动生成的一个随机 id，用来唯一标记这个实例。当从库和主库第一次复制时，因为不知道主库的 runid，所以将runid设为“?”。\n * offset：此时设为 -1，表示第一次复制。\n\n主库收到 psync 命令后，会用 fullresync 响应命令带上两个参数：主库 runid 和主库目前的复制进度 offset，返回给从库。从库收到响应后，会记录下这两个参数。\n\n这里有个地方需要注意，fullresync 响应表示第一次复制采用的全量复制，也就是说，主库会把当前所有的数据都复制给从库。\n\n在第二阶段，主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载。这个过程依赖于内存快照生成的 rdb 文件。\n\n具体来说，主库执行 bgsave 命令，生成 rdb 文件，接着将文件发给从库。从库接收到 rdb 文件后，会先清空当前数据库，然后加载 rdb 文件。这是因为从库在通过 replicaof 命令开始和主库同步前，可能保存了其他数据。为了避免之前数据的影响，从库需要先把当前数据库清空。\n\n在主库将数据同步给从库的过程中，主库不会被阻塞，仍然可以正常接收请求。否则，redis 的服务就被中断了。但是，这些请求中的写操作并没有记录到刚刚生成的 rdb 文件中。为了保证主从库的数据一致性，主库会在内存中用专门的 replication buffer，记录 rdb 文件生成后收到的所有写操作。\n\n最后，也就是第三阶段，主库会把第二阶段执行过程中新收到的写命令，再发送给从库。具体的操作是，当主库完成 rdb 文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再重新执行这些操作。这样一来，主从库就实现同步了。\n\n\n# 1.2 主从级联模式分担全量复制时的主库压力\n\n在主从同步时，全量复制的阶段需要主库完成两个耗时的操作：生成 rdb 和传输 rdb。\n\n若从库数量很多且都需要进行全量复制，会让主库忙于 fork 子进程生成 rdb，导致主库响应请求速度变慢。同时传输 rdb 也需要占用主库的带宽。那么，有没有好的解决方法来分担主库压力呢？这就是“主-从-从”模式。\n\n刚刚介绍的主从模式中，所有的从库都是从主库同步而来的，现在我们可以通过“主-从-从”的模式将主库生成的 rdb 和传输 rdb 的压力以级联的方式分散到从库上。\n\n简单来说，我们在部署主从集群的时候，可以手动选择一个从库（比如选择内存资源配置较高的从库），用于级联其他的从库。然后，我们可以再选择一些从库（例如三分之一的从库），在这些从库上执行如下命令，让它们和刚才所选的从库，建立起主从关系：\n\nreplicaof  所选从库的ip 6379\n\n\n1\n\n\n这样一来，这些从库就会知道，在进行同步时，不用再和主库进行交互了，只要和级联的从库进行写操作同步就行了，这就可以减轻主库上的压力，如下图所示：\n\n以上就是“主-从-从”模式的同步。一旦主从库完成了全量复制，它们之间就会一直维护一个网络连接，主库会通过这个连接将后续陆续收到的命令操作再同步给从库，这个过程也称为基于长连接的命令传播，可以避免频繁建立连接的开销。\n\n这个数据同步的过程存在一个风险点：网络断连或阻塞。如果网络断连，主从库之间就无法进行命令传播了，从库的数据自然也就没办法和主库保持一致了，客户端就可能从从库读到旧数据。接下来，我们就来聊聊网络断连后的解决办法.\n\n\n# 1.3 主从库间网络断了怎么办？\n\n在 redis 2.8 之前，如果主从库在命令传播时出现了网络闪断，那么，从库就会和主库重新进行一次全量复制，开销非常大。\n\n从 redis 2.8 开始，网络断了之后，主从库会采用增量复制的方式继续同步。也就是只会把网络断连期间主库收到的命令，同步给从库。\n\n那么，增量复制时，主从库之间具体是怎么保持同步的呢？这里的奥妙就在于 repl_backlog_buffer 这个缓冲区。我们先来看下它是如何用于增量命令的同步的。\n\n当主从库断连后，主库会把断连期间收到的写操作命令，写入 replication buffer ，同时也会把这些操作命令也写入 repl_backlog_buffer 这个缓冲区。repl_backlog_buffer 是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己已经读到的位置。\n\n刚开始的时候，主库和从库的写读位置在一起，这算是它们的起始位置。随着主库不断接收新的写操作，它在缓冲区中的写位置会逐步偏离起始位置，我们通常用偏移量来衡量这个偏移距离的大小，对主库来说，对应的偏移量就是 master_repl_offset。主库接收的新写操作越多，这个值就会越大。同样，从库在复制完写操作命令后，它在缓冲区中的读位置也开始逐步偏移刚才的起始位置，此时，从库已复制的偏移量 slave_repl_offset 也在不断增加。正常情况下，这两个偏移量基本相等。\n\n主从库的连接恢复之后，从库首先会给主库发送 psync 命令，并把自己当前的 slave_repl_offset 发给主库，主库会判断自己的 master_repl_offset 和 slave_repl_offset 之间的差距。在网络断连阶段，主库可能会收到新的写操作命令，所以，一般来说，master_repl_offset 会大于 slave_repl_offset。此时，主库只用把 master_repl_offset 和 slave_repl_offset 之间的命令操作同步给从库就行。\n\n就像刚刚示意图的中间部分，主库和从库之间相差了 put d e 和 put d f 两个操作，在增量复制时，主库只需要把它们同步给从库就行了。\n\n说到这里，我们再借助一张图，回顾下增量复制的流程：\n\n不过由于 repl_backlog_buffer 是一个环形缓冲区，所以在缓冲区写满后，主库会继续写入，此时，就会覆盖掉之前写入的操作。如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致。因此，我们要想办法避免这一情况，一般而言，我们可以调整 repl_backlog_size 这个参数。这个参数和所需的缓冲空间大小有关：缓冲空间大小 = 主库写入命令速度 * 操作大小 - 主从库间网络传输命令速度 * 操作大小。在实际应用中，考虑到可能存在一些突发的请求压力，我们通常需要把这个缓冲空间扩大一倍，即 repl_backlog_size = 缓冲空间大小 * 2，这也就是 repl_backlog_size 的最终值。\n\n> 举个例子，如果主库每秒写入 2000 个操作，每个操作的大小为 2kb，网络每秒能传输 1000 个操作，那么，有 1000 个操作需要缓冲起来，这就至少需要 2mb 的缓冲空间。否则，新写的命令就会覆盖掉旧操作了。为了应对可能的突发压力，我们最终把 repl_backlog_size 设为 4mb。\n\n这样一来，增量复制时主从库的数据不一致风险就降低了。不过，如果并发请求量非常大，连两倍的缓冲空间都存不下新操作请求的话，此时，主从库数据仍然可能不一致。针对这种情况：\n\n * 一方面，根据服务器的资源继续适当增加 repl_backlog_size 值。\n * 一方面，可以考虑使用切片集群来分担单个主库的请求压力。（后面会讲）\n\n\n# 1.4 小结\n\n这一节主要讲了 redis 主从同步的三种模式：\n\n 1. 全量复制：第一次同步不可避免，耗时。为减小主库的同步压力，引入了“主-从-从”的级联模式。\n    \n    💡 小建议: 一个redis实例的数据库不要太大，一个实例大小在几gb级别比较合适，这样可以减少rdb文件生成、传输和重新加载的开销。\n\n 2. 长连接复制：是主从库正常运行后的常规同步阶段，主从之间通过命令传播实现同步。\n\n 3. 增量复制：发生网络断连后，就需要增量复制来保证数据的同步。\n    \n    通过调大 repl_backlog_size 这个参数，可以减少从库在网络断连时全量复制的风险。\n\n不过，主从模式面临主库故障的潜在风险，下面将聊聊主库故障后，保证服务可靠性的解决方案。\n\n----------------------------------------\n\n本节问题 1：aof记录的操作命令更全，相比于rdb丢失的数据更少。为什么主从库间的复制不使用 aof？\n\n有两个原因：\n\n 1. rdb 文件是二进制文件，无论是要把 rdb 写入磁盘，还是要通过网络传输 rdb，io 效率都比记录和传输 aof 的高。\n 2. 在从库端进行恢复时，用 rdb 的恢复效率要高于用 aof。\n\n本节问题 2：replication buffer 和 repl_backlog_buffer 的区别？\n\n总的来说，replication buffer 是主从库在进行全量复制时，主库上用于和从库连接的客户端的 buffer，而 repl_backlog_buffer 是为了支持从库增量复制，主库上用于持续保存写操作的一块专用 buffer。\n\nredis主从库在进行复制时，当主库要把全量复制期间的写操作命令发给从库时，主库的操作：\n\n * 先创建一个客户端，用来连接从库\n * 通过这个客户端，把写操作命令发给从库\n\n在内存中，主库上的客户端就会对应一个 buffer，这个 buffer 就被称为 replication buffer。redis通过 client_buffer 配置项来控制这个 buffer 的大小。主库会给每个从库建立一个客户端，所以 replication buffer 不是共享的，而是每个从库都有一个对应的客户端。\n\nrepl_backlog_buffer 是一块专用 buffer，在 redis 服务器启动后，开始一直接收写操作命令，所以 repl_backlog_buffer 是所有从库共享的。主库和从库会各自记录自己的复制进度，所以，不同的从库在进行恢复时，会把自己的复制进度（slave_repl_offset）发给主库，主库就可以和它独立同步。\n\n\n# 2. 哨兵机制：主库挂了，如何不间断服务？\n\n上节学习了主从库的集群模式，在这个模式下，如果从库发生故障了，客户端可以继续向主库或其他从库发送请求，但是如果主库发生故障了，从库就没有主库可以进行数据复制了。如果请求是只读的话还好，但如果有写请求，那么此时就没有实例可以完成这个操作了。这种情况是不可接受的。\n\n所以，如果主库挂了，我们就需要运行一个新主库，比如说把一个从库切换为主库，但这就涉及到三个问题：\n\n 1. 主库真的挂了吗？\n 2. 该选择哪个从库作为主库？\n 3. 怎么把新主库的相关信息通知给从库和客户端呢？\n\n这就要提到哨兵机制了。在 redis 主从集群中，哨兵机制是实现主从库自动切换的关键机制，它有效地解决了主从复制模式下故障转移的这三个问题。\n\n\n# 2.1 哨兵机制的基本流程\n\n哨兵其实就是一个运行在特殊模式下的 redis 进程，主从库实例运行的同时，它也在运行。哨兵主要负责的就是三个任务：监控、选主（选择主库）和通知。\n\n * 监控是指哨兵进程在运行时，周期性地给所有的主从库发送 ping 命令，检测它们是否仍然在线运行。如果从库没有在规定时间内响应哨兵的ping命令，哨兵就会把它标记为“下线状态”；同样，如果主库也没有在规定时间内响应哨兵的ping命令，哨兵就会判定主库下线，然后开始自动切换主库的流程。\n * 自动切换主库的流程就是哨兵的选主的任务：主库挂了以后，哨兵就需要从很多个从库里，按照一定的规则选择一个从库实例，把它作为新的主库。这一步完成后，现在的集群里就有了新主库。\n * 然后，哨兵会执行最后一个任务：通知：哨兵把新主库的连接信息发给其他从库，让它们执行 replicaof 命令，和新主库建立连接，并进行数据复制。同时，哨兵会把新主库的连接信息通知给客户端，让它们把请求操作发到新主库上。\n\n在这三个任务中，通知任务相对来说比较简单，哨兵只需要把新主库信息发给从库和客户端，让它们和新主库建立连接就行，并不涉及决策的逻辑。但是，在监控和选主这两个任务中，哨兵需要做出两个决策：\n\n * 在监控任务中，哨兵需要判断主库是否处于下线状态；\n * 在选主任务中，哨兵也要决定选择哪个从库实例作为主库。\n\n接下来先说一下如何判断主库的下线状态。哨兵对主库的下线判断有“主观下线”和“客观下线”两种。\n\n\n# 2.2 主观下线和客观下线\n\n我先解释下什么是“主观下线”。\n\n哨兵进程会使用 ping 命令检测它自己和主、从库的网络连接情况，用来判断实例的状态。如果哨兵发现主库或从库对 ping 命令的响应超时了，那么，哨兵就会先把它标记为“主观下线”：\n\n * 如果检测的是从库，那么哨兵简单地把它标记为主观下线就行了，因为从库的下线影响一般不太大，集群的对外服务不会间断。\n * 但如果检测是主库，那么哨兵在标记为主观下线后，还需要开启主从切换。\n\n但存在哨兵误判主库的下线状态的问题，因为一旦开启主从切换，就会带来额外开销，因此需要特别注意避免误判的情况。误判就是说主库实际没有下线，但哨兵误以为它下线了，这通常发生在集群的网络压力较大的情况下。\n\n误判之后会产生什么开销？\n\n一旦哨兵判断主库下线了，就会开始选择新主库，并让从库和新主库进行数据同步，这个过程本身就会有开销，例如，哨兵要花时间选出新主库，从库也需要花时间和新主库同步。而在误判的情况下，主库本身根本就不需要进行切换的，所以这个过程的开销是没有价值的。\n\n那怎样减少误判呢？哨兵机制通常会由多台实例组成一个哨兵集群，让多个哨兵实例一起来判断，从而避免单个哨兵因网络问题而导致的误判。这样，只有当大多数的哨兵都认为主库已经主观下线了，那主库才被标记为客观下线。这个叫法表明主库下线成为一个客观事实了，判断的原则就是少数服从多数。这时会进一步出发哨兵进行主从切换的流程。\n\n上述标记为“主观下线”和“客观下线”的流程如下图所示：\n\n简单来说，“客观下线”的标准就是，当有 n 个哨兵实例时，最好要有 n/2 + 1 个实例判断主库为“主观下线”，才能最终判定主库为“客观下线”。这样一来，就可以减少误判的概率，也能避免误判带来的无谓的主从库切换。（当然，有多少个实例做出“主观下线”的判断才可以，可以由 redis 管理员自行设定）\n\n到这里我们可以看到，借助于多个哨兵实例来共同判断主库是否处于下线状态。如果主库的确下线了，哨兵就要开始下一个决策过程：选主。\n\n\n# 2.3 如何选定新主库？\n\n哨兵选择新主库的过程可以称为“筛选+打分”：\n\n * 筛选：在多个从库中按照一定的筛选条件来去掉不符合条件的从库。\n * 打分：再按照一定的规则，给剩下的从库逐个打分，评选得分最高的从库为新主库。\n\n这个过程如下图所示：\n\n在刚刚那段话中，有两个“一定”，我们看看分别是什么：\n\n# 2.3.1 筛选\n\n我们在多个从库中选主的时候，除了要检查从库的当前在线状态，还要判断它之前的网络连接状态，从而选出网络情况最好的实例。如果从库总是和主库断连，而且断连次数超出了一定的阈值，我们就有理由相信，这个从库的网络状况并不是太好，就可以把这个从库筛掉了。\n\n具体怎么判断呢？你使用配置项 down-after-milliseconds * 10。其中，down-after-milliseconds 是我们认定主从库断连的最大连接超时时间。如果在 down-after-milliseconds 毫秒内，主从节点都没有通过网络联系上，我们就可以认为主从节点断连了。如果发生断连的次数超过了 10 次，就说明这个从库的网络状况不好，不适合作为新主库。\n\n由此就过滤掉了不合适做主库的从库，完成了筛选工作。\n\n# 2.3.2 打分\n\n接下来就要给剩余的从库打分了。我们可以分别按照三个规则依次进行三轮打分：\n\n 1. 从库优先级\n 2. 从库复制进度\n 3. 从库 id 号\n\n只要在某一轮中，有从库得分最高，那么它就是主库了，选主过程到此结束。如果没有出现得分最高的从库，那么就继续进行下一轮。\n\n第一轮：优先级最高的从库得分高。\n\n用户可以通过 slave-priority 配置项，给不同的从库设置不同优先级。比如，你有两个从库，它们的内存大小不一样，你可以手动给内存大的实例设置一个高优先级。在选主时，哨兵会给优先级高的从库打高分，如果有一个从库优先级最高，那么它就是新主库了。如果从库的优先级都一样，那么哨兵开始第二轮打分。\n\n第二轮：和旧主库同步程度最接近的从库得分高。\n\n这个规则的依据是，如果选择和旧主库同步最接近的那个从库作为主库，那么，这个新主库上就有最新的数据。其实也就是哪个从库的 slave_repl_offset 最接近主库的 master_repl_offset 谁就得分高(在 repl_backlog_buffer 中的位置)。如下图所示：\n\n第三轮：id号小的从库得分高。\n\n每个实例都会有一个id，这个id就类似于这里的从库的编号。目前，redis 在选主库时，有一个默认的规定：在优先级和复制进度都相同的情况下，id 号最小的从库得分最高，会被选为新主库。\n\n到这里，“选主”这个过程就完成了。我们在回顾一下这个流程：\n\n * 首先，哨兵会按照在线状态、网络状态，筛选过滤掉一部分不符合要求的从库；\n * 然后，依次按照优先级、复制进度、id 号大小再对剩余的从库进行打分，只要有得分最高的从库出现，就把它选为新主库。\n\n\n# 2.4 小结\n\n哨兵机制是实现 redis 不间断服务的重要保证，它自动完成了以下三个功能，并实现了主从切换：\n\n * 监控主库运行状态，并判断主库是否客观下线；\n * 在主库客观下线后，选取新主库；\n * 选出新主库后，通知从库和客户端。\n\n为了降低误判率，哨兵机制通常采用多实例部署，通过“少数服从多数”的原则，来判断主库是否客观下线。\n\n但哨兵集群同时也带来了问题：\n\n * 哨兵集群中有实例挂了，怎么办，会影响主库状态判断和选主吗？\n * 哨兵集群多数实例达成共识，判断出主库“客观下线”后，由哪个实例来执行主从切换呢？\n\n为了搞懂这些问题，需要进一步了解哨兵集群。\n\n----------------------------------------\n\n本节问题 1：在主从切换过程中，客户端能否正常地进行请求操作呢？\n\n主从集群一般是采用读写分离模式，当主库故障后，客户端仍然可以把读请求发送给从库，让从库服务。但是，对于写请求操作，客户端就无法执行了。\n\n本节问题 2：如果想要应用程序不感知服务的中断，还需要哨兵或客户端再做些什么吗？\n\n * 一方面，客户端需要能缓存应用发送的写请求。只要不是同步写操作（redis 应用场景一般也没有同步写），写请求通常不会在应用程序的关键路径上，所以，客户端缓存写请求后，给应用程序返回一个确认就行。\n * 另一方面，主从切换完成后，客户端要能和新主库重新建立连接，哨兵需要提供订阅频道，让客户端能够订阅到新主库的信息。同时，客户端也需要能主动和哨兵通信，询问新主库的信息。\n\n\n# 3. 哨兵集群：哨兵挂了，主从库还能切换吗？\n\n上节讲的哨兵机制实现了主从切换，但如果有哨兵实例在运行时发生了故障，主从库还能正常切换吗？实际上，一旦多个实例组成了哨兵集群，即使有哨兵实例挂掉了，其他哨兵还能继续协作完成主从切换的工作，包括判定主库是不是处于下线状态、选择新主库，以及通知从库和客户端。\n\n如果你部署过哨兵集群的话就会知道，在配置哨兵的信息时，我们只需要用到下面的这个配置项，即设置主库的 ip和端口，并没有配置其他哨兵的连接信息：\n\nsentinel monitor <master-name> <ip> <redis-port> <quorum>\n\n\n1\n\n\n这些哨兵实例既然都不知道彼此的地址，又是怎么组成集群的呢？要弄明白这个问题，我们就需要学习一下哨兵集群的组成和运行机制了。\n\n\n# 3.1 基于 pub/sub 机制的哨兵集群组成\n\n哨兵实例之间可以相互发现，要归功于 redis 提供的 pub/sub 机制，也就是发布/订阅机制。哨兵只要和主库建立起了连接，就可以在主库上发布消息了，比如说发布它自己的连接信息（ip和端口）。同时，它也可以从主库上订阅消息，获得其他哨兵发布的连接信息。当多个哨兵实例都在主库上做了发布和订阅操作后，它们之间就能知道彼此的 ip 地址和端口。\n\n除了哨兵实例，我们自己编写的应用程序也可以通过redis进行消息的发布和订阅。所以，为了区分不同应用的消息，redis 会以频道的形式，对这些消息进行分门别类的管理。所谓的频道，实际上就是消息的类别。当消息类别相同时，它们就属于同一个频道。反之，就属于不同的频道。只有订阅了同一个频道的应用，才能通过发布的消息进行信息交换。\n\n在主从集群中，主库上有一个名为 __sentinel__: hello 的频道，不同哨兵就是通过它来相互发现，实现互相通信的。如下图示例：\n\n借助于上图所示的 pub/sub 机制，哨兵集群就形成了，它们之间可以通过网络连接进行通信，并对主库是否下线的判断进行协商。哨兵除了彼此之间建立起连接形成集群外，还需要和从库建立连接。这是因为，在哨兵的监控任务中，它需要对主从库都进行心跳判断，而且在主从库切换完成后，它还需要通知从库，让它们和新主库进行同步。\n\n那么， 哨兵是如何知道从库的 ip 地址和端口的呢？如下图所示，这是由哨兵向主库发送 info 命令来完成的，然后主库会响应给哨兵一个 slave 列表。由此，哨兵就可以与从库建立连接了。\n\n你看，通过 pub/sub 机制，哨兵之间可以组成集群，同时，哨兵又通过 info 命令，获得了从库连接信息，也能和从库建立连接，并进行监控了。\n\n但是，哨兵不能只和主、从库连接。因为主从库切换后，客户端也需要知道新主库的连接信息，才能向新主库发送请求操作。所以，哨兵还需要完成把新主库的信息告诉客户端这个任务。而且，在实际使用哨兵时，我们有时会遇到这样的问题：如何在客户端通过监控了解哨兵进行主从切换的过程呢？比如说，主从切换进行到哪一步了？这其实就是要求，客户端能够获取到哨兵集群在监控、选主、切换这个过程中发生的各种事件。\n\n此时，我们仍然可以依赖 pub/sub 机制，来帮助我们完成哨兵和客户端间的信息同步。\n\n\n# 3.2 基于 pub/sub 机制的客户端事件通知\n\n从本质上说，哨兵就是一个运行在特定模式下的 redis 实例，只不过它并不服务请求操作，只是完成监控、选主和通知的任务。所以，每个哨兵实例也提供 pub/sub 机制，客户端可以从哨兵订阅消息。哨兵提供的消息订阅频道有很多，不同频道包含了主从库切换过程中的不同关键事件。下面列出了一些重要的频道：\n\n知道了这些频道之后，你就可以让客户端从哨兵那里订阅消息了。具体的操作步骤是，客户端读取哨兵的配置文件后，可以获得哨兵的地址和端口，和哨兵建立网络连接。然后，我们可以在客户端执行订阅命令，来获取不同的事件消息。\n\n举个例子，你可以执行 subscribe +odown 命令，来订阅“所有实例进入客观下线状态的事件”，也可以执行 psubscribe * 来订阅所有的事件。\n\n当哨兵把新主库选择出来后，客户端就会看到下面的 switch-master 事件。这个事件表示主库已经切换了，新主库的 ip 址和端口信息已经有了。这个时候，客户端就可以用这里面的新主库地址和端口进行通信了：\n\nswitch-master <master name> <oldip> <oldport> <newip> <newport>\n\n\n1\n\n\n有了这些事件通知，客户端不仅可以在主从切换后得到新主库的连接信息，还可以监控到主从库切换过程中发生的各个重要事件。这样，客户端就可以知道主从切换进行到哪一步了，有助于了解切换进度。\n\n好了，有了 pub/sub 机制，哨兵和哨兵之间、哨兵和从库之间、哨兵和客户端之间就都能建立起连接了，再加上我们上节课介绍主库下线判断和选主依据，哨兵集群的监控、选主和通知三个任务就基本可以正常工作了。不过，我们还需要考虑一个问题：主库故障以后，哨兵集群有多个实例，那怎么确定由哪个哨兵来进行实际的主从切换呢？\n\n\n# 3.3 由哪个哨兵执行主从切换？\n\n确定由哪个哨兵执行主从切换的过程，和主库“客观下线”的判断过程类似，也是一个“投票仲裁”的过程。在具体了解这个过程前，我们再来看下，判断“客观下线”的仲裁过程。\n\n哨兵集群要判定主库“客观下线”，需要有一定数量的实例都认为该主库已经“主观下线”了。我在上节课向你介绍了判断“客观下线”的原则，接下来，我介绍下具体的判断过程：\n\n任何一个实例只要自身判断主库“主观下线”后，就会给其他实例发送 is-master-down-by-addr 命令。接着，其他实例会根据自己和主库的连接情况，做出 y 或 n 的响应，y 相当于赞成票，n 相当于反对票。如下图所示：\n\n一个哨兵获得了仲裁所需的赞成票数后，就可以标记主库为“客观下线”。这个所需的赞成票数是通过哨兵配置文件中的 quorum 配置项设定的。例如，现在有 5 个哨兵，quorum 配置的是 3，那么，一个哨兵需要3张赞成票，就可以标记主库为“客观下线”了。这3张赞成票包括哨兵自己的一张赞成票和另外两个哨兵的赞成票。\n\n此时，这个哨兵就可以再给其他哨兵发送命令，表明希望由自己来执行主从切换，并让所有其他哨兵进行投票。这个投票过程称为“leader 选举”。因为最终执行主从切换的哨兵称为 leader，投票过程就是确定 leader。在投票过程中，任何一个想成为 leader 的哨兵，要满足两个条件：\n\n 1. 拿到半数以上的赞成票；\n 2. 拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。以3个哨兵为例，假设此时的 quorum 设置为 2，那么，任何一个想成为 leader 的哨兵只要拿到2张赞成票，就可以了。\n\n下图就展示了 3 个哨兵、quorum=2 的选举过程：\n\n需要注意的是，如果哨兵集群只有 2 个实例，此时，一个哨兵要想成为 leader，必须获得 2 票，而不是 1 票。所以，如果有个哨兵挂掉了，那么，此时的集群是无法进行主从库切换的。因此，通常我们至少会配置 3 个哨兵实例。这一点很重要，你在实际应用时可不能忽略了。\n\n\n# 3.4 小结\n\n通常，我们在解决一个系统问题的时候，会引入一个新机制，或者设计一层新功能，就像我们在这两节课学习的内容：为了实现主从切换，我们引入了哨兵；为了避免单个哨兵故障后无法进行主从切换，以及为了减少误判率，又引入了哨兵集群；哨兵集群又需要有一些机制来支撑它的正常运行。\n\n这一节主要讲了哨兵集群的一些关键机制：\n\n * 基于 pub/sub 机制的哨兵集群组成过程；\n * 基于 info 命令的从库列表，这可以帮助哨兵和从库建立连接；\n * 基于哨兵自身的 pub/sub 功能，这实现了客户端和哨兵之间的事件通知。\n\n对于主从切换，需要哨兵集群在判断了主库“客观下线”后，经过投票仲裁，选举一个 leader 出来，由它负责实际的主从切换，即由它来完成新主库的选择以及通知从库与客户端。\n\n> 最后，我想再给你分享一个经验：要保证所有哨兵实例的配置是一致的，尤其是主观下线的判断值 down-after-milliseconds。我们曾经就踩过一个“坑”。当时，在我们的项目中，因为这个值在不同的哨兵实例上配置不一致，导致哨兵集群一直没有对有故障的主库形成共识，也就没有及时切换主库，最终的结果就是集群服务不稳定。所以，你一定不要忽略这条看似简单的经验。\n\n----------------------------------------\n\n本节问题 1：有一个redis集群，是“一主四从”，配置了 5 个哨兵实例的集群，quorum 值设为 2。在运行过程中，如果有 3 个哨兵实例都发生故障了，此时，redis 主库如果有故障，还能正确地判断主库“客观下线”吗？如果可以的话，还能进行主从库自动切换吗？\n\n因为判定主库“客观下线”的依据是，认为主库“主观下线”的哨兵个数要大于等于quorum值，现在还剩2个哨兵实例，个数正好等于quorum值，所以还能正常判断主库是否处于“客观下线”状态。如果一个哨兵想要执行主从切换，就要获到半数以上的哨兵投票赞成，也就是至少需要3个哨兵投票赞成。但是，现在只有2个哨兵了，所以就无法进行主从切换了。\n\n本节问题 2：哨兵实例是不是越多越好呢？如果同时调大 down-after-milliseconds 值，对减少误判是不是也有好处？\n\n哨兵实例越多，误判率会越低，但是在判定主库下线和选举leader时，实例需要拿到的赞成票数也越多，等待所有哨兵投完票的时间可能也会相应增加，主从库切换的时间也会变长，客户端容易堆积较多的请求操作，可能会导致客户端请求溢出，从而造成请求丢失。如果业务层对redis的操作有响应时间要求，就可能会因为新主库一直没有选定，新操作无法执行而发生超时报警。\n\n调大down-after-milliseconds后，可能会导致这样的情况：主库实际已经发生故障了，但是哨兵过了很长时间才判断出来，这就会影响到redis对业务的可用性。",charsets:{cjk:!0},lastUpdated:"2023/03/27, 09:26:06",lastUpdatedTimestamp:1679909166e3},{title:"切片集群",frontmatter:{title:"切片集群",date:"2023-03-27T15:47:12.000Z",permalink:"/pages/71b166/",categories:["中间件","Redis","专栏：Redis 核心技术与实战"],tags:[null]},regularPath:"/%E4%B8%AD%E9%97%B4%E4%BB%B6/05.Redis/05.%E4%B8%93%E6%A0%8F%EF%BC%9ARedis%20%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/09.%E5%88%87%E7%89%87%E9%9B%86%E7%BE%A4.html",relativePath:"中间件/05.Redis/05.专栏：Redis 核心技术与实战/09.切片集群.md",key:"v-31581127",path:"/pages/71b166/",headers:[{level:2,title:"1. 切片集群：数据增多了，是该加内存还是加实例？",slug:"_1-切片集群-数据增多了-是该加内存还是加实例",normalizedTitle:"1. 切片集群：数据增多了，是该加内存还是加实例？",charIndex:100},{level:3,title:"1.1 如何保存更多数据？",slug:"_1-1-如何保存更多数据",normalizedTitle:"1.1 如何保存更多数据？",charIndex:1061},{level:3,title:"1.2 数据切片和实例的对应分布关系",slug:"_1-2-数据切片和实例的对应分布关系",normalizedTitle:"1.2 数据切片和实例的对应分布关系",charIndex:1555},{level:3,title:"1.3 客户端如何定位数据？",slug:"_1-3-客户端如何定位数据",normalizedTitle:"1.3 客户端如何定位数据？",charIndex:2845},{level:3,title:"1.4 小结",slug:"_1-4-小结",normalizedTitle:"1.4 小结",charIndex:4738},{level:2,title:"2. Codis VS Redis Cluster：我该选择哪一个集群方案？",slug:"_2-codis-vs-redis-cluster-我该选择哪一个集群方案",normalizedTitle:"2. codis vs redis cluster：我该选择哪一个集群方案？",charIndex:5716},{level:3,title:"2.1 Codis 的整体架构和基本流程",slug:"_2-1-codis-的整体架构和基本流程",normalizedTitle:"2.1 codis 的整体架构和基本流程",charIndex:5864},{level:3,title:"2.2 Codis 的关键技术原理",slug:"_2-2-codis-的关键技术原理",normalizedTitle:"2.2 codis 的关键技术原理",charIndex:6772},{level:4,title:"2.2.1 数据如何在集群里分布？",slug:"_2-2-1-数据如何在集群里分布",normalizedTitle:"2.2.1 数据如何在集群里分布？",charIndex:6865},{level:4,title:"2.2.2 集群扩容和数据迁移如何进行?",slug:"_2-2-2-集群扩容和数据迁移如何进行",normalizedTitle:"2.2.2 集群扩容和数据迁移如何进行?",charIndex:8030},{level:4,title:"2.2.3 客户端的兼容性",slug:"_2-2-3-客户端的兼容性",normalizedTitle:"2.2.3 客户端的兼容性",charIndex:9906},{level:4,title:"2.2.4 怎么保证集群可靠性？",slug:"_2-2-4-怎么保证集群可靠性",normalizedTitle:"2.2.4 怎么保证集群可靠性？",charIndex:10488},{level:3,title:"2.3 切片集群方案选择建议",slug:"_2-3-切片集群方案选择建议",normalizedTitle:"2.3 切片集群方案选择建议",charIndex:11722}],headersStr:"1. 切片集群：数据增多了，是该加内存还是加实例？ 1.1 如何保存更多数据？ 1.2 数据切片和实例的对应分布关系 1.3 客户端如何定位数据？ 1.4 小结 2. Codis VS Redis Cluster：我该选择哪一个集群方案？ 2.1 Codis 的整体架构和基本流程 2.2 Codis 的关键技术原理 2.2.1 数据如何在集群里分布？ 2.2.2 集群扩容和数据迁移如何进行? 2.2.3 客户端的兼容性 2.2.4 怎么保证集群可靠性？ 2.3 切片集群方案选择建议",content:"> 参考：\n> \n>  * 09 切片集群：数据增多了，是该加内存还是加实例？| 极客时间\n>  * 35 Codis VS Redis Cluster：我该选择哪一个集群方案？| 极客时间\n\n\n# 1. 切片集群：数据增多了，是该加内存还是加实例？\n\n有这么一个需求：要用 Redis 保存 5000 万个键值对，每个键值对大约是 512B，为了能快速部署并对外提供服务，我们采用云主机来运行 Redis 实例，那么，该如何选择云主机的内存容量呢？\n\n粗略计算一下，这些 KV 所占的内存空间大约为 25GB，所以第一反应是选择一台 32G 内存的云主机来部署 Redis。但在使用过程中会发现，Redis 响应有时会非常慢，这时使用 INFO 命令查看 Redis 的 latest_fork_usec 指标值（表示最近一次 fork 的耗时），结果显示这个指标值特别高，快到秒级别了。\n\n这跟 Redis 的持久化机制有关系。在使用 RDB 进行持久化时，Redis 会 fork 子进程来完成，fork 操作的用时和 Redis 的数据量是正相关的，而 fork 在执行时会阻塞主线程。数据量越大，fork 操作造成的主线程阻塞的时间越长。所以，在使用 RDB 对 25GB 的数据进行持久化时，数据量较大，后台运行的子进程在 fork 创建时阻塞了主线程，于是就导致 Redis 响应变慢了。\n\n看来，第一个方案显然是不可行的，我们必须要寻找其他的方案。这个时候，我们注意到了 Redis 的切片集群。虽然组建切片集群比较麻烦，但是它可以保存大量数据，而且对 Redis 主线程的阻塞影响较小。\n\n切片集群，也叫分片集群，就是指启动多个 Redis 实例组成一个集群，然后按照一定的规则，把收到的数据划分成多份，每一份用一个实例来保存。回到我们刚刚的场景中，如果把 25GB 的数据平均分成 5 份（当然，也可以不做均分），使用 5 个实例来保存，每个实例只需要保存 5GB 数据。如下图所示：\n\n那么，在切片集群中，实例在为 5GB 数据生成 RDB 时，数据量就小了很多，fork 子进程一般不会给主线程带来较长时间的阻塞。采用多个实例保存数据切片后，我们既能保存 25GB 数据，又避免了 fork 子进程阻塞主线程而导致的响应突然变慢。\n\n在实际应用 Redis 时，随着用户或业务规模的扩展，保存大量数据的情况通常是无法避免的。而切片集群，就是一个非常好的解决方案。这节课，我们就来学习一下。\n\n\n# 1.1 如何保存更多数据？\n\n在刚刚的案例里，为了保存大量数据，我们使用了大内存云主机和切片集群两种方法。实际上，这两种方法分别对应着 Redis 应对数据量增多的两种方案：纵向扩展和横向扩展：\n\n * 纵向扩展（scale up）：升级单个 Redis 实例的资源配置，包括增加内存容量、增加磁盘容量、使用更高配置的 CPU。\n * 横向扩展（scale out）：横向增加当前 Redis 实例的个数。\n\n两种方式各有优缺点：\n\n * 纵向扩展实施简单，但持久化 RDB 文件会显著降低性能，而且会受到硬件与成本的限制。\n   \n   * 如果你不要求持久化保存Redis数据，那么，纵向扩展会是一个不错的选择。\n\n * 横向扩展不需要担心硬件和成本的限制，但涉及到多实例的分布式管理的问题。\n   \n   * 在面向百万、千万级别的用户规模时，横向扩展的Redis切片集群会是一个非常好的选择.\n\n要想把切片集群用起来，我们就需要解决两大问题：\n\n * 数据切片后，在多个实例之间如何分布？\n * 客户端怎么确定想要访问的数据在哪个实例上？\n\n接下来，我们就一个个地解决。\n\n\n# 1.2 数据切片和实例的对应分布关系\n\n在切片集群中，数据需要分布在不同实例上，那么，数据和实例之间如何对应呢？这就和接下来我要讲的 Redis Cluster 方案有关了。不过，我们要先弄明白切片集群和 Redis Cluster 的联系与区别。\n\n实际上，切片集群是一种保存大量数据的通用机制，这个机制可以有不同的实现方案。在 Redis 3.0 之前，官方并没有针对切片集群提供具体的方案。从 3.0 开始，官方提供了一个名为 Redis Cluster 的方案，用于实现切片集群。Redis Cluster 方案中就规定了数据和实例的对应规则。\n\n具体来说，Redis Cluster 方案采用哈希槽（Hash Slot，后面称为 Slot），来处理数据和实例之间的映射关系。在 Redis Cluster 方案中，一个切片集群共有 16384 个哈希槽，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个 slot 中。具体的映射过程分为两大步：\n\n * 首先根据键值对的 key，按照 CRC16 算法计算一个 16bit 的值；\n * 然后，再用这个 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的 slot。\n\n那么，这些 slot 又是如何被映射到具体的 Redis 实例上的呢？我们在部署 Redis Cluster 方案时，可以使用 cluster create 命令创建集群，此时，Redis 会自动把这些 slot 平均分布在集群实例上。例如，如果集群中有 N 个实例，那么，每个实例上的槽个数为 16384/N 个。这也是 DDIA 中讲的数据分区方法中的固定逻辑分区的方法。\n\n当然， 我们也可以使用 cluster meet 命令手动建立实例间的连接，形成集群，再使用 cluster addslots 命令，根据不同实例的资源情况指定每个实例上的 slot 个数。下图展示了数据、哈希槽和实例这三者的映射分布情况：\n\n示意图中的切片集群一共有 3 个实例，同时假设有 5 个 slot，我们首先可以通过下面的命令手动分配 slot：实例 1 保存 slot 0 和 1，实例 2 保存 slot 2 和 3，实例 3 保存 slot 4。配置命令如下：\n\nredis-cli -h 172.16.19.3 –p 6379 cluster addslots 0,1\nredis-cli -h 172.16.19.4 –p 6379 cluster addslots 2,3\nredis-cli -h 172.16.19.5 –p 6379 cluster addslots 4\n\n\n1\n2\n3\n\n\n注意：在手动分配 slot 时，需要把 16384 个 slot 都分配完，否则 Redis 集群无法正常工作。\n\n综上，通过哈希槽，切片集群就实现了数据到哈希槽、哈希槽再到实例的分配。但是，即使实例有了哈希槽的映射信息，客户端又是怎么知道要访问的数据在哪个实例上呢？\n\n\n# 1.3 客户端如何定位数据？\n\n在定位键值对数据时，它所处的哈希槽是可以通过计算得到的，这个计算可以在客户端发送请求时来执行。但是，要进一步定位到 Redis 实例，还需要知道 slot 分布在哪个实例上。\n\n一般来说，客户端和集群实例建立连接后，实例就会把哈希槽的分配信息发给客户端。但是，在集群刚刚创建的时候，每个实例只知道自己被分配了哪些哈希槽，是不知道其他实例拥有的哈希槽信息的。那么，客户端为什么可以在访问任何一个实例时，都能获得所有的哈希槽信息呢？这是因为，Redis 实例会把自己的哈希槽信息发给和它相连接的其它实例，来完成哈希槽分配信息的扩散。当实例之间相互连接后，每个实例就有所有哈希槽的映射关系了。\n\n客户端收到哈希槽信息后，会把哈希槽信息缓存在本地。当客户端请求键值对时，会先计算键所对应的哈希槽，然后就可以给相应的实例发送请求了。但是，在集群中，实例和哈希槽的对应关系并不是一成不变的，最常见的变化有两个：\n\n * 在集群中，实例有新增或删除，Redis 需要重新分配哈希槽；\n * 为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍。\n\n此时，实例之间还可以通过相互传递消息，获得最新的哈希槽分配信息，但是，客户端是无法主动感知这些变化的。这就会导致，它缓存的分配信息和最新的分配信息就不一致了，那该怎么办呢？\n\nRedis Cluster 方案提供了一种重定向机制，所谓的“重定向”，就是指，客户端给一个实例发送数据读写操作时，如果这个实例上并没有相应的数据，实例就会想客户端返回一个如下所示的 MOVED 命令响应结果，客户端这时就要再给一个新实例发送操作命令。\n\nGET hello:key\n(error) MOVED 13320 172.16.19.5:6379\n\n\n1\n2\n\n\n其中，MOVED 命令表示，客户端请求的键值对所在的哈希槽 13320，实际是在 172.16.19.5 这个实例上。通过返回的 MOVED 命令，就相当于把哈希槽所在的新实例的信息告诉给客户端了。这样一来，客户端就可以直接和 172.16.19.5 连接，并发送操作请求了。\n\n下面用一张图来说明一下 MOVED 命令的重定向的使用方法。可以看到，由于负载均衡，Slot 2中的数据已经从实例2迁移到了实例3，但是，客户端缓存仍然记录着“Slot 2在实例2”的信息，所以会给实例2发送命令。实例2给客户端返回一条 MOVED 命令，把Slot 2的最新位置（也就是在实例3上），返回给客户端，客户端就会再次向实例3发送请求，同时还会更新本地缓存，把 Slot 2与实例的对应关系更新过来。\n\n需要注意的是，在上图中，当客户端给实例2发送命令时，Slot 2中的数据已经全部迁移到了实例3。在实际应用时，如果Slot 2中的数据比较多，就可能会出现一种情况：客户端向实例2发送请求，但此时，Slot 2中的数据只有一部分迁移到了实例3，还有部分数据没有迁移。在这种迁移部分完成的情况下，客户端就会收到一条 ASK 报错信息，如下所示：\n\nGET hello:key\n(error) ASK 13320 172.16.19.5:6379\n\n\n1\n2\n\n\n这个结果中的 ASK 命令就表示，客户端请求的键值对所在的哈希槽 13320，在 172.16.19.5 这个实例上，但是这个哈希槽正在迁移。此时，客户端需要先给 172.16.19.5 这个实例发送一个 ASKING 命令。这个命令的意思是，让这个实例允许执行客户端接下来发送的命令。然后，客户端再向这个实例发送 GET 命令，以读取数据。\n\n看起来好像有点复杂，我再借助图片来解释一下。在下图中，Slot 2正在从实例2往实例3迁移，key1和key2已经迁移过去，key3和key4还在实例2。客户端向实例2请求key2后，就会收到实例2返回的ASK命令。\n\nASK 命令表示两层含义：\n\n * 第一，表明 slot 数据还在迁移中；\n * 第二，ASK 命令把客户端所请求数据的最新实例地址返回给客户端，此时，客户端需要给实例 3 发送 ASKING 命令，然后再发送操作命令。\n\n和 MOVED 命令不同，ASK命令并不会更新客户端缓存的哈希槽分配信息。所以，在上图中，如果客户端再次请求 slot 2 中的数据，它还是会给 实例 2 发送请求。这也就是说，ASK 命令的作用只是让客户端能给新实例发送一次请求，而不像 MOVED 命令那样，会更改本地缓存，让后续所有命令都发往新实例。\n\n\n# 1.4 小结\n\n这节课，我们学习了切片集群在保存大量数据方面的优势，以及基于哈希槽的数据分布机制和客户端定位键值对的方法。\n\n在应对数据量扩容时，虽然增加内存这种纵向扩展的方法简单直接，但是会造成数据库的内存过大，导致性能变慢。Redis 切片集群提供了横向扩展的模式，也就是使用多个实例，并给每个实例配置一定数量的哈希槽，数据可以通过键的哈希值映射到哈希槽，再通过哈希槽分散保存到不同的实例上。这样做的好处是扩展性好，不管有多少数据，切片集群都能应对。\n\n另外，集群的实例增减，或者是为了实现负载均衡而进行的数据重新分布，会导致哈希槽和实例的映射关系发生变化，客户端发送请求时，会收到命令执行报错信息。了解了 MOVED 和 ASK 命令，你就不会为这类报错而头疼了。\n\n我刚刚说过，在 Redis 3.0 之前，Redis 官方并没有提供切片集群方案，但是，其实当时业界已经有了一些切片集群的方案，例如基于客户端分区的 ShardedJedis，基于代理的 Codis、Twemproxy 等。这些方案的应用早于 Redis Cluster 方案，在支撑的集群实例规模、集群稳定性、客户端友好性方面也都有着各自的优势，我会在后面的课程中，专门和你聊聊这些方案的实现机制，以及实践经验。这样一来，当你再碰到业务发展带来的数据量巨大的难题时，就可以根据这些方案的特点，选择合适的方案实现切片集群，以应对业务需求了。\n\n----------------------------------------\n\n本节问题：为什么Redis不直接用一个表，把键值对和实例的对应关系记录下来，而是要对键值对的 key 做 CRC 计算？\n\n如果使用表记录键值对和实例的对应关系，一旦键值对和实例的对应关系发生了变化（例如实例有增减或者数据重新分布），就要修改表。如果是单线程操作表，那么所有操作都要串行执行，性能慢；如果是多线程操作表，就涉及到加锁开销。此外，如果数据量非常大，使用表记录键值对和实例的对应关系，需要的额外存储空间也会增加。\n\n基于哈希槽计算时，虽然也要记录哈希槽和实例的对应关系，但是哈希槽的个数要比键值对的个数少很多，无论是修改哈希槽和实例的对应关系，还是使用额外空间存储哈希槽和实例的对应关系，都比直接记录键值对和实例的关系的开销小得多。\n\n\n# 2. Codis VS Redis Cluster：我该选择哪一个集群方案？\n\n前面学习了 Redis 官方提供的切片集群方案 Redis Cluster，但在该方案发布之前，业界已经广泛使用 Codis。这一节将讲解 Codis 的实现原理，并将两者进行对比，从而选出最佳的集群方案。\n\n\n# 2.1 Codis 的整体架构和基本流程\n\nCodis 集群中包含了 4 类关键组件：\n\n * codis server：这是进行了二次开发的Redis实例，其中增加了额外的数据结构，支持数据迁移操作，主要负责处理具体的数据读写请求。\n * codis proxy：接收客户端请求，并把请求转发给codis server。\n * Zookeeper 集群：保存集群元数据，例如数据位置信息和codis proxy信息。这里，有个地方需要你注意，除了使用Zookeeper，Codis还可以使用etcd或本地文件系统保存元数据信息。\n * codis dashboard 和 codis fe：共同组成了集群管理工具。其中，codis dashboard负责执行集群管理工作，包括增删codis server、codis proxy和进行数据迁移。而codis fe负责提供dashboard的Web操作界面，便于我们直接在Web界面上进行集群管理。\n\n我用一张图来展示下 Codis 集群的架构和关键组件：\n\n下面具体解释一下 Codis 是如何处理请求的：\n\n * 首先，为了让集群能接收并处理请求，我们要先使用 codis dashboard 设置 codis server 和 codis proxy 的访问地址，完成设置后，codis server 和 codis proxy 才会开始接收连接。\n * 然后，当客户端要读写数据时，客户端直接和codis proxy建立连接。codis proxy 本身支持 Redis 的 RESP 交互协议，所以客户端访问codis proxy时，和访问原生的Redis实例没有什么区别，这样一来，原本连接单实例的客户端就可以轻松地和Codis集群建立起连接了。\n * 最后，codis proxy接收到请求，就会查询请求数据和codis server的映射关系，并把请求转发给相应的codis server进行处理。当codis server处理完请求后，会把结果返回给codis proxy，proxy再把数据返回给客户端。\n\n用一张图来展示这个处理流程：\n\n\n# 2.2 Codis 的关键技术原理\n\n这里将围绕影响切片集群使用效果的 4 方面技术因素：数据分布、集群扩容和数据迁移、客户端兼容性、可靠性保证，来讨论它们的具体设计选择和原理。\n\n# 2.2.1 数据如何在集群里分布？\n\n在 Codis 集群中，一个数据应该保存在哪个codis server上，这是通过逻辑槽（Slot）映射来完成的，具体来说，总共分成两步：\n\n 1. 第一步，Codis集群一共有1024个Slot，编号依次是0到1023。我们可以把这些Slot手动分配给codis server，每个server上包含一部分Slot。当然，我们也可以让codis dashboard进行自动分配，例如，dashboard把1024个Slot在所有server上均分。\n 2. 第二步，当客户端要读写数据时，会使用CRC32算法计算数据key的哈希值，并把这个哈希值对1024取模。而取模后的值，则对应Slot的编号。此时，根据第一步分配的Slot和server对应关系，我们就可以知道数据保存在哪个server上了。\n\n这个过程如下图所示：\n\n数据key和Slot的映射关系是客户端在读写数据前直接通过CRC32计算得到的，而Slot和codis server的映射关系是通过分配完成的，所以就需要用一个存储系统保存下来，否则，如果集群有故障了，映射关系就会丢失。\n\n我们把Slot和codis server的映射关系称为数据路由表（简称路由表）。我们在codis dashboard上分配好路由表后，dashboard会把路由表发送给codis proxy，同时，dashboard也会把路由表保存在Zookeeper中。codis-proxy会把路由表缓存在本地，当它接收到客户端请求后，直接查询本地的路由表，就可以完成正确的请求转发了。下图展示了路由表的分配和使用过程：\n\n在数据分片的实现方法上，Codis 和 Redis Cluster 很相似，都采用了 key 映射到 Slot、Slot 再分配到实例上的机制。但是，这里有一个明显的区别：\n\n * Codis中的路由表是我们通过codis dashboard分配和修改的，并被保存在Zookeeper集群中。一旦数据位置发生变化（例如有实例增减），路由表被修改了，codis dashbaord就会把修改后的路由表发送给codis proxy，proxy就可以根据最新的路由信息转发请求了。\n * 在Redis Cluster中，数据路由表是通过每个实例相互间的通信传递的，最后会在每个实例上保存一份。当数据路由信息发生变化时，就需要在所有实例间通过网络消息进行传递。所以，如果实例数量较多的话，就会消耗较多的集群网络资源。\n\n数据分布解决了新数据写入时该保存在哪个server的问题，但是，当业务数据增加后，如果集群中的现有实例不足以保存所有数据，我们就需要对集群进行扩容。接下来，我们再来学习下Codis针对集群扩容的关键技术设计。\n\n# 2.2.2 集群扩容和数据迁移如何进行?\n\nCodis 集群扩容包括了两方面：增加 codis server 和增加 codis proxy。\n\n----------------------------------------\n\n我们先来看增加 codis server，这个过程主要涉及到两步操作：\n\n 1. 启动新的 codis server，将它加入集群中；\n 2. 把部分数据迁移到新的 server。\n\n需要注意的是，这里的数据迁移是一个重要的机制。Codis 集群按照 Slot 的粒度进行数据迁移，我们来看下迁移的基本流程：\n\n 1. 在源server上，Codis从要迁移的Slot中随机选择一个数据，发送给目的server。\n 2. 目的server确认收到数据后，会给源server返回确认消息。这时，源server会在本地将刚才迁移的数据删除。\n 3. 第一步和第二步就是单个数据的迁移过程。Codis会不断重复这个迁移过程，直到要迁移的Slot中的数据全部迁移完成。\n\n下图显示了数据迁移的流程：\n\n针对刚才介绍的单个数据的迁移过程，Codis实现了两种迁移模式，分别是同步迁移和异步迁移：\n\n * 同步迁移是指，在数据从源server发送给目的server的过程中，源server是阻塞的，无法处理新的请求操作。这种模式很容易实现，但是迁移过程中会涉及多个操作（包括数据在源server序列化、网络传输、在目的server反序列化，以及在源server删除），如果迁移的数据是一个bigkey，源server就会阻塞较长时间，无法及时处理用户请求。\n * 为了避免数据迁移阻塞源server，Codis实现的第二种迁移模式就是异步迁移。异步迁移的关键特点有两个：\n   * 第一个特点是，当源server把数据发送给目的server后，就可以处理其他请求操作了，不用等到目的server的命令执行完。而目的server会在收到数据并反序列化保存到本地后，给源server发送一个ACK消息，表明迁移完成。此时，源server在本地把刚才迁移的数据删除。在这个过程中，迁移的数据会被设置为只读，所以，源server上的数据不会被修改，自然也就不会出现“和目的server上的数据不一致”的问题了。\n   * 第二个特点是，对于bigkey，异步迁移采用了拆分指令的方式进行迁移。具体来说就是，对bigkey中每个元素，用一条指令进行迁移，而不是把整个bigkey进行序列化后再整体传输。这种化整为零的方式，就避免了bigkey迁移时，因为要序列化大量数据而阻塞源server的问题。此外，当bigkey迁移了一部分数据后，如果Codis发生故障，就会导致bigkey的一部分元素在源server，而另一部分元素在目的server，这就破坏了迁移的原子性。所以，Codis会在目标server上，给bigkey的元素设置一个临时过期时间。如果迁移过程中发生故障，那么，目标server上的key会在过期后被删除，不会影响迁移的原子性。当正常完成迁移后，bigkey元素的临时过期时间会被删除。\n\n> 这里，有个地方需要你注意下，为了提升迁移的效率，Codis在异步迁移Slot时，允许每次迁移多个key。你可以通过异步迁移命令SLOTSMGRTTAGSLOT-ASYNC的参数numkeys设置每次迁移的key数量。\n\n----------------------------------------\n\n刚刚讲的是 codis server 的扩容和数据迁移机制，除此之外，我们可能还需要增加 codis proxy。因为在 Codis 集群中，客户端是和 codis proxy 直接连接的，所以，当客户端增加时，一个proxy无法支撑大量的请求操作，此时，我们就需要增加proxy。\n\n增加proxy比较容易，我们直接启动proxy，再通过codis dashboard把proxy加入集群就行。\n\n此时，codis proxy的访问连接信息都会保存在Zookeeper上。所以，当新增了proxy后，Zookeeper上会有最新的访问列表，客户端也就可以从Zookeeper上读取proxy访问列表，把请求发送给新增的proxy。这样一来，客户端的访问压力就可以在多个proxy上分担处理了，如下图所示：\n\n好了，到这里，我们就了解了Codis集群中的数据分布、集群扩容和数据迁移的方法，这都是切片集群中的关键机制。\n\n# 2.2.3 客户端的兼容性\n\n使用 Redis 单实例时，客户端只要符合 RESP 协议，就可以和实例进行交互和读写数据。但是，在使用切片集群时，有些功能是和单实例不一样的，比如集群中的数据迁移操作，在单实例上是没有的，而且迁移过程中，数据访问请求可能要被重定向（例如Redis Cluster中的MOVE命令）。所以，客户端需要增加和集群功能相关的命令操作的支持。如果原来使用单实例客户端，想要扩容使用集群，就需要使用新客户端，这对于业务应用的兼容性来说，并不是特别友好。\n\n> 所以对于使用切片集群 Redis Cluster 而言，要想从单实例扩容成集群，就需要从单实例客户端换成新的客户端，对业务应用的兼容性而言，不是很友好。\n\nCodis 集群在设计时，就充分考虑了对现有单实例客户端的兼容性。Codis 使用 codis proxy 直接和客户端连接，codis proxy 是和单实例客户端兼容的。而和集群相关的管理工作（例如请求转发、数据迁移等），都由 codis proxy、codis dashboard 这些组件来完成，不需要客户端参与。\n\n这样一来，业务应用使用 Codis 集群时，就不用修改客户端了，可以复用和单实例连接的客户端，既能利用集群读写大容量数据，又避免了修改客户端增加复杂的操作逻辑，保证了业务代码的稳定性和兼容性。\n\n# 2.2.4 怎么保证集群可靠性？\n\n对于一个分布式系统来说，它的可靠性和系统中的组件个数有关：组件越多，潜在的风险点也就越多。和Redis Cluster只包含Redis实例不一样，Codis集群包含的组件有4类。那你就会问了，这么多组件会降低Codis集群的可靠性吗？\n\n我们来分别看下 Codis 不同组件的可靠性保证方法。\n\n----------------------------------------\n\n首先是 codis server。\n\ncodis server其实就是Redis实例，只不过增加了和集群操作相关的命令。Redis的主从复制机制和哨兵机制在codis server上都是可以使用的，所以，Codis就使用主从集群来保证codis server的可靠性。简单来说就是，Codis给每个server配置从库，并使用哨兵机制进行监控，当发生故障时，主从库可以进行切换，从而保证了server的可靠性。\n\n在这种配置情况下，每个server就成为了一个server group，每个group中是一主多从的server。数据分布使用的Slot，也是按照group的粒度进行分配的。同时，codis proxy在转发请求时，也是按照数据所在的Slot和group的对应关系，把写请求发到相应group的主库，读请求发到group中的主库或从库上。\n\n下图展示的是配置了server group的Codis集群架构。在Codis集群中，我们通过部署server group和哨兵集群，实现codis server的主从切换，提升集群可靠性：\n\n----------------------------------------\n\n再看一下 codis proxy 和 Zookeeper 的可靠性。这俩组件是搭配使用的。\n\n在Codis集群设计时，proxy上的信息源头都是来自Zookeeper（例如路由表）。而Zookeeper集群使用多个实例来保存数据，只要有超过半数的Zookeeper实例可以正常工作， Zookeeper集群就可以提供服务，也可以保证这些数据的可靠性。\n\n所以，codis proxy使用Zookeeper集群保存路由表，可以充分利用Zookeeper的高可靠性保证来确保codis proxy的可靠性，不用再做额外的工作了。当codis proxy发生故障后，直接重启proxy就行。重启后的proxy，可以通过codis dashboard从Zookeeper集群上获取路由表，然后，就可以接收客户端请求进行转发了。这样的设计，也降低了Codis集群本身的开发复杂度。\n\n----------------------------------------\n\n对于codis dashboard和codis fe来说，它们主要提供配置管理和管理员手工操作，负载压力不大，所以，它们的可靠性可以不用额外进行保证了。\n\n\n# 2.3 切片集群方案选择建议\n\n下图总结了 Codis 和 Redis Cluster 两种切片集群方案，对比如下：\n\n最后，在实际应用的时候，对于这两种方案的选择有如下建议：\n\n 1. 从稳定性和成熟度来看，Codis应用得比较早，在业界已经有了成熟的生产部署。虽然Codis引入了proxy和Zookeeper，增加了集群复杂度，但是，proxy的无状态设计和Zookeeper自身的稳定性，也给Codis的稳定使用提供了保证。而Redis Cluster的推出时间晚于Codis，相对来说，成熟度要弱于Codis，如果你想选择一个成熟稳定的方案，Codis更加合适些。\n\n 2. 从业务应用客户端兼容性来看，连接单实例的客户端可以直接连接codis proxy，而原本连接单实例的客户端要想连接Redis Cluster的话，就需要开发新功能。所以，如果你的业务应用中大量使用了单实例的客户端，而现在想应用切片集群的话，建议你选择Codis，这样可以避免修改业务应用中的客户端。\n\n 3. 从使用Redis新命令和新特性来看，Codis server是基于开源的Redis 3.2.8开发的，所以，Codis并不支持Redis后续的开源版本中的新增命令和数据类型。另外，Codis并没有实现开源Redis版本的所有命令，比如BITOP、BLPOP、BRPOP，以及和与事务相关的MUTLI、EXEC等命令。 Codis官网 上列出了不被支持的命令列表，你在使用时记得去核查一下。所以，如果你想使用开源Redis 版本的新特性，Redis Cluster是一个合适的选择。\n\n 4. 从数据迁移性能维度来看，Codis能支持异步迁移，异步迁移对集群处理正常请求的性能影响要比使用同步迁移的小。所以，如果你在应用集群时，数据迁移比较频繁的话，Codis是个更合适的选择。\n\n另外这里再提供一个 Codis 使用上的小建议：当你有多条业务线要使用 Codis 时，可以启动多个 codis dashboard，每个 dashboard 管理一部分 codis server，同时，再用一个 dashboard 对应负责一个业务线的集群管理，这样就可以做到用一个 Codis 集群实现多条业务线的隔离管理了。",normalizedContent:"> 参考：\n> \n>  * 09 切片集群：数据增多了，是该加内存还是加实例？| 极客时间\n>  * 35 codis vs redis cluster：我该选择哪一个集群方案？| 极客时间\n\n\n# 1. 切片集群：数据增多了，是该加内存还是加实例？\n\n有这么一个需求：要用 redis 保存 5000 万个键值对，每个键值对大约是 512b，为了能快速部署并对外提供服务，我们采用云主机来运行 redis 实例，那么，该如何选择云主机的内存容量呢？\n\n粗略计算一下，这些 kv 所占的内存空间大约为 25gb，所以第一反应是选择一台 32g 内存的云主机来部署 redis。但在使用过程中会发现，redis 响应有时会非常慢，这时使用 info 命令查看 redis 的 latest_fork_usec 指标值（表示最近一次 fork 的耗时），结果显示这个指标值特别高，快到秒级别了。\n\n这跟 redis 的持久化机制有关系。在使用 rdb 进行持久化时，redis 会 fork 子进程来完成，fork 操作的用时和 redis 的数据量是正相关的，而 fork 在执行时会阻塞主线程。数据量越大，fork 操作造成的主线程阻塞的时间越长。所以，在使用 rdb 对 25gb 的数据进行持久化时，数据量较大，后台运行的子进程在 fork 创建时阻塞了主线程，于是就导致 redis 响应变慢了。\n\n看来，第一个方案显然是不可行的，我们必须要寻找其他的方案。这个时候，我们注意到了 redis 的切片集群。虽然组建切片集群比较麻烦，但是它可以保存大量数据，而且对 redis 主线程的阻塞影响较小。\n\n切片集群，也叫分片集群，就是指启动多个 redis 实例组成一个集群，然后按照一定的规则，把收到的数据划分成多份，每一份用一个实例来保存。回到我们刚刚的场景中，如果把 25gb 的数据平均分成 5 份（当然，也可以不做均分），使用 5 个实例来保存，每个实例只需要保存 5gb 数据。如下图所示：\n\n那么，在切片集群中，实例在为 5gb 数据生成 rdb 时，数据量就小了很多，fork 子进程一般不会给主线程带来较长时间的阻塞。采用多个实例保存数据切片后，我们既能保存 25gb 数据，又避免了 fork 子进程阻塞主线程而导致的响应突然变慢。\n\n在实际应用 redis 时，随着用户或业务规模的扩展，保存大量数据的情况通常是无法避免的。而切片集群，就是一个非常好的解决方案。这节课，我们就来学习一下。\n\n\n# 1.1 如何保存更多数据？\n\n在刚刚的案例里，为了保存大量数据，我们使用了大内存云主机和切片集群两种方法。实际上，这两种方法分别对应着 redis 应对数据量增多的两种方案：纵向扩展和横向扩展：\n\n * 纵向扩展（scale up）：升级单个 redis 实例的资源配置，包括增加内存容量、增加磁盘容量、使用更高配置的 cpu。\n * 横向扩展（scale out）：横向增加当前 redis 实例的个数。\n\n两种方式各有优缺点：\n\n * 纵向扩展实施简单，但持久化 rdb 文件会显著降低性能，而且会受到硬件与成本的限制。\n   \n   * 如果你不要求持久化保存redis数据，那么，纵向扩展会是一个不错的选择。\n\n * 横向扩展不需要担心硬件和成本的限制，但涉及到多实例的分布式管理的问题。\n   \n   * 在面向百万、千万级别的用户规模时，横向扩展的redis切片集群会是一个非常好的选择.\n\n要想把切片集群用起来，我们就需要解决两大问题：\n\n * 数据切片后，在多个实例之间如何分布？\n * 客户端怎么确定想要访问的数据在哪个实例上？\n\n接下来，我们就一个个地解决。\n\n\n# 1.2 数据切片和实例的对应分布关系\n\n在切片集群中，数据需要分布在不同实例上，那么，数据和实例之间如何对应呢？这就和接下来我要讲的 redis cluster 方案有关了。不过，我们要先弄明白切片集群和 redis cluster 的联系与区别。\n\n实际上，切片集群是一种保存大量数据的通用机制，这个机制可以有不同的实现方案。在 redis 3.0 之前，官方并没有针对切片集群提供具体的方案。从 3.0 开始，官方提供了一个名为 redis cluster 的方案，用于实现切片集群。redis cluster 方案中就规定了数据和实例的对应规则。\n\n具体来说，redis cluster 方案采用哈希槽（hash slot，后面称为 slot），来处理数据和实例之间的映射关系。在 redis cluster 方案中，一个切片集群共有 16384 个哈希槽，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个 slot 中。具体的映射过程分为两大步：\n\n * 首先根据键值对的 key，按照 crc16 算法计算一个 16bit 的值；\n * 然后，再用这个 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的 slot。\n\n那么，这些 slot 又是如何被映射到具体的 redis 实例上的呢？我们在部署 redis cluster 方案时，可以使用 cluster create 命令创建集群，此时，redis 会自动把这些 slot 平均分布在集群实例上。例如，如果集群中有 n 个实例，那么，每个实例上的槽个数为 16384/n 个。这也是 ddia 中讲的数据分区方法中的固定逻辑分区的方法。\n\n当然， 我们也可以使用 cluster meet 命令手动建立实例间的连接，形成集群，再使用 cluster addslots 命令，根据不同实例的资源情况指定每个实例上的 slot 个数。下图展示了数据、哈希槽和实例这三者的映射分布情况：\n\n示意图中的切片集群一共有 3 个实例，同时假设有 5 个 slot，我们首先可以通过下面的命令手动分配 slot：实例 1 保存 slot 0 和 1，实例 2 保存 slot 2 和 3，实例 3 保存 slot 4。配置命令如下：\n\nredis-cli -h 172.16.19.3 –p 6379 cluster addslots 0,1\nredis-cli -h 172.16.19.4 –p 6379 cluster addslots 2,3\nredis-cli -h 172.16.19.5 –p 6379 cluster addslots 4\n\n\n1\n2\n3\n\n\n注意：在手动分配 slot 时，需要把 16384 个 slot 都分配完，否则 redis 集群无法正常工作。\n\n综上，通过哈希槽，切片集群就实现了数据到哈希槽、哈希槽再到实例的分配。但是，即使实例有了哈希槽的映射信息，客户端又是怎么知道要访问的数据在哪个实例上呢？\n\n\n# 1.3 客户端如何定位数据？\n\n在定位键值对数据时，它所处的哈希槽是可以通过计算得到的，这个计算可以在客户端发送请求时来执行。但是，要进一步定位到 redis 实例，还需要知道 slot 分布在哪个实例上。\n\n一般来说，客户端和集群实例建立连接后，实例就会把哈希槽的分配信息发给客户端。但是，在集群刚刚创建的时候，每个实例只知道自己被分配了哪些哈希槽，是不知道其他实例拥有的哈希槽信息的。那么，客户端为什么可以在访问任何一个实例时，都能获得所有的哈希槽信息呢？这是因为，redis 实例会把自己的哈希槽信息发给和它相连接的其它实例，来完成哈希槽分配信息的扩散。当实例之间相互连接后，每个实例就有所有哈希槽的映射关系了。\n\n客户端收到哈希槽信息后，会把哈希槽信息缓存在本地。当客户端请求键值对时，会先计算键所对应的哈希槽，然后就可以给相应的实例发送请求了。但是，在集群中，实例和哈希槽的对应关系并不是一成不变的，最常见的变化有两个：\n\n * 在集群中，实例有新增或删除，redis 需要重新分配哈希槽；\n * 为了负载均衡，redis 需要把哈希槽在所有实例上重新分布一遍。\n\n此时，实例之间还可以通过相互传递消息，获得最新的哈希槽分配信息，但是，客户端是无法主动感知这些变化的。这就会导致，它缓存的分配信息和最新的分配信息就不一致了，那该怎么办呢？\n\nredis cluster 方案提供了一种重定向机制，所谓的“重定向”，就是指，客户端给一个实例发送数据读写操作时，如果这个实例上并没有相应的数据，实例就会想客户端返回一个如下所示的 moved 命令响应结果，客户端这时就要再给一个新实例发送操作命令。\n\nget hello:key\n(error) moved 13320 172.16.19.5:6379\n\n\n1\n2\n\n\n其中，moved 命令表示，客户端请求的键值对所在的哈希槽 13320，实际是在 172.16.19.5 这个实例上。通过返回的 moved 命令，就相当于把哈希槽所在的新实例的信息告诉给客户端了。这样一来，客户端就可以直接和 172.16.19.5 连接，并发送操作请求了。\n\n下面用一张图来说明一下 moved 命令的重定向的使用方法。可以看到，由于负载均衡，slot 2中的数据已经从实例2迁移到了实例3，但是，客户端缓存仍然记录着“slot 2在实例2”的信息，所以会给实例2发送命令。实例2给客户端返回一条 moved 命令，把slot 2的最新位置（也就是在实例3上），返回给客户端，客户端就会再次向实例3发送请求，同时还会更新本地缓存，把 slot 2与实例的对应关系更新过来。\n\n需要注意的是，在上图中，当客户端给实例2发送命令时，slot 2中的数据已经全部迁移到了实例3。在实际应用时，如果slot 2中的数据比较多，就可能会出现一种情况：客户端向实例2发送请求，但此时，slot 2中的数据只有一部分迁移到了实例3，还有部分数据没有迁移。在这种迁移部分完成的情况下，客户端就会收到一条 ask 报错信息，如下所示：\n\nget hello:key\n(error) ask 13320 172.16.19.5:6379\n\n\n1\n2\n\n\n这个结果中的 ask 命令就表示，客户端请求的键值对所在的哈希槽 13320，在 172.16.19.5 这个实例上，但是这个哈希槽正在迁移。此时，客户端需要先给 172.16.19.5 这个实例发送一个 asking 命令。这个命令的意思是，让这个实例允许执行客户端接下来发送的命令。然后，客户端再向这个实例发送 get 命令，以读取数据。\n\n看起来好像有点复杂，我再借助图片来解释一下。在下图中，slot 2正在从实例2往实例3迁移，key1和key2已经迁移过去，key3和key4还在实例2。客户端向实例2请求key2后，就会收到实例2返回的ask命令。\n\nask 命令表示两层含义：\n\n * 第一，表明 slot 数据还在迁移中；\n * 第二，ask 命令把客户端所请求数据的最新实例地址返回给客户端，此时，客户端需要给实例 3 发送 asking 命令，然后再发送操作命令。\n\n和 moved 命令不同，ask命令并不会更新客户端缓存的哈希槽分配信息。所以，在上图中，如果客户端再次请求 slot 2 中的数据，它还是会给 实例 2 发送请求。这也就是说，ask 命令的作用只是让客户端能给新实例发送一次请求，而不像 moved 命令那样，会更改本地缓存，让后续所有命令都发往新实例。\n\n\n# 1.4 小结\n\n这节课，我们学习了切片集群在保存大量数据方面的优势，以及基于哈希槽的数据分布机制和客户端定位键值对的方法。\n\n在应对数据量扩容时，虽然增加内存这种纵向扩展的方法简单直接，但是会造成数据库的内存过大，导致性能变慢。redis 切片集群提供了横向扩展的模式，也就是使用多个实例，并给每个实例配置一定数量的哈希槽，数据可以通过键的哈希值映射到哈希槽，再通过哈希槽分散保存到不同的实例上。这样做的好处是扩展性好，不管有多少数据，切片集群都能应对。\n\n另外，集群的实例增减，或者是为了实现负载均衡而进行的数据重新分布，会导致哈希槽和实例的映射关系发生变化，客户端发送请求时，会收到命令执行报错信息。了解了 moved 和 ask 命令，你就不会为这类报错而头疼了。\n\n我刚刚说过，在 redis 3.0 之前，redis 官方并没有提供切片集群方案，但是，其实当时业界已经有了一些切片集群的方案，例如基于客户端分区的 shardedjedis，基于代理的 codis、twemproxy 等。这些方案的应用早于 redis cluster 方案，在支撑的集群实例规模、集群稳定性、客户端友好性方面也都有着各自的优势，我会在后面的课程中，专门和你聊聊这些方案的实现机制，以及实践经验。这样一来，当你再碰到业务发展带来的数据量巨大的难题时，就可以根据这些方案的特点，选择合适的方案实现切片集群，以应对业务需求了。\n\n----------------------------------------\n\n本节问题：为什么redis不直接用一个表，把键值对和实例的对应关系记录下来，而是要对键值对的 key 做 crc 计算？\n\n如果使用表记录键值对和实例的对应关系，一旦键值对和实例的对应关系发生了变化（例如实例有增减或者数据重新分布），就要修改表。如果是单线程操作表，那么所有操作都要串行执行，性能慢；如果是多线程操作表，就涉及到加锁开销。此外，如果数据量非常大，使用表记录键值对和实例的对应关系，需要的额外存储空间也会增加。\n\n基于哈希槽计算时，虽然也要记录哈希槽和实例的对应关系，但是哈希槽的个数要比键值对的个数少很多，无论是修改哈希槽和实例的对应关系，还是使用额外空间存储哈希槽和实例的对应关系，都比直接记录键值对和实例的关系的开销小得多。\n\n\n# 2. codis vs redis cluster：我该选择哪一个集群方案？\n\n前面学习了 redis 官方提供的切片集群方案 redis cluster，但在该方案发布之前，业界已经广泛使用 codis。这一节将讲解 codis 的实现原理，并将两者进行对比，从而选出最佳的集群方案。\n\n\n# 2.1 codis 的整体架构和基本流程\n\ncodis 集群中包含了 4 类关键组件：\n\n * codis server：这是进行了二次开发的redis实例，其中增加了额外的数据结构，支持数据迁移操作，主要负责处理具体的数据读写请求。\n * codis proxy：接收客户端请求，并把请求转发给codis server。\n * zookeeper 集群：保存集群元数据，例如数据位置信息和codis proxy信息。这里，有个地方需要你注意，除了使用zookeeper，codis还可以使用etcd或本地文件系统保存元数据信息。\n * codis dashboard 和 codis fe：共同组成了集群管理工具。其中，codis dashboard负责执行集群管理工作，包括增删codis server、codis proxy和进行数据迁移。而codis fe负责提供dashboard的web操作界面，便于我们直接在web界面上进行集群管理。\n\n我用一张图来展示下 codis 集群的架构和关键组件：\n\n下面具体解释一下 codis 是如何处理请求的：\n\n * 首先，为了让集群能接收并处理请求，我们要先使用 codis dashboard 设置 codis server 和 codis proxy 的访问地址，完成设置后，codis server 和 codis proxy 才会开始接收连接。\n * 然后，当客户端要读写数据时，客户端直接和codis proxy建立连接。codis proxy 本身支持 redis 的 resp 交互协议，所以客户端访问codis proxy时，和访问原生的redis实例没有什么区别，这样一来，原本连接单实例的客户端就可以轻松地和codis集群建立起连接了。\n * 最后，codis proxy接收到请求，就会查询请求数据和codis server的映射关系，并把请求转发给相应的codis server进行处理。当codis server处理完请求后，会把结果返回给codis proxy，proxy再把数据返回给客户端。\n\n用一张图来展示这个处理流程：\n\n\n# 2.2 codis 的关键技术原理\n\n这里将围绕影响切片集群使用效果的 4 方面技术因素：数据分布、集群扩容和数据迁移、客户端兼容性、可靠性保证，来讨论它们的具体设计选择和原理。\n\n# 2.2.1 数据如何在集群里分布？\n\n在 codis 集群中，一个数据应该保存在哪个codis server上，这是通过逻辑槽（slot）映射来完成的，具体来说，总共分成两步：\n\n 1. 第一步，codis集群一共有1024个slot，编号依次是0到1023。我们可以把这些slot手动分配给codis server，每个server上包含一部分slot。当然，我们也可以让codis dashboard进行自动分配，例如，dashboard把1024个slot在所有server上均分。\n 2. 第二步，当客户端要读写数据时，会使用crc32算法计算数据key的哈希值，并把这个哈希值对1024取模。而取模后的值，则对应slot的编号。此时，根据第一步分配的slot和server对应关系，我们就可以知道数据保存在哪个server上了。\n\n这个过程如下图所示：\n\n数据key和slot的映射关系是客户端在读写数据前直接通过crc32计算得到的，而slot和codis server的映射关系是通过分配完成的，所以就需要用一个存储系统保存下来，否则，如果集群有故障了，映射关系就会丢失。\n\n我们把slot和codis server的映射关系称为数据路由表（简称路由表）。我们在codis dashboard上分配好路由表后，dashboard会把路由表发送给codis proxy，同时，dashboard也会把路由表保存在zookeeper中。codis-proxy会把路由表缓存在本地，当它接收到客户端请求后，直接查询本地的路由表，就可以完成正确的请求转发了。下图展示了路由表的分配和使用过程：\n\n在数据分片的实现方法上，codis 和 redis cluster 很相似，都采用了 key 映射到 slot、slot 再分配到实例上的机制。但是，这里有一个明显的区别：\n\n * codis中的路由表是我们通过codis dashboard分配和修改的，并被保存在zookeeper集群中。一旦数据位置发生变化（例如有实例增减），路由表被修改了，codis dashbaord就会把修改后的路由表发送给codis proxy，proxy就可以根据最新的路由信息转发请求了。\n * 在redis cluster中，数据路由表是通过每个实例相互间的通信传递的，最后会在每个实例上保存一份。当数据路由信息发生变化时，就需要在所有实例间通过网络消息进行传递。所以，如果实例数量较多的话，就会消耗较多的集群网络资源。\n\n数据分布解决了新数据写入时该保存在哪个server的问题，但是，当业务数据增加后，如果集群中的现有实例不足以保存所有数据，我们就需要对集群进行扩容。接下来，我们再来学习下codis针对集群扩容的关键技术设计。\n\n# 2.2.2 集群扩容和数据迁移如何进行?\n\ncodis 集群扩容包括了两方面：增加 codis server 和增加 codis proxy。\n\n----------------------------------------\n\n我们先来看增加 codis server，这个过程主要涉及到两步操作：\n\n 1. 启动新的 codis server，将它加入集群中；\n 2. 把部分数据迁移到新的 server。\n\n需要注意的是，这里的数据迁移是一个重要的机制。codis 集群按照 slot 的粒度进行数据迁移，我们来看下迁移的基本流程：\n\n 1. 在源server上，codis从要迁移的slot中随机选择一个数据，发送给目的server。\n 2. 目的server确认收到数据后，会给源server返回确认消息。这时，源server会在本地将刚才迁移的数据删除。\n 3. 第一步和第二步就是单个数据的迁移过程。codis会不断重复这个迁移过程，直到要迁移的slot中的数据全部迁移完成。\n\n下图显示了数据迁移的流程：\n\n针对刚才介绍的单个数据的迁移过程，codis实现了两种迁移模式，分别是同步迁移和异步迁移：\n\n * 同步迁移是指，在数据从源server发送给目的server的过程中，源server是阻塞的，无法处理新的请求操作。这种模式很容易实现，但是迁移过程中会涉及多个操作（包括数据在源server序列化、网络传输、在目的server反序列化，以及在源server删除），如果迁移的数据是一个bigkey，源server就会阻塞较长时间，无法及时处理用户请求。\n * 为了避免数据迁移阻塞源server，codis实现的第二种迁移模式就是异步迁移。异步迁移的关键特点有两个：\n   * 第一个特点是，当源server把数据发送给目的server后，就可以处理其他请求操作了，不用等到目的server的命令执行完。而目的server会在收到数据并反序列化保存到本地后，给源server发送一个ack消息，表明迁移完成。此时，源server在本地把刚才迁移的数据删除。在这个过程中，迁移的数据会被设置为只读，所以，源server上的数据不会被修改，自然也就不会出现“和目的server上的数据不一致”的问题了。\n   * 第二个特点是，对于bigkey，异步迁移采用了拆分指令的方式进行迁移。具体来说就是，对bigkey中每个元素，用一条指令进行迁移，而不是把整个bigkey进行序列化后再整体传输。这种化整为零的方式，就避免了bigkey迁移时，因为要序列化大量数据而阻塞源server的问题。此外，当bigkey迁移了一部分数据后，如果codis发生故障，就会导致bigkey的一部分元素在源server，而另一部分元素在目的server，这就破坏了迁移的原子性。所以，codis会在目标server上，给bigkey的元素设置一个临时过期时间。如果迁移过程中发生故障，那么，目标server上的key会在过期后被删除，不会影响迁移的原子性。当正常完成迁移后，bigkey元素的临时过期时间会被删除。\n\n> 这里，有个地方需要你注意下，为了提升迁移的效率，codis在异步迁移slot时，允许每次迁移多个key。你可以通过异步迁移命令slotsmgrttagslot-async的参数numkeys设置每次迁移的key数量。\n\n----------------------------------------\n\n刚刚讲的是 codis server 的扩容和数据迁移机制，除此之外，我们可能还需要增加 codis proxy。因为在 codis 集群中，客户端是和 codis proxy 直接连接的，所以，当客户端增加时，一个proxy无法支撑大量的请求操作，此时，我们就需要增加proxy。\n\n增加proxy比较容易，我们直接启动proxy，再通过codis dashboard把proxy加入集群就行。\n\n此时，codis proxy的访问连接信息都会保存在zookeeper上。所以，当新增了proxy后，zookeeper上会有最新的访问列表，客户端也就可以从zookeeper上读取proxy访问列表，把请求发送给新增的proxy。这样一来，客户端的访问压力就可以在多个proxy上分担处理了，如下图所示：\n\n好了，到这里，我们就了解了codis集群中的数据分布、集群扩容和数据迁移的方法，这都是切片集群中的关键机制。\n\n# 2.2.3 客户端的兼容性\n\n使用 redis 单实例时，客户端只要符合 resp 协议，就可以和实例进行交互和读写数据。但是，在使用切片集群时，有些功能是和单实例不一样的，比如集群中的数据迁移操作，在单实例上是没有的，而且迁移过程中，数据访问请求可能要被重定向（例如redis cluster中的move命令）。所以，客户端需要增加和集群功能相关的命令操作的支持。如果原来使用单实例客户端，想要扩容使用集群，就需要使用新客户端，这对于业务应用的兼容性来说，并不是特别友好。\n\n> 所以对于使用切片集群 redis cluster 而言，要想从单实例扩容成集群，就需要从单实例客户端换成新的客户端，对业务应用的兼容性而言，不是很友好。\n\ncodis 集群在设计时，就充分考虑了对现有单实例客户端的兼容性。codis 使用 codis proxy 直接和客户端连接，codis proxy 是和单实例客户端兼容的。而和集群相关的管理工作（例如请求转发、数据迁移等），都由 codis proxy、codis dashboard 这些组件来完成，不需要客户端参与。\n\n这样一来，业务应用使用 codis 集群时，就不用修改客户端了，可以复用和单实例连接的客户端，既能利用集群读写大容量数据，又避免了修改客户端增加复杂的操作逻辑，保证了业务代码的稳定性和兼容性。\n\n# 2.2.4 怎么保证集群可靠性？\n\n对于一个分布式系统来说，它的可靠性和系统中的组件个数有关：组件越多，潜在的风险点也就越多。和redis cluster只包含redis实例不一样，codis集群包含的组件有4类。那你就会问了，这么多组件会降低codis集群的可靠性吗？\n\n我们来分别看下 codis 不同组件的可靠性保证方法。\n\n----------------------------------------\n\n首先是 codis server。\n\ncodis server其实就是redis实例，只不过增加了和集群操作相关的命令。redis的主从复制机制和哨兵机制在codis server上都是可以使用的，所以，codis就使用主从集群来保证codis server的可靠性。简单来说就是，codis给每个server配置从库，并使用哨兵机制进行监控，当发生故障时，主从库可以进行切换，从而保证了server的可靠性。\n\n在这种配置情况下，每个server就成为了一个server group，每个group中是一主多从的server。数据分布使用的slot，也是按照group的粒度进行分配的。同时，codis proxy在转发请求时，也是按照数据所在的slot和group的对应关系，把写请求发到相应group的主库，读请求发到group中的主库或从库上。\n\n下图展示的是配置了server group的codis集群架构。在codis集群中，我们通过部署server group和哨兵集群，实现codis server的主从切换，提升集群可靠性：\n\n----------------------------------------\n\n再看一下 codis proxy 和 zookeeper 的可靠性。这俩组件是搭配使用的。\n\n在codis集群设计时，proxy上的信息源头都是来自zookeeper（例如路由表）。而zookeeper集群使用多个实例来保存数据，只要有超过半数的zookeeper实例可以正常工作， zookeeper集群就可以提供服务，也可以保证这些数据的可靠性。\n\n所以，codis proxy使用zookeeper集群保存路由表，可以充分利用zookeeper的高可靠性保证来确保codis proxy的可靠性，不用再做额外的工作了。当codis proxy发生故障后，直接重启proxy就行。重启后的proxy，可以通过codis dashboard从zookeeper集群上获取路由表，然后，就可以接收客户端请求进行转发了。这样的设计，也降低了codis集群本身的开发复杂度。\n\n----------------------------------------\n\n对于codis dashboard和codis fe来说，它们主要提供配置管理和管理员手工操作，负载压力不大，所以，它们的可靠性可以不用额外进行保证了。\n\n\n# 2.3 切片集群方案选择建议\n\n下图总结了 codis 和 redis cluster 两种切片集群方案，对比如下：\n\n最后，在实际应用的时候，对于这两种方案的选择有如下建议：\n\n 1. 从稳定性和成熟度来看，codis应用得比较早，在业界已经有了成熟的生产部署。虽然codis引入了proxy和zookeeper，增加了集群复杂度，但是，proxy的无状态设计和zookeeper自身的稳定性，也给codis的稳定使用提供了保证。而redis cluster的推出时间晚于codis，相对来说，成熟度要弱于codis，如果你想选择一个成熟稳定的方案，codis更加合适些。\n\n 2. 从业务应用客户端兼容性来看，连接单实例的客户端可以直接连接codis proxy，而原本连接单实例的客户端要想连接redis cluster的话，就需要开发新功能。所以，如果你的业务应用中大量使用了单实例的客户端，而现在想应用切片集群的话，建议你选择codis，这样可以避免修改业务应用中的客户端。\n\n 3. 从使用redis新命令和新特性来看，codis server是基于开源的redis 3.2.8开发的，所以，codis并不支持redis后续的开源版本中的新增命令和数据类型。另外，codis并没有实现开源redis版本的所有命令，比如bitop、blpop、brpop，以及和与事务相关的mutli、exec等命令。 codis官网 上列出了不被支持的命令列表，你在使用时记得去核查一下。所以，如果你想使用开源redis 版本的新特性，redis cluster是一个合适的选择。\n\n 4. 从数据迁移性能维度来看，codis能支持异步迁移，异步迁移对集群处理正常请求的性能影响要比使用同步迁移的小。所以，如果你在应用集群时，数据迁移比较频繁的话，codis是个更合适的选择。\n\n另外这里再提供一个 codis 使用上的小建议：当你有多条业务线要使用 codis 时，可以启动多个 codis dashboard，每个 dashboard 管理一部分 codis server，同时，再用一个 dashboard 对应负责一个业务线的集群管理，这样就可以做到用一个 codis 集群实现多条业务线的隔离管理了。",charsets:{cjk:!0},lastUpdated:"2023/04/21, 08:38:32",lastUpdatedTimestamp:1682066312e3},{title:"Redis 中的数据结构",frontmatter:{title:"Redis 中的数据结构",date:"2023-03-29T20:16:12.000Z",permalink:"/pages/2029a8/",categories:["中间件","Redis","专栏：Redis 核心技术与实战"],tags:[null]},regularPath:"/%E4%B8%AD%E9%97%B4%E4%BB%B6/05.Redis/05.%E4%B8%93%E6%A0%8F%EF%BC%9ARedis%20%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/11.Redis%20%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.html",relativePath:"中间件/05.Redis/05.专栏：Redis 核心技术与实战/11.Redis 中的数据结构.md",key:"v-c2ced796",path:"/pages/2029a8/",headers:[{level:2,title:"1. “万金油”的 String，为什么不好用了？",slug:"_1-万金油-的-string-为什么不好用了",normalizedTitle:"1. “万金油”的 string，为什么不好用了？",charIndex:255},{level:3,title:"1.1 为什么 String 类型内存开销大？",slug:"_1-1-为什么-string-类型内存开销大",normalizedTitle:"1.1 为什么 string 类型内存开销大？",charIndex:1285},{level:3,title:"1.2 用什么数据结构可以节省内存？",slug:"_1-2-用什么数据结构可以节省内存",normalizedTitle:"1.2 用什么数据结构可以节省内存？",charIndex:3166},{level:3,title:"1.3 如何用集合类型保存单值的键值对？",slug:"_1-3-如何用集合类型保存单值的键值对",normalizedTitle:"1.3 如何用集合类型保存单值的键值对？",charIndex:4239},{level:3,title:"1.4 小结",slug:"_1-4-小结",normalizedTitle:"1.4 小结",charIndex:5550},{level:2,title:"2. 有一亿个keys要统计，应该用哪种集合？",slug:"_2-有一亿个keys要统计-应该用哪种集合",normalizedTitle:"2. 有一亿个keys要统计，应该用哪种集合？",charIndex:5909},{level:3,title:"2.1 聚合统计 —— Set",slug:"_2-1-聚合统计-set",normalizedTitle:"2.1 聚合统计 —— set",charIndex:6327},{level:3,title:"2.2 排序统计 —— 有序集合",slug:"_2-2-排序统计-有序集合",normalizedTitle:"2.2 排序统计 —— 有序集合",charIndex:6994},{level:3,title:"2.3 二值状态统计 —— Bitmap",slug:"_2-3-二值状态统计-bitmap",normalizedTitle:"2.3 二值状态统计 —— bitmap",charIndex:8552},{level:3,title:"2.4 基数统计 —— HyperLogLog",slug:"_2-4-基数统计-hyperloglog",normalizedTitle:"2.4 基数统计 —— hyperloglog",charIndex:10111},{level:3,title:"2.5 小结",slug:"_2-5-小结",normalizedTitle:"2.5 小结",charIndex:11569},{level:2,title:"3. GEO 是什么？还可以定义新的数据类型吗？",slug:"_3-geo-是什么-还可以定义新的数据类型吗",normalizedTitle:"3. geo 是什么？还可以定义新的数据类型吗？",charIndex:12077},{level:3,title:"3.1 面向 LBS 应用的 GEO 类型",slug:"_3-1-面向-lbs-应用的-geo-类型",normalizedTitle:"3.1 面向 lbs 应用的 geo 类型",charIndex:12289},{level:4,title:"3.1.1 GEO 的底层结构",slug:"_3-1-1-geo-的底层结构",normalizedTitle:"3.1.1 geo 的底层结构",charIndex:12450},{level:4,title:"3.1.2 GeoHash 的编码方法",slug:"_3-1-2-geohash-的编码方法",normalizedTitle:"3.1.2 geohash 的编码方法",charIndex:13725},{level:4,title:"3.1.3 如何操作 GEO 类型？",slug:"_3-1-3-如何操作-geo-类型",normalizedTitle:"3.1.3 如何操作 geo 类型？",charIndex:15843},{level:3,title:"3.2 如何自定义数据类型",slug:"_3-2-如何自定义数据类型",normalizedTitle:"3.2 如何自定义数据类型",charIndex:16869},{level:4,title:"3.2.1 Redis 的基本对象结构：RedisObject",slug:"_3-2-1-redis-的基本对象结构-redisobject",normalizedTitle:"3.2.1 redis 的基本对象结构：redisobject",charIndex:16974},{level:4,title:"3.2.2 开发一个新的数据类型",slug:"_3-2-2-开发一个新的数据类型",normalizedTitle:"3.2.2 开发一个新的数据类型",charIndex:17442},{level:3,title:"3.3 小结",slug:"_3-3-小结",normalizedTitle:"3.3 小结",charIndex:20395}],headersStr:"1. “万金油”的 String，为什么不好用了？ 1.1 为什么 String 类型内存开销大？ 1.2 用什么数据结构可以节省内存？ 1.3 如何用集合类型保存单值的键值对？ 1.4 小结 2. 有一亿个keys要统计，应该用哪种集合？ 2.1 聚合统计 —— Set 2.2 排序统计 —— 有序集合 2.3 二值状态统计 —— Bitmap 2.4 基数统计 —— HyperLogLog 2.5 小结 3. GEO 是什么？还可以定义新的数据类型吗？ 3.1 面向 LBS 应用的 GEO 类型 3.1.1 GEO 的底层结构 3.1.2 GeoHash 的编码方法 3.1.3 如何操作 GEO 类型？ 3.2 如何自定义数据类型 3.2.1 Redis 的基本对象结构：RedisObject 3.2.2 开发一个新的数据类型 3.3 小结",content:'> 参考：\n> \n>  * 11 “万金油”的 String，为什么不好用了？| 极客时间\n>  * 12 有一亿个 keys 要统计，应该用哪种集合？| 极客时间\n>  * 13 GEO是什么？还可以定义新的数据类型吗？| 极客时间\n\n这一章进入实践篇，将学习“数据结构”，介绍内存开销以及保存和统计海量数据的数据类型及其底层数据结构，还会围绕典型的应用场景（例如地址位置查询、时间序列数据库读写和消息队列存取），跟你分享使用 Redis 的数据类型和 module 扩展功能来满足需求的具体方案。\n\n\n# 1. “万金油”的 String，为什么不好用了？\n\n这一节了解一下 String 类型的内存空间消耗问题，以及选择节省内存开销的数据类型的解决方案。\n\n先分享一个实际的需求。当时要开发一个图片存储系统，要求能快速记录并能够快速根据图片 ID 找到对应的图片存储对象 ID，即 photo_id -> photo_obj_id。由于图片数量巨大，我们就使用 10 位数来保存这个 ID，例如：\n\nphoto_id: 1101000051\nphoto_obj_id: 3301000051\n\n\n1\n2\n\n\n可以看到 photo_id 与 photo_obj_id 一一对应，是典型的“键-单值”模式。所谓的“单值”，就是指键值对中的值就是一个值，而不是一个集合，这和 String 类型提供的“一个键对应一个值的数据”的保存形式刚好契合。\n\n而且，String 类型可以保存二进制字节流，就像“万金油”一样，只要把数据转成二进制字节数组，就可以保存了。\n\n所以，我们的第一个方案就是用 String 保存数据。我们把图片 ID 和图片存储对象 ID 分别作为键值对的 key 和 value 来保存，其中，图片存储对象 ID 用了 String 类型。\n\n刚开始，我们保存了1亿张图片，大约用了6.4GB的内存。但随着图片数据量的不断增加，Redis 内存使用量也在增加，导致因生成 RDB 而响应变慢的问题。很显然，String 类型并不是一种好的选择，我们还需要进一步寻找能节省内存开销的数据类型方案。\n\n在这个过程中，我们研究发现：String 类型并不是适用于所有场合的，它有一个明显的短板，就是它保存数据时所消耗的内存空间较多。\n\n同时，我们还仔细研究了集合类型的数据结构，发现，集合类型有非常节省内存空间的底层实现结构，但是，集合类型保存的数据模式，是一个键对应一系列值，并不适合直接保存单值的键值对。所以，我们就使用二级编码的方法，实现了用集合类型保存单值键值对，Redis 实例的内存空间消耗明显下降了。\n\n这节课，我就把在解决这个问题时学到的经验和方法分享给你，包括 String 类型的内存空间消耗在哪儿了、用什么数据结构可以节省内存，以及如何用集合类型保存单值键值对。如果你在使用 String 类型时也遇到了内存空间消耗较多的问题，就可以尝试下今天的解决方案了。\n\n接下来，我们先来看看 String 类型的内存都消耗在哪里了。\n\n\n# 1.1 为什么 String 类型内存开销大？\n\n在刚才的案例中，我们保存了1亿张图片的信息，用了约 6.4GB 的内存，一个图片ID和图片存储对象ID的记录平均用了 64 字节。但问题是，一组图片ID及其存储对象ID的记录，实际只需要 16 字节就可以了。\n\n我们来分析一下。如果我们可以用两个8字节的 Long 类型表示这两个 ID，因为 8 字节的Long类型最大可以表示 $2^{64}$，所以肯定可以表示 10 位数。但是，为什么 String 类型却用了 64 字节呢？\n\n其实，除了记录实际数据，String类型还需要额外的内存空间记录数据长度、空间使用等信息，这些信息也叫作元数据。当实际保存的数据较小时，元数据的空间开销就显得比较大了，有点“喧宾夺主”的意思。\n\n那么，String 类型具体是怎么保存数据的呢？\n\n当你保存 64 位有符号整数时，String 类型会把它保存为一个 8 字节的 long 类型整数，这种方式通常也称为 int 编码方式。\n\n但当你保存的数据中包含字符时，String 类型就会用简单动态字符串（Simple Dynamic String，SDS）的 struct 来保存：\n\n * buf：char[] 类型，保存实际数据，同时会在尾部加一个 \\0。\n * len：4 byte，表示 buf 的长度。\n * alloc：4 byte，表示 buf 的分配长度。\n\n可以看到，len 和 alloc 就是 SDS 结构体的额外开销。另外，对于 String 类型来说，除了 SDS，还有一个来自于 RedisObject 结构体的开销。\n\nRedis 使用 RedisObject 结构体来统一记录不同的数据结构的元数据和实际数据位置。其结构示意图如下：\n\n为了节省内存，Redis 还对 Long 类型整数和 SDS 的内存布局做了专门的设计：\n\n * 当保存的是 Long 类型时，RedisObject 中的 ptr 就直接赋值为整数数据了，这样就不用额外的指针再指向整数了，节省了指针的开销。这也是前面说的 int 编码方式。\n * 当保存的是字符串时，且字符串小于等于 44 byte 时，RedisObject 中的元数据、指针和 SDS 是一块连续的内存区域，这样就可以避免内存碎片。这种布局方式也被称为 embstr 编码方式。\n * 当字符串大于 44 byte 时，SDS 数据量就开始变多，Redis 就不再把 SDS 和 RedisObject 布局在一起了，而是会给 SDS 分配独立的空间，并用指针指向 SDS 结构。这种布局方式被称为 raw 编码模式。\n\n三种编码方式如下图所示：\n\n现在知道了 RedisObject 的额外开销，我们就可以计算 String 类型的内存使用量了。\n\n因为10位数的图片ID和图片存储对象ID是Long类型整数，所以可以直接用int编码的RedisObject保存。每个int编码的RedisObject元数据部分占8字节，指针部分被直接赋值为8字节的整数了。此时，每个ID会使用16字节，加起来一共是32字节。但是，另外的32字节去哪儿了呢？其实，Redis 是使用一个全局 hash table 来保存所有的键值对的，哈希表的每一项是一个 dictEntry 的结构体，用来指向一个 kv pair。其中 dictEntry 有三个 8 byte 的指针，分别指向 key、value 以及下一个 dictEntry。一个 dictEntry 如下图所示：\n\n但 dictEntry 只占了 24 byte，那为啥会占用 32 byte 呢？这就要提到 Redis 使用的内存分配库 jemalloc 了。\n\njemalloc 在分配内存时，会根据我们申请的字节数 N，找一个比 N 大，但是最接近 N 的 2 的幂次数作为分配的空间，这样可以减少频繁分配的次数。举个例子。如果你申请6字节空间，jemalloc实际会分配8字节空间；如果你申请24字节空间，jemalloc则会分配32字节。所以，在我们刚刚说的场景里，dictEntry结构就占用了32字节。\n\n好了，到这里你就能理解，为什么用String类型保存图片ID和图片存储对象ID时需要用64个字节了。你看，明明有效信息只有 16 byte，使用 String 类型保存却需要 64 byte 的内存空间，有 48 byte 都是额外开销。那有没有更节省内存的方法呢？\n\n\n# 1.2 用什么数据结构可以节省内存？\n\nRedis 有一种底层数据结构，叫压缩列表（ziplist），这是一种非常节省内存的结构。\n\n我们先回顾下压缩列表的构成：表头有三个字段zlbytes、zltail和zllen，分别表示列表长度、列表尾的偏移量，以及列表中的entry个数。压缩列表尾还有一个zlend，表示列表结束。如下图：\n\n压缩列表之所以能节省内存，就在于它是用一系列连续的 entry 保存数据。每个 entry 的元数据包括下面几部分：\n\n * prev_len：表示前一个entry的长度。prev_len有两种取值情况：1字节或5字节。取值1字节时，表示上一个entry的长度小于254字节。虽然1字节的值能表示的数值范围是0到255，但是压缩列表中zlend的取值默认是255，因此，就默认用255表示整个压缩列表的结束，其他表示长度的地方就不能再用255这个值了。所以，当上一个entry长度小于254字节时，prev_len取值为1字节，否则，就取值为5字节。\n * len：表示自身长度，4 byte\n * encoding：表示编码方式，1 byte\n * content：保存实际数据\n\n这些 entry 会挨个儿放置在内存中，不需要再用额外的指针进行连接，这样就可以节省指针所占用的空间。\n\n我们以保存图片存储对象ID为例，来分析一下压缩列表是如何节省内存空间的。每个entry保存一个图片存储对象ID（8字节），此时，每个entry的prev_len只需要1个字节就行，因为每个entry的前一个entry长度都只有8字节，小于254字节。这样一来，一个图片的存储对象ID所占用的内存大小是14字节（1+4+1+8=14），实际分配16字节。\n\nRedis基于压缩列表实现了 List、Hash 和 Sorted Set 这样的集合类型，这样做的最大好处就是节省了 dictEntry 的开销。当你用 String 类型时，一个键值对就有一个 dictEntry，要用 32 字节空间。但采用集合类型时，一个 key 就对应一个集合的数据，能保存的数据多了很多，但也只用了一个 dictEntry，这样就节省了内存。\n\n这个方案听起来很好，但还存在一个问题：在用集合类型保存键值对时，一个键对应了一个集合的数据，但是在我们的场景中，一个图片ID只对应一个图片的存储对象ID，我们该怎么用集合类型呢？换句话说，在一个键对应一个值（也就是单值键值对）的情况下，我们该怎么用集合类型来保存这种单值键值对呢？\n\n\n# 1.3 如何用集合类型保存单值的键值对？\n\n在保存单值的键值对时，可以采用基于 Hash 类型的二级编码方法。这里说的二级编码，就是把一个单值的数据拆分成两部分，前一部分作为Hash集合的key，后一部分作为Hash集合的value，这样一来，我们就可以把单值数据保存到Hash集合中了。\n\n以图片ID 1101000060和图片存储对象ID 3302000080为例，我们可以把图片ID的前7位（1101000）作为Hash类型的键，把图片ID的最后3位（060）和图片存储对象ID分别作为Hash类型值中的key和value。\n\n按照这种设计方法，我在Redis中插入了一组图片ID及其存储对象ID的记录，并且用info命令查看了内存开销，我发现，增加一条记录后，内存占用只增加了16字节，如下所示：\n\n127.0.0.1:6379> info memory\n# Memory\nused_memory:1039120\n127.0.0.1:6379> hset 1101000 060 3302000080\n(integer) 1\n127.0.0.1:6379> info memory\n# Memory\nused_memory:1039136\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n在使用 String 类型时，每个记录需要消耗 64 字节，这种方式却只用了 16 字节，所使用的内存空间是原来的 1/4，满足了我们节省内存空间的需求。\n\n不过，你可能也会有疑惑：“二级编码一定要把图片ID的前7位作为Hash类型的键，把最后3位作为Hash类型值中的key吗？” 其实，二级编码方法中采用的ID长度是有讲究的。\n\n我们之前讲过，Redis 的 Hash 类型有两种底层实现结构，分别是压缩列表和哈希表。Hash 类型设置了一个用压缩列表保存数据时的阈值，一旦超过阈值，Hash 类型就会用哈希表来保存数据了。这两个阈值分别对应以下两个配置项：\n\n * hash-max-ziplist-entries：表示用压缩列表保存时哈希集合中的最大元素个数。\n * hash-max-ziplist-value：表示用压缩列表保存时哈希集合中单个元素的最大长度。\n\n如果我们往Hash集合中写入的元素个数超过了 hash-max-ziplist-entries，或者写入的单个元素大小超过了 hash-max-ziplist-value，Redis 就会自动把 Hash 类型的实现结构由压缩列表转为哈希表。\n\n一旦从压缩列表转为了哈希表，Hash 类型就会一直用哈希表进行保存，而不会再转回压缩列表了。在节省内存空间方面，哈希表就没有压缩列表那么高效了。\n\n为了能充分使用压缩列表的精简内存布局，我们一般要控制保存在Hash集合中的元素个数。所以，在刚才的二级编码中，我们只用图片ID最后3位作为Hash集合的key，也就保证了Hash集合的元素个数不超过1000，同时，我们把 hash-max-ziplist-entries 设置为 1000，这样一来，Hash 集合就可以一直使用压缩列表来节省内存空间了。\n\n\n# 1.4 小结\n\n这一节我们打破了对 String 的认知误区，了解到 String 并非万金油，当保存的 kv pair 本身占用内存空间不大时，String 类型的元数据开销就占据主导了，这包括了 RedisObject、SDS、dictEntry 结构的内存开销。\n\n针对这种情况，我们可以借助压缩列表这种底层结构，使用 Hash 类型的二级编码方法来保存单值 kv pair 的数据。也就是需要将原 kv pair 的 key 拆成两部分，前一部分作为 Hash 集合的 key，后一部分与原 kv pair 的 value 组合成一个新 kv 来作为 Hash 集合的 value。\n\n小妙招：如果你想知道 kv pair 采用不同类型保存时的内存开销，可以在Redis 容量预估这个网站上进行估计。\n\n\n# 2. 有一亿个keys要统计，应该用哪种集合？\n\n很多场景需要保存这样一种数据：一个 key 对应了一个数据集合。比如:\n\n * 手机App中的每天的用户登录信息：一天 -> 用户 ID / 登录设备;\n * 电商网站上商品的用户评论列表：一个商品 -> 一系列评论；\n * 用户在手机App上的签到打卡信息：员工 -> 一天打卡记录。\n\nRedis 的集合类型很适合存储这些数据，但在这些场景中，除了记录信息，我们往往还需要对集合中的数据进行统计，比如统计每天新增用户数、统计评论列表中的最新评论、一个月连续打卡的员工数等。通常我们会面临巨大的访问量，比如百万、千万级别。所以，我们必须要能够选择非常高效地统计大量数据（例如亿级）的集合类型。\n\n要想选择合适的集合，我们就得了解常用的集合统计模式。这一节将介绍集合类型的常见四种统计模式：聚合统计、排序统计、二值状态统计和基数统计，并介绍这些统计场景下什么数据结构更加合适。\n\n\n# 2.1 聚合统计 —— Set\n\n聚合统计：指统计多个集合元素的聚合结果，包括：统计多个集合的共有元素（交集统计）；把两个集合相比，统计其中一个集合独有的元素（差集统计）；统计多个集合的所有元素（并集统计）。\n\n比如统计手机 App 每天的新增用户数和第二天的留存用户数就是聚合统计。要完成这个统计任务，我们可以用一个集合记录所有登录过App的用户ID，同时，用另一个集合记录每一天登录过App的用户ID。然后，再对这两个集合做聚合统计。我们来看下具体的操作。\n\n可以使用 Set 类型来记录所有登录过 App 的用户 ID，把 key 设置成 user:id，value 就是保存了所有登陆过 App 的用户 ID 的 Set，如下图：\n\n还需要记录每一天登录的用户 ID，可以让 key 设为 user:id:<datetime>，比如 user:id:20200803，value 是记录了当天登录的所有用户 ID 的 Set。如下图：\n\n在统计每天的新增用户时，我们只用计算每日用户 Set 和累计用户 Set 的差集就行。\n\n当你需要对多个集合进行聚合计算时，Set 类型会是一个非常不错的选择。不过，这里有一个潜在的风险：Set 的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，会导致Redis实例阻塞。所以这里给一个小建议：你可以从主从集群中选择一个从库，让它专门负责聚合计算，或者是把数据读取到客户端，在客户端来完成聚合统计，这样就可以规避阻塞主库实例和其他从库实例的风险了。\n\n\n# 2.2 排序统计 —— 有序集合\n\n这一小节讲应对集合元素排序的需求的方法，这里以电商网站提供最新评论列表的场景为例进行讲解。\n\n最新评论列表包含了所有评论中的最新留言，这就要求集合类型能对元素保序，这种对元素保序的集合类型叫作有序集合。在 Redis 的四个集合类型中（List、Hash、Set 和 Sorted Set），List 和 Sorted Set 就属于有序集合。\n\n * List 按照元素添加的顺序进行排序；\n * Sorted Set 按照元素的权重来排序，其中权重值可以自己决定（比如让插入时间作为权重）。\n\n貌似都符合需求，接下来看一下如何选择。\n\n----------------------------------------\n\n如果使用 List 的话。每个商品对应一个 List，这个 List 包含了该商品的全部评论，并按照评论时间保存，每来一个新评论就用 LPUSH 命令把它插入到 List 的队头。\n\n在只有一页评论的时候，我们可以很清晰地看到最新的评论，但是，在实际应用中，网站一般会分页显示最新的评论列表，一旦涉及到分页操作，List就可能会出现问题了。\n\n假设当前的评论List是{A, B, C, D, E, F}（其中，A是最新的评论，以此类推，F是最早的评论），在展示第一页的3个评论时，我们可以用下面的命令，得到最新的三条评论A、B、C：\n\nLRANGE product1 0 2\n1) "A"\n2) "B"\n3) "C"\n\n\n1\n2\n3\n4\n\n\n然后，再用下面的命令获取第二页的3个评论，也就是D、E、F：\n\nLRANGE product1 3 5\n1) "D"\n2) "E"\n3) "F"\n\n\n1\n2\n3\n4\n\n\n但是，如果在展示第二页前，又产生了一个新评论G，评论G就会被LPUSH命令插入到评论List的队头，评论List就变成了{G, A, B, C, D, E, F}。此时，再用刚才的命令获取第二页评论时，就会发现，评论C又被展示出来了，也就是C、D、E：\n\nLRANGE product1 3 5\n1) "C"\n2) "D"\n3) "E"\n\n\n1\n2\n3\n4\n\n\n之所以会这样，关键原因就在于，List是通过元素在List中的位置来排序的，当有一个新元素插入时，原先的元素在List中的位置都后移了一位，比如说原来在第1位的元素现在排在了第2位。所以，对比新元素插入前后，List 相同位置上的元素就会发生变化，用 LRANGE 读取时，就会读到旧元素。\n\n----------------------------------------\n\n和 List 相比，Sorted Set 就不存在这个问题，因为它是根据元素的实际权重来排序和获取数据的。\n\n我们可以按评论时间的先后给每条评论设置一个权重值，然后再把评论保存到 Sorted Set 中。Sorted Set 的 ZRANGEBYSCORE 命令就可以按权重排序后返回元素。这样的话，即使集合中的元素频繁更新，Sorted Set 也能通过 ZRANGEBYSCORE 命令准确地获取到按序排列的数据。\n\n假设越新的评论权重越大，目前最新评论的权重是 N，我们执行下面的命令时，就可以获得最新的10条评论：\n\nZRANGEBYSCORE comments N-9 N\n\n\n1\n\n\n所以，在面对需要展示最新列表、排行榜等场景时，如果数据更新频繁或者需要分页显示，建议你优先考虑使用 Sorted Set。\n\n> Sorted Set 可以根据权重来进行排序，但 List 只能根据索引获得值，故增加元素时，Sorted Set 还是可以由权重得到正确的值，但 List 不行。\n\n\n# 2.3 二值状态统计 —— Bitmap\n\n二值状态就是指集合元素的取值就只有 0 和 1 两种。比如在签到打卡的场景中，只用记录签到（1）或未签到（0），所以这就是非常典型的二值状态。\n\n在签到统计时，每个用户一天的签到用 1 个 bit 位就能表示，一个月（假设是31天）的签到情况用 31 个 bit 位就可以，而一年的签到也只需要用 365 个 bit 位，根本不用太复杂的集合类型。这个时候，我们就可以选择 Bitmap。这是Redis提供的扩展数据类型。接下来介绍 Bitmap 的实现原理。\n\nBitmap 本身是用 String 类型作为底层数据结构实现的一种统计二值状态的数据类型。String 类型是会保存为二进制的字节数组，所以，Redis 就把字节数组的每个 bit 位利用起来，用来表示一个元素的二值状态。你可以把 Bitmap 看作是一个 bit 数组。\n\nBitmap 提供了 GETBIT/SETBIT 操作，使用一个偏移值 offset 对 bit 数组的某一个 bit 位进行读和写。不过，需要注意的是，Bitmap 的 offset 是从 0 开始算的，也就是说offset的最小值是0。当使用SETBIT对一个bit位进行写操作时，这个bit位会被设置为1。Bitmap 还提供了 BITCOUNT 操作，用来统计这个bit数组中所有“1”的个数。\n\n那么，具体该怎么用 Bitmap 进行签到统计呢？我还是借助一个具体的例子来说明。假设我们要统计 ID 3000 的用户在2020年8月份的签到情况，就可以按照下面的步骤进行操作：\n\n 1. 执行下面的命令，记录该用户8月3号已签到：\n\nSETBIT uid:sign:3000:202008 2 1\n\n\n1\n\n\n> 上述命令中的 2 表示 8 月的第三天。\n\n 2. 检查该用户8月3日是否签到：\n\nGETBIT uid:sign:3000:202008 2\n\n\n1\n\n 3. 统计该用户在8月份的签到次数：\n\nBITCOUNT uid:sign:3000:202008\n\n\n1\n\n\n这样，我们就知道该用户在8月份的签到情况了，是不是很简单呢？接下来，你可以再思考一个问题：如果记录了1亿个用户10天的签到情况，你有办法统计出这10天连续签到的用户总数吗？\n\n在介绍具体的方法之前，我们要先知道，Bitmap支持用 BITOP 命令对多个Bitmap按位做“与”、“或”、“异或”的操作，操作的结果会保存到一个新的Bitmap中。比如下图对三个 bitmap 做 AND 操作：\n\n回到刚刚的问题，在统计1亿个用户连续10天的签到情况时，你可以把每天的日期作为key，每个key对应一个1亿位的Bitmap，每一个bit对应一个用户当天的签到情况。\n\n接下来，我们对10个Bitmap做“与”操作，得到的结果也是一个Bitmap。在这个Bitmap中，只有10天都签到的用户对应的bit位上的值才会是1。最后，我们可以用BITCOUNT统计下Bitmap中的1的个数，这就是连续签到10天的用户总数了。\n\n现在，我们可以计算一下记录了10天签到情况后的内存开销。每天使用1个1亿位的Bitmap，大约占12MB的内存（10^8/8/1024/1024），10天的Bitmap的内存开销约为120MB，内存压力不算太大。不过，在实际应用时，最好对Bitmap设置过期时间，让Redis自动删除不再需要的签到记录，以节省内存开销。\n\n所以，如果只需要统计数据的二值状态，例如商品有没有、用户在不在等，就可以使用 Bitmap，因为它只用一个bit位就能表示0或1。在记录海量数据时，Bitmap能够有效地节省内存空间。\n\n\n# 2.4 基数统计 —— HyperLogLog\n\n基数统计就是指统计一个集合中不重复的元素个数。比如我们统计一个网页的独立访客（Unique Visitor，UV）量。UV 的统计有个独特的地方：需要去重，一个用户一天内的多次访问只能算作一次。\n\n在Redis的集合类型中，Set类型默认支持去重，所以看到有去重需求时，我们可能第一时间就会想到用Set类型。我们来结合一个例子看一看用Set的情况：有一个用户user1访问page1时，你把这个信息加到Set中：\n\nSADD page1:uv user1\n\n\n1\n\n\n用户1再来访问时，Set 的去重功能就保证了不会重复记录用户1的访问次数，这样，用户1就算是一个独立访客。当你需要统计UV时，可以直接用SCARD命令，这个命令会返回一个集合中的元素个数。但是，如果page1非常火爆，UV达到了千万时，一个Set就要记录千万个用户ID。对于一个搞大促的电商网站而言，这样的页面可能有成千上万个，如果每个页面都用这样的一个Set，就会消耗很大的内存空间。\n\n当然，你也可以用 Hash 类型记录 UV。例如，你可以把用户ID作为Hash集合的key，当用户访问页面时，就用HSET命令（用于设置Hash集合元素的值），对这个用户ID记录一个值“1”，表示一个独立访客，用户1访问page1后，我们就记录为1个独立访客，如下所示：\n\nHSET page1:uv user1 1\n\n\n1\n\n\n即使用户1多次访问页面，重复执行这个HSET命令，也只会把user1的值设置为1，仍然只记为1个独立访客。当要统计 UV 时，我们可以用 HLEN 命令统计 Hash 集合中的所有元素个数。\n\n但是，和Set类型相似，当页面很多时，Hash类型也会消耗很大的内存空间。那么，有什么办法既能完成统计，还能节省内存吗？这时候，就要用到Redis提供的 HyperLogLog 了。\n\nHyperLogLog 是一种用于统计基数的数据集合类型，它的最大优势就在于，当集合元素数量非常多时，它计算基数所需的空间总是固定的，而且还很小。在Redis中，每个 HyperLogLog 只需要花费 12 KB 内存，就可以计算接近 2^64 个元素的基数。你看，和元素越多就越耗费内存的Set和Hash类型相比，HyperLogLog 就非常节省空间。\n\n在统计 UV 时，你可以用 PFADD 命令（用于向 HyperLogLog 中添加新元素）把访问页面的每个用户都添加到 HyperLogLog 中：\n\nPFADD page1:uv user1 user2 user3 user4 user5\n\n\n1\n\n\n接下来，就可以用 PFCOUNT 命令 直接获得 page1 的 UV 值了，这个命令的作用就是返回 HyperLogLog 的统计结果：\n\nPFCOUNT page1:uv\n\n\n1\n\n\n> 关于 HyperLogLog 的具体实现原理，你不需要重点掌握，不会影响到你的日常使用。想要更多了解的话，可以参考这条链接。\n\n不过，有一点需要你注意一下，HyperLogLog 的统计规则是基于概率完成的，所以它给出的统计结果是有一定误差的，标准误算率是 0.81%。这也就意味着，你使用 HyperLogLog 统计的 UV 是 100 万，但实际的 UV 可能是 101 万。虽然误差率不算大，但是，如果你需要精确统计结果的话，最好还是继续用 Set 或 Hash 类型。\n\n\n# 2.5 小结\n\n这一大节针对聚合统计、排序统计、二值状态统计和基数统计四种场景讲解了多个数据结构，汇总如下：\n\n可以看到：\n\n * Set和Sorted Set都支持多种聚合统计，不过，对于差集计算来说，只有Set支持。Bitmap也能做多个Bitmap间的聚合计算，包括与、或和异或操作。\n * 当需要进行排序统计时，List中的元素虽然有序，但是一旦有新元素插入，原来的元素在List中的位置就会移动，那么，按位置读取的排序结果可能就不准确了。而Sorted Set本身是按照集合元素的权重排序，可以准确地按序获取结果，所以建议你优先使用它。\n * 如果我们记录的数据只有0和1两个值的状态，Bitmap会是一个很好的选择，这主要归功于Bitmap对于一个数据只用1个bit记录，可以节省内存。\n * 对于基数统计来说，如果集合元素量达到亿级别而且不需要精确统计时，我建议你使用HyperLogLog。\n\n当然，Redis的应用场景非常多，这张表中的总结不一定能覆盖到所有场景。我建议你也试着自己画一张表，把你遇到的其他场景添加进去。长久积累下来，你一定能够更加灵活地把集合类型应用到合适的实践项目中。\n\n\n# 3. GEO 是什么？还可以定义新的数据类型吗？\n\n我们之前学习了 Redis 的 5 大基本数据类型：String、List、Hash、Set 和 Sorted Set。在面对一些特殊场景时，这些类型无法很好地支持，于是 Redis 还提供了 3 种扩展类型：Bitmap、HyperLogLog 和 GEO。这一节主要讲一下 GEO。\n\n另外节还讲介绍开发自定义的新数据类型的基本步骤，从而满足个人的特殊需求。\n\n\n# 3.1 面向 LBS 应用的 GEO 类型\n\n日常的地图搜索、打车等都离不开基于位置信息服务（Location-Based Service，LBS）的应用。LBS 应用访问的数据是和人或物关联的一组经纬度信息，而且要能查询相邻的经纬度范围，GEO 就非常适合应用在 LBS 服务的场景中，我们来看一下它的底层结构。\n\n# 3.1.1 GEO 的底层结构\n\n一般来说，在设计一个数据类型的底层结构时，我们首先需要知道，要处理的数据有什么访问特点。所以，我们需要先搞清楚位置信息到底是怎么被存取的。\n\n以叫车服务为例，来分析下 LBS 应用中经纬度的存取特点：\n\n 1. 每一辆网约车都有一个编号（例如33），网约车需要将自己的经度信息（例如116.034579）和纬度信息（例如39.000452 ）发给叫车应用。\n 2. 用户在叫车的时候，叫车应用会根据用户的经纬度位置（例如经度116.054579，纬度39.030452），查找用户的附近车辆，并进行匹配。\n 3. 等把位置相近的用户和车辆匹配上以后，叫车应用就会根据车辆的编号，获取车辆的信息，并返回给用户。\n\n----------------------------------------\n\n考虑 Hash Set 类型：\n\n可以看到，一辆车（或一个用户）对应一组经纬度，并且随着车（或用户）的位置移动，相应的经纬度也会变化。这种数据记录模式属于一个key（例如车ID）对应一个value（一组经纬度）。当有很多车辆信息要保存时，就需要有一个集合来保存一系列的key和value。Hash集合类型可以快速存取一系列的key和value，正好可以用来记录一系列车辆ID和经纬度的对应关系，所以，我们可以把不同车辆的ID和它们对应的经纬度信息存在Hash集合中，如下图所示：\n\n同时，Hash类型的HSET操作命令，会根据key来设置相应的value值，所以，我们可以用它来快速地更新车辆变化的经纬度信息。到这里，Hash类型看起来是一个不错的选择。但问题是，对于一个LBS应用来说，除了记录经纬度信息，还需要根据用户的经纬度信息在车辆的Hash集合中进行范围查询。\n\n一旦涉及到范围查询，就意味着集合中的元素需要有序，但Hash类型的元素是无序的，显然不能满足我们的要求。\n\n----------------------------------------\n\n考虑 Sorted Set 类型：\n\n我们再来看看使用 Sorted Set类型是不是合适。\n\nSorted Set 类型也支持一个 key 对应一个 value 的记录模式，其中，key就是Sorted Set中的元素，而value则是元素的权重分数。更重要的是，Sorted Set可以根据元素的权重分数排序，支持范围查询。这就能满足LBS服务中查找相邻位置的需求了。\n\n实际上，GEO 类型的底层数据结构就是用 Sorted Set 来实现的。咱们还是借着叫车应用的例子来加深下理解。用Sorted Set来保存车辆的经纬度信息时，Sorted Set的元素是车辆ID，元素的权重分数是经纬度信息，如下图所示：\n\n这时问题来了，Sorted Set元素的权重分数是一个浮点数（float类型），而一组经纬度包含的是经度和纬度两个值，是没法直接保存为一个浮点数的，那具体该怎么进行保存呢？这就要用到 GEO 类型中的 GeoHash 编码了。\n\n# 3.1.2 GeoHash 的编码方法\n\n为了能高效地对经纬度进行比较，Redis 采用了业界广泛使用的 GeoHash 编码方法，这个方法的基本原理就是“二分区间，区间编码”。\n\n当我们要对一组经纬度进行 GeoHash 编码时，我们要先对经度和纬度分别编码，然后再把经纬度各自的编码组合成一个最终编码。\n\n首先，我们来看下经度和纬度的单独编码过程。\n\n对于一个地理位置信息来说，它的经度范围是 [-180,180] 。GeoHash 编码会把一个经度值编码成一个 N 位的二进制值，我们来对经度范围 [-180,180] 做N次的二分区操作，其中 N 可以自定义。\n\n * 在进行第一次二分区时，经度范围[-180,180]会被分成两个子区间：[-180,0)和[0,180]（我称之为左、右分区）。此时，我们可以查看一下要编码的经度值落在了左分区还是右分区。如果是落在左分区，我们就用0表示；如果落在右分区，就用1表示。这样一来，每做完一次二分区，我们就可以得到1位编码值。\n * 然后，我们再对经度值所属的分区再做一次二分区，同时再次查看经度值落在了二分区后的左分区还是右分区，按照刚才的规则再做1位编码。当做完N次的二分区后，经度值就可以用一个N bit的数来表示了。\n\n举个例子，假设我们要编码的经度值是116.37，我们用5位编码值（也就是N=5，做5次分区）。我们先做第一次二分区操作，把经度区间[-180,180]分成了左分区[-180,0)和右分区[0,180]，此时，经度值116.37是属于右分区[0,180]，所以，我们用1表示第一次二分区后的编码值。接下来，我们做第二次二分区：把经度值116.37所属的[0,180]区间，分成[0,90)和[90, 180]。此时，经度值116.37还是属于右分区[90,180]，所以，第二次分区后的编码值仍然为1。等到第三次对[90,180]进行二分区，经度值116.37落在了分区后的左分区[90, 135)中，所以，第三次分区后的编码值就是0。\n\n按照这种方法，做完5次分区后，我们把经度值116.37定位在[112.5, 123.75]这个区间，并且得到了经度值的5位编码值，即11010。这个编码过程如下表所示：\n\n对纬度的编码方式，和对经度的一样，只是纬度的范围是[-90，90]，下面这张表显示了对纬度值39.86的编码过程：\n\n当一组经纬度值都编完码后，我们再把它们的各自编码值组合在一起，组合的规则是：最终编码值的偶数位上依次是经度的编码值，奇数位上依次是纬度的编码值，其中，偶数位从0开始，奇数位从1开始。\n\n我们刚刚计算的经纬度（116.37，39.86）的各自编码值是11010和10111，组合之后，第0位是经度的第0位1，第1位是纬度的第0位1，第2位是经度的第1位1，第3位是纬度的第1位0，以此类推，就能得到最终编码值1110011101，如下图所示：\n\n用了 GeoHash 编码后，原来无法用一个权重分数表示的一组经纬度（116.37，39.86）就可以用1110011101这一个值来表示，就可以保存为 Sorted Set 的权重分数了。\n\n当然，使用 GeoHash 编码后，我们相当于把整个地理空间划分成了一个个方格，每个方格对应了 GeoHash 中的一个分区。\n\n举个例子。我们把经度区间[-180,180]做一次二分区，把纬度区间[-90,90]做一次二分区，就会得到4个分区。我们来看下它们的经度和纬度范围以及对应的GeoHash组合编码。\n\n * 分区一：[-180,0)和[-90,0)，编码00；\n * 分区二：[-180,0)和[0,90]，编码01；\n * 分区三：[0,180]和[-90,0)，编码10；\n * 分区四：[0,180]和[0,90]，编码11。\n\n这4个分区对应了4个方格，每个方格覆盖了一定范围内的经纬度值，分区越多，每个方格能覆盖到的地理空间就越小，也就越精准。我们把所有方格的编码值映射到一维空间时，相邻方格的 GeoHash 编码值基本也是接近的，如下图所示：\n\n所以，我们使用 Sorted Set 范围查询得到的相近编码值，在实际的地理空间上，也是相邻的方格，这就可以实现LBS应用“搜索附近的人或物”的功能了。\n\n不过要注意，有的编码值虽然在大小上接近，但实际对应的方格却距离比较远。例如，我们用4位来做GeoHash编码，把经度区间[-180,180]和纬度区间[-90,90]各分成了4个分区，一共16个分区，对应了16个方格。编码值为0111和1000的两个方格就离得比较远，如下图所示：\n\n所以，为了避免查询不准确问题，我们可以同时查询给定经纬度所在的方格周围的4个或8个方格。\n\n总结一下，GEO 类型是把经纬度所在的区间编码作为Sorted Set中元素的权重分数，把和经纬度相关的车辆 ID 作为 Sorted Set 中元素本身的值保存下来，这样相邻经纬度的查询就可以通过编码值的大小范围查询来实现了。接下来，我们再来聊聊具体如何操作 GEO 类型。\n\n# 3.1.3 如何操作 GEO 类型？\n\n操作 GEO 类型经常使用两个命令：\n\n * GEOADD 命令：用于把一组经纬度信息和相对应的一个 ID 记录到 GEO 类型集合中；\n * GEORADIUS 命令：会根据输入的经纬度位置，查找以这个经纬度为中心的一定范围内的其他元素。当然，我们可以自己定义这个范围。\n\n我还是以“叫车应用”的车辆匹配场景为例，介绍下具体如何使用这两个命令。\n\n----------------------------------------\n\nGEOADD 命令：\n\n假设车辆ID是33，经纬度位置是（116.034579，39.030452），我们可以用一个 GEO 集合保存所有车辆的经纬度，集合 key 是 cars:locations。执行下面的这个命令，就可以把 ID 号为 33 的车辆的当前经纬度位置存入 GEO 集合中：\n\nGEOADD cars:locations 116.034579 39.030452 33\n\n\n1\n\n\n----------------------------------------\n\nGEORADIUS 命令：\n\n当用户想要寻找自己附近的网约车时，LBS 应用就可以使用 GEORADIUS 命令：\n\n例如，LBS 应用执行下面的命令时，Redis 会根据输入的用户的经纬度信息（116.054579，39.030452 ），查找以这个经纬度为中心的5公里内的车辆信息，并返回给LBS应用。当然， 你可以修改“5”这个参数，来返回更大或更小范围内的车辆信息。\n\nGEORADIUS cars:locations 116.054579 39.030452 5 km ASC COUNT 10\n\n\n1\n\n\n另外，我们还可以进一步限定返回的车辆信息。比如，我们可以使用ASC选项，让返回的车辆信息按照距离这个中心位置从近到远的方式来排序，以方便选择最近的车辆；还可以使用COUNT选项，指定返回的车辆信息的数量。毕竟，5公里范围内的车辆可能有很多，如果返回全部信息，会占用比较多的数据带宽，这个选项可以帮助控制返回的数据量，节省带宽。\n\n可以看到，使用 GEO 数据类型可以非常轻松地操作经纬度这种信息。\n\n尽管 Redis 有如此多数据类型，但是有些场景下，我们对数据类型会有特殊需求。接下来就介绍 Redis 的自定义数据类型。这样你就可以定制符合自己需求的数据类型了。\n\n\n# 3.2 如何自定义数据类型\n\n为了实现自定义数据类型，首先，我们需要了解 Redis 的基本对象结构 RedisObject，因为 Redis 键值对中的每一个值都是用 RedisObject 保存的。\n\n# 3.2.1 Redis 的基本对象结构：RedisObject\n\nRedisObject 主要包括元数据和指针：\n\n * 元数据主要用来区分不同的数据类型；\n * 指针用来指向具体的值。\n\n具体而言，RedisObject 内部包含：\n\n * type：表示值的类型，涵盖了我们前面学习的五大基本类型；\n * encoding：是值的编码方式，用来表示Redis中实现各个基本类型的底层数据结构，例如SDS、压缩列表、哈希表、跳表等；\n * lru：记录了这个对象最后一次被访问的时间，用于淘汰过期的键值对；\n * refcount：记录了对象的引用计数；\n * *ptr：是指向数据的指针。\n\nRedisObject结构借助 *ptr 指针，就可以指向不同的数据类型，例如， *ptr 指向一个SDS或一个跳表，就表示键值对中的值是String类型或Sorted Set类型。所以，我们在定义了新的数据类型后，也只要在RedisObject中设置好新类型的type和encoding，再用 *ptr 指向新类型的实现，就行了。\n\n# 3.2.2 开发一个新的数据类型\n\n了解了 RedisObject 结构后，定义一个新的数据类型也就不难了。首先，我们需要为新数据类型定义好它的底层结构、type 和 encoding 属性值，然后再实现新数据类型的创建、释放函数和基本命令。\n\n我以开发一个名字叫作 NewTypeObject 的新数据类型为例，来解释下具体的4个操作步骤：\n\n----------------------------------------\n\n第一步：定义新数据类型的底层结构.\n\n我们用 newtype.h 文件来保存这个新类型的定义，具体定义的代码如下所示：\n\nstruct NewTypeObject {\n    struct NewTypeNode *head;\n    size_t len;\n} NewTypeObject;\n\n\n1\n2\n3\n4\n\n\n其中，NewTypeNode 结构就是我们自定义的新类型的底层结构。我们为底层结构设计两个成员变量：一个是Long类型的value值，用来保存实际数据；一个是 *next 指针，指向下一个 NewTypeNode 结构。\n\nstruct NewTypeNode {\n    long value;\n    struct NewTypeNode *next;\n};\n\n\n1\n2\n3\n4\n\n\n从代码中可以看到，NewTypeObject 类型的底层结构其实就是一个 Long 类型的单向链表。当然，你还可以根据自己的需求，把 NewTypeObject 的底层结构定义为其他类型。例如，如果我们想要 NewTypeObject 的查询效率比链表高，就可以把它的底层结构设计成一颗B+树。\n\n----------------------------------------\n\n第二步：在RedisObject的type属性中，增加这个新类型的定义.\n\n这个定义是在 Redis 的 server.h 文件中。比如，我们增加一个叫作 OBJ_NEWTYPE 的宏定义，用来在代码中指代 NewTypeObject 这个新类型：\n\n#define OBJ_STRING 0    /* String object. */\n#define OBJ_LIST 1      /* List object. */\n#define OBJ_SET 2       /* Set object. */\n#define OBJ_ZSET 3      /* Sorted set object. */\n…\n#define OBJ_NEWTYPE 7\n\n\n1\n2\n3\n4\n5\n6\n\n\n----------------------------------------\n\n第三步：开发新类型的创建和释放函数.\n\nRedis 把数据类型的创建和释放函数都定义在了 object.c 文件中。所以，我们可以在这个文件中增加 NewTypeObject 的创建函数 createNewTypeObject，如下所示：\n\nrobj *createNewTypeObject(void){\n   NewTypeObject *h = newtypeNew();\n   robj *o = createObject(OBJ_NEWTYPE,h);\n   return o;\n}\n\n\n1\n2\n3\n4\n5\n\n\ncreateNewTypeObject 分别调用了 newtypeNew 和 createObject 两个函数，我分别来介绍下：\n\n * newtypeNew 函数：用来为新数据类型初始化内存结构的。这个初始化过程主要是用zmalloc做底层结构分配空间，以便写入数据：\n\nNewTypeObject *newtypeNew(void){\n    NewTypeObject *n = zmalloc(sizeof(*n));\n    n->head = NULL;\n    n->len = 0;\n    return n;\n}\n\n\n1\n2\n3\n4\n5\n6\n\n\nnewtypeNew 函数涉及到新数据类型的具体创建，而 Redis 默认会为每个数据类型定义一个单独文件，实现这个类型的创建和命令操作，例如，t_string.c和t_list.c分别对应String和List类型。按照Redis的惯例，我们就把newtypeNew函数定义在名为 t_newtype.c 的文件中。\n\n * createObject 函数：Redis本身提供的RedisObject创建函数，它的参数是数据类型的type和指向数据类型实现的指针。\n\n我们给 createObject 函数中传入了两个参数，分别是新类型的 type 值 OBJ_NEWTYPE，以及指向一个初始化过的 NewTypeObjec 的指针。这样一来，创建的 RedisObject 就能指向我们自定义的新数据类型了：\n\nrobj *createObject(int type, void *ptr) {\n    robj *o = zmalloc(sizeof(*o));\n    o->type = type;\n    o->ptr = ptr;\n    ...\n    return o;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n对于释放函数来说，它是创建函数的反过程，是用zfree命令把新结构的内存空间释放掉。\n\n第四步：开发新类型的命令操作.\n\n简单来说，增加相应的命令操作的过程可以分成三小步：\n\n 1. 在 t_newtype.c 文件中增加命令操作的实现。比如说，我们定义 ntinsertCommand 函数，由它实现对 NewTypeObject 单向链表的插入操作：\n\nvoid ntinsertCommand(client *c){\n  //基于客户端传递的参数，实现在NewTypeObject链表头插入元素\n}\n\n\n1\n2\n3\n\n 2. 在 server.h 文件中，声明我们已经实现的命令，以便在 server.c 文件引用这个命令，例如：\n\nvoid ntinsertCommand(client *c)\n\n\n1\n\n 3. 在 server.c 文件中的 redisCommandTable 里面，把新增命令和实现函数关联起来。例如，新增的 ntinsert 命令由 ntinsertCommand 函数实现，我们就可以用 ntinsert 命令给 NewTypeObject 数据类型插入元素了：\n\nstruct redisCommand redisCommandTable[] = {\n    ...\n    {"ntinsert",ntinsertCommand,2,"m",...}\n}\n\n\n1\n2\n3\n4\n\n\n此时，我们就完成了一个自定义的 NewTypeObject 数据类型，可以实现基本的命令操作了。当然，如果你还希望新的数据类型能被持久化保存，我们还需要在 Redis 的 RDB 和 AOF 模块中增加对新数据类型进行持久化保存的代码，我会在后面的加餐中再和你分享。\n\n\n# 3.3 小结\n\n这一节要学习了 Redis 的扩展类型：GEO 类型。它可以记录经纬度形式的地理位置信息，被广泛地应用在LBS服务中。GEO 本身并没有设计新的底层数据结构，而是直接使用了 Sorted Set 集合类型。\n\nGEO类型使用GeoHash编码方法实现了经纬度到Sorted Set中元素权重分数的转换，这其中的两个关键机制就是对二维地图做区间划分，以及对区间进行编码。一组经纬度落在某个区间后，就用区间的编码值来表示，并把编码值作为Sorted Set元素的权重分数。这样一来，我们就可以把经纬度保存到Sorted Set中，利用Sorted Set提供的“按权重进行有序范围查找”的特性，实现LBS服务中频繁使用的“搜索附近”的需求。\n\n之后又讲解了在 Redis 中扩展自定义数据结构的方式。\n\n扩展数据类型的两种实现途径\n\n * 一种是基于现有的数据类型，通过数据编码或是实现新的操作的方式，来实现扩展数据类型，例如基于Sorted Set和GeoHash编码实现GEO，以及基于String和位操作实现Bitmap；\n * 另一种就是开发自定义的数据类型，具体的操作是增加新数据类型的定义，实现创建和释放函数，实现新数据类型支持的命令操作，建议你尝试着把今天学到的内容灵活地应用到你的工作场景中。\n\n----------------------------------------\n\n本节问题：除了我们讲到的五大基本数据类型，还用过什么别的数据类型？\n\nRedis还有一种数据类型，叫作布隆过滤器。它的查询效率很高，经常会用在缓存场景中，可以用来判断数据是否存在缓存中。会在后面（第25讲）具体地介绍一下它。',normalizedContent:'> 参考：\n> \n>  * 11 “万金油”的 string，为什么不好用了？| 极客时间\n>  * 12 有一亿个 keys 要统计，应该用哪种集合？| 极客时间\n>  * 13 geo是什么？还可以定义新的数据类型吗？| 极客时间\n\n这一章进入实践篇，将学习“数据结构”，介绍内存开销以及保存和统计海量数据的数据类型及其底层数据结构，还会围绕典型的应用场景（例如地址位置查询、时间序列数据库读写和消息队列存取），跟你分享使用 redis 的数据类型和 module 扩展功能来满足需求的具体方案。\n\n\n# 1. “万金油”的 string，为什么不好用了？\n\n这一节了解一下 string 类型的内存空间消耗问题，以及选择节省内存开销的数据类型的解决方案。\n\n先分享一个实际的需求。当时要开发一个图片存储系统，要求能快速记录并能够快速根据图片 id 找到对应的图片存储对象 id，即 photo_id -> photo_obj_id。由于图片数量巨大，我们就使用 10 位数来保存这个 id，例如：\n\nphoto_id: 1101000051\nphoto_obj_id: 3301000051\n\n\n1\n2\n\n\n可以看到 photo_id 与 photo_obj_id 一一对应，是典型的“键-单值”模式。所谓的“单值”，就是指键值对中的值就是一个值，而不是一个集合，这和 string 类型提供的“一个键对应一个值的数据”的保存形式刚好契合。\n\n而且，string 类型可以保存二进制字节流，就像“万金油”一样，只要把数据转成二进制字节数组，就可以保存了。\n\n所以，我们的第一个方案就是用 string 保存数据。我们把图片 id 和图片存储对象 id 分别作为键值对的 key 和 value 来保存，其中，图片存储对象 id 用了 string 类型。\n\n刚开始，我们保存了1亿张图片，大约用了6.4gb的内存。但随着图片数据量的不断增加，redis 内存使用量也在增加，导致因生成 rdb 而响应变慢的问题。很显然，string 类型并不是一种好的选择，我们还需要进一步寻找能节省内存开销的数据类型方案。\n\n在这个过程中，我们研究发现：string 类型并不是适用于所有场合的，它有一个明显的短板，就是它保存数据时所消耗的内存空间较多。\n\n同时，我们还仔细研究了集合类型的数据结构，发现，集合类型有非常节省内存空间的底层实现结构，但是，集合类型保存的数据模式，是一个键对应一系列值，并不适合直接保存单值的键值对。所以，我们就使用二级编码的方法，实现了用集合类型保存单值键值对，redis 实例的内存空间消耗明显下降了。\n\n这节课，我就把在解决这个问题时学到的经验和方法分享给你，包括 string 类型的内存空间消耗在哪儿了、用什么数据结构可以节省内存，以及如何用集合类型保存单值键值对。如果你在使用 string 类型时也遇到了内存空间消耗较多的问题，就可以尝试下今天的解决方案了。\n\n接下来，我们先来看看 string 类型的内存都消耗在哪里了。\n\n\n# 1.1 为什么 string 类型内存开销大？\n\n在刚才的案例中，我们保存了1亿张图片的信息，用了约 6.4gb 的内存，一个图片id和图片存储对象id的记录平均用了 64 字节。但问题是，一组图片id及其存储对象id的记录，实际只需要 16 字节就可以了。\n\n我们来分析一下。如果我们可以用两个8字节的 long 类型表示这两个 id，因为 8 字节的long类型最大可以表示 $2^{64}$，所以肯定可以表示 10 位数。但是，为什么 string 类型却用了 64 字节呢？\n\n其实，除了记录实际数据，string类型还需要额外的内存空间记录数据长度、空间使用等信息，这些信息也叫作元数据。当实际保存的数据较小时，元数据的空间开销就显得比较大了，有点“喧宾夺主”的意思。\n\n那么，string 类型具体是怎么保存数据的呢？\n\n当你保存 64 位有符号整数时，string 类型会把它保存为一个 8 字节的 long 类型整数，这种方式通常也称为 int 编码方式。\n\n但当你保存的数据中包含字符时，string 类型就会用简单动态字符串（simple dynamic string，sds）的 struct 来保存：\n\n * buf：char[] 类型，保存实际数据，同时会在尾部加一个 \\0。\n * len：4 byte，表示 buf 的长度。\n * alloc：4 byte，表示 buf 的分配长度。\n\n可以看到，len 和 alloc 就是 sds 结构体的额外开销。另外，对于 string 类型来说，除了 sds，还有一个来自于 redisobject 结构体的开销。\n\nredis 使用 redisobject 结构体来统一记录不同的数据结构的元数据和实际数据位置。其结构示意图如下：\n\n为了节省内存，redis 还对 long 类型整数和 sds 的内存布局做了专门的设计：\n\n * 当保存的是 long 类型时，redisobject 中的 ptr 就直接赋值为整数数据了，这样就不用额外的指针再指向整数了，节省了指针的开销。这也是前面说的 int 编码方式。\n * 当保存的是字符串时，且字符串小于等于 44 byte 时，redisobject 中的元数据、指针和 sds 是一块连续的内存区域，这样就可以避免内存碎片。这种布局方式也被称为 embstr 编码方式。\n * 当字符串大于 44 byte 时，sds 数据量就开始变多，redis 就不再把 sds 和 redisobject 布局在一起了，而是会给 sds 分配独立的空间，并用指针指向 sds 结构。这种布局方式被称为 raw 编码模式。\n\n三种编码方式如下图所示：\n\n现在知道了 redisobject 的额外开销，我们就可以计算 string 类型的内存使用量了。\n\n因为10位数的图片id和图片存储对象id是long类型整数，所以可以直接用int编码的redisobject保存。每个int编码的redisobject元数据部分占8字节，指针部分被直接赋值为8字节的整数了。此时，每个id会使用16字节，加起来一共是32字节。但是，另外的32字节去哪儿了呢？其实，redis 是使用一个全局 hash table 来保存所有的键值对的，哈希表的每一项是一个 dictentry 的结构体，用来指向一个 kv pair。其中 dictentry 有三个 8 byte 的指针，分别指向 key、value 以及下一个 dictentry。一个 dictentry 如下图所示：\n\n但 dictentry 只占了 24 byte，那为啥会占用 32 byte 呢？这就要提到 redis 使用的内存分配库 jemalloc 了。\n\njemalloc 在分配内存时，会根据我们申请的字节数 n，找一个比 n 大，但是最接近 n 的 2 的幂次数作为分配的空间，这样可以减少频繁分配的次数。举个例子。如果你申请6字节空间，jemalloc实际会分配8字节空间；如果你申请24字节空间，jemalloc则会分配32字节。所以，在我们刚刚说的场景里，dictentry结构就占用了32字节。\n\n好了，到这里你就能理解，为什么用string类型保存图片id和图片存储对象id时需要用64个字节了。你看，明明有效信息只有 16 byte，使用 string 类型保存却需要 64 byte 的内存空间，有 48 byte 都是额外开销。那有没有更节省内存的方法呢？\n\n\n# 1.2 用什么数据结构可以节省内存？\n\nredis 有一种底层数据结构，叫压缩列表（ziplist），这是一种非常节省内存的结构。\n\n我们先回顾下压缩列表的构成：表头有三个字段zlbytes、zltail和zllen，分别表示列表长度、列表尾的偏移量，以及列表中的entry个数。压缩列表尾还有一个zlend，表示列表结束。如下图：\n\n压缩列表之所以能节省内存，就在于它是用一系列连续的 entry 保存数据。每个 entry 的元数据包括下面几部分：\n\n * prev_len：表示前一个entry的长度。prev_len有两种取值情况：1字节或5字节。取值1字节时，表示上一个entry的长度小于254字节。虽然1字节的值能表示的数值范围是0到255，但是压缩列表中zlend的取值默认是255，因此，就默认用255表示整个压缩列表的结束，其他表示长度的地方就不能再用255这个值了。所以，当上一个entry长度小于254字节时，prev_len取值为1字节，否则，就取值为5字节。\n * len：表示自身长度，4 byte\n * encoding：表示编码方式，1 byte\n * content：保存实际数据\n\n这些 entry 会挨个儿放置在内存中，不需要再用额外的指针进行连接，这样就可以节省指针所占用的空间。\n\n我们以保存图片存储对象id为例，来分析一下压缩列表是如何节省内存空间的。每个entry保存一个图片存储对象id（8字节），此时，每个entry的prev_len只需要1个字节就行，因为每个entry的前一个entry长度都只有8字节，小于254字节。这样一来，一个图片的存储对象id所占用的内存大小是14字节（1+4+1+8=14），实际分配16字节。\n\nredis基于压缩列表实现了 list、hash 和 sorted set 这样的集合类型，这样做的最大好处就是节省了 dictentry 的开销。当你用 string 类型时，一个键值对就有一个 dictentry，要用 32 字节空间。但采用集合类型时，一个 key 就对应一个集合的数据，能保存的数据多了很多，但也只用了一个 dictentry，这样就节省了内存。\n\n这个方案听起来很好，但还存在一个问题：在用集合类型保存键值对时，一个键对应了一个集合的数据，但是在我们的场景中，一个图片id只对应一个图片的存储对象id，我们该怎么用集合类型呢？换句话说，在一个键对应一个值（也就是单值键值对）的情况下，我们该怎么用集合类型来保存这种单值键值对呢？\n\n\n# 1.3 如何用集合类型保存单值的键值对？\n\n在保存单值的键值对时，可以采用基于 hash 类型的二级编码方法。这里说的二级编码，就是把一个单值的数据拆分成两部分，前一部分作为hash集合的key，后一部分作为hash集合的value，这样一来，我们就可以把单值数据保存到hash集合中了。\n\n以图片id 1101000060和图片存储对象id 3302000080为例，我们可以把图片id的前7位（1101000）作为hash类型的键，把图片id的最后3位（060）和图片存储对象id分别作为hash类型值中的key和value。\n\n按照这种设计方法，我在redis中插入了一组图片id及其存储对象id的记录，并且用info命令查看了内存开销，我发现，增加一条记录后，内存占用只增加了16字节，如下所示：\n\n127.0.0.1:6379> info memory\n# memory\nused_memory:1039120\n127.0.0.1:6379> hset 1101000 060 3302000080\n(integer) 1\n127.0.0.1:6379> info memory\n# memory\nused_memory:1039136\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n在使用 string 类型时，每个记录需要消耗 64 字节，这种方式却只用了 16 字节，所使用的内存空间是原来的 1/4，满足了我们节省内存空间的需求。\n\n不过，你可能也会有疑惑：“二级编码一定要把图片id的前7位作为hash类型的键，把最后3位作为hash类型值中的key吗？” 其实，二级编码方法中采用的id长度是有讲究的。\n\n我们之前讲过，redis 的 hash 类型有两种底层实现结构，分别是压缩列表和哈希表。hash 类型设置了一个用压缩列表保存数据时的阈值，一旦超过阈值，hash 类型就会用哈希表来保存数据了。这两个阈值分别对应以下两个配置项：\n\n * hash-max-ziplist-entries：表示用压缩列表保存时哈希集合中的最大元素个数。\n * hash-max-ziplist-value：表示用压缩列表保存时哈希集合中单个元素的最大长度。\n\n如果我们往hash集合中写入的元素个数超过了 hash-max-ziplist-entries，或者写入的单个元素大小超过了 hash-max-ziplist-value，redis 就会自动把 hash 类型的实现结构由压缩列表转为哈希表。\n\n一旦从压缩列表转为了哈希表，hash 类型就会一直用哈希表进行保存，而不会再转回压缩列表了。在节省内存空间方面，哈希表就没有压缩列表那么高效了。\n\n为了能充分使用压缩列表的精简内存布局，我们一般要控制保存在hash集合中的元素个数。所以，在刚才的二级编码中，我们只用图片id最后3位作为hash集合的key，也就保证了hash集合的元素个数不超过1000，同时，我们把 hash-max-ziplist-entries 设置为 1000，这样一来，hash 集合就可以一直使用压缩列表来节省内存空间了。\n\n\n# 1.4 小结\n\n这一节我们打破了对 string 的认知误区，了解到 string 并非万金油，当保存的 kv pair 本身占用内存空间不大时，string 类型的元数据开销就占据主导了，这包括了 redisobject、sds、dictentry 结构的内存开销。\n\n针对这种情况，我们可以借助压缩列表这种底层结构，使用 hash 类型的二级编码方法来保存单值 kv pair 的数据。也就是需要将原 kv pair 的 key 拆成两部分，前一部分作为 hash 集合的 key，后一部分与原 kv pair 的 value 组合成一个新 kv 来作为 hash 集合的 value。\n\n小妙招：如果你想知道 kv pair 采用不同类型保存时的内存开销，可以在redis 容量预估这个网站上进行估计。\n\n\n# 2. 有一亿个keys要统计，应该用哪种集合？\n\n很多场景需要保存这样一种数据：一个 key 对应了一个数据集合。比如:\n\n * 手机app中的每天的用户登录信息：一天 -> 用户 id / 登录设备;\n * 电商网站上商品的用户评论列表：一个商品 -> 一系列评论；\n * 用户在手机app上的签到打卡信息：员工 -> 一天打卡记录。\n\nredis 的集合类型很适合存储这些数据，但在这些场景中，除了记录信息，我们往往还需要对集合中的数据进行统计，比如统计每天新增用户数、统计评论列表中的最新评论、一个月连续打卡的员工数等。通常我们会面临巨大的访问量，比如百万、千万级别。所以，我们必须要能够选择非常高效地统计大量数据（例如亿级）的集合类型。\n\n要想选择合适的集合，我们就得了解常用的集合统计模式。这一节将介绍集合类型的常见四种统计模式：聚合统计、排序统计、二值状态统计和基数统计，并介绍这些统计场景下什么数据结构更加合适。\n\n\n# 2.1 聚合统计 —— set\n\n聚合统计：指统计多个集合元素的聚合结果，包括：统计多个集合的共有元素（交集统计）；把两个集合相比，统计其中一个集合独有的元素（差集统计）；统计多个集合的所有元素（并集统计）。\n\n比如统计手机 app 每天的新增用户数和第二天的留存用户数就是聚合统计。要完成这个统计任务，我们可以用一个集合记录所有登录过app的用户id，同时，用另一个集合记录每一天登录过app的用户id。然后，再对这两个集合做聚合统计。我们来看下具体的操作。\n\n可以使用 set 类型来记录所有登录过 app 的用户 id，把 key 设置成 user:id，value 就是保存了所有登陆过 app 的用户 id 的 set，如下图：\n\n还需要记录每一天登录的用户 id，可以让 key 设为 user:id:<datetime>，比如 user:id:20200803，value 是记录了当天登录的所有用户 id 的 set。如下图：\n\n在统计每天的新增用户时，我们只用计算每日用户 set 和累计用户 set 的差集就行。\n\n当你需要对多个集合进行聚合计算时，set 类型会是一个非常不错的选择。不过，这里有一个潜在的风险：set 的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，会导致redis实例阻塞。所以这里给一个小建议：你可以从主从集群中选择一个从库，让它专门负责聚合计算，或者是把数据读取到客户端，在客户端来完成聚合统计，这样就可以规避阻塞主库实例和其他从库实例的风险了。\n\n\n# 2.2 排序统计 —— 有序集合\n\n这一小节讲应对集合元素排序的需求的方法，这里以电商网站提供最新评论列表的场景为例进行讲解。\n\n最新评论列表包含了所有评论中的最新留言，这就要求集合类型能对元素保序，这种对元素保序的集合类型叫作有序集合。在 redis 的四个集合类型中（list、hash、set 和 sorted set），list 和 sorted set 就属于有序集合。\n\n * list 按照元素添加的顺序进行排序；\n * sorted set 按照元素的权重来排序，其中权重值可以自己决定（比如让插入时间作为权重）。\n\n貌似都符合需求，接下来看一下如何选择。\n\n----------------------------------------\n\n如果使用 list 的话。每个商品对应一个 list，这个 list 包含了该商品的全部评论，并按照评论时间保存，每来一个新评论就用 lpush 命令把它插入到 list 的队头。\n\n在只有一页评论的时候，我们可以很清晰地看到最新的评论，但是，在实际应用中，网站一般会分页显示最新的评论列表，一旦涉及到分页操作，list就可能会出现问题了。\n\n假设当前的评论list是{a, b, c, d, e, f}（其中，a是最新的评论，以此类推，f是最早的评论），在展示第一页的3个评论时，我们可以用下面的命令，得到最新的三条评论a、b、c：\n\nlrange product1 0 2\n1) "a"\n2) "b"\n3) "c"\n\n\n1\n2\n3\n4\n\n\n然后，再用下面的命令获取第二页的3个评论，也就是d、e、f：\n\nlrange product1 3 5\n1) "d"\n2) "e"\n3) "f"\n\n\n1\n2\n3\n4\n\n\n但是，如果在展示第二页前，又产生了一个新评论g，评论g就会被lpush命令插入到评论list的队头，评论list就变成了{g, a, b, c, d, e, f}。此时，再用刚才的命令获取第二页评论时，就会发现，评论c又被展示出来了，也就是c、d、e：\n\nlrange product1 3 5\n1) "c"\n2) "d"\n3) "e"\n\n\n1\n2\n3\n4\n\n\n之所以会这样，关键原因就在于，list是通过元素在list中的位置来排序的，当有一个新元素插入时，原先的元素在list中的位置都后移了一位，比如说原来在第1位的元素现在排在了第2位。所以，对比新元素插入前后，list 相同位置上的元素就会发生变化，用 lrange 读取时，就会读到旧元素。\n\n----------------------------------------\n\n和 list 相比，sorted set 就不存在这个问题，因为它是根据元素的实际权重来排序和获取数据的。\n\n我们可以按评论时间的先后给每条评论设置一个权重值，然后再把评论保存到 sorted set 中。sorted set 的 zrangebyscore 命令就可以按权重排序后返回元素。这样的话，即使集合中的元素频繁更新，sorted set 也能通过 zrangebyscore 命令准确地获取到按序排列的数据。\n\n假设越新的评论权重越大，目前最新评论的权重是 n，我们执行下面的命令时，就可以获得最新的10条评论：\n\nzrangebyscore comments n-9 n\n\n\n1\n\n\n所以，在面对需要展示最新列表、排行榜等场景时，如果数据更新频繁或者需要分页显示，建议你优先考虑使用 sorted set。\n\n> sorted set 可以根据权重来进行排序，但 list 只能根据索引获得值，故增加元素时，sorted set 还是可以由权重得到正确的值，但 list 不行。\n\n\n# 2.3 二值状态统计 —— bitmap\n\n二值状态就是指集合元素的取值就只有 0 和 1 两种。比如在签到打卡的场景中，只用记录签到（1）或未签到（0），所以这就是非常典型的二值状态。\n\n在签到统计时，每个用户一天的签到用 1 个 bit 位就能表示，一个月（假设是31天）的签到情况用 31 个 bit 位就可以，而一年的签到也只需要用 365 个 bit 位，根本不用太复杂的集合类型。这个时候，我们就可以选择 bitmap。这是redis提供的扩展数据类型。接下来介绍 bitmap 的实现原理。\n\nbitmap 本身是用 string 类型作为底层数据结构实现的一种统计二值状态的数据类型。string 类型是会保存为二进制的字节数组，所以，redis 就把字节数组的每个 bit 位利用起来，用来表示一个元素的二值状态。你可以把 bitmap 看作是一个 bit 数组。\n\nbitmap 提供了 getbit/setbit 操作，使用一个偏移值 offset 对 bit 数组的某一个 bit 位进行读和写。不过，需要注意的是，bitmap 的 offset 是从 0 开始算的，也就是说offset的最小值是0。当使用setbit对一个bit位进行写操作时，这个bit位会被设置为1。bitmap 还提供了 bitcount 操作，用来统计这个bit数组中所有“1”的个数。\n\n那么，具体该怎么用 bitmap 进行签到统计呢？我还是借助一个具体的例子来说明。假设我们要统计 id 3000 的用户在2020年8月份的签到情况，就可以按照下面的步骤进行操作：\n\n 1. 执行下面的命令，记录该用户8月3号已签到：\n\nsetbit uid:sign:3000:202008 2 1\n\n\n1\n\n\n> 上述命令中的 2 表示 8 月的第三天。\n\n 2. 检查该用户8月3日是否签到：\n\ngetbit uid:sign:3000:202008 2\n\n\n1\n\n 3. 统计该用户在8月份的签到次数：\n\nbitcount uid:sign:3000:202008\n\n\n1\n\n\n这样，我们就知道该用户在8月份的签到情况了，是不是很简单呢？接下来，你可以再思考一个问题：如果记录了1亿个用户10天的签到情况，你有办法统计出这10天连续签到的用户总数吗？\n\n在介绍具体的方法之前，我们要先知道，bitmap支持用 bitop 命令对多个bitmap按位做“与”、“或”、“异或”的操作，操作的结果会保存到一个新的bitmap中。比如下图对三个 bitmap 做 and 操作：\n\n回到刚刚的问题，在统计1亿个用户连续10天的签到情况时，你可以把每天的日期作为key，每个key对应一个1亿位的bitmap，每一个bit对应一个用户当天的签到情况。\n\n接下来，我们对10个bitmap做“与”操作，得到的结果也是一个bitmap。在这个bitmap中，只有10天都签到的用户对应的bit位上的值才会是1。最后，我们可以用bitcount统计下bitmap中的1的个数，这就是连续签到10天的用户总数了。\n\n现在，我们可以计算一下记录了10天签到情况后的内存开销。每天使用1个1亿位的bitmap，大约占12mb的内存（10^8/8/1024/1024），10天的bitmap的内存开销约为120mb，内存压力不算太大。不过，在实际应用时，最好对bitmap设置过期时间，让redis自动删除不再需要的签到记录，以节省内存开销。\n\n所以，如果只需要统计数据的二值状态，例如商品有没有、用户在不在等，就可以使用 bitmap，因为它只用一个bit位就能表示0或1。在记录海量数据时，bitmap能够有效地节省内存空间。\n\n\n# 2.4 基数统计 —— hyperloglog\n\n基数统计就是指统计一个集合中不重复的元素个数。比如我们统计一个网页的独立访客（unique visitor，uv）量。uv 的统计有个独特的地方：需要去重，一个用户一天内的多次访问只能算作一次。\n\n在redis的集合类型中，set类型默认支持去重，所以看到有去重需求时，我们可能第一时间就会想到用set类型。我们来结合一个例子看一看用set的情况：有一个用户user1访问page1时，你把这个信息加到set中：\n\nsadd page1:uv user1\n\n\n1\n\n\n用户1再来访问时，set 的去重功能就保证了不会重复记录用户1的访问次数，这样，用户1就算是一个独立访客。当你需要统计uv时，可以直接用scard命令，这个命令会返回一个集合中的元素个数。但是，如果page1非常火爆，uv达到了千万时，一个set就要记录千万个用户id。对于一个搞大促的电商网站而言，这样的页面可能有成千上万个，如果每个页面都用这样的一个set，就会消耗很大的内存空间。\n\n当然，你也可以用 hash 类型记录 uv。例如，你可以把用户id作为hash集合的key，当用户访问页面时，就用hset命令（用于设置hash集合元素的值），对这个用户id记录一个值“1”，表示一个独立访客，用户1访问page1后，我们就记录为1个独立访客，如下所示：\n\nhset page1:uv user1 1\n\n\n1\n\n\n即使用户1多次访问页面，重复执行这个hset命令，也只会把user1的值设置为1，仍然只记为1个独立访客。当要统计 uv 时，我们可以用 hlen 命令统计 hash 集合中的所有元素个数。\n\n但是，和set类型相似，当页面很多时，hash类型也会消耗很大的内存空间。那么，有什么办法既能完成统计，还能节省内存吗？这时候，就要用到redis提供的 hyperloglog 了。\n\nhyperloglog 是一种用于统计基数的数据集合类型，它的最大优势就在于，当集合元素数量非常多时，它计算基数所需的空间总是固定的，而且还很小。在redis中，每个 hyperloglog 只需要花费 12 kb 内存，就可以计算接近 2^64 个元素的基数。你看，和元素越多就越耗费内存的set和hash类型相比，hyperloglog 就非常节省空间。\n\n在统计 uv 时，你可以用 pfadd 命令（用于向 hyperloglog 中添加新元素）把访问页面的每个用户都添加到 hyperloglog 中：\n\npfadd page1:uv user1 user2 user3 user4 user5\n\n\n1\n\n\n接下来，就可以用 pfcount 命令 直接获得 page1 的 uv 值了，这个命令的作用就是返回 hyperloglog 的统计结果：\n\npfcount page1:uv\n\n\n1\n\n\n> 关于 hyperloglog 的具体实现原理，你不需要重点掌握，不会影响到你的日常使用。想要更多了解的话，可以参考这条链接。\n\n不过，有一点需要你注意一下，hyperloglog 的统计规则是基于概率完成的，所以它给出的统计结果是有一定误差的，标准误算率是 0.81%。这也就意味着，你使用 hyperloglog 统计的 uv 是 100 万，但实际的 uv 可能是 101 万。虽然误差率不算大，但是，如果你需要精确统计结果的话，最好还是继续用 set 或 hash 类型。\n\n\n# 2.5 小结\n\n这一大节针对聚合统计、排序统计、二值状态统计和基数统计四种场景讲解了多个数据结构，汇总如下：\n\n可以看到：\n\n * set和sorted set都支持多种聚合统计，不过，对于差集计算来说，只有set支持。bitmap也能做多个bitmap间的聚合计算，包括与、或和异或操作。\n * 当需要进行排序统计时，list中的元素虽然有序，但是一旦有新元素插入，原来的元素在list中的位置就会移动，那么，按位置读取的排序结果可能就不准确了。而sorted set本身是按照集合元素的权重排序，可以准确地按序获取结果，所以建议你优先使用它。\n * 如果我们记录的数据只有0和1两个值的状态，bitmap会是一个很好的选择，这主要归功于bitmap对于一个数据只用1个bit记录，可以节省内存。\n * 对于基数统计来说，如果集合元素量达到亿级别而且不需要精确统计时，我建议你使用hyperloglog。\n\n当然，redis的应用场景非常多，这张表中的总结不一定能覆盖到所有场景。我建议你也试着自己画一张表，把你遇到的其他场景添加进去。长久积累下来，你一定能够更加灵活地把集合类型应用到合适的实践项目中。\n\n\n# 3. geo 是什么？还可以定义新的数据类型吗？\n\n我们之前学习了 redis 的 5 大基本数据类型：string、list、hash、set 和 sorted set。在面对一些特殊场景时，这些类型无法很好地支持，于是 redis 还提供了 3 种扩展类型：bitmap、hyperloglog 和 geo。这一节主要讲一下 geo。\n\n另外节还讲介绍开发自定义的新数据类型的基本步骤，从而满足个人的特殊需求。\n\n\n# 3.1 面向 lbs 应用的 geo 类型\n\n日常的地图搜索、打车等都离不开基于位置信息服务（location-based service，lbs）的应用。lbs 应用访问的数据是和人或物关联的一组经纬度信息，而且要能查询相邻的经纬度范围，geo 就非常适合应用在 lbs 服务的场景中，我们来看一下它的底层结构。\n\n# 3.1.1 geo 的底层结构\n\n一般来说，在设计一个数据类型的底层结构时，我们首先需要知道，要处理的数据有什么访问特点。所以，我们需要先搞清楚位置信息到底是怎么被存取的。\n\n以叫车服务为例，来分析下 lbs 应用中经纬度的存取特点：\n\n 1. 每一辆网约车都有一个编号（例如33），网约车需要将自己的经度信息（例如116.034579）和纬度信息（例如39.000452 ）发给叫车应用。\n 2. 用户在叫车的时候，叫车应用会根据用户的经纬度位置（例如经度116.054579，纬度39.030452），查找用户的附近车辆，并进行匹配。\n 3. 等把位置相近的用户和车辆匹配上以后，叫车应用就会根据车辆的编号，获取车辆的信息，并返回给用户。\n\n----------------------------------------\n\n考虑 hash set 类型：\n\n可以看到，一辆车（或一个用户）对应一组经纬度，并且随着车（或用户）的位置移动，相应的经纬度也会变化。这种数据记录模式属于一个key（例如车id）对应一个value（一组经纬度）。当有很多车辆信息要保存时，就需要有一个集合来保存一系列的key和value。hash集合类型可以快速存取一系列的key和value，正好可以用来记录一系列车辆id和经纬度的对应关系，所以，我们可以把不同车辆的id和它们对应的经纬度信息存在hash集合中，如下图所示：\n\n同时，hash类型的hset操作命令，会根据key来设置相应的value值，所以，我们可以用它来快速地更新车辆变化的经纬度信息。到这里，hash类型看起来是一个不错的选择。但问题是，对于一个lbs应用来说，除了记录经纬度信息，还需要根据用户的经纬度信息在车辆的hash集合中进行范围查询。\n\n一旦涉及到范围查询，就意味着集合中的元素需要有序，但hash类型的元素是无序的，显然不能满足我们的要求。\n\n----------------------------------------\n\n考虑 sorted set 类型：\n\n我们再来看看使用 sorted set类型是不是合适。\n\nsorted set 类型也支持一个 key 对应一个 value 的记录模式，其中，key就是sorted set中的元素，而value则是元素的权重分数。更重要的是，sorted set可以根据元素的权重分数排序，支持范围查询。这就能满足lbs服务中查找相邻位置的需求了。\n\n实际上，geo 类型的底层数据结构就是用 sorted set 来实现的。咱们还是借着叫车应用的例子来加深下理解。用sorted set来保存车辆的经纬度信息时，sorted set的元素是车辆id，元素的权重分数是经纬度信息，如下图所示：\n\n这时问题来了，sorted set元素的权重分数是一个浮点数（float类型），而一组经纬度包含的是经度和纬度两个值，是没法直接保存为一个浮点数的，那具体该怎么进行保存呢？这就要用到 geo 类型中的 geohash 编码了。\n\n# 3.1.2 geohash 的编码方法\n\n为了能高效地对经纬度进行比较，redis 采用了业界广泛使用的 geohash 编码方法，这个方法的基本原理就是“二分区间，区间编码”。\n\n当我们要对一组经纬度进行 geohash 编码时，我们要先对经度和纬度分别编码，然后再把经纬度各自的编码组合成一个最终编码。\n\n首先，我们来看下经度和纬度的单独编码过程。\n\n对于一个地理位置信息来说，它的经度范围是 [-180,180] 。geohash 编码会把一个经度值编码成一个 n 位的二进制值，我们来对经度范围 [-180,180] 做n次的二分区操作，其中 n 可以自定义。\n\n * 在进行第一次二分区时，经度范围[-180,180]会被分成两个子区间：[-180,0)和[0,180]（我称之为左、右分区）。此时，我们可以查看一下要编码的经度值落在了左分区还是右分区。如果是落在左分区，我们就用0表示；如果落在右分区，就用1表示。这样一来，每做完一次二分区，我们就可以得到1位编码值。\n * 然后，我们再对经度值所属的分区再做一次二分区，同时再次查看经度值落在了二分区后的左分区还是右分区，按照刚才的规则再做1位编码。当做完n次的二分区后，经度值就可以用一个n bit的数来表示了。\n\n举个例子，假设我们要编码的经度值是116.37，我们用5位编码值（也就是n=5，做5次分区）。我们先做第一次二分区操作，把经度区间[-180,180]分成了左分区[-180,0)和右分区[0,180]，此时，经度值116.37是属于右分区[0,180]，所以，我们用1表示第一次二分区后的编码值。接下来，我们做第二次二分区：把经度值116.37所属的[0,180]区间，分成[0,90)和[90, 180]。此时，经度值116.37还是属于右分区[90,180]，所以，第二次分区后的编码值仍然为1。等到第三次对[90,180]进行二分区，经度值116.37落在了分区后的左分区[90, 135)中，所以，第三次分区后的编码值就是0。\n\n按照这种方法，做完5次分区后，我们把经度值116.37定位在[112.5, 123.75]这个区间，并且得到了经度值的5位编码值，即11010。这个编码过程如下表所示：\n\n对纬度的编码方式，和对经度的一样，只是纬度的范围是[-90，90]，下面这张表显示了对纬度值39.86的编码过程：\n\n当一组经纬度值都编完码后，我们再把它们的各自编码值组合在一起，组合的规则是：最终编码值的偶数位上依次是经度的编码值，奇数位上依次是纬度的编码值，其中，偶数位从0开始，奇数位从1开始。\n\n我们刚刚计算的经纬度（116.37，39.86）的各自编码值是11010和10111，组合之后，第0位是经度的第0位1，第1位是纬度的第0位1，第2位是经度的第1位1，第3位是纬度的第1位0，以此类推，就能得到最终编码值1110011101，如下图所示：\n\n用了 geohash 编码后，原来无法用一个权重分数表示的一组经纬度（116.37，39.86）就可以用1110011101这一个值来表示，就可以保存为 sorted set 的权重分数了。\n\n当然，使用 geohash 编码后，我们相当于把整个地理空间划分成了一个个方格，每个方格对应了 geohash 中的一个分区。\n\n举个例子。我们把经度区间[-180,180]做一次二分区，把纬度区间[-90,90]做一次二分区，就会得到4个分区。我们来看下它们的经度和纬度范围以及对应的geohash组合编码。\n\n * 分区一：[-180,0)和[-90,0)，编码00；\n * 分区二：[-180,0)和[0,90]，编码01；\n * 分区三：[0,180]和[-90,0)，编码10；\n * 分区四：[0,180]和[0,90]，编码11。\n\n这4个分区对应了4个方格，每个方格覆盖了一定范围内的经纬度值，分区越多，每个方格能覆盖到的地理空间就越小，也就越精准。我们把所有方格的编码值映射到一维空间时，相邻方格的 geohash 编码值基本也是接近的，如下图所示：\n\n所以，我们使用 sorted set 范围查询得到的相近编码值，在实际的地理空间上，也是相邻的方格，这就可以实现lbs应用“搜索附近的人或物”的功能了。\n\n不过要注意，有的编码值虽然在大小上接近，但实际对应的方格却距离比较远。例如，我们用4位来做geohash编码，把经度区间[-180,180]和纬度区间[-90,90]各分成了4个分区，一共16个分区，对应了16个方格。编码值为0111和1000的两个方格就离得比较远，如下图所示：\n\n所以，为了避免查询不准确问题，我们可以同时查询给定经纬度所在的方格周围的4个或8个方格。\n\n总结一下，geo 类型是把经纬度所在的区间编码作为sorted set中元素的权重分数，把和经纬度相关的车辆 id 作为 sorted set 中元素本身的值保存下来，这样相邻经纬度的查询就可以通过编码值的大小范围查询来实现了。接下来，我们再来聊聊具体如何操作 geo 类型。\n\n# 3.1.3 如何操作 geo 类型？\n\n操作 geo 类型经常使用两个命令：\n\n * geoadd 命令：用于把一组经纬度信息和相对应的一个 id 记录到 geo 类型集合中；\n * georadius 命令：会根据输入的经纬度位置，查找以这个经纬度为中心的一定范围内的其他元素。当然，我们可以自己定义这个范围。\n\n我还是以“叫车应用”的车辆匹配场景为例，介绍下具体如何使用这两个命令。\n\n----------------------------------------\n\ngeoadd 命令：\n\n假设车辆id是33，经纬度位置是（116.034579，39.030452），我们可以用一个 geo 集合保存所有车辆的经纬度，集合 key 是 cars:locations。执行下面的这个命令，就可以把 id 号为 33 的车辆的当前经纬度位置存入 geo 集合中：\n\ngeoadd cars:locations 116.034579 39.030452 33\n\n\n1\n\n\n----------------------------------------\n\ngeoradius 命令：\n\n当用户想要寻找自己附近的网约车时，lbs 应用就可以使用 georadius 命令：\n\n例如，lbs 应用执行下面的命令时，redis 会根据输入的用户的经纬度信息（116.054579，39.030452 ），查找以这个经纬度为中心的5公里内的车辆信息，并返回给lbs应用。当然， 你可以修改“5”这个参数，来返回更大或更小范围内的车辆信息。\n\ngeoradius cars:locations 116.054579 39.030452 5 km asc count 10\n\n\n1\n\n\n另外，我们还可以进一步限定返回的车辆信息。比如，我们可以使用asc选项，让返回的车辆信息按照距离这个中心位置从近到远的方式来排序，以方便选择最近的车辆；还可以使用count选项，指定返回的车辆信息的数量。毕竟，5公里范围内的车辆可能有很多，如果返回全部信息，会占用比较多的数据带宽，这个选项可以帮助控制返回的数据量，节省带宽。\n\n可以看到，使用 geo 数据类型可以非常轻松地操作经纬度这种信息。\n\n尽管 redis 有如此多数据类型，但是有些场景下，我们对数据类型会有特殊需求。接下来就介绍 redis 的自定义数据类型。这样你就可以定制符合自己需求的数据类型了。\n\n\n# 3.2 如何自定义数据类型\n\n为了实现自定义数据类型，首先，我们需要了解 redis 的基本对象结构 redisobject，因为 redis 键值对中的每一个值都是用 redisobject 保存的。\n\n# 3.2.1 redis 的基本对象结构：redisobject\n\nredisobject 主要包括元数据和指针：\n\n * 元数据主要用来区分不同的数据类型；\n * 指针用来指向具体的值。\n\n具体而言，redisobject 内部包含：\n\n * type：表示值的类型，涵盖了我们前面学习的五大基本类型；\n * encoding：是值的编码方式，用来表示redis中实现各个基本类型的底层数据结构，例如sds、压缩列表、哈希表、跳表等；\n * lru：记录了这个对象最后一次被访问的时间，用于淘汰过期的键值对；\n * refcount：记录了对象的引用计数；\n * *ptr：是指向数据的指针。\n\nredisobject结构借助 *ptr 指针，就可以指向不同的数据类型，例如， *ptr 指向一个sds或一个跳表，就表示键值对中的值是string类型或sorted set类型。所以，我们在定义了新的数据类型后，也只要在redisobject中设置好新类型的type和encoding，再用 *ptr 指向新类型的实现，就行了。\n\n# 3.2.2 开发一个新的数据类型\n\n了解了 redisobject 结构后，定义一个新的数据类型也就不难了。首先，我们需要为新数据类型定义好它的底层结构、type 和 encoding 属性值，然后再实现新数据类型的创建、释放函数和基本命令。\n\n我以开发一个名字叫作 newtypeobject 的新数据类型为例，来解释下具体的4个操作步骤：\n\n----------------------------------------\n\n第一步：定义新数据类型的底层结构.\n\n我们用 newtype.h 文件来保存这个新类型的定义，具体定义的代码如下所示：\n\nstruct newtypeobject {\n    struct newtypenode *head;\n    size_t len;\n} newtypeobject;\n\n\n1\n2\n3\n4\n\n\n其中，newtypenode 结构就是我们自定义的新类型的底层结构。我们为底层结构设计两个成员变量：一个是long类型的value值，用来保存实际数据；一个是 *next 指针，指向下一个 newtypenode 结构。\n\nstruct newtypenode {\n    long value;\n    struct newtypenode *next;\n};\n\n\n1\n2\n3\n4\n\n\n从代码中可以看到，newtypeobject 类型的底层结构其实就是一个 long 类型的单向链表。当然，你还可以根据自己的需求，把 newtypeobject 的底层结构定义为其他类型。例如，如果我们想要 newtypeobject 的查询效率比链表高，就可以把它的底层结构设计成一颗b+树。\n\n----------------------------------------\n\n第二步：在redisobject的type属性中，增加这个新类型的定义.\n\n这个定义是在 redis 的 server.h 文件中。比如，我们增加一个叫作 obj_newtype 的宏定义，用来在代码中指代 newtypeobject 这个新类型：\n\n#define obj_string 0    /* string object. */\n#define obj_list 1      /* list object. */\n#define obj_set 2       /* set object. */\n#define obj_zset 3      /* sorted set object. */\n…\n#define obj_newtype 7\n\n\n1\n2\n3\n4\n5\n6\n\n\n----------------------------------------\n\n第三步：开发新类型的创建和释放函数.\n\nredis 把数据类型的创建和释放函数都定义在了 object.c 文件中。所以，我们可以在这个文件中增加 newtypeobject 的创建函数 createnewtypeobject，如下所示：\n\nrobj *createnewtypeobject(void){\n   newtypeobject *h = newtypenew();\n   robj *o = createobject(obj_newtype,h);\n   return o;\n}\n\n\n1\n2\n3\n4\n5\n\n\ncreatenewtypeobject 分别调用了 newtypenew 和 createobject 两个函数，我分别来介绍下：\n\n * newtypenew 函数：用来为新数据类型初始化内存结构的。这个初始化过程主要是用zmalloc做底层结构分配空间，以便写入数据：\n\nnewtypeobject *newtypenew(void){\n    newtypeobject *n = zmalloc(sizeof(*n));\n    n->head = null;\n    n->len = 0;\n    return n;\n}\n\n\n1\n2\n3\n4\n5\n6\n\n\nnewtypenew 函数涉及到新数据类型的具体创建，而 redis 默认会为每个数据类型定义一个单独文件，实现这个类型的创建和命令操作，例如，t_string.c和t_list.c分别对应string和list类型。按照redis的惯例，我们就把newtypenew函数定义在名为 t_newtype.c 的文件中。\n\n * createobject 函数：redis本身提供的redisobject创建函数，它的参数是数据类型的type和指向数据类型实现的指针。\n\n我们给 createobject 函数中传入了两个参数，分别是新类型的 type 值 obj_newtype，以及指向一个初始化过的 newtypeobjec 的指针。这样一来，创建的 redisobject 就能指向我们自定义的新数据类型了：\n\nrobj *createobject(int type, void *ptr) {\n    robj *o = zmalloc(sizeof(*o));\n    o->type = type;\n    o->ptr = ptr;\n    ...\n    return o;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n对于释放函数来说，它是创建函数的反过程，是用zfree命令把新结构的内存空间释放掉。\n\n第四步：开发新类型的命令操作.\n\n简单来说，增加相应的命令操作的过程可以分成三小步：\n\n 1. 在 t_newtype.c 文件中增加命令操作的实现。比如说，我们定义 ntinsertcommand 函数，由它实现对 newtypeobject 单向链表的插入操作：\n\nvoid ntinsertcommand(client *c){\n  //基于客户端传递的参数，实现在newtypeobject链表头插入元素\n}\n\n\n1\n2\n3\n\n 2. 在 server.h 文件中，声明我们已经实现的命令，以便在 server.c 文件引用这个命令，例如：\n\nvoid ntinsertcommand(client *c)\n\n\n1\n\n 3. 在 server.c 文件中的 rediscommandtable 里面，把新增命令和实现函数关联起来。例如，新增的 ntinsert 命令由 ntinsertcommand 函数实现，我们就可以用 ntinsert 命令给 newtypeobject 数据类型插入元素了：\n\nstruct rediscommand rediscommandtable[] = {\n    ...\n    {"ntinsert",ntinsertcommand,2,"m",...}\n}\n\n\n1\n2\n3\n4\n\n\n此时，我们就完成了一个自定义的 newtypeobject 数据类型，可以实现基本的命令操作了。当然，如果你还希望新的数据类型能被持久化保存，我们还需要在 redis 的 rdb 和 aof 模块中增加对新数据类型进行持久化保存的代码，我会在后面的加餐中再和你分享。\n\n\n# 3.3 小结\n\n这一节要学习了 redis 的扩展类型：geo 类型。它可以记录经纬度形式的地理位置信息，被广泛地应用在lbs服务中。geo 本身并没有设计新的底层数据结构，而是直接使用了 sorted set 集合类型。\n\ngeo类型使用geohash编码方法实现了经纬度到sorted set中元素权重分数的转换，这其中的两个关键机制就是对二维地图做区间划分，以及对区间进行编码。一组经纬度落在某个区间后，就用区间的编码值来表示，并把编码值作为sorted set元素的权重分数。这样一来，我们就可以把经纬度保存到sorted set中，利用sorted set提供的“按权重进行有序范围查找”的特性，实现lbs服务中频繁使用的“搜索附近”的需求。\n\n之后又讲解了在 redis 中扩展自定义数据结构的方式。\n\n扩展数据类型的两种实现途径\n\n * 一种是基于现有的数据类型，通过数据编码或是实现新的操作的方式，来实现扩展数据类型，例如基于sorted set和geohash编码实现geo，以及基于string和位操作实现bitmap；\n * 另一种就是开发自定义的数据类型，具体的操作是增加新数据类型的定义，实现创建和释放函数，实现新数据类型支持的命令操作，建议你尝试着把今天学到的内容灵活地应用到你的工作场景中。\n\n----------------------------------------\n\n本节问题：除了我们讲到的五大基本数据类型，还用过什么别的数据类型？\n\nredis还有一种数据类型，叫作布隆过滤器。它的查询效率很高，经常会用在缓存场景中，可以用来判断数据是否存在缓存中。会在后面（第25讲）具体地介绍一下它。',charsets:{cjk:!0},lastUpdated:"2023/04/10, 14:17:28",lastUpdatedTimestamp:1681136248e3},{title:"时间序列数据的保存",frontmatter:{title:"时间序列数据的保存",date:"2023-04-06T10:27:39.000Z",permalink:"/pages/a3ed18/",categories:["中间件","Redis","专栏：Redis 核心技术与实战"],tags:[null]},regularPath:"/%E4%B8%AD%E9%97%B4%E4%BB%B6/05.Redis/05.%E4%B8%93%E6%A0%8F%EF%BC%9ARedis%20%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/14.%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E7%9A%84%E4%BF%9D%E5%AD%98.html",relativePath:"中间件/05.Redis/05.专栏：Redis 核心技术与实战/14.时间序列数据的保存.md",key:"v-3fe17966",path:"/pages/a3ed18/",headers:[{level:2,title:"1. 如何在 Redis 中保存时间序列数据？",slug:"_1-如何在-redis-中保存时间序列数据",normalizedTitle:"1. 如何在 redis 中保存时间序列数据？",charIndex:48},{level:3,title:"1.1 时间序列数据的读写特点",slug:"_1-1-时间序列数据的读写特点",normalizedTitle:"1.1 时间序列数据的读写特点",charIndex:377},{level:4,title:"1） 写特点",slug:"_1-写特点",normalizedTitle:"1） 写特点",charIndex:396},{level:4,title:"2） 读特点",slug:"_2-读特点",normalizedTitle:"2） 读特点",charIndex:568},{level:3,title:"1.2 基于 Hash 和 Sorted Set 保存时间序列数据",slug:"_1-2-基于-hash-和-sorted-set-保存时间序列数据",normalizedTitle:"1.2 基于 hash 和 sorted set 保存时间序列数据",charIndex:922},{level:4,title:"1.2.1 为什么要同时使用这两种类型？",slug:"_1-2-1-为什么要同时使用这两种类型",normalizedTitle:"1.2.1 为什么要同时使用这两种类型？",charIndex:1054},{level:4,title:"1.2.2 如何保证原子性？",slug:"_1-2-2-如何保证原子性",normalizedTitle:"1.2.2 如何保证原子性？",charIndex:2059},{level:4,title:"1.2.3 如何对时间序列数据聚合计算？",slug:"_1-2-3-如何对时间序列数据聚合计算",normalizedTitle:"1.2.3 如何对时间序列数据聚合计算？",charIndex:3058},{level:3,title:"1.3 基于 RedisTimeSeries 模块保存时间序列数据",slug:"_1-3-基于-redistimeseries-模块保存时间序列数据",normalizedTitle:"1.3 基于 redistimeseries 模块保存时间序列数据",charIndex:3225},{level:4,title:"1.3.1 RedisTimeSeries 适合的场景",slug:"_1-3-1-redistimeseries-适合的场景",normalizedTitle:"1.3.1 redistimeseries 适合的场景",charIndex:3262},{level:4,title:"1.3.2 RedisTimeSeries 是什么",slug:"_1-3-2-redistimeseries-是什么",normalizedTitle:"1.3.2 redistimeseries 是什么",charIndex:4205},{level:3,title:"1.4 小结",slug:"_1-4-小结",normalizedTitle:"1.4 小结",charIndex:6770}],headersStr:"1. 如何在 Redis 中保存时间序列数据？ 1.1 时间序列数据的读写特点 1） 写特点 2） 读特点 1.2 基于 Hash 和 Sorted Set 保存时间序列数据 1.2.1 为什么要同时使用这两种类型？ 1.2.2 如何保证原子性？ 1.2.3 如何对时间序列数据聚合计算？ 1.3 基于 RedisTimeSeries 模块保存时间序列数据 1.3.1 RedisTimeSeries 适合的场景 1.3.2 RedisTimeSeries 是什么 1.4 小结",content:'> 参考：\n> \n>  * 14 如何在 Redis 中保存时间序列数据？| 极客时间\n\n\n# 1. 如何在 Redis 中保存时间序列数据？\n\n我们经常面临这样一个需求：记录用户在网站或者 App 上的点击行为数据，来分析用户行为。这里的数据一般包括用户 ID、行为类型（例如浏览、登录、下单等）、行为发生的时间戳：\n\nUserID, Type, TimeStamp\n\n\n1\n\n\n这些与发生时间相关的一组数据，就是时间序列数据。这些数据的特点是没有严格的关系模型，记录的信息可以表示成键和值的关系（例如，一个设备ID对应一条记录），所以，并不需要专门用关系型数据库（例如 MySQL）来保存。而 Redis 的键值数据模型，正好可以满足这里的数据存取需求。Redis 基于自身数据结构以及扩展模块，提供了两种解决方案。我们在这里对其进行讨论。\n\n\n# 1.1 时间序列数据的读写特点\n\n# 1） 写特点\n\n在实际应用中，时间序列数据通常是持续高并发写入的，这些数据的写入主要是插入新数据，而不是更新数据，也就是说，一个时间序列数据被记录后通常就不会变了。因为这些数据往往代表某个设备在某个时刻的测量值。\n\n所以，这种数据的写入特点很简单，就是插入数据快，这就要求我们选择的数据类型，在进行数据插入时，复杂度要低，尽量不要阻塞。\n\n# 2） 读特点\n\n我们在查询时间序列数据时，既有对单条记录的查询（如查询一个设备的某时刻状态），也有对某个时间范围内的数据的查询（如查看一上午所有设备的状态）。除此之外，还有一些更复杂的查询，比如对某个时间范围内的数据做聚合计算，如计算均值、求最大值等。\n\n概括时间序列数据的特点：查询模式多。\n\n弄清楚了时间序列数据的读写特点，接下来我们就看看如何在 Redis 中保存这些数据。我们来分析下：针对时间序列数据的“写要快”，Redis的高性能写特性直接就可以满足了；而针对“查询模式多”，也就是要支持单点查询、范围查询和聚合计算，Redis 提供了保存时间序列数据的两种方案，分别是：\n\n * 基于 Hash 和 Sorted Set 实现；\n * 基于 RedisTimeSeries 模块实现。\n\n\n# 1.2 基于 Hash 和 Sorted Set 保存时间序列数据\n\nHash 和 Sorted Set 组合的方式有一个明显的好处：它们是 Redis 内在的数据类型，代码成熟和性能稳定。所以，基于这两个数据类型保存时间序列数据，系统稳定性是可以预期的。\n\n# 1.2.1 为什么要同时使用这两种类型？\n\n不过，在前面学习的场景中，我们都是使用一个数据类型来存取数据，那么，为什么保存时间序列数据，要同时使用这两种类型？这是我们要回答的第一个问题。\n\n关于 Hash 类型，我们都知道，它有一个特点是，可以实现对单键的快速查询。这就满足了时间序列数据的单键查询需求。我们可以把时间戳作为 Hash 集合的 key，把记录的设备状态值作为 Hash 集合的 value。\n\n可以看下用 Hash 集合记录设备的温度值的示意图：\n\n当我们想要查询某个时间点或者是多个时间点上的温度数据时，直接使用 HGET 命令或者 HMGET 命令，就可以分别获得 Hash 集合中的一个 key 和多个 key 的 value 值了。示例如下：\n\n用HGET命令查询202008030905这个时刻的温度值，使用HMGET查询202008030905、202008030907、202008030908这三个时刻的温度值：\n\nHGET device:temperature 202008030905\n"25.1"\n\nHMGET device:temperature 202008030905 202008030907 202008030908\n1) "25.1"\n2) "25.9"\n3) "24.9"\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n你看，用 Hash 类型来实现单键的查询很简单。但是，Hash类型有个短板：它并不支持对数据进行范围查询。如果想要做范围查询的话，Hash 类型需要全部扫描才行。\n\n为了能同时支持按时间戳范围的查询，可以用 Sorted Set 来保存时间序列数据，因为它能够根据元素的权重分数来排序。我们可以把时间戳作为 Sorted Set 集合的元素分数，把时间点上记录的数据作为元素本身：\n\n使用 Sorted Set 保存数据后，我们就可以使用ZRANGEBYSCORE命令，按照输入的最大时间戳和最小时间戳来查询这个时间范围内的温度值了。如下所示，我们来查询一下在2020年8月3日9点7分到9点10分间的所有温度值：\n\nZRANGEBYSCORE device:temperature 202008030907 202008030910\n1) "25.9"\n2) "24.9"\n3) "25.3"\n4) "25.2"\n\n\n1\n2\n3\n4\n5\n\n\n# 1.2.2 如何保证原子性？\n\n同时使用 Hash 与 Sorted Set 满足了单个时间点和一个时间范围内的数据查询需求了，但是我们又会面临一个新的问题：如何保证写入 Hash 和 Sorted Set 是一个原子性的操作呢？所谓的原子性操作，就是指多个写命令要么全部成功，要么全都不成功。\n\n那 Redis 是怎么保证原子性操作的呢？这里就涉及到了 Redis 用来实现简单的事务的 MULTI 和 EXEC 命令。当多个命令及其参数本身无误时，MULTI 和 EXEC 命令可以保证执行这些命令时的原子性：\n\n * MULTI 命令：表示一系列原子性操作的开始。收到这个命令后，Redis 就知道，接下来再收到的命令需要放到一个内部队列中，后续一起执行，保证原子性。\n * EXEC 命令：表示一系列原子性操作的结束。一旦 Redis 收到了这个命令，就表示所有要保证原子性的命令操作都已经发送完成了。此时，Redis 开始执行刚才放到内部队列中的所有命令操作。\n\n如下图所示：\n\n以保存设备状态信息的需求为例，我们执行下面的代码，把设备在2020年8月3日9时5分的温度，分别用 HSET 命令和 ZADD 命令写入 Hash 集合和 Sorted Set 集合：\n\n127.0.0.1:6379> MULTI\nOK\n\n127.0.0.1:6379> HSET device:temperature 202008030911 26.8\nQUEUED\n\n127.0.0.1:6379> ZADD device:temperature 202008030911 26.8\nQUEUED\n\n127.0.0.1:6379> EXEC\n1) (integer) 1\n2) (integer) 1\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n可以看到，首先，Redis收到了客户端执行的MULTI命令。然后，客户端再执行HSET和ZADD命令后，Redis返回的结果为“QUEUED”，表示这两个命令暂时入队，先不执行；执行了EXEC命令后，HSET命令和ZADD命令才真正执行，并返回成功结果（结果值为1）。\n\n到这里，我们就解决了时间序列数据的单点查询、范围查询问题，并使用MUTLI和EXEC命令保证了Redis能原子性地把数据保存到Hash和Sorted Set中。\n\n# 1.2.3 如何对时间序列数据聚合计算？\n\n接下来，我们要继续解决第三个问题：如何对时间序列数据进行聚合计算？聚合计算一般被用来周期性地统计时间窗口内的数据汇总状态，在实时监控与预警等场景下会频繁执行。\n\n基于 Hash 和 Sorted Set 保存时间序列数据时，无法完美地解决这个问题。具体将在 1.3.1 节中讲述。\n\n\n# 1.3 基于 RedisTimeSeries 模块保存时间序列数据\n\n# 1.3.1 RedisTimeSeries 适合的场景\n\n接下来，我们继续解决第三个问题：如何对时间序列数据进行聚合计算？\n\n因为Sorted Set只支持范围查询，无法直接进行聚合计算，所以，我们只能先把时间范围内的数据取回到客户端，然后在客户端自行完成聚合计算。这个方法虽然能完成聚合计算，但是会带来一定的潜在风险，也就是 大量数据在Redis实例和客户端间频繁传输，这会和其他操作命令竞争网络资源，导致其他操作变慢。\n\n在一个物联网项目中，需要每3分钟统计一下各个设备的温度状态，一旦设备温度超出了设定的阈值，就要进行报警。这是一个典型的聚合计算场景，我们可以来看看这个过程中的数据体量：假设我们需要每3分钟计算一次的所有设备各指标的最大值，每个设备每15秒记录一个指标值，1分钟就会记录4个值，3分钟就会有12个值。我们要统计的设备指标数量有33个，所以，单个设备每3分钟记录的指标数据有将近400个（33 * 12 = 396），而设备总数量有1万台，这样一来，每3分钟就有将近400万条（396 * 1万 = 396万）数据需要在客户端和Redis实例间进行传输。\n\n为了避免客户端和Redis实例间频繁的大量数据传输，我们可以使用 RedisTimeSeries 来保存时间序列数据。\n\nRedisTimeSeries 支持直接在 Redis 实例上进行聚合计算。还是以刚才每3分钟算一次最大值为例。在Redis实例上直接聚合计算，那么，对于单个设备的一个指标值来说，每3分钟记录的12条数据可以聚合计算成一个值，单个设备每3分钟也就只有33个聚合值需要传输，1万台设备也只有33万条数据。数据量大约是在客户端做聚合计算的十分之一，很显然，可以减少大量数据传输对Redis实例网络的性能影响。\n\n所以：\n\n * 如果我们只需要进行单个时间点查询或是对某个时间范围查询的话，适合使用 Hash 和 Sorted Set 的组合，它们都是 Redis 的内在数据结构，性能好，稳定性高。\n * 但是，如果我们需要进行大量的聚合计算，同时网络带宽条件不是太好时，使用 RedisTimeSeries 就更加合适一些。\n\n那我们就学习一下 RedisTimeSeries。\n\n# 1.3.2 RedisTimeSeries 是什么\n\nRedisTimeSeries 是 Redis 的一个扩展模块。它专门面向时间序列数据提供了数据类型和访问接口，并且支持在 Redis 实例上直接对数据进行按时间范围的聚合计算。\n\n因为 RedisTimeSeries 不属于Redis的内建功能模块，在使用时，我们需要先把它的源码单独编译成动态链接库 redistimeseries.so，再使用 loadmodule 命令进行加载，如下所示：\n\nloadmodule redistimeseries.so\n\n\n1\n\n\n当用于时间序列数据存取时，RedisTimeSeries 的操作主要有 5 个：\n\n * 用 TS.CREATE 命令创建时间序列数据集合；\n * 用 TS.ADD 命令插入数据；\n * 用 TS.GET 命令读取最新数据；\n * 用 TS.MGET 命令按标签过滤查询数据集合；\n * 用 TS.RANGE 支持聚合计算的范围查询。\n\n下面，我来介绍一下如何使用这5个操作。\n\n----------------------------------------\n\n1）用 TS.CREATE 命令创建一个时间序列数据集合：\n\n在TS.CREATE命令中，我们需要设置时间序列数据集合的 key 和数据的过期时间（以毫秒为单位）。此外，我们还可以为数据集合设置标签，来表示数据集合的属性。\n\n例如，我们执行下面的命令，创建一个key为device:temperature、数据有效期为600s的时间序列数据集合。也就是说，这个集合中的数据创建了600s后，就会被自动删除。最后，我们给这个集合设置了一个标签属性{device_id:1}，表明这个数据集合中记录的是属于设备ID号为1的数据。\n\nTS.CREATE device:temperature RETENTION 600000 LABELS device_id 1\nOK\n\n\n1\n2\n\n\n----------------------------------------\n\n2）用 TS.ADD 命令插入数据，用 TS.GET 命令读取最新数据：\n\n我们可以用 TS.ADD 命令往时间序列集合中插入数据，包括时间戳和具体的数值，并使用 TS.GET 命令读取数据集合中的最新一条数据。\n\n例如，我们执行下列 TS.ADD 命令时，就往 device:temperature 集合中插入了一条数据，记录的是设备在2020年8月3日9时5分的设备温度；再执行 TS.GET 命令时，就会把刚刚插入的最新数据读取出来：\n\nTS.ADD device:temperature 1596416700 25.1\n1596416700\n\nTS.GET device:temperature\n25.1\n\n\n1\n2\n3\n4\n5\n\n\n3）用 TS.MGET 命令按标签过滤查询数据集合：\n\n在保存多个设备的时间序列数据时，我们通常会把不同设备的数据保存到不同集合中。此时，我们就可以使用TS.MGET命令，按照标签查询部分集合中的最新数据。在使用TS.CREATE创建数据集合时，我们可以给集合设置标签属性。当我们进行查询时，就可以在查询条件中对集合标签属性进行匹配，最后的查询结果里只返回匹配上的集合中的最新数据。\n\n举个例子。假设我们一共用4个集合为4个设备保存时间序列数据，设备的ID号是1、2、3、4，我们在创建数据集合时，把device_id设置为每个集合的标签。此时，我们就可以使用下列TS.MGET命令，以及FILTER设置（这个配置项用来设置集合标签的过滤条件），查询device_id不等于2的所有其他设备的数据集合，并返回各自集合中的最新的一条数据。\n\nTS.MGET FILTER device_id!=2\n1) 1) "device:temperature:1"\n   2) (empty list or set)\n   3) 1) (integer) 1596417000\n      2) "25.3"\n2) 1) "device:temperature:3"\n   2) (empty list or set)\n   3) 1) (integer) 1596417000\n      2) "29.5"\n3) 1) "device:temperature:4"\n   2) (empty list or set)\n   3) 1) (integer) 1596417000\n      2) "30.1"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n4）用 TS.RANGE 支持需要聚合计算的范围查询：\n\n最后，在对时间序列数据进行聚合计算时，我们可以使用TS.RANGE命令指定要查询的数据的时间范围，同时用AGGREGATION参数指定要执行的聚合计算类型。RedisTimeSeries支持的聚合计算类型很丰富，包括求均值（avg）、求最大/最小值（max/min），求和（sum）等。\n\n例如，在执行下列命令时，我们就可以按照每180s的时间窗口，对2020年8月3日9时5分和2020年8月3日9时12分这段时间内的数据进行均值计算了。\n\nTS.RANGE device:temperature 1596416700 1596417120 AGGREGATION avg 180000\n1) 1) (integer) 1596416700\n   2) "25.6"\n2) 1) (integer) 1596416880\n   2) "25.8"\n3) 1) (integer) 1596417060\n   2) "26.1"\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n与使用Hash和Sorted Set来保存时间序列数据相比，RedisTimeSeries是专门为时间序列数据访问设计的扩展模块，能支持在Redis实例上直接进行聚合计算，以及按标签属性过滤查询数据集合，当我们需要频繁进行聚合计算，以及从大量集合中筛选出特定设备或用户的数据集合时，RedisTimeSeries就可以发挥优势了。\n\n\n# 1.4 小结\n\n这一节学习了如何使用 Redis 保存时间序列数据。时间序列数据的写入特点是要能快速写入，而查询的特点有三个：\n\n * 点查询，根据一个时间戳，查询相应时间的数据；\n * 范围查询，查询起始和截止时间戳范围内的数据；\n * 聚合计算，针对起始和截止时间戳范围内的所有数据进行计算，例如求最大/最小值，求均值等。\n\n为了针对多样化的查询需求，Redis 提供了两种方案：\n\n 1. 组合使用 Redis 内置的 Hash 和 Sorted Set 类型\n 2. 使用 RedisTimeSeries 模块\n\n两种方案各自的优劣：\n\n * 第一种：\n   * 既可以利用Hash类型实现对单键的快速查询，还能利用Sorted Set实现对范围查询的高效支持，一下子满足了时间序列数据的两大查询需求。\n   * 两个不足：一个是，在执行聚合计算时，我们需要把数据读取到客户端再进行聚合，当有大量数据要聚合时，数据传输开销大；另一个是，所有的数据会在两个数据类型中各保存一份，内存开销不小。不过，我们可以通过设置适当的数据过期时间，释放内存，减小内存压力。\n * 第二种：\n   * RedisTimeSeries能支持直接在Redis实例上进行多种数据聚合计算，避免了大量数据在实例和客户端间传输。\n   * 不足：RedisTimeSeries的底层数据结构使用了链表，它的范围查询的复杂度是O(N)级别的，同时，它的TS.GET查询只能返回最新的数据，没有办法像第一种方案的Hash类型一样，可以返回任一时间点的数据。\n\n这两种方案各有优劣，建议是：\n\n * 如果你的部署环境中网络带宽高、Redis实例内存大，可以优先考虑第一种方案；\n * 如果你的部署环境中网络、内存资源有限，而且数据量大，聚合计算频繁，需要按数据集合属性查询，可以优先考虑第二种方案。\n\n----------------------------------------\n\n本节问题 1：在用Sorted Set保存时间序列数据时，我们把时间戳作为score，把实际的数据作为member，这样保存数据有没有潜在的风险？\n\nSorted Set和Set一样，都会对集合中的元素进行去重，相同member的值，在Sorted Set中只会保留一个。\n\n对于时间序列数据来说，这种去重的特性是会带来数据丢失风险的。毕竟，某一时间段内的多个时间序列数据的值可能是相同的。如果我们往Sorted Set中写入的数据是在不同时刻产生的，但是写入的时刻不同，Sorted Set中只会保存一份最近时刻的数据。这样一来，其他时刻的数据就都没有保存下来。\n\n举个例子，在记录物联网设备的温度时，一个设备一个上午的温度值可能都是26。在Sorted Set中，我们把温度值作为member，把时间戳作为score。我们用ZADD命令把上午不同时刻的温度值写入Sorted Set。由于member值一样，所以只会把score更新为最新时间戳，最后只有一个最新时间戳（例如上午12点）下的温度值。这肯定是无法满足保存多个时刻数据的需求的。\n\n本节问题 2：如果你是Redis的开发维护者，你会把聚合计算也设计为Sorted Set的一个内在功能吗？\n\n考虑到Redis的读写功能是由单线程执行，在进行数据读写时，本身就会消耗较多的CPU资源，如果再在Sorted Set中实现聚合计算，就会进一步增加CPU的资源消耗，影响到Redis的正常数据读取。所以，如果我是Redis的开发维护者，除非对Redis的线程模型做修改，比如说在Redis中使用额外的线程池做聚合计算，否则，我不会把聚合计算作为Redis的内在功能实现的。',normalizedContent:'> 参考：\n> \n>  * 14 如何在 redis 中保存时间序列数据？| 极客时间\n\n\n# 1. 如何在 redis 中保存时间序列数据？\n\n我们经常面临这样一个需求：记录用户在网站或者 app 上的点击行为数据，来分析用户行为。这里的数据一般包括用户 id、行为类型（例如浏览、登录、下单等）、行为发生的时间戳：\n\nuserid, type, timestamp\n\n\n1\n\n\n这些与发生时间相关的一组数据，就是时间序列数据。这些数据的特点是没有严格的关系模型，记录的信息可以表示成键和值的关系（例如，一个设备id对应一条记录），所以，并不需要专门用关系型数据库（例如 mysql）来保存。而 redis 的键值数据模型，正好可以满足这里的数据存取需求。redis 基于自身数据结构以及扩展模块，提供了两种解决方案。我们在这里对其进行讨论。\n\n\n# 1.1 时间序列数据的读写特点\n\n# 1） 写特点\n\n在实际应用中，时间序列数据通常是持续高并发写入的，这些数据的写入主要是插入新数据，而不是更新数据，也就是说，一个时间序列数据被记录后通常就不会变了。因为这些数据往往代表某个设备在某个时刻的测量值。\n\n所以，这种数据的写入特点很简单，就是插入数据快，这就要求我们选择的数据类型，在进行数据插入时，复杂度要低，尽量不要阻塞。\n\n# 2） 读特点\n\n我们在查询时间序列数据时，既有对单条记录的查询（如查询一个设备的某时刻状态），也有对某个时间范围内的数据的查询（如查看一上午所有设备的状态）。除此之外，还有一些更复杂的查询，比如对某个时间范围内的数据做聚合计算，如计算均值、求最大值等。\n\n概括时间序列数据的特点：查询模式多。\n\n弄清楚了时间序列数据的读写特点，接下来我们就看看如何在 redis 中保存这些数据。我们来分析下：针对时间序列数据的“写要快”，redis的高性能写特性直接就可以满足了；而针对“查询模式多”，也就是要支持单点查询、范围查询和聚合计算，redis 提供了保存时间序列数据的两种方案，分别是：\n\n * 基于 hash 和 sorted set 实现；\n * 基于 redistimeseries 模块实现。\n\n\n# 1.2 基于 hash 和 sorted set 保存时间序列数据\n\nhash 和 sorted set 组合的方式有一个明显的好处：它们是 redis 内在的数据类型，代码成熟和性能稳定。所以，基于这两个数据类型保存时间序列数据，系统稳定性是可以预期的。\n\n# 1.2.1 为什么要同时使用这两种类型？\n\n不过，在前面学习的场景中，我们都是使用一个数据类型来存取数据，那么，为什么保存时间序列数据，要同时使用这两种类型？这是我们要回答的第一个问题。\n\n关于 hash 类型，我们都知道，它有一个特点是，可以实现对单键的快速查询。这就满足了时间序列数据的单键查询需求。我们可以把时间戳作为 hash 集合的 key，把记录的设备状态值作为 hash 集合的 value。\n\n可以看下用 hash 集合记录设备的温度值的示意图：\n\n当我们想要查询某个时间点或者是多个时间点上的温度数据时，直接使用 hget 命令或者 hmget 命令，就可以分别获得 hash 集合中的一个 key 和多个 key 的 value 值了。示例如下：\n\n用hget命令查询202008030905这个时刻的温度值，使用hmget查询202008030905、202008030907、202008030908这三个时刻的温度值：\n\nhget device:temperature 202008030905\n"25.1"\n\nhmget device:temperature 202008030905 202008030907 202008030908\n1) "25.1"\n2) "25.9"\n3) "24.9"\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n你看，用 hash 类型来实现单键的查询很简单。但是，hash类型有个短板：它并不支持对数据进行范围查询。如果想要做范围查询的话，hash 类型需要全部扫描才行。\n\n为了能同时支持按时间戳范围的查询，可以用 sorted set 来保存时间序列数据，因为它能够根据元素的权重分数来排序。我们可以把时间戳作为 sorted set 集合的元素分数，把时间点上记录的数据作为元素本身：\n\n使用 sorted set 保存数据后，我们就可以使用zrangebyscore命令，按照输入的最大时间戳和最小时间戳来查询这个时间范围内的温度值了。如下所示，我们来查询一下在2020年8月3日9点7分到9点10分间的所有温度值：\n\nzrangebyscore device:temperature 202008030907 202008030910\n1) "25.9"\n2) "24.9"\n3) "25.3"\n4) "25.2"\n\n\n1\n2\n3\n4\n5\n\n\n# 1.2.2 如何保证原子性？\n\n同时使用 hash 与 sorted set 满足了单个时间点和一个时间范围内的数据查询需求了，但是我们又会面临一个新的问题：如何保证写入 hash 和 sorted set 是一个原子性的操作呢？所谓的原子性操作，就是指多个写命令要么全部成功，要么全都不成功。\n\n那 redis 是怎么保证原子性操作的呢？这里就涉及到了 redis 用来实现简单的事务的 multi 和 exec 命令。当多个命令及其参数本身无误时，multi 和 exec 命令可以保证执行这些命令时的原子性：\n\n * multi 命令：表示一系列原子性操作的开始。收到这个命令后，redis 就知道，接下来再收到的命令需要放到一个内部队列中，后续一起执行，保证原子性。\n * exec 命令：表示一系列原子性操作的结束。一旦 redis 收到了这个命令，就表示所有要保证原子性的命令操作都已经发送完成了。此时，redis 开始执行刚才放到内部队列中的所有命令操作。\n\n如下图所示：\n\n以保存设备状态信息的需求为例，我们执行下面的代码，把设备在2020年8月3日9时5分的温度，分别用 hset 命令和 zadd 命令写入 hash 集合和 sorted set 集合：\n\n127.0.0.1:6379> multi\nok\n\n127.0.0.1:6379> hset device:temperature 202008030911 26.8\nqueued\n\n127.0.0.1:6379> zadd device:temperature 202008030911 26.8\nqueued\n\n127.0.0.1:6379> exec\n1) (integer) 1\n2) (integer) 1\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n可以看到，首先，redis收到了客户端执行的multi命令。然后，客户端再执行hset和zadd命令后，redis返回的结果为“queued”，表示这两个命令暂时入队，先不执行；执行了exec命令后，hset命令和zadd命令才真正执行，并返回成功结果（结果值为1）。\n\n到这里，我们就解决了时间序列数据的单点查询、范围查询问题，并使用mutli和exec命令保证了redis能原子性地把数据保存到hash和sorted set中。\n\n# 1.2.3 如何对时间序列数据聚合计算？\n\n接下来，我们要继续解决第三个问题：如何对时间序列数据进行聚合计算？聚合计算一般被用来周期性地统计时间窗口内的数据汇总状态，在实时监控与预警等场景下会频繁执行。\n\n基于 hash 和 sorted set 保存时间序列数据时，无法完美地解决这个问题。具体将在 1.3.1 节中讲述。\n\n\n# 1.3 基于 redistimeseries 模块保存时间序列数据\n\n# 1.3.1 redistimeseries 适合的场景\n\n接下来，我们继续解决第三个问题：如何对时间序列数据进行聚合计算？\n\n因为sorted set只支持范围查询，无法直接进行聚合计算，所以，我们只能先把时间范围内的数据取回到客户端，然后在客户端自行完成聚合计算。这个方法虽然能完成聚合计算，但是会带来一定的潜在风险，也就是 大量数据在redis实例和客户端间频繁传输，这会和其他操作命令竞争网络资源，导致其他操作变慢。\n\n在一个物联网项目中，需要每3分钟统计一下各个设备的温度状态，一旦设备温度超出了设定的阈值，就要进行报警。这是一个典型的聚合计算场景，我们可以来看看这个过程中的数据体量：假设我们需要每3分钟计算一次的所有设备各指标的最大值，每个设备每15秒记录一个指标值，1分钟就会记录4个值，3分钟就会有12个值。我们要统计的设备指标数量有33个，所以，单个设备每3分钟记录的指标数据有将近400个（33 * 12 = 396），而设备总数量有1万台，这样一来，每3分钟就有将近400万条（396 * 1万 = 396万）数据需要在客户端和redis实例间进行传输。\n\n为了避免客户端和redis实例间频繁的大量数据传输，我们可以使用 redistimeseries 来保存时间序列数据。\n\nredistimeseries 支持直接在 redis 实例上进行聚合计算。还是以刚才每3分钟算一次最大值为例。在redis实例上直接聚合计算，那么，对于单个设备的一个指标值来说，每3分钟记录的12条数据可以聚合计算成一个值，单个设备每3分钟也就只有33个聚合值需要传输，1万台设备也只有33万条数据。数据量大约是在客户端做聚合计算的十分之一，很显然，可以减少大量数据传输对redis实例网络的性能影响。\n\n所以：\n\n * 如果我们只需要进行单个时间点查询或是对某个时间范围查询的话，适合使用 hash 和 sorted set 的组合，它们都是 redis 的内在数据结构，性能好，稳定性高。\n * 但是，如果我们需要进行大量的聚合计算，同时网络带宽条件不是太好时，使用 redistimeseries 就更加合适一些。\n\n那我们就学习一下 redistimeseries。\n\n# 1.3.2 redistimeseries 是什么\n\nredistimeseries 是 redis 的一个扩展模块。它专门面向时间序列数据提供了数据类型和访问接口，并且支持在 redis 实例上直接对数据进行按时间范围的聚合计算。\n\n因为 redistimeseries 不属于redis的内建功能模块，在使用时，我们需要先把它的源码单独编译成动态链接库 redistimeseries.so，再使用 loadmodule 命令进行加载，如下所示：\n\nloadmodule redistimeseries.so\n\n\n1\n\n\n当用于时间序列数据存取时，redistimeseries 的操作主要有 5 个：\n\n * 用 ts.create 命令创建时间序列数据集合；\n * 用 ts.add 命令插入数据；\n * 用 ts.get 命令读取最新数据；\n * 用 ts.mget 命令按标签过滤查询数据集合；\n * 用 ts.range 支持聚合计算的范围查询。\n\n下面，我来介绍一下如何使用这5个操作。\n\n----------------------------------------\n\n1）用 ts.create 命令创建一个时间序列数据集合：\n\n在ts.create命令中，我们需要设置时间序列数据集合的 key 和数据的过期时间（以毫秒为单位）。此外，我们还可以为数据集合设置标签，来表示数据集合的属性。\n\n例如，我们执行下面的命令，创建一个key为device:temperature、数据有效期为600s的时间序列数据集合。也就是说，这个集合中的数据创建了600s后，就会被自动删除。最后，我们给这个集合设置了一个标签属性{device_id:1}，表明这个数据集合中记录的是属于设备id号为1的数据。\n\nts.create device:temperature retention 600000 labels device_id 1\nok\n\n\n1\n2\n\n\n----------------------------------------\n\n2）用 ts.add 命令插入数据，用 ts.get 命令读取最新数据：\n\n我们可以用 ts.add 命令往时间序列集合中插入数据，包括时间戳和具体的数值，并使用 ts.get 命令读取数据集合中的最新一条数据。\n\n例如，我们执行下列 ts.add 命令时，就往 device:temperature 集合中插入了一条数据，记录的是设备在2020年8月3日9时5分的设备温度；再执行 ts.get 命令时，就会把刚刚插入的最新数据读取出来：\n\nts.add device:temperature 1596416700 25.1\n1596416700\n\nts.get device:temperature\n25.1\n\n\n1\n2\n3\n4\n5\n\n\n3）用 ts.mget 命令按标签过滤查询数据集合：\n\n在保存多个设备的时间序列数据时，我们通常会把不同设备的数据保存到不同集合中。此时，我们就可以使用ts.mget命令，按照标签查询部分集合中的最新数据。在使用ts.create创建数据集合时，我们可以给集合设置标签属性。当我们进行查询时，就可以在查询条件中对集合标签属性进行匹配，最后的查询结果里只返回匹配上的集合中的最新数据。\n\n举个例子。假设我们一共用4个集合为4个设备保存时间序列数据，设备的id号是1、2、3、4，我们在创建数据集合时，把device_id设置为每个集合的标签。此时，我们就可以使用下列ts.mget命令，以及filter设置（这个配置项用来设置集合标签的过滤条件），查询device_id不等于2的所有其他设备的数据集合，并返回各自集合中的最新的一条数据。\n\nts.mget filter device_id!=2\n1) 1) "device:temperature:1"\n   2) (empty list or set)\n   3) 1) (integer) 1596417000\n      2) "25.3"\n2) 1) "device:temperature:3"\n   2) (empty list or set)\n   3) 1) (integer) 1596417000\n      2) "29.5"\n3) 1) "device:temperature:4"\n   2) (empty list or set)\n   3) 1) (integer) 1596417000\n      2) "30.1"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n4）用 ts.range 支持需要聚合计算的范围查询：\n\n最后，在对时间序列数据进行聚合计算时，我们可以使用ts.range命令指定要查询的数据的时间范围，同时用aggregation参数指定要执行的聚合计算类型。redistimeseries支持的聚合计算类型很丰富，包括求均值（avg）、求最大/最小值（max/min），求和（sum）等。\n\n例如，在执行下列命令时，我们就可以按照每180s的时间窗口，对2020年8月3日9时5分和2020年8月3日9时12分这段时间内的数据进行均值计算了。\n\nts.range device:temperature 1596416700 1596417120 aggregation avg 180000\n1) 1) (integer) 1596416700\n   2) "25.6"\n2) 1) (integer) 1596416880\n   2) "25.8"\n3) 1) (integer) 1596417060\n   2) "26.1"\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n与使用hash和sorted set来保存时间序列数据相比，redistimeseries是专门为时间序列数据访问设计的扩展模块，能支持在redis实例上直接进行聚合计算，以及按标签属性过滤查询数据集合，当我们需要频繁进行聚合计算，以及从大量集合中筛选出特定设备或用户的数据集合时，redistimeseries就可以发挥优势了。\n\n\n# 1.4 小结\n\n这一节学习了如何使用 redis 保存时间序列数据。时间序列数据的写入特点是要能快速写入，而查询的特点有三个：\n\n * 点查询，根据一个时间戳，查询相应时间的数据；\n * 范围查询，查询起始和截止时间戳范围内的数据；\n * 聚合计算，针对起始和截止时间戳范围内的所有数据进行计算，例如求最大/最小值，求均值等。\n\n为了针对多样化的查询需求，redis 提供了两种方案：\n\n 1. 组合使用 redis 内置的 hash 和 sorted set 类型\n 2. 使用 redistimeseries 模块\n\n两种方案各自的优劣：\n\n * 第一种：\n   * 既可以利用hash类型实现对单键的快速查询，还能利用sorted set实现对范围查询的高效支持，一下子满足了时间序列数据的两大查询需求。\n   * 两个不足：一个是，在执行聚合计算时，我们需要把数据读取到客户端再进行聚合，当有大量数据要聚合时，数据传输开销大；另一个是，所有的数据会在两个数据类型中各保存一份，内存开销不小。不过，我们可以通过设置适当的数据过期时间，释放内存，减小内存压力。\n * 第二种：\n   * redistimeseries能支持直接在redis实例上进行多种数据聚合计算，避免了大量数据在实例和客户端间传输。\n   * 不足：redistimeseries的底层数据结构使用了链表，它的范围查询的复杂度是o(n)级别的，同时，它的ts.get查询只能返回最新的数据，没有办法像第一种方案的hash类型一样，可以返回任一时间点的数据。\n\n这两种方案各有优劣，建议是：\n\n * 如果你的部署环境中网络带宽高、redis实例内存大，可以优先考虑第一种方案；\n * 如果你的部署环境中网络、内存资源有限，而且数据量大，聚合计算频繁，需要按数据集合属性查询，可以优先考虑第二种方案。\n\n----------------------------------------\n\n本节问题 1：在用sorted set保存时间序列数据时，我们把时间戳作为score，把实际的数据作为member，这样保存数据有没有潜在的风险？\n\nsorted set和set一样，都会对集合中的元素进行去重，相同member的值，在sorted set中只会保留一个。\n\n对于时间序列数据来说，这种去重的特性是会带来数据丢失风险的。毕竟，某一时间段内的多个时间序列数据的值可能是相同的。如果我们往sorted set中写入的数据是在不同时刻产生的，但是写入的时刻不同，sorted set中只会保存一份最近时刻的数据。这样一来，其他时刻的数据就都没有保存下来。\n\n举个例子，在记录物联网设备的温度时，一个设备一个上午的温度值可能都是26。在sorted set中，我们把温度值作为member，把时间戳作为score。我们用zadd命令把上午不同时刻的温度值写入sorted set。由于member值一样，所以只会把score更新为最新时间戳，最后只有一个最新时间戳（例如上午12点）下的温度值。这肯定是无法满足保存多个时刻数据的需求的。\n\n本节问题 2：如果你是redis的开发维护者，你会把聚合计算也设计为sorted set的一个内在功能吗？\n\n考虑到redis的读写功能是由单线程执行，在进行数据读写时，本身就会消耗较多的cpu资源，如果再在sorted set中实现聚合计算，就会进一步增加cpu的资源消耗，影响到redis的正常数据读取。所以，如果我是redis的开发维护者，除非对redis的线程模型做修改，比如说在redis中使用额外的线程池做聚合计算，否则，我不会把聚合计算作为redis的内在功能实现的。',charsets:{cjk:!0},lastUpdated:"2023/04/10, 14:17:28",lastUpdatedTimestamp:1681136248e3},{title:"Redis 的消息队列方案",frontmatter:{title:"Redis 的消息队列方案",date:"2023-04-06T11:27:04.000Z",permalink:"/pages/5d636a/",categories:["中间件","Redis","专栏：Redis 核心技术与实战"],tags:[null]},regularPath:"/%E4%B8%AD%E9%97%B4%E4%BB%B6/05.Redis/05.%E4%B8%93%E6%A0%8F%EF%BC%9ARedis%20%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/15.Redis%20%E7%9A%84%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E6%96%B9%E6%A1%88.html",relativePath:"中间件/05.Redis/05.专栏：Redis 核心技术与实战/15.Redis 的消息队列方案.md",key:"v-0b361225",path:"/pages/5d636a/",headers:[{level:2,title:"1. 消息队列的考验：Redis有哪些解决方案？",slug:"_1-消息队列的考验-redis有哪些解决方案",normalizedTitle:"1. 消息队列的考验：redis有哪些解决方案？",charIndex:50},{level:3,title:"1.1 MQ 的消息存取需求",slug:"_1-1-mq-的消息存取需求",normalizedTitle:"1.1 mq 的消息存取需求",charIndex:281},{level:4,title:"需求一：消息保序",slug:"需求一-消息保序",normalizedTitle:"需求一：消息保序",charIndex:652},{level:4,title:"需求二：重复消息处理（幂等要求）",slug:"需求二-重复消息处理-幂等要求",normalizedTitle:"需求二：重复消息处理（幂等要求）",charIndex:946},{level:4,title:"需求三：消息可靠性保证",slug:"需求三-消息可靠性保证",normalizedTitle:"需求三：消息可靠性保证",charIndex:1087},{level:3,title:"1.2 基于 List 的 MQ 解决方案",slug:"_1-2-基于-list-的-mq-解决方案",normalizedTitle:"1.2 基于 list 的 mq 解决方案",charIndex:1267},{level:4,title:"1.2.1 解决消息保序问题",slug:"_1-2-1-解决消息保序问题",normalizedTitle:"1.2.1 解决消息保序问题",charIndex:1292},{level:4,title:"1.2.2 幂等性要求（处理重复消息）",slug:"_1-2-2-幂等性要求-处理重复消息",normalizedTitle:"1.2.2 幂等性要求（处理重复消息）",charIndex:1624},{level:4,title:"1.2.3 消息可靠性保证",slug:"_1-2-3-消息可靠性保证",normalizedTitle:"1.2.3 消息可靠性保证",charIndex:1947},{level:3,title:"1.3 基于 Streams 的消息队列解决方案",slug:"_1-3-基于-streams-的消息队列解决方案",normalizedTitle:"1.3 基于 streams 的消息队列解决方案",charIndex:2620},{level:4,title:"1）XADD 命令",slug:"_1-xadd-命令",normalizedTitle:"1）xadd 命令",charIndex:2872},{level:4,title:"2）XREAD 命令",slug:"_2-xread-命令",normalizedTitle:"2）xread 命令",charIndex:3355},{level:4,title:"3）XGROUP 与 XREADGROUP",slug:"_3-xgroup-与-xreadgroup",normalizedTitle:"3）xgroup 与 xreadgroup",charIndex:4246},{level:4,title:"4）XPENDING 和 XACK",slug:"_4-xpending-和-xack",normalizedTitle:"4）xpending 和 xack",charIndex:5887},{level:3,title:"1.4 小结",slug:"_1-4-小结",normalizedTitle:"1.4 小结",charIndex:7041}],headersStr:"1. 消息队列的考验：Redis有哪些解决方案？ 1.1 MQ 的消息存取需求 需求一：消息保序 需求二：重复消息处理（幂等要求） 需求三：消息可靠性保证 1.2 基于 List 的 MQ 解决方案 1.2.1 解决消息保序问题 1.2.2 幂等性要求（处理重复消息） 1.2.3 消息可靠性保证 1.3 基于 Streams 的消息队列解决方案 1）XADD 命令 2）XREAD 命令 3）XGROUP 与 XREADGROUP 4）XPENDING 和 XACK 1.4 小结",content:'> 参考：\n> \n>  * 15 消息队列的考验：Redis 有哪些解决方案？| 极客时间\n\n\n# 1. 消息队列的考验：Redis有哪些解决方案？\n\n消息队列是分布式系统的基础软件，要能支持组件通信消息的快速读写。Redis 本身支持数据的高速访问，因此很多人关心一个问题：Redis 适合做 MQ 吗？\n\n这个问题的背后，隐含着两方面的核心问题：\n\n * 消息队列的消息存取需求是什么？\n * Redis 如何实现消息队列的需求？\n\n理解了 MQ 的特征和 Redis 提供的 MQ 方案，才能根据实际需求来选择出适合的 Redis 消息队列方案。\n\n\n# 1.1 MQ 的消息存取需求\n\n先介绍一下消息队列存取消息的过程。在分布式系统中，当两个组件要基于消息队列进行通信时，一个组件会把要处理的数据以消息的形式传递给消息队列，然后，这个组件就可以继续执行其他操作了；远端的另一个组件从消息队列中把消息读取出来，再在本地进行处理。\n\n一个通用的 MQ 的架构模型为：\n\n消息队列中发送消息的组件称为生产者，接收消息的组件称为消费者。\n\n在使用消息队列时，消费者可以异步读取生产者消息，然后再进行处理。这样一来，即使生产者发送消息的速度远远超过了消费者处理消息的速度，生产者已经发送的消息也可以缓存在消息队列中，避免阻塞生产者，这是消息队列作为分布式组件通信的一大优势。\n\nMQ 在存取消息时，必须要满足三个需求：\n\n 1. 消息保序\n 2. 处理重复的消息（幂等要求）\n 3. 保证消息可靠性\n\n# 需求一：消息保序\n\n虽然消费者是异步处理消息，但是，消费者仍然需要按照生产者发送消息的顺序来处理消息，避免后发送的消息被先处理了。对于要求消息保序的场景来说，一旦出现这种消息被乱序处理的情况，就可能会导致业务逻辑被错误执行，从而给业务方造成损失。\n\n我们来看一个更新商品库存的场景：假设生产者负责接收库存更新请求，消费者负责实际更新库存，现有库存量是10。生产者先后发送了消息1和消息2，消息1要把商品X的库存记录更新为5，消息2是把商品X库存更新为3。如果消息1和2在消息队列中无法保序，出现消息2早于消息1被处理的情况，那么，很显然，库存更新就出错了。这是业务应用无法接受的。\n\n# 需求二：重复消息处理（幂等要求）\n\n消费者从消息队列读取消息时，有时会因为网络堵塞而出现消息重传的情况。对于重复的消息，消费者如果多次处理的话，就可能造成一个业务逻辑被多次执行，如果业务逻辑正好是要修改数据，那就会出现数据被多次修改的问题了。\n\n比如可能出现重复扣款的问题。\n\n# 需求三：消息可靠性保证\n\n消费者在处理消息的时候，还可能出现因为故障或宕机导致消息没有处理完成的情况。此时，消息队列需要能提供消息可靠性的保证，也就是说，当消费者重启后，可以重新读取消息再次进行处理，否则，就会出现消息漏处理的问题了。\n\nRedis 的 List 和 Streams 两种数据类型，就可以满足消息队列的这三个需求。下面来看这两种方案。\n\n\n# 1.2 基于 List 的 MQ 解决方案\n\n# 1.2.1 解决消息保序问题\n\nList 本身就是按先进先出的顺序对数据进行存取的，所以如果使用 List 作为消息队列保存消息的话，就已经能满足消息保序的需求了：\n\n * 生产者使用 LPUSH 命令把消息写入 List\n * 消费者使用 RPOP 命令读取消息\n\n不过这样的话 List 不会主动告知消费者有新消息的写入，这样就需要消费者一直调用 RPOP 来监听消息（比如使用一个while(1)循环），这会带来不必要的性能损失。\n\n为了解决这个问题，Redis 提供了 BRPOP 命令：阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列，再开始读取新数据。这种方式相比消费者不停调用 RPOP 而言，更加节省 CPU 开销。\n\n# 1.2.2 幂等性要求（处理重复消息）\n\n解决消息重复问题，其实有一个要求：消费者程序本身能对重复消息进行判断：\n\n * 一方面，消息队列要能给每一个消息提供全局唯一的 ID 号；\n * 另一方面，消费者程序要把已经处理过的消息的 ID 号记录下来。\n\n幂等性就是指，对于同一条消息，消费者收到一次的处理结果和收到多次的处理结果是一致的。\n\n因为 List 本身不会为消息生成 ID 号，因此需要生产者在发送消息时附带上全局唯一 ID。例如，我们执行以下命令，就把一条全局 ID 为 101030001、库存量为 5 的消息插入了消息队列：\n\nLPUSH mq "101030001:stock:5"\n(integer) 1\n\n\n1\n2\n\n\n# 1.2.3 消息可靠性保证\n\n当消费者程序从 List 中读取一条消息后，List 就不会再留存这条消息了。所以，如果消费者程序在处理消息的过程出现了故障或宕机，就会导致消息没有处理完成，那么，消费者程序再次启动后，就没法再次从 List 中读取消息了。\n\n为了留存消息，List 类型提供了 BRPOPLPUSH 命令，这个命令的作用是让消费者程序从一个 List 中读取消息，同时，Redis 会把这个消息再插入到另一个 List（可以叫作备份List）留存。这样一来，如果消费者程序读了消息但没能正常处理，等它重启后，就可以从备份 List 中重新读取消息并进行处理了。下图是使用 BRPOPLPUSH 命令留存消息，以及消费者再次读取消息的过程：\n\n好了，到这里你可以看到，基于 List 类型，我们可以满足分布式组件对消息队列的三大需求。但是，在用 List 做消息队列时，我们还可能遇到过一个问题：生产者消息发送很快，而消费者处理消息的速度比较慢，这就导致 List 中的消息越积越多，给 Redis 的内存带来很大压力。这个时候，我们希望启动多个消费者程序组成一个消费组，一起分担处理 List 中的消息。但是，List 类型并不支持消费组的实现。那么，还有没有更合适的解决方案呢？这就要说到 Redis 从 5.0 版本开始提供的 Streams 数据类型了。\n\n和 List 相比，Streams 同样能够满足消息队列的三大需求。而且，它还支持消费组形式的消息读取。接下来，我们就来了解下 Streams 的使用方法。\n\n\n# 1.3 基于 Streams 的消息队列解决方案\n\nStreams 是 Redis 专门为消息队列设计的数据类型，它提供了丰富的消息队列操作命令：\n\n * XADD：插入消息，保证有序，可以自动生成全局唯一 ID；\n * XREAD：用于读取消息，可以按 ID 读取数据；\n * XREADGROUP：按消费组形式读取消息；\n * XPENDING 和 XACK：XPENDING 命令可以用来查询每个消费组内所有消费者已读取但尚未确认的消息，而 XACK 命令用于向消息队列确认消息处理已完成。\n\n# 1）XADD 命令\n\nXADD 命令可以往消息队列中插入新消息，消息的格式是键-值对形式。对于插入的每一条消息，Streams 可以自动为其生成一个全局唯一的 ID。\n\n比如说，我们执行下面的命令，就可以往名称为 mqstream 的消息队列中插入一条消息，消息的键是repo，值是5。其中，消息队列名称后面的 *，表示让Redis为插入的数据自动生成一个全局唯一的ID，例如“1599203861727-0”。当然，我们也可以不用 *，直接在消息队列名称后自行设定一个ID号，只要保证这个ID号是全局唯一的就行。不过，相比自行设定ID号，使用 * 会更加方便高效。\n\nXADD mqstream * repo 5\n"1599203861727-0"\n\n\n1\n2\n\n\n可以看到，消息的全局唯一ID由两部分组成，第一部分“1599203861727”是数据插入时，以毫秒为单位计算的当前服务器时间，第二部分表示插入消息在当前毫秒内的消息序号，这是从0开始编号的。例如，“1599203861727-0”就表示在“1599203861727”毫秒内的第1条消息。\n\n# 2）XREAD 命令\n\n当消费者需要读取消息时，可以直接使用XREAD命令从消息队列中读取。XREAD 在读取消息时，可以指定一个消息 ID，并从这个消息 ID 的下一条消息开始进行读取。\n\n例如，我们可以执行下面的命令，从 ID 号为 1599203861727-0 的消息开始，读取后续的所有消息（示例中一共 3 条）：\n\nXREAD BLOCK 100 STREAMS  mqstream 1599203861727-0\n1) 1) "mqstream"\n   2) 1) 1) "1599274912765-0"\n         2) 1) "repo"\n            2) "3"\n      2) 1) "1599274925823-0"\n         2) 1) "repo"\n            2) "2"\n      3) 1) "1599274927910-0"\n         2) 1) "repo"\n            2) "1"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n另外，消费者也可以在调用 XRAED 时设定 block 配置项，实现类似于 BRPOP 的阻塞读取操作。当消息队列中没有消息时，一旦设置了 block 配置项，XREAD 就会阻塞，阻塞的时长可以在 block 配置项进行设置。\n\n举个例子，我们来看一下下面的命令，其中，命令最后的“$”符号表示读取最新的消息，同时，我们设置了block 10000的配置项，10000的单位是毫秒，表明XREAD在读取最新消息时，如果没有消息到来，XREAD将阻塞10000毫秒（即10秒），然后再返回。下面命令中的XREAD执行后，消息队列mqstream中一直没有消息，所以，XREAD在10秒后返回空值（nil）：\n\nXREAD block 10000 streams mqstream $\n(nil)\n(10.00s)\n\n\n1\n2\n3\n\n\n刚刚讲到的这些操作是 List 也支持的，接下来，我们再来学习下 Streams 特有的功能。\n\n# 3）XGROUP 与 XREADGROUP\n\nStreams 本身可以使用 XGROUP 创建消费组，创建消费组之后，Streams 可以使用 XREADGROUP 命令让消费组内的消费者读取消息。\n\n例如，我们执行下面的命令，创建一个名为 group1 的消费组，这个消费组消费的消息队列是 mqstream：\n\nXGROUP create mqstream group1 0\nOK\n\n\n1\n2\n\n\n然后，我们再执行一段命令，让group1消费组里的消费者consumer1从mqstream中读取所有消息，其中，命令最后的参数“>”，表示从第一条尚未被消费的消息开始读取。因为在consumer1读取消息前，group1中没有其他消费者读取过消息，所以，consumer1就得到mqstream消息队列中的所有消息了（一共4条）：\n\nXREADGROUP group group1 consumer1 streams mqstream >\n1) 1) "mqstream"\n   2) 1) 1) "1599203861727-0"\n         2) 1) "repo"\n            2) "5"\n      2) 1) "1599274912765-0"\n         2) 1) "repo"\n            2) "3"\n      3) 1) "1599274925823-0"\n         2) 1) "repo"\n            2) "2"\n      4) 1) "1599274927910-0"\n         2) 1) "repo"\n            2) "1"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n需要注意的是，消息队列中的消息一旦被消费组里的一个消费者读取了，就不能再被该消费组内的其他消费者读取了。比如说，我们执行完刚才的XREADGROUP命令后，再执行下面的命令，让group1内的consumer2读取消息时，consumer2读到的就是空值，因为消息已经被consumer1读取完了，如下所示：\n\nXREADGROUP group group1 consumer2  streams mqstream 0\n1) 1) "mqstream"\n   2) (empty list or set)\n\n\n1\n2\n3\n\n\n使用消费组的目的是让组内的多个消费者共同分担读取消息，所以，我们通常会让每个消费者读取部分消息，从而实现消息读取负载在多个消费者间是均衡分布的。例如，我们执行下列命令，让 group2 中的 consumer1、2、3 各自读取一条消息。\n\nXREADGROUP group group2 consumer1 count 1 streams mqstream >\n1) 1) "mqstream"\n   2) 1) 1) "1599203861727-0"\n         2) 1) "repo"\n            2) "5"\n\nXREADGROUP group group2 consumer2 count 1 streams mqstream >\n1) 1) "mqstream"\n   2) 1) 1) "1599274912765-0"\n         2) 1) "repo"\n            2) "3"\n\nXREADGROUP group group2 consumer3 count 1 streams mqstream >\n1) 1) "mqstream"\n   2) 1) 1) "1599274925823-0"\n         2) 1) "repo"\n            2) "2"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n# 4）XPENDING 和 XACK\n\n为了保证消费者在发生故障或宕机再次重启后，仍然可以读取未处理完的消息，Streams 会自动使用内部队列（也称为 PENDING List）留存消费组里每个消费者读取的消息，直到消费者使用 XACK 命令通知Streams“消息已经处理完成”。如果消费者没有成功处理消息，它就不会给 Streams 发送 XACK 命令，消息仍然会留存。此时，消费者可以在重启后，用 XPENDING 命令查看已读取、但尚未确认处理完成的消息。\n\n例如，我们来查看一下group2中各个消费者已读取、但尚未确认的消息个数。其中，XPENDING返回结果的第二、三行分别表示group2中所有消费者读取的消息最小ID和最大ID：\n\nXPENDING mqstream group2\n1) (integer) 3\n2) "1599203861727-0"\n3) "1599274925823-0"\n4) 1) 1) "consumer1"\n      2) "1"\n   2) 1) "consumer2"\n      2) "1"\n   3) 1) "consumer3"\n      2) "1"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n如果我们还需要进一步查看某个消费者具体读取了哪些数据，可以执行下面的命令：\n\nXPENDING mqstream group2 - + 10 consumer2\n1) 1) "1599274912765-0"\n   2) "consumer2"\n   3) (integer) 513336\n   4) (integer) 1\n\n\n1\n2\n3\n4\n5\n\n\n可以看到，consumer2 已读取的消息的 ID 是 1599274912765-0。\n\n一旦消息 1599274912765-0 被 consumer2 处理了，consumer2 就可以使用 XACK 命令通知 Streams，然后这条消息就会被删除。当我们再使用 XPENDING 命令查看时，就可以看到，consumer2 已经没有已读取、但尚未确认处理的消息了。\n\n XACK mqstream group2 1599274912765-0\n(integer) 1\nXPENDING mqstream group2 - + 10 consumer2\n(empty list or set)\n\n\n1\n2\n3\n4\n\n\n现在，我们就知道了用 Streams 实现消息队列的方法，我还想再强调下，Streams 是 Redis 5.0 专门针对消息队列场景设计的数据类型，如果你的 Redis 是5.0及5.0以后的版本，就可以考虑把 Streams 用作消息队列了。\n\n\n# 1.4 小结\n\n我们学习了分布式系统组件使用消息队列时的三大需求：消息保序、重复消息处理和消息可靠性保证，这三大需求可以进一步转换为对消息队列的三大要求：消息数据有序存取，消息数据具有全局唯一编号，以及消息数据在消费完成后被删除。\n\n下图汇总了 List 和 Streams 实现消息队列的特点和区别：\n\n> 其实，关于Redis是否适合做消息队列，业界一直是有争论的。很多人认为，要使用消息队列，就应该采用 Kafka、RabbitMQ 这些专门面向消息队列场景的软件，而 Redis 更加适合做缓存。\n> \n> 根据这些年做Redis研发工作的经验，我的看法是：Redis是一个非常轻量级的键值数据库，部署一个Redis实例就是启动一个进程，部署Redis集群，也就是部署多个Redis实例。而Kafka、RabbitMQ部署时，涉及额外的组件，例如Kafka的运行就需要再部署ZooKeeper。相比Redis来说，Kafka和RabbitMQ一般被认为是重量级的消息队列。\n> \n> 所以，关于是否用Redis做消息队列的问题，不能一概而论，我们需要考虑业务层面的数据体量，以及对性能、可靠性、可扩展性的需求。如果分布式系统中的组件消息通信量不大，那么，Redis只需要使用有限的内存空间就能满足消息存储的需求，而且，Redis的高性能特性能支持快速的消息读写，不失为消息队列的一个好的解决方案。\n\n----------------------------------------\n\n本节问题：如果一个生产者发送给消息队列的消息，需要被多个消费者进行读取和处理（例如，一个消息是一条从业务系统采集的数据，既要被消费者1读取并进行实时计算，也要被消费者2读取并留存到分布式文件系统HDFS中，以便后续进行历史查询），你会使用Redis的什么数据类型来解决这个问题呢？\n\n可以使用Streams数据类型的消费组，同时消费生产者的数据，这是可以的。但是，需要注意，如果只是使用一个消费组的话，消费组内的多个消费者在消费消息时是互斥的，换句话说，在一个消费组内，一个消息只能被一个消费者消费。我们希望消息既要被消费者1读取，也要被消费者2读取，是一个多消费者的需求。所以，如果使用消费组模式，需要让消费者1和消费者2属于不同的消费组，这样它们就能同时消费了。\n\n另外，Redis基于字典和链表数据结构，实现了发布和订阅功能，这个功能可以实现一个消息被多个消费者消费使用，可以满足问题中的场景需求。',normalizedContent:'> 参考：\n> \n>  * 15 消息队列的考验：redis 有哪些解决方案？| 极客时间\n\n\n# 1. 消息队列的考验：redis有哪些解决方案？\n\n消息队列是分布式系统的基础软件，要能支持组件通信消息的快速读写。redis 本身支持数据的高速访问，因此很多人关心一个问题：redis 适合做 mq 吗？\n\n这个问题的背后，隐含着两方面的核心问题：\n\n * 消息队列的消息存取需求是什么？\n * redis 如何实现消息队列的需求？\n\n理解了 mq 的特征和 redis 提供的 mq 方案，才能根据实际需求来选择出适合的 redis 消息队列方案。\n\n\n# 1.1 mq 的消息存取需求\n\n先介绍一下消息队列存取消息的过程。在分布式系统中，当两个组件要基于消息队列进行通信时，一个组件会把要处理的数据以消息的形式传递给消息队列，然后，这个组件就可以继续执行其他操作了；远端的另一个组件从消息队列中把消息读取出来，再在本地进行处理。\n\n一个通用的 mq 的架构模型为：\n\n消息队列中发送消息的组件称为生产者，接收消息的组件称为消费者。\n\n在使用消息队列时，消费者可以异步读取生产者消息，然后再进行处理。这样一来，即使生产者发送消息的速度远远超过了消费者处理消息的速度，生产者已经发送的消息也可以缓存在消息队列中，避免阻塞生产者，这是消息队列作为分布式组件通信的一大优势。\n\nmq 在存取消息时，必须要满足三个需求：\n\n 1. 消息保序\n 2. 处理重复的消息（幂等要求）\n 3. 保证消息可靠性\n\n# 需求一：消息保序\n\n虽然消费者是异步处理消息，但是，消费者仍然需要按照生产者发送消息的顺序来处理消息，避免后发送的消息被先处理了。对于要求消息保序的场景来说，一旦出现这种消息被乱序处理的情况，就可能会导致业务逻辑被错误执行，从而给业务方造成损失。\n\n我们来看一个更新商品库存的场景：假设生产者负责接收库存更新请求，消费者负责实际更新库存，现有库存量是10。生产者先后发送了消息1和消息2，消息1要把商品x的库存记录更新为5，消息2是把商品x库存更新为3。如果消息1和2在消息队列中无法保序，出现消息2早于消息1被处理的情况，那么，很显然，库存更新就出错了。这是业务应用无法接受的。\n\n# 需求二：重复消息处理（幂等要求）\n\n消费者从消息队列读取消息时，有时会因为网络堵塞而出现消息重传的情况。对于重复的消息，消费者如果多次处理的话，就可能造成一个业务逻辑被多次执行，如果业务逻辑正好是要修改数据，那就会出现数据被多次修改的问题了。\n\n比如可能出现重复扣款的问题。\n\n# 需求三：消息可靠性保证\n\n消费者在处理消息的时候，还可能出现因为故障或宕机导致消息没有处理完成的情况。此时，消息队列需要能提供消息可靠性的保证，也就是说，当消费者重启后，可以重新读取消息再次进行处理，否则，就会出现消息漏处理的问题了。\n\nredis 的 list 和 streams 两种数据类型，就可以满足消息队列的这三个需求。下面来看这两种方案。\n\n\n# 1.2 基于 list 的 mq 解决方案\n\n# 1.2.1 解决消息保序问题\n\nlist 本身就是按先进先出的顺序对数据进行存取的，所以如果使用 list 作为消息队列保存消息的话，就已经能满足消息保序的需求了：\n\n * 生产者使用 lpush 命令把消息写入 list\n * 消费者使用 rpop 命令读取消息\n\n不过这样的话 list 不会主动告知消费者有新消息的写入，这样就需要消费者一直调用 rpop 来监听消息（比如使用一个while(1)循环），这会带来不必要的性能损失。\n\n为了解决这个问题，redis 提供了 brpop 命令：阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列，再开始读取新数据。这种方式相比消费者不停调用 rpop 而言，更加节省 cpu 开销。\n\n# 1.2.2 幂等性要求（处理重复消息）\n\n解决消息重复问题，其实有一个要求：消费者程序本身能对重复消息进行判断：\n\n * 一方面，消息队列要能给每一个消息提供全局唯一的 id 号；\n * 另一方面，消费者程序要把已经处理过的消息的 id 号记录下来。\n\n幂等性就是指，对于同一条消息，消费者收到一次的处理结果和收到多次的处理结果是一致的。\n\n因为 list 本身不会为消息生成 id 号，因此需要生产者在发送消息时附带上全局唯一 id。例如，我们执行以下命令，就把一条全局 id 为 101030001、库存量为 5 的消息插入了消息队列：\n\nlpush mq "101030001:stock:5"\n(integer) 1\n\n\n1\n2\n\n\n# 1.2.3 消息可靠性保证\n\n当消费者程序从 list 中读取一条消息后，list 就不会再留存这条消息了。所以，如果消费者程序在处理消息的过程出现了故障或宕机，就会导致消息没有处理完成，那么，消费者程序再次启动后，就没法再次从 list 中读取消息了。\n\n为了留存消息，list 类型提供了 brpoplpush 命令，这个命令的作用是让消费者程序从一个 list 中读取消息，同时，redis 会把这个消息再插入到另一个 list（可以叫作备份list）留存。这样一来，如果消费者程序读了消息但没能正常处理，等它重启后，就可以从备份 list 中重新读取消息并进行处理了。下图是使用 brpoplpush 命令留存消息，以及消费者再次读取消息的过程：\n\n好了，到这里你可以看到，基于 list 类型，我们可以满足分布式组件对消息队列的三大需求。但是，在用 list 做消息队列时，我们还可能遇到过一个问题：生产者消息发送很快，而消费者处理消息的速度比较慢，这就导致 list 中的消息越积越多，给 redis 的内存带来很大压力。这个时候，我们希望启动多个消费者程序组成一个消费组，一起分担处理 list 中的消息。但是，list 类型并不支持消费组的实现。那么，还有没有更合适的解决方案呢？这就要说到 redis 从 5.0 版本开始提供的 streams 数据类型了。\n\n和 list 相比，streams 同样能够满足消息队列的三大需求。而且，它还支持消费组形式的消息读取。接下来，我们就来了解下 streams 的使用方法。\n\n\n# 1.3 基于 streams 的消息队列解决方案\n\nstreams 是 redis 专门为消息队列设计的数据类型，它提供了丰富的消息队列操作命令：\n\n * xadd：插入消息，保证有序，可以自动生成全局唯一 id；\n * xread：用于读取消息，可以按 id 读取数据；\n * xreadgroup：按消费组形式读取消息；\n * xpending 和 xack：xpending 命令可以用来查询每个消费组内所有消费者已读取但尚未确认的消息，而 xack 命令用于向消息队列确认消息处理已完成。\n\n# 1）xadd 命令\n\nxadd 命令可以往消息队列中插入新消息，消息的格式是键-值对形式。对于插入的每一条消息，streams 可以自动为其生成一个全局唯一的 id。\n\n比如说，我们执行下面的命令，就可以往名称为 mqstream 的消息队列中插入一条消息，消息的键是repo，值是5。其中，消息队列名称后面的 *，表示让redis为插入的数据自动生成一个全局唯一的id，例如“1599203861727-0”。当然，我们也可以不用 *，直接在消息队列名称后自行设定一个id号，只要保证这个id号是全局唯一的就行。不过，相比自行设定id号，使用 * 会更加方便高效。\n\nxadd mqstream * repo 5\n"1599203861727-0"\n\n\n1\n2\n\n\n可以看到，消息的全局唯一id由两部分组成，第一部分“1599203861727”是数据插入时，以毫秒为单位计算的当前服务器时间，第二部分表示插入消息在当前毫秒内的消息序号，这是从0开始编号的。例如，“1599203861727-0”就表示在“1599203861727”毫秒内的第1条消息。\n\n# 2）xread 命令\n\n当消费者需要读取消息时，可以直接使用xread命令从消息队列中读取。xread 在读取消息时，可以指定一个消息 id，并从这个消息 id 的下一条消息开始进行读取。\n\n例如，我们可以执行下面的命令，从 id 号为 1599203861727-0 的消息开始，读取后续的所有消息（示例中一共 3 条）：\n\nxread block 100 streams  mqstream 1599203861727-0\n1) 1) "mqstream"\n   2) 1) 1) "1599274912765-0"\n         2) 1) "repo"\n            2) "3"\n      2) 1) "1599274925823-0"\n         2) 1) "repo"\n            2) "2"\n      3) 1) "1599274927910-0"\n         2) 1) "repo"\n            2) "1"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n另外，消费者也可以在调用 xraed 时设定 block 配置项，实现类似于 brpop 的阻塞读取操作。当消息队列中没有消息时，一旦设置了 block 配置项，xread 就会阻塞，阻塞的时长可以在 block 配置项进行设置。\n\n举个例子，我们来看一下下面的命令，其中，命令最后的“$”符号表示读取最新的消息，同时，我们设置了block 10000的配置项，10000的单位是毫秒，表明xread在读取最新消息时，如果没有消息到来，xread将阻塞10000毫秒（即10秒），然后再返回。下面命令中的xread执行后，消息队列mqstream中一直没有消息，所以，xread在10秒后返回空值（nil）：\n\nxread block 10000 streams mqstream $\n(nil)\n(10.00s)\n\n\n1\n2\n3\n\n\n刚刚讲到的这些操作是 list 也支持的，接下来，我们再来学习下 streams 特有的功能。\n\n# 3）xgroup 与 xreadgroup\n\nstreams 本身可以使用 xgroup 创建消费组，创建消费组之后，streams 可以使用 xreadgroup 命令让消费组内的消费者读取消息。\n\n例如，我们执行下面的命令，创建一个名为 group1 的消费组，这个消费组消费的消息队列是 mqstream：\n\nxgroup create mqstream group1 0\nok\n\n\n1\n2\n\n\n然后，我们再执行一段命令，让group1消费组里的消费者consumer1从mqstream中读取所有消息，其中，命令最后的参数“>”，表示从第一条尚未被消费的消息开始读取。因为在consumer1读取消息前，group1中没有其他消费者读取过消息，所以，consumer1就得到mqstream消息队列中的所有消息了（一共4条）：\n\nxreadgroup group group1 consumer1 streams mqstream >\n1) 1) "mqstream"\n   2) 1) 1) "1599203861727-0"\n         2) 1) "repo"\n            2) "5"\n      2) 1) "1599274912765-0"\n         2) 1) "repo"\n            2) "3"\n      3) 1) "1599274925823-0"\n         2) 1) "repo"\n            2) "2"\n      4) 1) "1599274927910-0"\n         2) 1) "repo"\n            2) "1"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n需要注意的是，消息队列中的消息一旦被消费组里的一个消费者读取了，就不能再被该消费组内的其他消费者读取了。比如说，我们执行完刚才的xreadgroup命令后，再执行下面的命令，让group1内的consumer2读取消息时，consumer2读到的就是空值，因为消息已经被consumer1读取完了，如下所示：\n\nxreadgroup group group1 consumer2  streams mqstream 0\n1) 1) "mqstream"\n   2) (empty list or set)\n\n\n1\n2\n3\n\n\n使用消费组的目的是让组内的多个消费者共同分担读取消息，所以，我们通常会让每个消费者读取部分消息，从而实现消息读取负载在多个消费者间是均衡分布的。例如，我们执行下列命令，让 group2 中的 consumer1、2、3 各自读取一条消息。\n\nxreadgroup group group2 consumer1 count 1 streams mqstream >\n1) 1) "mqstream"\n   2) 1) 1) "1599203861727-0"\n         2) 1) "repo"\n            2) "5"\n\nxreadgroup group group2 consumer2 count 1 streams mqstream >\n1) 1) "mqstream"\n   2) 1) 1) "1599274912765-0"\n         2) 1) "repo"\n            2) "3"\n\nxreadgroup group group2 consumer3 count 1 streams mqstream >\n1) 1) "mqstream"\n   2) 1) 1) "1599274925823-0"\n         2) 1) "repo"\n            2) "2"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n# 4）xpending 和 xack\n\n为了保证消费者在发生故障或宕机再次重启后，仍然可以读取未处理完的消息，streams 会自动使用内部队列（也称为 pending list）留存消费组里每个消费者读取的消息，直到消费者使用 xack 命令通知streams“消息已经处理完成”。如果消费者没有成功处理消息，它就不会给 streams 发送 xack 命令，消息仍然会留存。此时，消费者可以在重启后，用 xpending 命令查看已读取、但尚未确认处理完成的消息。\n\n例如，我们来查看一下group2中各个消费者已读取、但尚未确认的消息个数。其中，xpending返回结果的第二、三行分别表示group2中所有消费者读取的消息最小id和最大id：\n\nxpending mqstream group2\n1) (integer) 3\n2) "1599203861727-0"\n3) "1599274925823-0"\n4) 1) 1) "consumer1"\n      2) "1"\n   2) 1) "consumer2"\n      2) "1"\n   3) 1) "consumer3"\n      2) "1"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n如果我们还需要进一步查看某个消费者具体读取了哪些数据，可以执行下面的命令：\n\nxpending mqstream group2 - + 10 consumer2\n1) 1) "1599274912765-0"\n   2) "consumer2"\n   3) (integer) 513336\n   4) (integer) 1\n\n\n1\n2\n3\n4\n5\n\n\n可以看到，consumer2 已读取的消息的 id 是 1599274912765-0。\n\n一旦消息 1599274912765-0 被 consumer2 处理了，consumer2 就可以使用 xack 命令通知 streams，然后这条消息就会被删除。当我们再使用 xpending 命令查看时，就可以看到，consumer2 已经没有已读取、但尚未确认处理的消息了。\n\n xack mqstream group2 1599274912765-0\n(integer) 1\nxpending mqstream group2 - + 10 consumer2\n(empty list or set)\n\n\n1\n2\n3\n4\n\n\n现在，我们就知道了用 streams 实现消息队列的方法，我还想再强调下，streams 是 redis 5.0 专门针对消息队列场景设计的数据类型，如果你的 redis 是5.0及5.0以后的版本，就可以考虑把 streams 用作消息队列了。\n\n\n# 1.4 小结\n\n我们学习了分布式系统组件使用消息队列时的三大需求：消息保序、重复消息处理和消息可靠性保证，这三大需求可以进一步转换为对消息队列的三大要求：消息数据有序存取，消息数据具有全局唯一编号，以及消息数据在消费完成后被删除。\n\n下图汇总了 list 和 streams 实现消息队列的特点和区别：\n\n> 其实，关于redis是否适合做消息队列，业界一直是有争论的。很多人认为，要使用消息队列，就应该采用 kafka、rabbitmq 这些专门面向消息队列场景的软件，而 redis 更加适合做缓存。\n> \n> 根据这些年做redis研发工作的经验，我的看法是：redis是一个非常轻量级的键值数据库，部署一个redis实例就是启动一个进程，部署redis集群，也就是部署多个redis实例。而kafka、rabbitmq部署时，涉及额外的组件，例如kafka的运行就需要再部署zookeeper。相比redis来说，kafka和rabbitmq一般被认为是重量级的消息队列。\n> \n> 所以，关于是否用redis做消息队列的问题，不能一概而论，我们需要考虑业务层面的数据体量，以及对性能、可靠性、可扩展性的需求。如果分布式系统中的组件消息通信量不大，那么，redis只需要使用有限的内存空间就能满足消息存储的需求，而且，redis的高性能特性能支持快速的消息读写，不失为消息队列的一个好的解决方案。\n\n----------------------------------------\n\n本节问题：如果一个生产者发送给消息队列的消息，需要被多个消费者进行读取和处理（例如，一个消息是一条从业务系统采集的数据，既要被消费者1读取并进行实时计算，也要被消费者2读取并留存到分布式文件系统hdfs中，以便后续进行历史查询），你会使用redis的什么数据类型来解决这个问题呢？\n\n可以使用streams数据类型的消费组，同时消费生产者的数据，这是可以的。但是，需要注意，如果只是使用一个消费组的话，消费组内的多个消费者在消费消息时是互斥的，换句话说，在一个消费组内，一个消息只能被一个消费者消费。我们希望消息既要被消费者1读取，也要被消费者2读取，是一个多消费者的需求。所以，如果使用消费组模式，需要让消费者1和消费者2属于不同的消费组，这样它们就能同时消费了。\n\n另外，redis基于字典和链表数据结构，实现了发布和订阅功能，这个功能可以实现一个消息被多个消费者消费使用，可以满足问题中的场景需求。',charsets:{cjk:!0},lastUpdated:"2023/04/10, 14:17:28",lastUpdatedTimestamp:1681136248e3},{title:"异步机制、CPU 架构对性能的影响",frontmatter:{title:"异步机制、CPU 架构对性能的影响",date:"2023-04-07T19:23:37.000Z",permalink:"/pages/ca62e3/",categories:["中间件","Redis","专栏：Redis 核心技术与实战"],tags:[null]},regularPath:"/%E4%B8%AD%E9%97%B4%E4%BB%B6/05.Redis/05.%E4%B8%93%E6%A0%8F%EF%BC%9ARedis%20%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/16.%E5%BC%82%E6%AD%A5%E6%9C%BA%E5%88%B6%E3%80%81CPU%20%E6%9E%B6%E6%9E%84%E5%AF%B9%E6%80%A7%E8%83%BD%E7%9A%84%E5%BD%B1%E5%93%8D.html",relativePath:"中间件/05.Redis/05.专栏：Redis 核心技术与实战/16.异步机制、CPU 架构对性能的影响.md",key:"v-68306418",path:"/pages/ca62e3/",headers:[{level:2,title:"1. 异步机制：如何避免单线程模型的阻塞？",slug:"_1-异步机制-如何避免单线程模型的阻塞",normalizedTitle:"1. 异步机制：如何避免单线程模型的阻塞？",charIndex:240},{level:3,title:"1.1 Redis 实例有哪些阻塞点？",slug:"_1-1-redis-实例有哪些阻塞点",normalizedTitle:"1.1 redis 实例有哪些阻塞点？",charIndex:266},{level:4,title:"1）和客户端交互时的阻塞点",slug:"_1-和客户端交互时的阻塞点",normalizedTitle:"1）和客户端交互时的阻塞点",charIndex:499},{level:4,title:"2）和磁盘交互时的阻塞点",slug:"_2-和磁盘交互时的阻塞点",normalizedTitle:"2）和磁盘交互时的阻塞点",charIndex:1671},{level:4,title:"3）主从节点交互时的阻塞点",slug:"_3-主从节点交互时的阻塞点",normalizedTitle:"3）主从节点交互时的阻塞点",charIndex:1866},{level:4,title:"4）切片集群实例交互时的阻塞点",slug:"_4-切片集群实例交互时的阻塞点",normalizedTitle:"4）切片集群实例交互时的阻塞点",charIndex:2075},{level:3,title:"1.2 哪些阻塞点可以异步执行？",slug:"_1-2-哪些阻塞点可以异步执行",normalizedTitle:"1.2 哪些阻塞点可以异步执行？",charIndex:2676},{level:3,title:"1.3 异步的子线程机制",slug:"_1-3-异步的子线程机制",normalizedTitle:"1.3 异步的子线程机制",charIndex:3569},{level:3,title:"1.4 小结",slug:"_1-4-小结",normalizedTitle:"1.4 小结",charIndex:4268},{level:2,title:"2. 为什么 CPU 结构也会影响 Redis 的性能？",slug:"_2-为什么-cpu-结构也会影响-redis-的性能",normalizedTitle:"2. 为什么 cpu 结构也会影响 redis 的性能？",charIndex:4338},{level:3,title:"2.1 主流的 CPU 架构",slug:"_2-1-主流的-cpu-架构",normalizedTitle:"2.1 主流的 cpu 架构",charIndex:4474},{level:3,title:"2.2 CPU 多核对 Redis 性能的影响",slug:"_2-2-cpu-多核对-redis-性能的影响",normalizedTitle:"2.2 cpu 多核对 redis 性能的影响",charIndex:5572},{level:3,title:"2.3 CPU 的 NUMA 架构对 Redis 性能的影响",slug:"_2-3-cpu-的-numa-架构对-redis-性能的影响",normalizedTitle:"2.3 cpu 的 numa 架构对 redis 性能的影响",charIndex:6260},{level:3,title:"2.4 绑核的风险和解决方案",slug:"_2-4-绑核的风险和解决方案",normalizedTitle:"2.4 绑核的风险和解决方案",charIndex:7354},{level:4,title:"方案一：一个 Redis 实例对应绑一个物理核",slug:"方案一-一个-redis-实例对应绑一个物理核",normalizedTitle:"方案一：一个 redis 实例对应绑一个物理核",charIndex:7486},{level:4,title:"方案二：优化 Redis 源码",slug:"方案二-优化-redis-源码",normalizedTitle:"方案二：优化 redis 源码",charIndex:7923},{level:3,title:"2.5 小结",slug:"_2-5-小结",normalizedTitle:"2.5 小结",charIndex:10093}],headersStr:"1. 异步机制：如何避免单线程模型的阻塞？ 1.1 Redis 实例有哪些阻塞点？ 1）和客户端交互时的阻塞点 2）和磁盘交互时的阻塞点 3）主从节点交互时的阻塞点 4）切片集群实例交互时的阻塞点 1.2 哪些阻塞点可以异步执行？ 1.3 异步的子线程机制 1.4 小结 2. 为什么 CPU 结构也会影响 Redis 的性能？ 2.1 主流的 CPU 架构 2.2 CPU 多核对 Redis 性能的影响 2.3 CPU 的 NUMA 架构对 Redis 性能的影响 2.4 绑核的风险和解决方案 方案一：一个 Redis 实例对应绑一个物理核 方案二：优化 Redis 源码 2.5 小结",content:'> 参考：\n> \n>  * 16 异步机制：如何避免单线程模型的阻塞？| 极客时间\n>  * 17 为什么 CPU 结构也会影响 Redis 的性能？| 极客时间\n\nRedis 因其高性能而被广泛应用，我们需要避免性能异常的情况出现。影响 Redis 性能的 5 大方面因素有：\n\n * Redis 内部的阻塞式操作\n * CPU 核和 NUMA 架构的影响\n * Redis 关键系统配置\n * Redis 内存碎片\n * Redis 缓冲区\n\n本文将分析前两个因素。\n\n\n# 1. 异步机制：如何避免单线程模型的阻塞？\n\n\n# 1.1 Redis 实例有哪些阻塞点？\n\n我们前面学习过，Redis 的网络 IO 和键值对读写是由主线程完成的，这些不同的交互要涉及不同的操作。我们看一下 Redis 和不同对象交互时，有哪些交互操作：\n\n * 客户端：网络 IP、KV 的 CRUD 等\n * 磁盘：AOF 与 RDB 操作\n * 主从节点：数据复制操作\n * 切片集群：向其他实例传输哈希槽信息、数据迁移\n\n这四类交互对象和操作之间的关系如下图：\n\n下面我们逐个分析哪些操作会引起阻塞：\n\n# 1）和客户端交互时的阻塞点\n\n由于 Redis 使用了 IO 多路复用机制避免了主线程的一直等待，所以网络 IO 不是导致 Redis 阻塞的因素。\n\nCRUD 操作是 Redis 与客户端交互的主要部分，也是 Redis 主线程执行的主要任务。所以，复杂度高的增删改查操作肯定会阻塞 Redis。\n\n那怎么判断操作复杂度高不高呢？这里有一个最基本的标准，就是看操作的复杂度是否为 O(N)。\n\nRedis 中涉及集合的操作复杂度通常为O(N)，我们要在使用时重视起来。例如集合元素全量查询操作HGETALL、SMEMBERS，以及集合的聚合统计操作，例如求交、并和差集。这些操作可以作为 Redis 的第一个阻塞点：集合全量查询和聚合操作。\n\n除此之外，集合自身的删除操作同样也有潜在的阻塞风险。因为删除操作的本质是要释放键值对占用的内存空间，而操作系统在释放内存时需要把所释放的内存块插入空闲链表中以便管理，这个过程可能会阻塞程序。所以，如果一下子释放了大量内存，空闲内存块链表操作时间就会增加，相应地就会造成 Redis 主线程的阻塞。\n\n释放大量内存的场景，就是在删除大量键值对数据时，最典型的就是删除包含了大量元素的集合，也称为 bigkey 删除。下图测试了不同元素数量的集合进行删除操作所耗费的时间：\n\n从这张表里，我们可以得出三个结论：\n\n 1. 当元素数量从10万增加到100万时，4大集合类型的删除时间的增长幅度从5倍上升到了近20倍；\n 2. 集合元素越大，删除所花费的时间就越长；\n 3. 当删除有100万个元素的集合时，最大的删除时间绝对值已经达到了1.98s（Hash类型）。Redis的响应时间一般在微秒级别，所以，一个操作达到了近2s，不可避免地会阻塞主线程。\n\n所以，bigkey 删除操作就是 Redis 的第二个阻塞点。删除操作对Redis实例性能的负面影响很大，而且在实际业务开发时容易被忽略，所以一定要重视它。\n\n小建议\n\n当遇到 bigkey 删除时，有一个小建议：先使用集合类型提供的 SCAN 命令读取数据，然后再进行删除。因为用 SCAN 命令可以每次只读取一部分数据并进行删除，这样可以避免一次性删除大量 key 给主线程带来的阻塞。\n\n例如，对于 Hash 类型的 bigkey 删除，你可以使用 HSCAN 命令，每次从Hash集合中获取一部分键值对（例如200个），再使用 HDEL 删除这些键值对，这样就可以把删除压力分摊到多次操作中，那么，每次删除操作的耗时就不会太长，也就不会阻塞主线程了。\n\n容易联想到，清空数据库（flushdb 和 flushall 操作）也必然是一个潜在的阻塞风险，因为它们也涉及到大量 KV 的删除。所以，Redis 的第三个阻塞点：清空数据库。\n\n# 2）和磁盘交互时的阻塞点\n\n由于磁盘 IO 一般比较慢，因此需要重点关注。Redis 采用子进程的方式来执行 RDB 的生成和 AOF 的重写，从而避免了对主线程的阻塞。\n\n但 Redis 直接记录 AOF 时，会根据不同的写回策略对数据做落盘保存。一次同步写磁盘大约耗时 1~2ms，如果存在大量同步写操作的话，就会阻塞主线程。因此 Redis 的四个阻塞点：AOF 日志同步写。\n\n# 3）主从节点交互时的阻塞点\n\n在主从复制时，主库创建和传输 RDB 文件都是由子进程完成的，不会阻塞主线程；从库接收 RDB 文件后，需要使用 flushdb 命令来清空当前数据库，这正好装上了刚刚分析的第三个阻塞点。\n\n此外，从库在清空数据库后，还需要把 RDB 加载到内存中，这个过程与 RDB 文件的大小密切相关，RDB 越大，加载过程越慢。所以，加载 RDB 文件就成为了 Redis 的第五个阻塞点。\n\n# 4）切片集群实例交互时的阻塞点\n\n最后，当我们部署Redis切片集群时，每个Redis实例上分配的哈希槽信息需要在不同实例间进行传递，同时，当需要进行负载均衡或者有实例增删时，数据会在不同的实例间进行迁移。不过，哈希槽的信息量不大，而数据迁移是渐进式执行的，所以，一般来说，这两类操作对 Redis 主线程的阻塞风险不大。\n\n不过，如果你使用了 Redis Cluster 方案，而且同时正好迁移的是 bigkey 的话，就会造成主线程的阻塞，因为 Redis Cluster 使用了同步迁移。我将在第33讲中向你介绍不同切片集群方案对数据迁移造成的阻塞的解决方法，这里你只需要知道，当没有 bigkey 时，切片集群的各实例在进行交互时不会阻塞主线程，就可以了。\n\n现在我们总结下刚刚找到的五个阻塞点：\n\n * 集合全量查询和聚合操作\n * bigkey 删除\n * 清空数据库\n * AOF 日志同步写\n * 从库加载 RDB 文件\n\n如果在主线程中执行这些操作，必然会导致主线程长时间无法服务其他请求。为了避免阻塞式操作，Redis 提供了异步线程机制。所谓的异步线程机制：指 Redis 会启动一些子线程，然后把一些任务交给这些子线程，让它们在后台完成，而不再由主线程来执行这些任务。使用异步线程机制执行操作，可以避免阻塞主线程。\n\n不过问题来了，这五个阻塞式操作都可以被异步执行吗？\n\n\n# 1.2 哪些阻塞点可以异步执行？\n\n先看一下异步执行对操作的要求。\n\n如果一个操作能被异步执行，就意味着，它并不是 Redis 主线程的关键路径上的操作。关键路径上的操作是说，客户端把请求发给 Redis 后就等着返回数据结果。如下图：\n\n * 左图的操作 1 就不算关键路径上的操作，因此可以让后台子线程来异步执行；\n * 右图的操作 2 就是关键路径上的操作，所以主线程必须立即把这个操作执行完。\n\n对 Redis 来说，读操作是典型的关键路径操作。Redis 的第一个阻塞点“集合全量查询和聚合操作”都涉及到了读操作，所以，它们是不能进行异步操作了。\n\n而删除操作不需要立刻返回具体的结果，不算是关键路径操作，因此我们可以使用后台子线程来异步执行删除操作。故第二个和第三个阻塞点可以异步解决。\n\n对于第四个阻塞点“AOF日志同步写”来说，为保证数据可靠性，Redis 实例需要保证 AOF 日志中的操作记录已经落盘，这个操作虽然需要实例等待，但它并不会返回具体的数据结果给实例。所以，我们也可以启动一个子线程来执行AOF日志的同步写，而不用让主线程等待AOF日志的写完成。\n\n最后再看下“从库加载 RDB 文件”这第五个阻塞点。从库必须把 RDB 加载完，这操作也属于关键路径上的操作，所以我们必须让从库的主线程来执行。\n\n对于 Redis 的五大阻塞点来说，除了“集合全量查询和聚合操作”和“从库加载 RDB 文件”，其他三个阻塞点涉及的操作都不在关键路径上，所以可以使用 Redis 的异步子线程机制来实现 bigkey 删除，清空数据库，以及 AOF 日志同步写。\n\n小建议\n\n集合全量查询和聚合操作、从库加载RDB文件是在关键路径上，无法使用异步操作来完成。对于这两个阻塞点也有两个小建议：\n\n * 集合全量查询和聚合操作：可以使用 SCAN 命令，分批读取数据，再在客户端进行聚合计算；\n * 从库加载 RDB 文件：把主库的数据量大小控制在 2~4GB 左右，以保证 RDB 文件能以较快的速度加载。\n\n那 Redis 实现的异步子线程机制具体是怎么执行呢？\n\n\n# 1.3 异步的子线程机制\n\nRedis 主线程启动后，会使用操作系统提供的 pthread_create 函数创建 3 个子线程，分别由它们负责 AOF 日志写操作、键值对删除以及文件关闭的异步执行。\n\n主线程通过一个链表形式的任务队列和子线程进行交互。当收到键值对删除和清空数据库的操作时，主线程会把这个操作封装成一个任务，放入到任务队列中，然后给客户端返回一个完成信息，表明删除已经完成。但实际上，这个时候删除还没有执行，等到后台子线程从任务队列中读取任务后，才开始实际删除键值对，并释放相应的内存空间。因此，我们把这种异步删除也称为惰性删除（lazy free）。此时，删除或清空操作不会阻塞主线程，这就避免了对主线程的性能影响。\n\n和惰性删除类似，当 AOF 日志配置成 everysec 选项后，主线程会把 AOF 写日志操作封装成一个任务，也放到任务队列中。后台子线程读取任务后，开始自行写入 AOF 日志，这样主线程就不用一直等待 AOF 日志写完了。\n\n下面这张图展示了 Redis 中的异步子线程执行机制：\n\n异步的键值对删除和数据库清空操作是 Redis 4.0 后提供的功能，Redis也提供了新的命令来执行这两个操作：\n\n * 键值对删除：当你的集合类型中有大量元素（例如有百万级别或千万级别元素）需要删除时，我建议你使用 UNLINK 命令。\n * 清空数据库：可以在 FLUSHDB 和 FLUSHALL 命令后加上 ASYNC 选项，这样就可以让后台子线程异步地清空数据库，如下所示：\n\nFLUSHDB ASYNC\nFLUSHALL AYSNC\n\n\n1\n2\n\n\n\n# 1.4 小结\n\n这一节主要讲了 Redis 运行时的交互对象和交互操作，并对其中不属于关键路径的操作讲解使用异步子线程机制来完成。\n\n\n# 2. 为什么 CPU 结构也会影响 Redis 的性能？\n\nCPU 的架构（CPU 的多核架构以及多 CPU 架构）也会影响 Redis 的性能，了解这些对我们的性能调优有很多帮助。\n\n这一节主要学习目前主流 CPU 架构以及基于此优化 Redis 性能的方法。\n\n\n# 2.1 主流的 CPU 架构\n\n一个 CPU 一般由多个物理核，每个核都可以运行程序，每个核都拥有私有的 L1 cache 和私有的 L2 cache。注意，每个物理核的私有 cache 只能被当前物理核使用。当数据或指令保存在 L1 或 L2 cache 中时，物理核对它们的访问延迟不超过 10 纳秒，速度非常快。\n\n如果 Redis 能把指令或数据存在物理核 cache 中，就能高速访问。但这些 cache 一般只有 KB 级别，放不下太多数据。若 cache 不命中，则需要访问内存，而访存的延迟一般是访问 cache 的 10 倍，不可避免地会对性能造成影响。\n\n所以，不同的物理核还会共享一个共同的 L3 cache。L3 cache 往往较大，能达到几 MB 到几十 MB，从而尽可能避免访问内存。\n\n另外，现在主流的 CPU 中，每个物理核通常都会运行两个超线程，也叫作逻辑核。同一个物理核的逻辑核会共享使用 L1、L2 缓存。\n\n下图展示了物理核、逻辑核、cache 之间的关系：\n\n同时，为了提升服务器的处理能力，服务器还往往会有多个 CPU 处理器，也称多 CPU Socket，每个 CPU Socket 有自己的物理核、L3 cache 以及连接内存，不用 CPU Socket 之间通过总线连接。如下图所示：\n\n> 一个 CPU 就是一个 CPU Socket -- > 多 CPU 架构； 一个 CPU 可以有多个物理核，一个物理核可以有多个逻辑核 -- > CPU 多核架构。\n\n在多CPU架构上，应用程序可以在不同的处理器上运行。在刚才的图中，Redis 可以先在 Socket 1 上运行一段时间，然后再被调度到 Socket 2 上运行。但当程序被调度到 Socket 2 后，再访问内存就需要访问之前 Socket 上连接的内存，这种访问属于远端内存访问。相比访问直接连接的内存，远端内存访问会增加延迟。在多CPU架构下，一个应用程序访问所在 Socket 的本地内存和访问远端内存的延迟并不一致，所以，我们也把这个架构称为非统一内存访问架构（Non-Uniform Memory Access，NUMA 架构）。\n\n到这里，我们就知道了主流的 CPU 多核架构和多 CPU 架构，我们来简单总结下 CPU 架构对应用程序运行的影响：\n\n * 充分利用 L1、L2 cache 可以有效缩短应用程序的执行时间。\n * 在 NUMA 架构下，远端内存访问的情况也会增加程序的执行时间。\n\n接下来看一下 CPU 多核是如何影响 Redis 性能的。\n\n\n# 2.2 CPU 多核对 Redis 性能的影响\n\n在一个CPU核上运行时，应用程序需要记录自身使用的软硬件资源信息（例如栈指针、CPU核的寄存器值等），我们把这些信息称为 运行时信息。同时，应用程序访问最频繁的指令和数据还会被缓存到L1、L2缓存上，以便提升执行速度。但在多核CPU的场景下，一旦程序需要在新的CPU核上运行时，那运行时信息就需要重新加载到新的CPU核上。而且，新的CPU核的L1、L2缓存也需要重新加载数据和指令，这会导致程序的运行时间增加。\n\n程序在不同 CPU 核上切换时，会发生运行时上下文的重新加载，从而导致延迟。\n\n作者就经历过由于 context switch（线程的上下文切换）导致 Redis 的 99% 尾延迟过大。\n\n> 99% 尾延迟：我们把所有请求的处理延迟从小到大排个序，99%的请求延迟小于的值就是99%尾延迟。比如说，我们有1000个请求，假设按请求延迟从小到大排序后，第991个请求的延迟实测值是1ms，而前990个请求的延迟都小于1ms，所以，这里的99%尾延迟就是1ms。\n\n如果想避免 Redis 总是在不同 CPU 核上来回调度，可以使用 taskset 命令把一个程序绑定在一个核上运行，即绑核。比如下面这条命令把 Redis 实例绑在了 0 号核上，其中，“-c”选项用于设置要绑定的核编号：\n\ntaskset -c 0 ./redis-server\n\n\n1\n\n\n下表对比了绑核前后的Redis的99%尾延迟：\n\n绑核不仅对降低尾延迟有好处，同样也能降低平均延迟、提升吞吐率，进而提升 Redis 性能。\n\n\n# 2.3 CPU 的 NUMA 架构对 Redis 性能的影响\n\n实际应用中，经常看到一种说法：为了提升 Redis 的网络性能，把操作系统的网络中断处理程序和 CPU 核绑定。这个做法可以避免网络中断处理程序在不同核上来回调度执行，的确能有效提升 Redis 的网络处理性能。但是，网络中断程序是要和 Redis 实例进行网络数据交互的，一旦把网络中断程序绑核后，我们就需要注意 Redis 实例是绑在哪个核上了，这会关系到 Redis 访问网络数据的效率高低。\n\n我们先来看下Redis实例和网络中断程序的数据交互：网络中断处理程序从网卡硬件中读取数据，并把数据写入到操作系统内核维护的一块内存缓冲区。内核会通过epoll机制触发事件，通知Redis实例，Redis实例再把数据从内核的内存缓冲区拷贝到自己的内存空间，如下图所示：\n\n那么，在CPU的NUMA架构下，当网络中断处理程序、Redis实例分别和CPU核绑定后，就会有一个潜在的风险：如果网络中断处理程序和 Redis 实例没有绑定到同一 CPU Socket 上，那 Redis 读取网络数据时，就需要跨 CPU Socket 访问内存，这个过程会花费较多时间。如下图所示：\n\n为了避免 Redis 跨 CPU Socket 访问，我们最好把网络中断程序和Redis实例绑在同一个 CPU Socket 上。如下图所示：\n\nCPU Socket 的编号可以通过 lscpu 命令来查看.假设有2个CPU Socket，每个Socket上有6个物理核，每个物理核又有2个逻辑核，总共24个逻辑核：\n\n$ lscpu\nArchitecture: x86_64\n...\nNUMA node0 CPU(s): 0-5,12-17\nNUMA node1 CPU(s): 6-11,18-23\n...\n\n\n1\n2\n3\n4\n5\n6\n\n * 在CPU的NUMA架构下，对CPU核的编号规则，并不是先把一个CPU Socket中的所有逻辑核编完，再对下一个CPU Socket中的逻辑核编码，而是先给每个CPU Socket中每个物理核的第一个逻辑核依次编号，再给每个CPU Socket中的物理核的第二个逻辑核依次编号。\n * 可以看到，NUMA node0的CPU核编号是0到5、12到17。其中，0到5是node0上的6个物理核中的第一个逻辑核的编号，12到17是相应物理核中的第二个逻辑核编号。NUMA node1的CPU核编号规则和node0一样。\n\n不过，绑核也存在一定的风险。接下来就来了解下它的潜在风险点和解决方案。\n\n\n# 2.4 绑核的风险和解决方案\n\nRedis 除了主线程以外，还有许多子进程和后台线程，当我们把 Redis 实例绑核后，可能会导致子进程、后台线程和 Redis 主线程竞争 CPU 资源，从而导致 Redis 请求延迟增加。\n\n针对这种情况有两个解决方案：\n\n# 方案一：一个 Redis 实例对应绑一个物理核\n\n在给 Redis 实例绑核时，我们不要把一个实例和一个逻辑核绑定，而要和一个物理核绑定，也就是说，把一个物理核的 2 个逻辑核都用上。\n\n我们还是以刚才的NUMA架构为例，NUMA node0的CPU核编号是0到5、12到17。其中，编号0和12、1和13、2和14等都是表示一个物理核的2个逻辑核。所以，在绑核时，我们使用属于同一个物理核的2个逻辑核进行绑核操作。例如，我们执行下面的命令，就把Redis实例绑定到了逻辑核0和12上，而这两个核正好都属于物理核1。\n\ntaskset -c 0,12 ./redis-server\n\n\n1\n\n\n和只绑一个逻辑核相比，把 Redis 实例和物理核绑定，可以让主线程、子进程、后台线程共享使用2个逻辑核，可以在一定程度上缓解 CPU 资源竞争。但是，因为只用了 2 个逻辑核，它们相互之间的 CPU 竞争仍然还会存在。如果你还想进一步减少 CPU 竞争，还有另一种方案。\n\n# 方案二：优化 Redis 源码\n\n> 这部分只是粗略的过了一下。\n\n这个方案就是通过修改Redis源码，把子进程和后台线程绑到不同的CPU核上。\n\n如果你对Redis的源码不太熟悉，也没关系，因为这是通过编程实现绑核的一个通用做法。学会了这个方案，你可以在熟悉了源码之后把它用上，也可以应用在其他需要绑核的场景中。\n\n接下来，我先介绍一下通用的做法，然后，再具体说说可以把这个做法对应到Redis的哪部分源码中。\n\n通过编程实现绑核时，要用到操作系统提供的1个数据结构cpu_set_t和3个函数CPU_ZERO、CPU_SET和sched_setaffinity，我先来解释下它们。\n\n * cpu_set_t数据结构：是一个位图，每一位用来表示服务器上的一个CPU逻辑核。\n * CPU_ZERO函数：以cpu_set_t结构的位图为输入参数，把位图中所有的位设置为0。\n * CPU_SET函数：以CPU逻辑核编号和cpu_set_t位图为参数，把位图中和输入的逻辑核编号对应的位设置为1。\n * sched_setaffinity函数：以进程/线程ID号和cpu_set_t为参数，检查cpu_set_t中哪一位为1，就把输入的ID号所代表的进程/线程绑在对应的逻辑核上。\n\n那么，怎么在编程时把这三个函数结合起来实现绑核呢？很简单，我们分四步走就行。\n\n * 第一步：创建一个cpu_set_t结构的位图变量；\n * 第二步：使用CPU_ZERO函数，把cpu_set_t结构的位图所有的位都设置为0；\n * 第三步：根据要绑定的逻辑核编号，使用CPU_SET函数，把cpu_set_t结构的位图相应位设置为1；\n * 第四步：使用sched_setaffinity函数，把程序绑定在cpu_set_t结构位图中为1的逻辑核上。\n\n下面，我就具体介绍下，分别把后台线程、子进程绑到不同的核上的做法。\n\n先说后台线程。为了让你更好地理解编程实现绑核，你可以看下这段示例代码，它实现了为线程绑核的操作：\n\n//线程函数\nvoid worker(int bind_cpu){\n    cpu_set_t cpuset;  //创建位图变量\n    CPU_ZERO(&cpu_set); //位图变量所有位设置0\n    CPU_SET(bind_cpu, &cpuset); //根据输入的bind_cpu编号，把位图对应为设置为1\n    sched_setaffinity(0, sizeof(cpuset), &cpuset); //把程序绑定在cpu_set_t结构位图中为1的逻辑核\n    //实际线程函数工作\n}\nint main(){\n    pthread_t pthread1\n    //把创建的pthread1绑在编号为3的逻辑核上\n    pthread_create(&pthread1, NULL, (void *)worker, 3);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n对于Redis来说，它是在bio.c文件中的bioProcessBackgroundJobs函数中创建了后台线程。bioProcessBackgroundJobs函数类似于刚刚的例子中的worker函数，在这个函数中实现绑核四步操作，就可以把后台线程绑到和主线程不同的核上了。\n\n和给线程绑核类似，当我们使用fork创建子进程时，也可以把刚刚说的四步操作实现在fork后的子进程代码中，示例代码如下：\n\nint main(){\n   //用fork创建一个子进程\n   pid_t p = fork();\n   if(p < 0){\n      printf(" fork error\\n");\n   }\n   //子进程代码部分\n   else if(!p){\n      cpu_set_t cpuset;  //创建位图变量\n      CPU_ZERO(&cpu_set); //位图变量所有位设置0\n      CPU_SET(3, &cpuset); //把位图的第3位设置为1\n      sched_setaffinity(0, sizeof(cpuset), &cpuset);  //把程序绑定在3号逻辑核\n      //实际子进程工作\n      exit(0);\n   }\n   ...\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n对于Redis来说，生成RDB和AOF日志重写的子进程分别是下面两个文件的函数中实现的。\n\n * rdb.c文件：rdbSaveBackground函数；\n * aof.c文件：rewriteAppendOnlyFileBackground函数。\n\n这两个函数中都调用了fork创建子进程，所以，我们可以在子进程代码部分加上绑核的四步操作。\n\n使用源码优化方案，我们既可以实现Redis实例绑核，避免切换核带来的性能影响，还可以让子进程、后台线程和主线程不在同一个核上运行，避免了它们之间的CPU资源竞争。相比使用taskset绑核来说，这个方案可以进一步降低绑核的风险。\n\n\n# 2.5 小结\n\n这一节讲了主流的 CPU 架构以及 NUMA 架构，并解释了 CPU 对 Redis 性能的影响。\n\n * 由于 CPU Socket 之间的切换会增加尾延迟，因此建议把实例与某个核进行绑定。\n * 为提升 Redis 的网络性能，有时需要把网络中断处理程序和 CPU 核绑定。\n * 为防止绑核导致 Redis 主线程与子进程的竞争，本文提出了两种方案来解决。\n\nRedis 的低延迟是我们永恒的追求目标，而多核 CPU 和 NUMA 架构已经成为了目前服务器的主流配置。所以绑核优化方案在实践中很重要。\n\n----------------------------------------\n\n**本节问题：**在一台有两个CPU Socket（每个Socket 8个物理核）的服务器上，我们部署了一个有着8个实例的Redis切片集群（8个实例都为主节点，没有主备关系），现在有两个方案：\n\n 1. 在同一个CPU Socket上运行8个实例，并和8个CPU核绑定；\n 2. 在两个CPU Socket上各运行4个实例，并和相应Socket上的核绑定。\n\n如果不考虑网络数据读取的影响，你会选择哪个方案呢？\n\n答案：建议使用第二个方案，主要有两方面的原因。\n\n 1. 同一个CPU Socket上的进程，会共享L3缓存。如果把8个实例都部署在同一个Socket上，它们会竞争L3缓存，这就会导致它们的L3缓存命中率降低，影响访问性能。\n\n 2. 同一个CPU Socket上的进程，会使用同一个Socket上的内存空间。8个实例共享同一个Socket上的内存空间，肯定会竞争内存资源。如果有实例保存的数据量大，其他实例能用到的内存空间可能就不够了，此时，其他实例就会跨Socket申请内存，进而造成跨Socket访问内存，造成实例的性能降低。\n\n另外，在切片集群中，不同实例间通过网络进行消息通信和数据迁移，并不会使用共享内存空间进行跨实例的数据访问。所以，即使把不同的实例部署到不同的Socket上，它们之间也不会发生跨Socket内存的访问，不会受跨Socket内存访问的负面影响。',normalizedContent:'> 参考：\n> \n>  * 16 异步机制：如何避免单线程模型的阻塞？| 极客时间\n>  * 17 为什么 cpu 结构也会影响 redis 的性能？| 极客时间\n\nredis 因其高性能而被广泛应用，我们需要避免性能异常的情况出现。影响 redis 性能的 5 大方面因素有：\n\n * redis 内部的阻塞式操作\n * cpu 核和 numa 架构的影响\n * redis 关键系统配置\n * redis 内存碎片\n * redis 缓冲区\n\n本文将分析前两个因素。\n\n\n# 1. 异步机制：如何避免单线程模型的阻塞？\n\n\n# 1.1 redis 实例有哪些阻塞点？\n\n我们前面学习过，redis 的网络 io 和键值对读写是由主线程完成的，这些不同的交互要涉及不同的操作。我们看一下 redis 和不同对象交互时，有哪些交互操作：\n\n * 客户端：网络 ip、kv 的 crud 等\n * 磁盘：aof 与 rdb 操作\n * 主从节点：数据复制操作\n * 切片集群：向其他实例传输哈希槽信息、数据迁移\n\n这四类交互对象和操作之间的关系如下图：\n\n下面我们逐个分析哪些操作会引起阻塞：\n\n# 1）和客户端交互时的阻塞点\n\n由于 redis 使用了 io 多路复用机制避免了主线程的一直等待，所以网络 io 不是导致 redis 阻塞的因素。\n\ncrud 操作是 redis 与客户端交互的主要部分，也是 redis 主线程执行的主要任务。所以，复杂度高的增删改查操作肯定会阻塞 redis。\n\n那怎么判断操作复杂度高不高呢？这里有一个最基本的标准，就是看操作的复杂度是否为 o(n)。\n\nredis 中涉及集合的操作复杂度通常为o(n)，我们要在使用时重视起来。例如集合元素全量查询操作hgetall、smembers，以及集合的聚合统计操作，例如求交、并和差集。这些操作可以作为 redis 的第一个阻塞点：集合全量查询和聚合操作。\n\n除此之外，集合自身的删除操作同样也有潜在的阻塞风险。因为删除操作的本质是要释放键值对占用的内存空间，而操作系统在释放内存时需要把所释放的内存块插入空闲链表中以便管理，这个过程可能会阻塞程序。所以，如果一下子释放了大量内存，空闲内存块链表操作时间就会增加，相应地就会造成 redis 主线程的阻塞。\n\n释放大量内存的场景，就是在删除大量键值对数据时，最典型的就是删除包含了大量元素的集合，也称为 bigkey 删除。下图测试了不同元素数量的集合进行删除操作所耗费的时间：\n\n从这张表里，我们可以得出三个结论：\n\n 1. 当元素数量从10万增加到100万时，4大集合类型的删除时间的增长幅度从5倍上升到了近20倍；\n 2. 集合元素越大，删除所花费的时间就越长；\n 3. 当删除有100万个元素的集合时，最大的删除时间绝对值已经达到了1.98s（hash类型）。redis的响应时间一般在微秒级别，所以，一个操作达到了近2s，不可避免地会阻塞主线程。\n\n所以，bigkey 删除操作就是 redis 的第二个阻塞点。删除操作对redis实例性能的负面影响很大，而且在实际业务开发时容易被忽略，所以一定要重视它。\n\n小建议\n\n当遇到 bigkey 删除时，有一个小建议：先使用集合类型提供的 scan 命令读取数据，然后再进行删除。因为用 scan 命令可以每次只读取一部分数据并进行删除，这样可以避免一次性删除大量 key 给主线程带来的阻塞。\n\n例如，对于 hash 类型的 bigkey 删除，你可以使用 hscan 命令，每次从hash集合中获取一部分键值对（例如200个），再使用 hdel 删除这些键值对，这样就可以把删除压力分摊到多次操作中，那么，每次删除操作的耗时就不会太长，也就不会阻塞主线程了。\n\n容易联想到，清空数据库（flushdb 和 flushall 操作）也必然是一个潜在的阻塞风险，因为它们也涉及到大量 kv 的删除。所以，redis 的第三个阻塞点：清空数据库。\n\n# 2）和磁盘交互时的阻塞点\n\n由于磁盘 io 一般比较慢，因此需要重点关注。redis 采用子进程的方式来执行 rdb 的生成和 aof 的重写，从而避免了对主线程的阻塞。\n\n但 redis 直接记录 aof 时，会根据不同的写回策略对数据做落盘保存。一次同步写磁盘大约耗时 1~2ms，如果存在大量同步写操作的话，就会阻塞主线程。因此 redis 的四个阻塞点：aof 日志同步写。\n\n# 3）主从节点交互时的阻塞点\n\n在主从复制时，主库创建和传输 rdb 文件都是由子进程完成的，不会阻塞主线程；从库接收 rdb 文件后，需要使用 flushdb 命令来清空当前数据库，这正好装上了刚刚分析的第三个阻塞点。\n\n此外，从库在清空数据库后，还需要把 rdb 加载到内存中，这个过程与 rdb 文件的大小密切相关，rdb 越大，加载过程越慢。所以，加载 rdb 文件就成为了 redis 的第五个阻塞点。\n\n# 4）切片集群实例交互时的阻塞点\n\n最后，当我们部署redis切片集群时，每个redis实例上分配的哈希槽信息需要在不同实例间进行传递，同时，当需要进行负载均衡或者有实例增删时，数据会在不同的实例间进行迁移。不过，哈希槽的信息量不大，而数据迁移是渐进式执行的，所以，一般来说，这两类操作对 redis 主线程的阻塞风险不大。\n\n不过，如果你使用了 redis cluster 方案，而且同时正好迁移的是 bigkey 的话，就会造成主线程的阻塞，因为 redis cluster 使用了同步迁移。我将在第33讲中向你介绍不同切片集群方案对数据迁移造成的阻塞的解决方法，这里你只需要知道，当没有 bigkey 时，切片集群的各实例在进行交互时不会阻塞主线程，就可以了。\n\n现在我们总结下刚刚找到的五个阻塞点：\n\n * 集合全量查询和聚合操作\n * bigkey 删除\n * 清空数据库\n * aof 日志同步写\n * 从库加载 rdb 文件\n\n如果在主线程中执行这些操作，必然会导致主线程长时间无法服务其他请求。为了避免阻塞式操作，redis 提供了异步线程机制。所谓的异步线程机制：指 redis 会启动一些子线程，然后把一些任务交给这些子线程，让它们在后台完成，而不再由主线程来执行这些任务。使用异步线程机制执行操作，可以避免阻塞主线程。\n\n不过问题来了，这五个阻塞式操作都可以被异步执行吗？\n\n\n# 1.2 哪些阻塞点可以异步执行？\n\n先看一下异步执行对操作的要求。\n\n如果一个操作能被异步执行，就意味着，它并不是 redis 主线程的关键路径上的操作。关键路径上的操作是说，客户端把请求发给 redis 后就等着返回数据结果。如下图：\n\n * 左图的操作 1 就不算关键路径上的操作，因此可以让后台子线程来异步执行；\n * 右图的操作 2 就是关键路径上的操作，所以主线程必须立即把这个操作执行完。\n\n对 redis 来说，读操作是典型的关键路径操作。redis 的第一个阻塞点“集合全量查询和聚合操作”都涉及到了读操作，所以，它们是不能进行异步操作了。\n\n而删除操作不需要立刻返回具体的结果，不算是关键路径操作，因此我们可以使用后台子线程来异步执行删除操作。故第二个和第三个阻塞点可以异步解决。\n\n对于第四个阻塞点“aof日志同步写”来说，为保证数据可靠性，redis 实例需要保证 aof 日志中的操作记录已经落盘，这个操作虽然需要实例等待，但它并不会返回具体的数据结果给实例。所以，我们也可以启动一个子线程来执行aof日志的同步写，而不用让主线程等待aof日志的写完成。\n\n最后再看下“从库加载 rdb 文件”这第五个阻塞点。从库必须把 rdb 加载完，这操作也属于关键路径上的操作，所以我们必须让从库的主线程来执行。\n\n对于 redis 的五大阻塞点来说，除了“集合全量查询和聚合操作”和“从库加载 rdb 文件”，其他三个阻塞点涉及的操作都不在关键路径上，所以可以使用 redis 的异步子线程机制来实现 bigkey 删除，清空数据库，以及 aof 日志同步写。\n\n小建议\n\n集合全量查询和聚合操作、从库加载rdb文件是在关键路径上，无法使用异步操作来完成。对于这两个阻塞点也有两个小建议：\n\n * 集合全量查询和聚合操作：可以使用 scan 命令，分批读取数据，再在客户端进行聚合计算；\n * 从库加载 rdb 文件：把主库的数据量大小控制在 2~4gb 左右，以保证 rdb 文件能以较快的速度加载。\n\n那 redis 实现的异步子线程机制具体是怎么执行呢？\n\n\n# 1.3 异步的子线程机制\n\nredis 主线程启动后，会使用操作系统提供的 pthread_create 函数创建 3 个子线程，分别由它们负责 aof 日志写操作、键值对删除以及文件关闭的异步执行。\n\n主线程通过一个链表形式的任务队列和子线程进行交互。当收到键值对删除和清空数据库的操作时，主线程会把这个操作封装成一个任务，放入到任务队列中，然后给客户端返回一个完成信息，表明删除已经完成。但实际上，这个时候删除还没有执行，等到后台子线程从任务队列中读取任务后，才开始实际删除键值对，并释放相应的内存空间。因此，我们把这种异步删除也称为惰性删除（lazy free）。此时，删除或清空操作不会阻塞主线程，这就避免了对主线程的性能影响。\n\n和惰性删除类似，当 aof 日志配置成 everysec 选项后，主线程会把 aof 写日志操作封装成一个任务，也放到任务队列中。后台子线程读取任务后，开始自行写入 aof 日志，这样主线程就不用一直等待 aof 日志写完了。\n\n下面这张图展示了 redis 中的异步子线程执行机制：\n\n异步的键值对删除和数据库清空操作是 redis 4.0 后提供的功能，redis也提供了新的命令来执行这两个操作：\n\n * 键值对删除：当你的集合类型中有大量元素（例如有百万级别或千万级别元素）需要删除时，我建议你使用 unlink 命令。\n * 清空数据库：可以在 flushdb 和 flushall 命令后加上 async 选项，这样就可以让后台子线程异步地清空数据库，如下所示：\n\nflushdb async\nflushall aysnc\n\n\n1\n2\n\n\n\n# 1.4 小结\n\n这一节主要讲了 redis 运行时的交互对象和交互操作，并对其中不属于关键路径的操作讲解使用异步子线程机制来完成。\n\n\n# 2. 为什么 cpu 结构也会影响 redis 的性能？\n\ncpu 的架构（cpu 的多核架构以及多 cpu 架构）也会影响 redis 的性能，了解这些对我们的性能调优有很多帮助。\n\n这一节主要学习目前主流 cpu 架构以及基于此优化 redis 性能的方法。\n\n\n# 2.1 主流的 cpu 架构\n\n一个 cpu 一般由多个物理核，每个核都可以运行程序，每个核都拥有私有的 l1 cache 和私有的 l2 cache。注意，每个物理核的私有 cache 只能被当前物理核使用。当数据或指令保存在 l1 或 l2 cache 中时，物理核对它们的访问延迟不超过 10 纳秒，速度非常快。\n\n如果 redis 能把指令或数据存在物理核 cache 中，就能高速访问。但这些 cache 一般只有 kb 级别，放不下太多数据。若 cache 不命中，则需要访问内存，而访存的延迟一般是访问 cache 的 10 倍，不可避免地会对性能造成影响。\n\n所以，不同的物理核还会共享一个共同的 l3 cache。l3 cache 往往较大，能达到几 mb 到几十 mb，从而尽可能避免访问内存。\n\n另外，现在主流的 cpu 中，每个物理核通常都会运行两个超线程，也叫作逻辑核。同一个物理核的逻辑核会共享使用 l1、l2 缓存。\n\n下图展示了物理核、逻辑核、cache 之间的关系：\n\n同时，为了提升服务器的处理能力，服务器还往往会有多个 cpu 处理器，也称多 cpu socket，每个 cpu socket 有自己的物理核、l3 cache 以及连接内存，不用 cpu socket 之间通过总线连接。如下图所示：\n\n> 一个 cpu 就是一个 cpu socket -- > 多 cpu 架构； 一个 cpu 可以有多个物理核，一个物理核可以有多个逻辑核 -- > cpu 多核架构。\n\n在多cpu架构上，应用程序可以在不同的处理器上运行。在刚才的图中，redis 可以先在 socket 1 上运行一段时间，然后再被调度到 socket 2 上运行。但当程序被调度到 socket 2 后，再访问内存就需要访问之前 socket 上连接的内存，这种访问属于远端内存访问。相比访问直接连接的内存，远端内存访问会增加延迟。在多cpu架构下，一个应用程序访问所在 socket 的本地内存和访问远端内存的延迟并不一致，所以，我们也把这个架构称为非统一内存访问架构（non-uniform memory access，numa 架构）。\n\n到这里，我们就知道了主流的 cpu 多核架构和多 cpu 架构，我们来简单总结下 cpu 架构对应用程序运行的影响：\n\n * 充分利用 l1、l2 cache 可以有效缩短应用程序的执行时间。\n * 在 numa 架构下，远端内存访问的情况也会增加程序的执行时间。\n\n接下来看一下 cpu 多核是如何影响 redis 性能的。\n\n\n# 2.2 cpu 多核对 redis 性能的影响\n\n在一个cpu核上运行时，应用程序需要记录自身使用的软硬件资源信息（例如栈指针、cpu核的寄存器值等），我们把这些信息称为 运行时信息。同时，应用程序访问最频繁的指令和数据还会被缓存到l1、l2缓存上，以便提升执行速度。但在多核cpu的场景下，一旦程序需要在新的cpu核上运行时，那运行时信息就需要重新加载到新的cpu核上。而且，新的cpu核的l1、l2缓存也需要重新加载数据和指令，这会导致程序的运行时间增加。\n\n程序在不同 cpu 核上切换时，会发生运行时上下文的重新加载，从而导致延迟。\n\n作者就经历过由于 context switch（线程的上下文切换）导致 redis 的 99% 尾延迟过大。\n\n> 99% 尾延迟：我们把所有请求的处理延迟从小到大排个序，99%的请求延迟小于的值就是99%尾延迟。比如说，我们有1000个请求，假设按请求延迟从小到大排序后，第991个请求的延迟实测值是1ms，而前990个请求的延迟都小于1ms，所以，这里的99%尾延迟就是1ms。\n\n如果想避免 redis 总是在不同 cpu 核上来回调度，可以使用 taskset 命令把一个程序绑定在一个核上运行，即绑核。比如下面这条命令把 redis 实例绑在了 0 号核上，其中，“-c”选项用于设置要绑定的核编号：\n\ntaskset -c 0 ./redis-server\n\n\n1\n\n\n下表对比了绑核前后的redis的99%尾延迟：\n\n绑核不仅对降低尾延迟有好处，同样也能降低平均延迟、提升吞吐率，进而提升 redis 性能。\n\n\n# 2.3 cpu 的 numa 架构对 redis 性能的影响\n\n实际应用中，经常看到一种说法：为了提升 redis 的网络性能，把操作系统的网络中断处理程序和 cpu 核绑定。这个做法可以避免网络中断处理程序在不同核上来回调度执行，的确能有效提升 redis 的网络处理性能。但是，网络中断程序是要和 redis 实例进行网络数据交互的，一旦把网络中断程序绑核后，我们就需要注意 redis 实例是绑在哪个核上了，这会关系到 redis 访问网络数据的效率高低。\n\n我们先来看下redis实例和网络中断程序的数据交互：网络中断处理程序从网卡硬件中读取数据，并把数据写入到操作系统内核维护的一块内存缓冲区。内核会通过epoll机制触发事件，通知redis实例，redis实例再把数据从内核的内存缓冲区拷贝到自己的内存空间，如下图所示：\n\n那么，在cpu的numa架构下，当网络中断处理程序、redis实例分别和cpu核绑定后，就会有一个潜在的风险：如果网络中断处理程序和 redis 实例没有绑定到同一 cpu socket 上，那 redis 读取网络数据时，就需要跨 cpu socket 访问内存，这个过程会花费较多时间。如下图所示：\n\n为了避免 redis 跨 cpu socket 访问，我们最好把网络中断程序和redis实例绑在同一个 cpu socket 上。如下图所示：\n\ncpu socket 的编号可以通过 lscpu 命令来查看.假设有2个cpu socket，每个socket上有6个物理核，每个物理核又有2个逻辑核，总共24个逻辑核：\n\n$ lscpu\narchitecture: x86_64\n...\nnuma node0 cpu(s): 0-5,12-17\nnuma node1 cpu(s): 6-11,18-23\n...\n\n\n1\n2\n3\n4\n5\n6\n\n * 在cpu的numa架构下，对cpu核的编号规则，并不是先把一个cpu socket中的所有逻辑核编完，再对下一个cpu socket中的逻辑核编码，而是先给每个cpu socket中每个物理核的第一个逻辑核依次编号，再给每个cpu socket中的物理核的第二个逻辑核依次编号。\n * 可以看到，numa node0的cpu核编号是0到5、12到17。其中，0到5是node0上的6个物理核中的第一个逻辑核的编号，12到17是相应物理核中的第二个逻辑核编号。numa node1的cpu核编号规则和node0一样。\n\n不过，绑核也存在一定的风险。接下来就来了解下它的潜在风险点和解决方案。\n\n\n# 2.4 绑核的风险和解决方案\n\nredis 除了主线程以外，还有许多子进程和后台线程，当我们把 redis 实例绑核后，可能会导致子进程、后台线程和 redis 主线程竞争 cpu 资源，从而导致 redis 请求延迟增加。\n\n针对这种情况有两个解决方案：\n\n# 方案一：一个 redis 实例对应绑一个物理核\n\n在给 redis 实例绑核时，我们不要把一个实例和一个逻辑核绑定，而要和一个物理核绑定，也就是说，把一个物理核的 2 个逻辑核都用上。\n\n我们还是以刚才的numa架构为例，numa node0的cpu核编号是0到5、12到17。其中，编号0和12、1和13、2和14等都是表示一个物理核的2个逻辑核。所以，在绑核时，我们使用属于同一个物理核的2个逻辑核进行绑核操作。例如，我们执行下面的命令，就把redis实例绑定到了逻辑核0和12上，而这两个核正好都属于物理核1。\n\ntaskset -c 0,12 ./redis-server\n\n\n1\n\n\n和只绑一个逻辑核相比，把 redis 实例和物理核绑定，可以让主线程、子进程、后台线程共享使用2个逻辑核，可以在一定程度上缓解 cpu 资源竞争。但是，因为只用了 2 个逻辑核，它们相互之间的 cpu 竞争仍然还会存在。如果你还想进一步减少 cpu 竞争，还有另一种方案。\n\n# 方案二：优化 redis 源码\n\n> 这部分只是粗略的过了一下。\n\n这个方案就是通过修改redis源码，把子进程和后台线程绑到不同的cpu核上。\n\n如果你对redis的源码不太熟悉，也没关系，因为这是通过编程实现绑核的一个通用做法。学会了这个方案，你可以在熟悉了源码之后把它用上，也可以应用在其他需要绑核的场景中。\n\n接下来，我先介绍一下通用的做法，然后，再具体说说可以把这个做法对应到redis的哪部分源码中。\n\n通过编程实现绑核时，要用到操作系统提供的1个数据结构cpu_set_t和3个函数cpu_zero、cpu_set和sched_setaffinity，我先来解释下它们。\n\n * cpu_set_t数据结构：是一个位图，每一位用来表示服务器上的一个cpu逻辑核。\n * cpu_zero函数：以cpu_set_t结构的位图为输入参数，把位图中所有的位设置为0。\n * cpu_set函数：以cpu逻辑核编号和cpu_set_t位图为参数，把位图中和输入的逻辑核编号对应的位设置为1。\n * sched_setaffinity函数：以进程/线程id号和cpu_set_t为参数，检查cpu_set_t中哪一位为1，就把输入的id号所代表的进程/线程绑在对应的逻辑核上。\n\n那么，怎么在编程时把这三个函数结合起来实现绑核呢？很简单，我们分四步走就行。\n\n * 第一步：创建一个cpu_set_t结构的位图变量；\n * 第二步：使用cpu_zero函数，把cpu_set_t结构的位图所有的位都设置为0；\n * 第三步：根据要绑定的逻辑核编号，使用cpu_set函数，把cpu_set_t结构的位图相应位设置为1；\n * 第四步：使用sched_setaffinity函数，把程序绑定在cpu_set_t结构位图中为1的逻辑核上。\n\n下面，我就具体介绍下，分别把后台线程、子进程绑到不同的核上的做法。\n\n先说后台线程。为了让你更好地理解编程实现绑核，你可以看下这段示例代码，它实现了为线程绑核的操作：\n\n//线程函数\nvoid worker(int bind_cpu){\n    cpu_set_t cpuset;  //创建位图变量\n    cpu_zero(&cpu_set); //位图变量所有位设置0\n    cpu_set(bind_cpu, &cpuset); //根据输入的bind_cpu编号，把位图对应为设置为1\n    sched_setaffinity(0, sizeof(cpuset), &cpuset); //把程序绑定在cpu_set_t结构位图中为1的逻辑核\n    //实际线程函数工作\n}\nint main(){\n    pthread_t pthread1\n    //把创建的pthread1绑在编号为3的逻辑核上\n    pthread_create(&pthread1, null, (void *)worker, 3);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n对于redis来说，它是在bio.c文件中的bioprocessbackgroundjobs函数中创建了后台线程。bioprocessbackgroundjobs函数类似于刚刚的例子中的worker函数，在这个函数中实现绑核四步操作，就可以把后台线程绑到和主线程不同的核上了。\n\n和给线程绑核类似，当我们使用fork创建子进程时，也可以把刚刚说的四步操作实现在fork后的子进程代码中，示例代码如下：\n\nint main(){\n   //用fork创建一个子进程\n   pid_t p = fork();\n   if(p < 0){\n      printf(" fork error\\n");\n   }\n   //子进程代码部分\n   else if(!p){\n      cpu_set_t cpuset;  //创建位图变量\n      cpu_zero(&cpu_set); //位图变量所有位设置0\n      cpu_set(3, &cpuset); //把位图的第3位设置为1\n      sched_setaffinity(0, sizeof(cpuset), &cpuset);  //把程序绑定在3号逻辑核\n      //实际子进程工作\n      exit(0);\n   }\n   ...\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n对于redis来说，生成rdb和aof日志重写的子进程分别是下面两个文件的函数中实现的。\n\n * rdb.c文件：rdbsavebackground函数；\n * aof.c文件：rewriteappendonlyfilebackground函数。\n\n这两个函数中都调用了fork创建子进程，所以，我们可以在子进程代码部分加上绑核的四步操作。\n\n使用源码优化方案，我们既可以实现redis实例绑核，避免切换核带来的性能影响，还可以让子进程、后台线程和主线程不在同一个核上运行，避免了它们之间的cpu资源竞争。相比使用taskset绑核来说，这个方案可以进一步降低绑核的风险。\n\n\n# 2.5 小结\n\n这一节讲了主流的 cpu 架构以及 numa 架构，并解释了 cpu 对 redis 性能的影响。\n\n * 由于 cpu socket 之间的切换会增加尾延迟，因此建议把实例与某个核进行绑定。\n * 为提升 redis 的网络性能，有时需要把网络中断处理程序和 cpu 核绑定。\n * 为防止绑核导致 redis 主线程与子进程的竞争，本文提出了两种方案来解决。\n\nredis 的低延迟是我们永恒的追求目标，而多核 cpu 和 numa 架构已经成为了目前服务器的主流配置。所以绑核优化方案在实践中很重要。\n\n----------------------------------------\n\n**本节问题：**在一台有两个cpu socket（每个socket 8个物理核）的服务器上，我们部署了一个有着8个实例的redis切片集群（8个实例都为主节点，没有主备关系），现在有两个方案：\n\n 1. 在同一个cpu socket上运行8个实例，并和8个cpu核绑定；\n 2. 在两个cpu socket上各运行4个实例，并和相应socket上的核绑定。\n\n如果不考虑网络数据读取的影响，你会选择哪个方案呢？\n\n答案：建议使用第二个方案，主要有两方面的原因。\n\n 1. 同一个cpu socket上的进程，会共享l3缓存。如果把8个实例都部署在同一个socket上，它们会竞争l3缓存，这就会导致它们的l3缓存命中率降低，影响访问性能。\n\n 2. 同一个cpu socket上的进程，会使用同一个socket上的内存空间。8个实例共享同一个socket上的内存空间，肯定会竞争内存资源。如果有实例保存的数据量大，其他实例能用到的内存空间可能就不够了，此时，其他实例就会跨socket申请内存，进而造成跨socket访问内存，造成实例的性能降低。\n\n另外，在切片集群中，不同实例间通过网络进行消息通信和数据迁移，并不会使用共享内存空间进行跨实例的数据访问。所以，即使把不同的实例部署到不同的socket上，它们之间也不会发生跨socket内存的访问，不会受跨socket内存访问的负面影响。',charsets:{cjk:!0},lastUpdated:"2023/04/10, 14:17:28",lastUpdatedTimestamp:1681136248e3},{title:"如何应对变慢的 Redis",frontmatter:{title:"如何应对变慢的 Redis",date:"2023-04-08T21:28:19.000Z",permalink:"/pages/f111bf/",categories:["中间件","Redis","专栏：Redis 核心技术与实战"],tags:[null]},regularPath:"/%E4%B8%AD%E9%97%B4%E4%BB%B6/05.Redis/05.%E4%B8%93%E6%A0%8F%EF%BC%9ARedis%20%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/18.%E5%A6%82%E4%BD%95%E5%BA%94%E5%AF%B9%E5%8F%98%E6%85%A2%E7%9A%84%20Redis.html",relativePath:"中间件/05.Redis/05.专栏：Redis 核心技术与实战/18.如何应对变慢的 Redis.md",key:"v-6c981036",path:"/pages/f111bf/",headers:[{level:2,title:"1. Redis 真的变慢了吗？",slug:"_1-redis-真的变慢了吗",normalizedTitle:"1. redis 真的变慢了吗？",charIndex:368},{level:2,title:"2. 如何应对 Redis 变慢？",slug:"_2-如何应对-redis-变慢",normalizedTitle:"2. 如何应对 redis 变慢？",charIndex:1670},{level:3,title:"2.1 Redis 自身操作特性的影响",slug:"_2-1-redis-自身操作特性的影响",normalizedTitle:"2.1 redis 自身操作特性的影响",charIndex:1938},{level:4,title:"2.1.1 慢查询命令",slug:"_2-1-1-慢查询命令",normalizedTitle:"2.1.1 慢查询命令",charIndex:2024},{level:4,title:"2.1.2 过期 key 操作",slug:"_2-1-2-过期-key-操作",normalizedTitle:"2.1.2 过期 key 操作",charIndex:2845},{level:3,title:"2.2 文件系统：AOF 模式",slug:"_2-2-文件系统-aof-模式",normalizedTitle:"2.2 文件系统：aof 模式",charIndex:4254},{level:3,title:"2.3 操作系统：swap",slug:"_2-3-操作系统-swap",normalizedTitle:"2.3 操作系统：swap",charIndex:6146},{level:3,title:"2.4 操作系统：内存大页",slug:"_2-4-操作系统-内存大页",normalizedTitle:"2.4 操作系统：内存大页",charIndex:7739},{level:2,title:"3. 小结",slug:"_3-小结",normalizedTitle:"3. 小结",charIndex:8632}],headersStr:"1. Redis 真的变慢了吗？ 2. 如何应对 Redis 变慢？ 2.1 Redis 自身操作特性的影响 2.1.1 慢查询命令 2.1.2 过期 key 操作 2.2 文件系统：AOF 模式 2.3 操作系统：swap 2.4 操作系统：内存大页 3. 小结",content:'> 参考：\n> \n>  * 18 波动的响应延迟：如何应对变慢的Redis？（上）| 极客时间\n>  * 19 波动的响应延迟：如何应对变慢的Redis？（下）| 极客时间\n\nRedis 因其高性能而被广泛应用，我们需要避免性能异常的情况出现。影响 Redis 性能的 5 大方面因素有：\n\n * Redis 内部的阻塞式操作\n * CPU 核和 NUMA 架构的影响\n * Redis 关键系统配置\n * Redis 内存碎片\n * Redis 缓冲区\n\n上一篇分析了前两个因素，本文分析第三个因素。\n\n在实际部署中，有一个很严重的问题：Redis 突然变慢了，这可能会直接影响其他系统，导致一连串的连锁反应。本文将介绍如何系统性地应对 Redis 变慢这个问题，并从问题认定、系统性排查和应对方案这 3 个方面来进行讲解。\n\n\n# 1. Redis 真的变慢了吗？\n\n判断 Redis 是否真的变慢了有个最直接的方法：查看 Redis 的响应延迟。\n\n大部分时候 Redis 延迟很低，但某些时刻可能会出现很高的相应延迟，甚至能达到几秒到十几秒，不过持续时间不长，这也叫延迟毛刺。当你发现 Redis 命令的执行时间突然就增长到了几秒，基本就可以认定 Redis 变慢了。\n\n这种方法看的是 Redis 延迟的绝对值，但在不同的软硬件环境下，Redis 的绝对性能本身并不相同。比如差的机器延迟 1ms 才认定变慢了，但好的机器延迟 0.2ms 就可以认定变慢了。\n\n所以需要第二个判断方法：基于当前环境下的 Redis 基线性能做判断。基线性能：指一个系统在低压力、无干扰下的基本性能，这个性能只由当前的软硬件配置决定。\n\n具体如何确定基线性能呢？redis-cli 命令提供了 –intrinsic-latency 选项，可以用来监测和统计测试期间内的最大延迟，这个延迟可以作为 Redis 的基线性能。其中，测试时长可以用 –intrinsic-latency 选项的参数来指定。\n\n举个例子，比如说，我们运行下面的命令，该命令会打印 120 秒内监测到的最大延迟。可以看到，这里的最大延迟是 119 微秒，也就是基线性能为 119 微秒。一般情况下，运行 120 秒就足够监测到最大延迟了，所以，我们可以把参数设置为 120。\n\n./redis-cli --intrinsic-latency 120\nMax latency so far: 17 microseconds.\nMax latency so far: 44 microseconds.\nMax latency so far: 94 microseconds.\nMax latency so far: 110 microseconds.\nMax latency so far: 119 microseconds.\n36481658 total runs (avg latency: 3.2893 microseconds / 3289.32 nanoseconds per run).\nWorst run took 36x longer than the average latency.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n一般来说，你要把运行时延迟和基线性能进行对比，如果你观察到的 Redis 运行时延迟是其基线性能的 2 倍及以上，就可以认定 Redis 变慢了。\n\n我们通常是通过客户端和网络访问Redis服务，为了避免网络对基线性能的影响，刚刚说的这个命令需要在服务器端直接运行，这也就是说，我们只考虑服务器端软硬件环境的影响。如果你想了解网络对Redis性能的影响，一个简单的方法是用 iPerf 这样的工具，测量从 Redis 客户端到服务器端的网络延迟。如果这个延迟有几十毫秒甚至是几百毫秒，就说明，Redis 运行的网络环境中很可能有大流量的其他应用程序在运行，导致网络拥塞了。这个时候，你就需要协调网络运维，调整网络的流量分配了。\n\n\n# 2. 如何应对 Redis 变慢？\n\n我们现在需要诊断 Redis 变慢的原因。要基于自己对Redis本身的工作原理的理解，并且结合和它交互的操作系统、存储以及网络等外部系统关键机制，再借助一些辅助工具来定位原因，并制定行之有效的解决方案。\n\n下图是 Redis 的架构图，红色模块就是影响 Redis 的三大要素：Redis 自身的操作特性、文件系统和操作系统。\n\n下面将从这三大要素入手，并结合实际的应用场景，依次介绍从不同要素出发排查和解决问题的实践经验。性能诊断通常是一件困难的事，所以我们一定不能毫无目标地“乱找”。\n\n\n# 2.1 Redis 自身操作特性的影响\n\n首先来学习下 Redis 提供的键值对命令操作对延迟性能的影响。这里重点介绍两类关键操作：慢查询命令和过期 key 操作。\n\n# 2.1.1 慢查询命令\n\n慢查询命令：指在 Redis 中执行速度慢的命令，这会导致 Redis 延迟增加。\n\n执行快慢与操作复杂度相关。比如说，Value 类型为 String 时，GET/SET 操作主要就是操作 Redis 的哈希表索引。这个操作复杂度基本是固定的，即 O(1)。但是，当 Value 类型为 Set 时，SORT、SUNION/SMEMBERS 操作复杂度分别为 O(N+M*log(M)) 和 O(N) 。其中，N 为 Set 中的元素个数，M 为 SORT 操作返回的元素个数。这个复杂度就增加了很多。Redis官方文档 中对每个命令的复杂度都有介绍，当你需要了解某个命令的复杂度时，可以直接查询。\n\n当你发现 Redis 性能变慢时，可以通过 Redis 日志，或者是 latency monitor 工具，查询变慢的请求，根据请求对应的具体命令以及官方文档，确认下是否采用了复杂度高的慢查询命令。如果的确有大量的慢查询命令，有两种处理方式：\n\n 1. 用其他高效命令代替。比如说，如果你需要返回一个SET中的所有成员时，不要使用SMEMBERS命令，而是要使用SSCAN多次迭代返回，避免一次返回大量数据，造成线程阻塞。\n 2. 当你需要执行排序、交集、并集操作时，可以在客户端完成，而不要用 SORT、SUNION、SINTER 这些命令，以免拖慢 Redis 实例。\n\n还有一个比较容易忽略的慢查询命令，就是 KEYS：用于返回和输入模式匹配的所有key。例如，以下命令返回所有包含“name”字符串的 keys：\n\nredis> KEYS *name*\n1) "lastname"\n2) "firstname"\n\n\n1\n2\n3\n\n\n因为 KEYS 命令需要遍历存储的键值对，所以操作延时高。如果你不了解它的实现而使用了它，就会导致Redis性能变慢。所以，KEYS命令一般不被建议用于生产环境中。\n\n# 2.1.2 过期 key 操作\n\n过期 key 的自动删除机制是 Redis 用来回收内存空间的常用机制，应用广泛，本身就会引起Redis操作阻塞，导致性能变慢，所以，你必须要知道该机制对性能的影响。\n\nRedis 键值对的 key 可以设置过期时间。默认情况下，Redis 每 100 毫秒会删除一些过期 key，具体的算法如下：\n\n 1. 采样 ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP 个数的 key，并将其中过期的 key 全部删除；\n 2. 如果超过 25% 的 key 过期了，则重复删除的过程，直到过期 key 的比例降至 25% 以下。\n\n> 上述 1 是会每秒都在执行的。\n\nACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP 是 Redis 的一个参数，默认是 20，那么，一秒内基本有 200 个过期 key 会被删除。这一策略对清除过期 key、释放内存空间很有帮助。如果每秒钟删除 200 个过期 key，并不会对 Redis 造成太大影响。\n\n但是，如果触发了上面这个算法的第二条，Redis 就会一直删除以释放内存空间。注意，删除操作是阻塞的（Redis 4.0后可以用异步线程机制来减少阻塞影响）。所以，一旦该条件触发，Redis 的线程就会一直执行删除，这样一来，就没办法正常服务其他的键值操作了，就会进一步引起其他键值操作的延迟增加，Redis 就会变慢。\n\n算法的第二条被触发的一个重要来源就是：频繁使用带有相同时间参数的 EXPIREAT 命令设置过期 key，这就会导致，在同一秒内有大量的 key 同时过期。这里我就要给出第二条排查建议和解决方法了：\n\n你要检查业务代码在使用 EXPIREAT 命令设置 key 过期时间时，是否使用了相同的 UNIX 时间戳，有没有使用 EXPIRE 命令给批量的 key 设置相同的过期秒数。因为，这都会造成大量 key 在同一时间过期，导致性能变慢。\n\n遇到这种情况时，千万不要嫌麻烦，你首先要根据实际业务的使用需求，决定 EXPIREAT 和 EXPIRE 的过期时间参数。其次，如果一批 key 的确是同时过期，你还可以在 EXPIREAT 和 EXPIRE 的过期时间参数上，加上一个一定大小范围内的随机数，这样，既保证了 key 在一个邻近时间范围内被删除，又避免了同时过期造成的压力。\n\n----------------------------------------\n\n刚刚讲了从 Redis 自身命令操作层面排查的方案，但如果发现 Redis 有执行大量的慢查询命令，也没有同时删除大量过期 keys，那就要关注影响性能的其他机制了，也就是文件系统和操作系统：\n\n * 一方面，Redis 会持久化保存数据到磁盘，这个过程要依赖文件系统来完成，所以，文件系统将数据写回磁盘的机制，会直接影响到 Redis 持久化的效率。而且，在持久化的过程中，Redis 也还在接收其他请求，持久化的效率高低又会影响到 Redis 处理请求的性能。\n * 另一方面，Redis是内存数据库，内存操作非常频繁，所以，操作系统的内存机制会直接影响到 Redis 的处理效率。比如说，如果 Redis 的内存不够用了，操作系统会启动 swap 机制，这就会直接拖慢 Redis。\n\n\n# 2.2 文件系统：AOF 模式\n\nRedis是个内存数据库，为什么它的性能还和文件系统有关呢？\n\n∵ 为了保证数据可靠性，Redis会采用AOF日志或RDB快照。其中，AOF 日志提供了三种日志写回策略：no、everysec、always。这三种写回策略依赖文件系统的两个系统调用完成，也就是 write 和 fsync：\n\n * write 只要把日志记录写到内核缓冲区，就可以返回了，并不需要等待日志实际写回到磁盘；\n * fsync 需要把日志记录写回到磁盘后才能返回，时间较长。\n\n下表展示了三种写回策略所执行的系统调用：\n\n当写回策略配置为 everysec 和 always 时，Redis 需要调用 fsync 把日志写回磁盘。但是，这两种写回策略的具体执行情况还不太一样：\n\n * 在使用everysec时，Redis允许丢失一秒的操作记录，所以，Redis主线程并不需要确保每个操作记录日志都写回磁盘。而且，fsync的执行时间很长，如果是在Redis主线程中执行fsync，就容易阻塞主线程。所以，当写回策略配置为everysec时，Redis会使用后台的子线程异步完成fsync的操作。\n * 而对于always策略来说，Redis需要确保每个操作记录日志都写回磁盘，如果用后台子线程异步完成，主线程就无法及时地知道每个操作是否已经完成了，这就不符合always策略的要求了。所以，always策略并不使用后台子线程来执行。\n\n另外，在使用AOF日志时，为了避免日志文件不断增大，Redis会执行AOF重写，生成体量缩小的新的AOF日志文件。AOF重写本身需要的时间很长，也容易阻塞Redis主线程，所以，Redis使用子进程来进行AOF重写。\n\n但是，这里有一个潜在的风险点：AOF 重写会对磁盘进行大量 IO 操作，同时，fsync 又需要等到数据写到磁盘后才能返回，所以，当 AOF 重写的压力比较大时，就会导致 fsync 被阻塞。虽然fsync是由后台子线程负责执行的，但是，主线程会监控fsync的执行进度。\n\n当主线程使用后台子线程执行了一次fsync，需要再次把新接收的操作记录写回磁盘时，如果主线程发现上一次的fsync还没有执行完，那么它就会阻塞。所以，如果后台子线程执行的fsync频繁阻塞的话（比如AOF重写占用了大量的磁盘IO带宽），主线程也会阻塞，导致Redis性能变慢。\n\n下图展示了在磁盘压力小和压力大的时候，fsync后台子线程和主线程受到的影响：\n\n到这里你应该可以了解了，由于 fsync 后台子线程和 AOF 重写子进程的存在，主 IO 线程一般不会被阻塞。但是，如果在重写日志时，AOF 重写子进程的写入量比较大，fsync 线程也会被阻塞，进而阻塞主线程，导致延迟增加。\n\n现在，我来给出排查和解决建议。\n\n首先，你可以检查下 Redis 配置文件中的 appendfsync 配置项，该配置项的取值表明了 Redis 实例使用的是哪种 AOF 日志写回策略，如下所示：\n\n如果 AOF 写回策略使用了 everysec 或 always 配置，请先确认下业务方对数据可靠性的要求，明确是否需要每一秒或每一个操作都记日志。有的业务方不了解 Redis AOF 机制，很可能就直接使用数据可靠性最高等级的 always 配置了。其实，很多场景中 Redis 只是作为缓存，并不需要很高的数据可靠性。\n\n如果业务应用对延迟非常敏感，但同时允许一定量的数据丢失，那么，可以把配置项 no-appendfsync-on-rewrite 设置为 yes。这样表示在 AOF 重写时，不进行 fsync 操作。也就是说，Redis 实例把写命令写到内存后，不调用后台线程进行 fsync 操作，就可以直接返回了。当然，如果此时实例发生宕机，就会导致数据丢失。反之，如果这个配置项设置为 no（也是默认配置），在 AOF 重写时，Redis 实例仍然会调用后台线程进行 fsync 操作，这就会给实例带来阻塞。\n\nno-appendfsync-on-rewrite yes\n\n\n1\n\n\n如果的确需要高性能，同时也需要高可靠数据保证，那建议考虑采用高速的固态硬盘作为AOF日志的写入设备。高速固态盘的带宽和并发度比传统的机械硬盘的要高出10倍及以上。在AOF重写和fsync后台线程同时执行时，固态硬盘可以提供较为充足的磁盘IO资源，让AOF重写和fsync后台线程的磁盘IO资源竞争减少，从而降低对Redis的性能影响。\n\n\n# 2.3 操作系统：swap\n\n如果Redis的AOF日志配置只是no，或者就没有采用AOF模式，那么，还会有什么问题导致性能变慢吗？还有一个潜在的瓶颈：操作系统的内存 swap。\n\n内存 swap 是操作系统将内存数据在内存和磁盘间来回换入和换出的机制。由于这涉及磁盘 IO，会导致性能极大地降低。\n\n一旦 swap 被触发，Redis 本身直接通过访问内存就能完成的操作需要等到磁盘数据读写完成后才行。而且和使用 fsync 线程读写 AOF 日志不同，swap 触发后影响的是 Redis 的主线程，会极大增加 Redis 的响应时间。\n\n通常触发 swap 的原因主要是物理机器内存不足，对于 Redis 而言，有两种常见的情况：\n\n * Redis 实例自身使用了大量的内存，导致物理机器的可用内存不足；\n * 和 Redis 实例在同一台机器上运行的其他进程，在进行大量的文件读写操作。文件读写本身会占用系统内存，这会导致分配给 Redis 实例的内存量变少，进而触发 Redis 发生 swap。\n\n针对该问题的解决方式：增加机器的内存或者使用 Redis 集群。\n\n操作系统本身会在后台记录每个进程的swap使用情况，即有多少数据量发生了swap。可以通过下面的介绍来查看每个进程的 swap 使用情况。\n\n * 你可以先通过下面的命令查看Redis的进程号，这里是5332：\n\n$ redis-cli info | grep process_id\nprocess_id: 5332\n\n\n1\n2\n\n * 然后，进入 Redis 所在机器的 /proc 目录下的该进程目录中：\n\ncd /proc/5332\n\n\n1\n\n * 最后，运行下面的命令，查看该Redis进程的使用情况。在这儿，我只截取了部分结果：\n\n$cat smaps | egrep \'^(Swap|Size)\'\nSize: 584 kB\nSwap: 0 kB\nSize: 4 kB\nSwap: 4 kB\nSize: 4 kB\nSwap: 0 kB\nSize: 462044 kB\nSwap: 462008 kB\nSize: 21392 kB\nSwap: 0 kB\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n每一行Size表示的是Redis实例所用的一块内存大小，而Size下方的Swap和它相对应，表示这块Size大小的内存区域有多少已经被换出到磁盘上了。如果这两个值相等，就表示这块内存区域已经完全被换出到磁盘了。\n\n作为内存数据库，Redis本身会使用很多大小不一的内存块，所以，你可以看到有很多Size行，有的很小，就是4KB，而有的很大，例如462044KB。不同内存块被换出到磁盘上的大小也不一样，例如刚刚的结果中的第一个4KB内存块，它下方的Swap也是4KB，这表示这个内存块已经被换出了；另外，462044KB这个内存块也被换出了462008KB，差不多有462MB。\n\n这里有个重要的地方，我得提醒你一下，当出现百MB，甚至GB级别的swap大小时，就表明，此时，Redis实例的内存压力很大，很有可能会变慢。所以，swap 的大小是排查 Redis 性能变慢是否由 swap 引起的重要指标。\n\n一旦发生内存swap，最直接的解决方法就是增加机器内存。如果该实例在一个Redis切片集群中，可以增加Redis集群的实例个数，来分摊每个实例服务的数据量，进而减少每个实例所需的内存量。\n\n当然，如果Redis实例和其他操作大量文件的程序（例如数据分析程序）共享机器，你可以将Redis实例迁移到单独的机器上运行，以满足它的内存需求量。如果该实例正好是Redis主从集群中的主库，而从库的内存很大，也可以考虑进行主从切换，把大内存的从库变成主库，由它来处理客户端请求。\n\n\n# 2.4 操作系统：内存大页\n\n除了内存 swap，还有一个和内存相关的因素，即内存大页机制（Transparent Huge Page, THP），也会影响 Redis 性能。Linux内核从2.6.38开始支持内存大页机制，该机制支持2MB大小的内存页分配，而常规的内存页分配是按4KB的粒度来执行的。\n\n很多人都觉得：“Redis是内存数据库，内存大页不正好可以满足Redis的需求吗？而且在分配相同的内存量时，内存大页还能减少分配次数，不也是对Redis友好吗?”其实内存大页存在一个 trade-off：虽然内存大页可以给Redis带来内存分配方面的收益，但是，不要忘了，Redis为了提供数据可靠性保证，需要将数据做持久化保存。这个写入过程由额外的线程执行，所以，此时，Redis主线程仍然可以接收客户端写请求。客户端的写请求可能会修改正在进行持久化的数据。在这一过程中，Redis就会采用写时复制机制，也就是说，一旦有数据要被修改，Redis并不会直接修改内存中的数据，而是将这些数据拷贝一份，然后再进行修改。如果采用了内存大页，那么，即使客户端请求只修改100B的数据，Redis也需要拷贝2MB的大页。相反，如果是常规内存页机制，只用拷贝4KB。两者相比，你可以看到，当客户端请求修改或新写入数据较多时，内存大页机制将导致大量的拷贝，这就会影响 Redis 正常的访存操作，最终导致性能变慢。\n\n那该怎么办呢？很简单，关闭内存大页就行了。\n\n首先，我们要先排查下内存大页。方法是：在Redis实例运行的机器上执行如下命令：\n\ncat /sys/kernel/mm/transparent_hugepage/enabled\n\n\n1\n\n\n如果执行结果是always，就表明内存大页机制被启动了；如果是never，就表示，内存大页机制被禁止。\n\n在实际生产环境中部署时，我建议你不要使用内存大页机制，操作也很简单，只需要执行下面的命令就可以了：\n\necho never /sys/kernel/mm/transparent_hugepage/enabled\n\n\n1\n\n\n\n# 3. 小结\n\n这里梳理了包含 9 个检查点的 checklist，当遇到 Redis 性能变慢时，可以按照这些步骤逐一检查：\n\n 1. 获取Redis实例在当前环境下的基线性能。\n 2. 是否用了慢查询命令？如果是的话，就使用其他命令替代慢查询命令，或者把聚合计算命令放在客户端做。\n 3. 是否对过期key设置了相同的过期时间？对于批量删除的key，可以在每个key的过期时间上加一个随机数，避免同时删除。\n 4. 是否存在bigkey？ 对于bigkey的删除操作，如果你的Redis是4.0及以上的版本，可以直接利用异步线程机制减少主线程阻塞；如果是Redis 4.0以前的版本，可以使用SCAN命令迭代删除；对于bigkey的集合查询和聚合操作，可以使用SCAN命令在客户端完成。\n 5. Redis AOF配置级别是什么？业务层面是否的确需要这一可靠性级别？如果我们需要高性能，同时也允许数据丢失，可以将配置项no-appendfsync-on-rewrite设置为yes，避免AOF重写和fsync竞争磁盘IO资源，导致Redis延迟增加。当然， 如果既需要高性能又需要高可靠性，最好使用高速固态盘作为AOF日志的写入盘。\n 6. Redis实例的内存使用是否过大？发生swap了吗？如果是的话，就增加机器内存，或者是使用Redis集群，分摊单机Redis的键值对数量和内存压力。同时，要避免出现Redis和其他内存需求大的应用共享机器的情况。\n 7. 在Redis实例的运行环境中，是否启用了透明大页机制？如果是的话，直接关闭内存大页机制就行了。\n 8. 是否运行了Redis主从集群？如果是的话，把主库实例的数据量大小控制在2~4GB，以免主从复制时，从库因加载大的RDB文件而阻塞。\n 9. 是否使用了多核CPU或NUMA架构的机器运行Redis实例？使用多核CPU时，可以给Redis实例绑定物理核；使用NUMA架构时，注意把Redis实例和网络中断处理程序运行在同一个CPU Socket上。\n\n实际上，影响系统性能的因素还有很多，这里讲的只是最常见问题的解决方案。\n\n如果你遇到了一些特殊情况，也不要慌，我再给你分享一个小技巧：仔细检查下有没有恼人的邻居，具体点说，就是Redis所在的机器上有没有一些其他占内存、磁盘IO和网络IO的程序，比如说数据库程序或者数据采集程序。如果有的话，我建议你将这些程序迁移到其他机器上运行。为了保证 Redis 高性能，我们需要给 Redis 充足的计算、内存和 IO 资源，给它提供一个“安静”的环境。',normalizedContent:'> 参考：\n> \n>  * 18 波动的响应延迟：如何应对变慢的redis？（上）| 极客时间\n>  * 19 波动的响应延迟：如何应对变慢的redis？（下）| 极客时间\n\nredis 因其高性能而被广泛应用，我们需要避免性能异常的情况出现。影响 redis 性能的 5 大方面因素有：\n\n * redis 内部的阻塞式操作\n * cpu 核和 numa 架构的影响\n * redis 关键系统配置\n * redis 内存碎片\n * redis 缓冲区\n\n上一篇分析了前两个因素，本文分析第三个因素。\n\n在实际部署中，有一个很严重的问题：redis 突然变慢了，这可能会直接影响其他系统，导致一连串的连锁反应。本文将介绍如何系统性地应对 redis 变慢这个问题，并从问题认定、系统性排查和应对方案这 3 个方面来进行讲解。\n\n\n# 1. redis 真的变慢了吗？\n\n判断 redis 是否真的变慢了有个最直接的方法：查看 redis 的响应延迟。\n\n大部分时候 redis 延迟很低，但某些时刻可能会出现很高的相应延迟，甚至能达到几秒到十几秒，不过持续时间不长，这也叫延迟毛刺。当你发现 redis 命令的执行时间突然就增长到了几秒，基本就可以认定 redis 变慢了。\n\n这种方法看的是 redis 延迟的绝对值，但在不同的软硬件环境下，redis 的绝对性能本身并不相同。比如差的机器延迟 1ms 才认定变慢了，但好的机器延迟 0.2ms 就可以认定变慢了。\n\n所以需要第二个判断方法：基于当前环境下的 redis 基线性能做判断。基线性能：指一个系统在低压力、无干扰下的基本性能，这个性能只由当前的软硬件配置决定。\n\n具体如何确定基线性能呢？redis-cli 命令提供了 –intrinsic-latency 选项，可以用来监测和统计测试期间内的最大延迟，这个延迟可以作为 redis 的基线性能。其中，测试时长可以用 –intrinsic-latency 选项的参数来指定。\n\n举个例子，比如说，我们运行下面的命令，该命令会打印 120 秒内监测到的最大延迟。可以看到，这里的最大延迟是 119 微秒，也就是基线性能为 119 微秒。一般情况下，运行 120 秒就足够监测到最大延迟了，所以，我们可以把参数设置为 120。\n\n./redis-cli --intrinsic-latency 120\nmax latency so far: 17 microseconds.\nmax latency so far: 44 microseconds.\nmax latency so far: 94 microseconds.\nmax latency so far: 110 microseconds.\nmax latency so far: 119 microseconds.\n36481658 total runs (avg latency: 3.2893 microseconds / 3289.32 nanoseconds per run).\nworst run took 36x longer than the average latency.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n一般来说，你要把运行时延迟和基线性能进行对比，如果你观察到的 redis 运行时延迟是其基线性能的 2 倍及以上，就可以认定 redis 变慢了。\n\n我们通常是通过客户端和网络访问redis服务，为了避免网络对基线性能的影响，刚刚说的这个命令需要在服务器端直接运行，这也就是说，我们只考虑服务器端软硬件环境的影响。如果你想了解网络对redis性能的影响，一个简单的方法是用 iperf 这样的工具，测量从 redis 客户端到服务器端的网络延迟。如果这个延迟有几十毫秒甚至是几百毫秒，就说明，redis 运行的网络环境中很可能有大流量的其他应用程序在运行，导致网络拥塞了。这个时候，你就需要协调网络运维，调整网络的流量分配了。\n\n\n# 2. 如何应对 redis 变慢？\n\n我们现在需要诊断 redis 变慢的原因。要基于自己对redis本身的工作原理的理解，并且结合和它交互的操作系统、存储以及网络等外部系统关键机制，再借助一些辅助工具来定位原因，并制定行之有效的解决方案。\n\n下图是 redis 的架构图，红色模块就是影响 redis 的三大要素：redis 自身的操作特性、文件系统和操作系统。\n\n下面将从这三大要素入手，并结合实际的应用场景，依次介绍从不同要素出发排查和解决问题的实践经验。性能诊断通常是一件困难的事，所以我们一定不能毫无目标地“乱找”。\n\n\n# 2.1 redis 自身操作特性的影响\n\n首先来学习下 redis 提供的键值对命令操作对延迟性能的影响。这里重点介绍两类关键操作：慢查询命令和过期 key 操作。\n\n# 2.1.1 慢查询命令\n\n慢查询命令：指在 redis 中执行速度慢的命令，这会导致 redis 延迟增加。\n\n执行快慢与操作复杂度相关。比如说，value 类型为 string 时，get/set 操作主要就是操作 redis 的哈希表索引。这个操作复杂度基本是固定的，即 o(1)。但是，当 value 类型为 set 时，sort、sunion/smembers 操作复杂度分别为 o(n+m*log(m)) 和 o(n) 。其中，n 为 set 中的元素个数，m 为 sort 操作返回的元素个数。这个复杂度就增加了很多。redis官方文档 中对每个命令的复杂度都有介绍，当你需要了解某个命令的复杂度时，可以直接查询。\n\n当你发现 redis 性能变慢时，可以通过 redis 日志，或者是 latency monitor 工具，查询变慢的请求，根据请求对应的具体命令以及官方文档，确认下是否采用了复杂度高的慢查询命令。如果的确有大量的慢查询命令，有两种处理方式：\n\n 1. 用其他高效命令代替。比如说，如果你需要返回一个set中的所有成员时，不要使用smembers命令，而是要使用sscan多次迭代返回，避免一次返回大量数据，造成线程阻塞。\n 2. 当你需要执行排序、交集、并集操作时，可以在客户端完成，而不要用 sort、sunion、sinter 这些命令，以免拖慢 redis 实例。\n\n还有一个比较容易忽略的慢查询命令，就是 keys：用于返回和输入模式匹配的所有key。例如，以下命令返回所有包含“name”字符串的 keys：\n\nredis> keys *name*\n1) "lastname"\n2) "firstname"\n\n\n1\n2\n3\n\n\n因为 keys 命令需要遍历存储的键值对，所以操作延时高。如果你不了解它的实现而使用了它，就会导致redis性能变慢。所以，keys命令一般不被建议用于生产环境中。\n\n# 2.1.2 过期 key 操作\n\n过期 key 的自动删除机制是 redis 用来回收内存空间的常用机制，应用广泛，本身就会引起redis操作阻塞，导致性能变慢，所以，你必须要知道该机制对性能的影响。\n\nredis 键值对的 key 可以设置过期时间。默认情况下，redis 每 100 毫秒会删除一些过期 key，具体的算法如下：\n\n 1. 采样 active_expire_cycle_lookups_per_loop 个数的 key，并将其中过期的 key 全部删除；\n 2. 如果超过 25% 的 key 过期了，则重复删除的过程，直到过期 key 的比例降至 25% 以下。\n\n> 上述 1 是会每秒都在执行的。\n\nactive_expire_cycle_lookups_per_loop 是 redis 的一个参数，默认是 20，那么，一秒内基本有 200 个过期 key 会被删除。这一策略对清除过期 key、释放内存空间很有帮助。如果每秒钟删除 200 个过期 key，并不会对 redis 造成太大影响。\n\n但是，如果触发了上面这个算法的第二条，redis 就会一直删除以释放内存空间。注意，删除操作是阻塞的（redis 4.0后可以用异步线程机制来减少阻塞影响）。所以，一旦该条件触发，redis 的线程就会一直执行删除，这样一来，就没办法正常服务其他的键值操作了，就会进一步引起其他键值操作的延迟增加，redis 就会变慢。\n\n算法的第二条被触发的一个重要来源就是：频繁使用带有相同时间参数的 expireat 命令设置过期 key，这就会导致，在同一秒内有大量的 key 同时过期。这里我就要给出第二条排查建议和解决方法了：\n\n你要检查业务代码在使用 expireat 命令设置 key 过期时间时，是否使用了相同的 unix 时间戳，有没有使用 expire 命令给批量的 key 设置相同的过期秒数。因为，这都会造成大量 key 在同一时间过期，导致性能变慢。\n\n遇到这种情况时，千万不要嫌麻烦，你首先要根据实际业务的使用需求，决定 expireat 和 expire 的过期时间参数。其次，如果一批 key 的确是同时过期，你还可以在 expireat 和 expire 的过期时间参数上，加上一个一定大小范围内的随机数，这样，既保证了 key 在一个邻近时间范围内被删除，又避免了同时过期造成的压力。\n\n----------------------------------------\n\n刚刚讲了从 redis 自身命令操作层面排查的方案，但如果发现 redis 有执行大量的慢查询命令，也没有同时删除大量过期 keys，那就要关注影响性能的其他机制了，也就是文件系统和操作系统：\n\n * 一方面，redis 会持久化保存数据到磁盘，这个过程要依赖文件系统来完成，所以，文件系统将数据写回磁盘的机制，会直接影响到 redis 持久化的效率。而且，在持久化的过程中，redis 也还在接收其他请求，持久化的效率高低又会影响到 redis 处理请求的性能。\n * 另一方面，redis是内存数据库，内存操作非常频繁，所以，操作系统的内存机制会直接影响到 redis 的处理效率。比如说，如果 redis 的内存不够用了，操作系统会启动 swap 机制，这就会直接拖慢 redis。\n\n\n# 2.2 文件系统：aof 模式\n\nredis是个内存数据库，为什么它的性能还和文件系统有关呢？\n\n∵ 为了保证数据可靠性，redis会采用aof日志或rdb快照。其中，aof 日志提供了三种日志写回策略：no、everysec、always。这三种写回策略依赖文件系统的两个系统调用完成，也就是 write 和 fsync：\n\n * write 只要把日志记录写到内核缓冲区，就可以返回了，并不需要等待日志实际写回到磁盘；\n * fsync 需要把日志记录写回到磁盘后才能返回，时间较长。\n\n下表展示了三种写回策略所执行的系统调用：\n\n当写回策略配置为 everysec 和 always 时，redis 需要调用 fsync 把日志写回磁盘。但是，这两种写回策略的具体执行情况还不太一样：\n\n * 在使用everysec时，redis允许丢失一秒的操作记录，所以，redis主线程并不需要确保每个操作记录日志都写回磁盘。而且，fsync的执行时间很长，如果是在redis主线程中执行fsync，就容易阻塞主线程。所以，当写回策略配置为everysec时，redis会使用后台的子线程异步完成fsync的操作。\n * 而对于always策略来说，redis需要确保每个操作记录日志都写回磁盘，如果用后台子线程异步完成，主线程就无法及时地知道每个操作是否已经完成了，这就不符合always策略的要求了。所以，always策略并不使用后台子线程来执行。\n\n另外，在使用aof日志时，为了避免日志文件不断增大，redis会执行aof重写，生成体量缩小的新的aof日志文件。aof重写本身需要的时间很长，也容易阻塞redis主线程，所以，redis使用子进程来进行aof重写。\n\n但是，这里有一个潜在的风险点：aof 重写会对磁盘进行大量 io 操作，同时，fsync 又需要等到数据写到磁盘后才能返回，所以，当 aof 重写的压力比较大时，就会导致 fsync 被阻塞。虽然fsync是由后台子线程负责执行的，但是，主线程会监控fsync的执行进度。\n\n当主线程使用后台子线程执行了一次fsync，需要再次把新接收的操作记录写回磁盘时，如果主线程发现上一次的fsync还没有执行完，那么它就会阻塞。所以，如果后台子线程执行的fsync频繁阻塞的话（比如aof重写占用了大量的磁盘io带宽），主线程也会阻塞，导致redis性能变慢。\n\n下图展示了在磁盘压力小和压力大的时候，fsync后台子线程和主线程受到的影响：\n\n到这里你应该可以了解了，由于 fsync 后台子线程和 aof 重写子进程的存在，主 io 线程一般不会被阻塞。但是，如果在重写日志时，aof 重写子进程的写入量比较大，fsync 线程也会被阻塞，进而阻塞主线程，导致延迟增加。\n\n现在，我来给出排查和解决建议。\n\n首先，你可以检查下 redis 配置文件中的 appendfsync 配置项，该配置项的取值表明了 redis 实例使用的是哪种 aof 日志写回策略，如下所示：\n\n如果 aof 写回策略使用了 everysec 或 always 配置，请先确认下业务方对数据可靠性的要求，明确是否需要每一秒或每一个操作都记日志。有的业务方不了解 redis aof 机制，很可能就直接使用数据可靠性最高等级的 always 配置了。其实，很多场景中 redis 只是作为缓存，并不需要很高的数据可靠性。\n\n如果业务应用对延迟非常敏感，但同时允许一定量的数据丢失，那么，可以把配置项 no-appendfsync-on-rewrite 设置为 yes。这样表示在 aof 重写时，不进行 fsync 操作。也就是说，redis 实例把写命令写到内存后，不调用后台线程进行 fsync 操作，就可以直接返回了。当然，如果此时实例发生宕机，就会导致数据丢失。反之，如果这个配置项设置为 no（也是默认配置），在 aof 重写时，redis 实例仍然会调用后台线程进行 fsync 操作，这就会给实例带来阻塞。\n\nno-appendfsync-on-rewrite yes\n\n\n1\n\n\n如果的确需要高性能，同时也需要高可靠数据保证，那建议考虑采用高速的固态硬盘作为aof日志的写入设备。高速固态盘的带宽和并发度比传统的机械硬盘的要高出10倍及以上。在aof重写和fsync后台线程同时执行时，固态硬盘可以提供较为充足的磁盘io资源，让aof重写和fsync后台线程的磁盘io资源竞争减少，从而降低对redis的性能影响。\n\n\n# 2.3 操作系统：swap\n\n如果redis的aof日志配置只是no，或者就没有采用aof模式，那么，还会有什么问题导致性能变慢吗？还有一个潜在的瓶颈：操作系统的内存 swap。\n\n内存 swap 是操作系统将内存数据在内存和磁盘间来回换入和换出的机制。由于这涉及磁盘 io，会导致性能极大地降低。\n\n一旦 swap 被触发，redis 本身直接通过访问内存就能完成的操作需要等到磁盘数据读写完成后才行。而且和使用 fsync 线程读写 aof 日志不同，swap 触发后影响的是 redis 的主线程，会极大增加 redis 的响应时间。\n\n通常触发 swap 的原因主要是物理机器内存不足，对于 redis 而言，有两种常见的情况：\n\n * redis 实例自身使用了大量的内存，导致物理机器的可用内存不足；\n * 和 redis 实例在同一台机器上运行的其他进程，在进行大量的文件读写操作。文件读写本身会占用系统内存，这会导致分配给 redis 实例的内存量变少，进而触发 redis 发生 swap。\n\n针对该问题的解决方式：增加机器的内存或者使用 redis 集群。\n\n操作系统本身会在后台记录每个进程的swap使用情况，即有多少数据量发生了swap。可以通过下面的介绍来查看每个进程的 swap 使用情况。\n\n * 你可以先通过下面的命令查看redis的进程号，这里是5332：\n\n$ redis-cli info | grep process_id\nprocess_id: 5332\n\n\n1\n2\n\n * 然后，进入 redis 所在机器的 /proc 目录下的该进程目录中：\n\ncd /proc/5332\n\n\n1\n\n * 最后，运行下面的命令，查看该redis进程的使用情况。在这儿，我只截取了部分结果：\n\n$cat smaps | egrep \'^(swap|size)\'\nsize: 584 kb\nswap: 0 kb\nsize: 4 kb\nswap: 4 kb\nsize: 4 kb\nswap: 0 kb\nsize: 462044 kb\nswap: 462008 kb\nsize: 21392 kb\nswap: 0 kb\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n每一行size表示的是redis实例所用的一块内存大小，而size下方的swap和它相对应，表示这块size大小的内存区域有多少已经被换出到磁盘上了。如果这两个值相等，就表示这块内存区域已经完全被换出到磁盘了。\n\n作为内存数据库，redis本身会使用很多大小不一的内存块，所以，你可以看到有很多size行，有的很小，就是4kb，而有的很大，例如462044kb。不同内存块被换出到磁盘上的大小也不一样，例如刚刚的结果中的第一个4kb内存块，它下方的swap也是4kb，这表示这个内存块已经被换出了；另外，462044kb这个内存块也被换出了462008kb，差不多有462mb。\n\n这里有个重要的地方，我得提醒你一下，当出现百mb，甚至gb级别的swap大小时，就表明，此时，redis实例的内存压力很大，很有可能会变慢。所以，swap 的大小是排查 redis 性能变慢是否由 swap 引起的重要指标。\n\n一旦发生内存swap，最直接的解决方法就是增加机器内存。如果该实例在一个redis切片集群中，可以增加redis集群的实例个数，来分摊每个实例服务的数据量，进而减少每个实例所需的内存量。\n\n当然，如果redis实例和其他操作大量文件的程序（例如数据分析程序）共享机器，你可以将redis实例迁移到单独的机器上运行，以满足它的内存需求量。如果该实例正好是redis主从集群中的主库，而从库的内存很大，也可以考虑进行主从切换，把大内存的从库变成主库，由它来处理客户端请求。\n\n\n# 2.4 操作系统：内存大页\n\n除了内存 swap，还有一个和内存相关的因素，即内存大页机制（transparent huge page, thp），也会影响 redis 性能。linux内核从2.6.38开始支持内存大页机制，该机制支持2mb大小的内存页分配，而常规的内存页分配是按4kb的粒度来执行的。\n\n很多人都觉得：“redis是内存数据库，内存大页不正好可以满足redis的需求吗？而且在分配相同的内存量时，内存大页还能减少分配次数，不也是对redis友好吗?”其实内存大页存在一个 trade-off：虽然内存大页可以给redis带来内存分配方面的收益，但是，不要忘了，redis为了提供数据可靠性保证，需要将数据做持久化保存。这个写入过程由额外的线程执行，所以，此时，redis主线程仍然可以接收客户端写请求。客户端的写请求可能会修改正在进行持久化的数据。在这一过程中，redis就会采用写时复制机制，也就是说，一旦有数据要被修改，redis并不会直接修改内存中的数据，而是将这些数据拷贝一份，然后再进行修改。如果采用了内存大页，那么，即使客户端请求只修改100b的数据，redis也需要拷贝2mb的大页。相反，如果是常规内存页机制，只用拷贝4kb。两者相比，你可以看到，当客户端请求修改或新写入数据较多时，内存大页机制将导致大量的拷贝，这就会影响 redis 正常的访存操作，最终导致性能变慢。\n\n那该怎么办呢？很简单，关闭内存大页就行了。\n\n首先，我们要先排查下内存大页。方法是：在redis实例运行的机器上执行如下命令：\n\ncat /sys/kernel/mm/transparent_hugepage/enabled\n\n\n1\n\n\n如果执行结果是always，就表明内存大页机制被启动了；如果是never，就表示，内存大页机制被禁止。\n\n在实际生产环境中部署时，我建议你不要使用内存大页机制，操作也很简单，只需要执行下面的命令就可以了：\n\necho never /sys/kernel/mm/transparent_hugepage/enabled\n\n\n1\n\n\n\n# 3. 小结\n\n这里梳理了包含 9 个检查点的 checklist，当遇到 redis 性能变慢时，可以按照这些步骤逐一检查：\n\n 1. 获取redis实例在当前环境下的基线性能。\n 2. 是否用了慢查询命令？如果是的话，就使用其他命令替代慢查询命令，或者把聚合计算命令放在客户端做。\n 3. 是否对过期key设置了相同的过期时间？对于批量删除的key，可以在每个key的过期时间上加一个随机数，避免同时删除。\n 4. 是否存在bigkey？ 对于bigkey的删除操作，如果你的redis是4.0及以上的版本，可以直接利用异步线程机制减少主线程阻塞；如果是redis 4.0以前的版本，可以使用scan命令迭代删除；对于bigkey的集合查询和聚合操作，可以使用scan命令在客户端完成。\n 5. redis aof配置级别是什么？业务层面是否的确需要这一可靠性级别？如果我们需要高性能，同时也允许数据丢失，可以将配置项no-appendfsync-on-rewrite设置为yes，避免aof重写和fsync竞争磁盘io资源，导致redis延迟增加。当然， 如果既需要高性能又需要高可靠性，最好使用高速固态盘作为aof日志的写入盘。\n 6. redis实例的内存使用是否过大？发生swap了吗？如果是的话，就增加机器内存，或者是使用redis集群，分摊单机redis的键值对数量和内存压力。同时，要避免出现redis和其他内存需求大的应用共享机器的情况。\n 7. 在redis实例的运行环境中，是否启用了透明大页机制？如果是的话，直接关闭内存大页机制就行了。\n 8. 是否运行了redis主从集群？如果是的话，把主库实例的数据量大小控制在2~4gb，以免主从复制时，从库因加载大的rdb文件而阻塞。\n 9. 是否使用了多核cpu或numa架构的机器运行redis实例？使用多核cpu时，可以给redis实例绑定物理核；使用numa架构时，注意把redis实例和网络中断处理程序运行在同一个cpu socket上。\n\n实际上，影响系统性能的因素还有很多，这里讲的只是最常见问题的解决方案。\n\n如果你遇到了一些特殊情况，也不要慌，我再给你分享一个小技巧：仔细检查下有没有恼人的邻居，具体点说，就是redis所在的机器上有没有一些其他占内存、磁盘io和网络io的程序，比如说数据库程序或者数据采集程序。如果有的话，我建议你将这些程序迁移到其他机器上运行。为了保证 redis 高性能，我们需要给 redis 充足的计算、内存和 io 资源，给它提供一个“安静”的环境。',charsets:{cjk:!0},lastUpdated:"2023/04/10, 13:35:58",lastUpdatedTimestamp:1681133758e3},{title:"Redis 的内存碎片、缓冲区",frontmatter:{title:"Redis 的内存碎片、缓冲区",date:"2023-04-09T17:15:43.000Z",permalink:"/pages/6135bf/",categories:["中间件","Redis","专栏：Redis 核心技术与实战"],tags:[null]},regularPath:"/%E4%B8%AD%E9%97%B4%E4%BB%B6/05.Redis/05.%E4%B8%93%E6%A0%8F%EF%BC%9ARedis%20%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/20.Redis%20%E7%9A%84%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87%E3%80%81%E7%BC%93%E5%86%B2%E5%8C%BA.html",relativePath:"中间件/05.Redis/05.专栏：Redis 核心技术与实战/20.Redis 的内存碎片、缓冲区.md",key:"v-1a140cfc",path:"/pages/6135bf/",headers:[{level:2,title:"1. Redis 的内存碎片问题",slug:"_1-redis-的内存碎片问题",normalizedTitle:"1. redis 的内存碎片问题",charIndex:257},{level:3,title:"1.1 什么是内存碎片？",slug:"_1-1-什么是内存碎片",normalizedTitle:"1.1 什么是内存碎片？",charIndex:640},{level:3,title:"1.2 内存碎片是如何形成的？",slug:"_1-2-内存碎片是如何形成的",normalizedTitle:"1.2 内存碎片是如何形成的？",charIndex:806},{level:4,title:"1.2.1 内因：内存分配器的分配策略",slug:"_1-2-1-内因-内存分配器的分配策略",normalizedTitle:"1.2.1 内因：内存分配器的分配策略",charIndex:887},{level:4,title:"1.2.2 外因：键值对大小不一样和删改操作",slug:"_1-2-2-外因-键值对大小不一样和删改操作",normalizedTitle:"1.2.2 外因：键值对大小不一样和删改操作",charIndex:1401},{level:3,title:"1.3 如何判断是否有内存碎片？",slug:"_1-3-如何判断是否有内存碎片",normalizedTitle:"1.3 如何判断是否有内存碎片？",charIndex:1966},{level:3,title:"1.4 如何清理内存碎片？",slug:"_1-4-如何清理内存碎片",normalizedTitle:"1.4 如何清理内存碎片？",charIndex:2753},{level:4,title:"1.4.1 重启 Redis 的方法",slug:"_1-4-1-重启-redis-的方法",normalizedTitle:"1.4.1 重启 redis 的方法",charIndex:2770},{level:4,title:"1.4.2 内存碎片自动清理的方法",slug:"_1-4-2-内存碎片自动清理的方法",normalizedTitle:"1.4.2 内存碎片自动清理的方法",charIndex:2996},{level:4,title:"1.4.3 内存碎片自动清理的相关参数",slug:"_1-4-3-内存碎片自动清理的相关参数",normalizedTitle:"1.4.3 内存碎片自动清理的相关参数",charIndex:3385},{level:3,title:"1.5 小结",slug:"_1-5-小结",normalizedTitle:"1.5 小结",charIndex:4215},{level:2,title:"2. 缓冲区：一个可能引发“惨案”的地方",slug:"_2-缓冲区-一个可能引发-惨案-的地方",normalizedTitle:"2. 缓冲区：一个可能引发“惨案”的地方",charIndex:4603},{level:3,title:"2.1 客户端的输入和输出缓冲区",slug:"_2-1-客户端的输入和输出缓冲区",normalizedTitle:"2.1 客户端的输入和输出缓冲区",charIndex:5103},{level:4,title:"2.1.1 如何应对输入缓冲区溢出？",slug:"_2-1-1-如何应对输入缓冲区溢出",normalizedTitle:"2.1.1 如何应对输入缓冲区溢出？",charIndex:5368},{level:4,title:"2.1.2 如何应对输出缓冲区溢出？",slug:"_2-1-2-如何应对输出缓冲区溢出",normalizedTitle:"2.1.2 如何应对输出缓冲区溢出？",charIndex:6883},{level:3,title:"2.2 主从集群中的缓冲区",slug:"_2-2-主从集群中的缓冲区",normalizedTitle:"2.2 主从集群中的缓冲区",charIndex:8639},{level:4,title:"2.2.1 全量复制期间--复制缓冲区的溢出问题",slug:"_2-2-1-全量复制期间-复制缓冲区的溢出问题",normalizedTitle:"2.2.1 全量复制期间--复制缓冲区的溢出问题",charIndex:8805},{level:4,title:"2.2.2 增量复制期间--复制积压缓冲区的溢出问题",slug:"_2-2-2-增量复制期间-复制积压缓冲区的溢出问题",normalizedTitle:"2.2.2 增量复制期间--复制积压缓冲区的溢出问题",charIndex:10033},{level:3,title:"2.3 小结",slug:"_2-3-小结",normalizedTitle:"2.3 小结",charIndex:10530}],headersStr:"1. Redis 的内存碎片问题 1.1 什么是内存碎片？ 1.2 内存碎片是如何形成的？ 1.2.1 内因：内存分配器的分配策略 1.2.2 外因：键值对大小不一样和删改操作 1.3 如何判断是否有内存碎片？ 1.4 如何清理内存碎片？ 1.4.1 重启 Redis 的方法 1.4.2 内存碎片自动清理的方法 1.4.3 内存碎片自动清理的相关参数 1.5 小结 2. 缓冲区：一个可能引发“惨案”的地方 2.1 客户端的输入和输出缓冲区 2.1.1 如何应对输入缓冲区溢出？ 2.1.2 如何应对输出缓冲区溢出？ 2.2 主从集群中的缓冲区 2.2.1 全量复制期间--复制缓冲区的溢出问题 2.2.2 增量复制期间--复制积压缓冲区的溢出问题 2.3 小结",content:"> 参考：\n> \n>  * 20 删除数据后，为什么内存占用率还是很高？| 极客时间\n>  * 21 缓冲区：一个可能引发“惨案”的地方 | 极客时间\n\nRedis 因其高性能而被广泛应用，我们需要避免性能异常的情况出现。影响 Redis 性能的 5 大方面因素有：\n\n * Redis 内部的阻塞式操作\n * CPU 核和 NUMA 架构的影响\n * Redis 关键系统配置\n * Redis 内存碎片\n * Redis 缓冲区\n\n前面两篇文章分别分析了第一二个和第三个因素，本文分析第四、五个因素。\n\n\n# 1. Redis 的内存碎片问题\n\n使用 Redis 时经常会遇到这样一个问题：明明做了数据删除，数据量已经不大了，为什么使用top命令查看时，还会发现Redis占用了很多内存呢？实际上，这是因为，当数据删除后，Redis 释放的内存空间会由内存分配器管理，并不会立即返回给操作系统。所以，操作系统仍然会记录着给Redis分配了大量内存。\n\n但是，这往往会伴随一个潜在的风险点：Redis 释放的内存空间可能并不是连续的，那么，这些不连续的内存空间很有可能处于一种闲置的状态。这就会导致一个问题：虽然有空闲空间，Redis却无法用来保存数据，不仅会减少Redis能够实际保存的数据量，还会降低Redis运行机器的成本回报率。\n\n这一节将讨论一下 Redis 的内存空间存储效率问题，探索一下，为什么数据已经删除了，但内存却闲置着没有用，以及相应的解决方案。\n\n\n# 1.1 什么是内存碎片？\n\n通常情况下，内存空间闲置，往往是因为操作系统发生了较为严重的内存碎片，导致无法继续分配一块连续空间。\n\n内存碎片：内存中还有 5KB 的空余，但都是零散在不同地方，无法满足“申请一块连续 2KB 空间”的要求。\n\n类似于3个人想买连着的火车票，但此时车上只有不连续的三个空座位，因此就换趟车了。\n\n\n# 1.2 内存碎片是如何形成的？\n\n其实，内存碎片的形成有内因和外因两个层面的原因。简单来说，内因是操作系统的内存分配机制，外因是 Redis 的负载特征。\n\n# 1.2.1 内因：内存分配器的分配策略\n\n内存分配器的分配策略就决定了操作系统无法做到“按需分配”。这是因为，内存分配器一般是按固定大小来分配内存，而不是完全按照应用程序申请的内存空间大小给程序分配。\n\nRedis可以使用libc、jemalloc、tcmalloc多种内存分配器来分配内存，默认使用jemalloc。接下来，我就以jemalloc为例，来具体解释一下。其他分配器也存在类似的问题。\n\njemalloc的分配策略之一，是按照一系列固定的大小划分内存空间，例如8字节、16字节、32字节、48字节，…, 2KB、4KB、8KB等。当程序申请的内存最接近某个固定值时，jemalloc会给它分配相应大小的空间。\n\n这样的分配方式本身是为了减少分配次数。例如，Redis申请一个20字节的空间保存数据，jemalloc就会分配32字节，此时，如果应用还要写入10字节的数据，Redis就不用再向操作系统申请空间了，因为刚才分配的32字节已经够用了，这就避免了一次分配操作。\n\n但是，如果 Redis 每次向分配器申请的内存空间大小不一样，这种分配方式就会有形成碎片的风险，而这正好来源于 Redis 的外因了。\n\n# 1.2.2 外因：键值对大小不一样和删改操作\n\n第一个外因：\n\nRedis 通常作为共用的缓存系统或键值数据库对外提供服务，所以，不同业务应用的数据都可能保存在 Redis 中，这就会带来不同大小的键值对。但内存分配器只能按固定大小分配内存，所以，分配的内存空间一般都会比申请的空间大一些，不会完全一致，这本身就会造成一定的碎片，降低内存空间存储效率。\n\n第二个外因：\n\n第二个外因是，这些键值对会被修改和删除，这会导致空间的扩容和释放。具体来说，一方面，如果修改后的键值对变大或变小了，就需要占用额外的空间或者释放不用的空间。另一方面，删除的键值对就不再需要内存空间了，此时，就会把空间释放出来，形成空闲空间。\n\n但这样频繁操作后，会形成很多碎片空间，它们不是连续的，导致难以被利用。如下图：\n\n----------------------------------------\n\n好了，到这里，我们就知道了造成内存碎片的内外因素，其中，内存分配器策略是内因，而Redis的负载属于外因，包括了大小不一的键值对和键值对修改删除带来的内存空间变化。\n\n大量内存碎片的存在，会造成 Redis 的内存实际利用率变低，接下来，我们就要来解决这个问题了。不过，在解决问题前，我们要先判断 Redis 运行过程中是否存在内存碎片。\n\n\n# 1.3 如何判断是否有内存碎片？\n\n为了让用户能监控到实时的内存使用情况，Redis 自身提供了 INFO 命令，可以用来查询内存使用的详细信息，命令如下：\n\nINFO memory\n# Memory\nused_memory:1073741736\nused_memory_human:1024.00M\nused_memory_rss:1997159792\nused_memory_rss_human:1.86G\n…\nmem_fragmentation_ratio:1.86\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n这里有一个 mem_fragmentation_ratio 的指标，它表示的就是 Redis 当前的内存碎片率。那么，这个碎片率是怎么计算的呢？其实，就是上面的命令中的两个指标used_memory_rss和used_memory相除的结果：\n\nmem_fragmentation_ratio = used_memory_rss/ used_memory\n\n\n1\n\n * used_memory_rss 是操作系统实际分配给Redis的物理内存空间，里面就包含了碎片；\n * used_memory 是 Redis 为了保存数据实际申请使用的空间。\n\n这个指标如何使用呢？这里有一些经验阈值：\n\n * mem_fragmentation_ratio 大于 1 但小于 1.5。这种情况是合理的。这是因为，刚才我介绍的那些因素是难以避免的。毕竟，内因的内存分配器是一定要使用的，分配策略都是通用的，不会轻易修改；而外因由Redis负载决定，也无法限制。所以，存在内存碎片也是正常的。\n * mem_fragmentation_ratio 大于 1.5 。这表明内存碎片率已经超过了50%。一般情况下，这个时候，我们就需要采取一些措施来降低内存碎片率了。\n\n\n# 1.4 如何清理内存碎片？\n\n# 1.4.1 重启 Redis 的方法\n\n当 Redis 发生内存碎片后，一个“简单粗暴”的方法就是重启Redis实例。当然，这并不是一个“优雅”的方法，毕竟，重启 Redis 会带来两个后果：\n\n * 如果 Redis 中的数据没有持久化，那么，数据就会丢失；\n * 即使 Redis 数据持久化了，我们还需要通过 AOF 或 RDB 进行恢复，恢复时长取决于 AOF 或 RDB 的大小，如果只有一个 Redis 实例，恢复阶段无法提供服务。\n\n# 1.4.2 内存碎片自动清理的方法\n\n所以，还有什么其他好办法吗？幸运的是，从 4.0-RC3 版本以后，Redis 自身提供了一种内存碎片自动清理的方法，我们先来看这个方法的基本机制：“搬家让位，合并空间”，用一张图来解释就是：\n\n以刚刚的高铁的例子来看，就是三个人买了不在一起的车票，上车之后和别人调换作为，坐在了一起。\n\n当然，如果数据拷贝后，并没有形成连续的内存空间，这就不能算是清理了。\n\n不过需要注意：碎片清理是有代价的，操作系统需要把多份数据拷贝到新位置，把原有空间释放出来，这会带来时间开销，会阻塞 Redis 的线程。\n\n有什么办法可以尽量缓解这个问题吗？这就要提到 Redis 专门为自动内存碎片清理机制设置的参数了。我们可以通过设置参数，来控制碎片清理的开始和结束时机，以及占用的CPU比例，从而减少碎片清理对 Redis 本身请求处理的性能影响。\n\n# 1.4.3 内存碎片自动清理的相关参数\n\n首先，Redis 需要启用自动内存碎片清理，可以把 activedefrag 配置项设置为 yes，命令如下：\n\nconfig set activedefrag yes\n\n\n1\n\n\n这个命令只是启用了自动清理功能，但是，具体什么时候清理，会受到下面这两个参数的控制。这两个参数分别设置了触发内存清理的一个条件，如果同时满足这两个条件，就开始清理。在清理的过程中，只要有一个条件不满足了，就停止自动清理：\n\n * active-defrag-ignore-bytes 100mb：表示内存碎片的字节数达到100MB时，开始清理；\n * active-defrag-threshold-lower 10：表示内存碎片空间占操作系统分配给Redis的总空间比例达到10%时，开始清理。\n\n为了尽可能减少碎片清理对 Redis 正常请求处理的影响，自动内存碎片清理功能在执行时，还会监控清理操作占用的 CPU 时间，而且还设置了两个参数，分别用于控制清理操作占用的CPU时间比例的上、下限，既保证清理工作能正常进行，又避免了降低 Redis 性能。这两个参数具体如下：\n\n * active-defrag-cycle-min 25： 表示自动清理过程所用CPU时间的比例不低于25%，保证清理能正常开展；\n * active-defrag-cycle-max 75：表示自动清理过程所用CPU时间的比例不高于75%，一旦超过，就停止清理，从而避免在清理时，大量的内存拷贝阻塞Redis，导致响应延迟升高。\n\n自动内存碎片清理机制在控制碎片清理启停的时机上，既考虑了碎片的空间占比、对 Redis 内存使用效率的影响，还考虑了清理机制本身的 CPU 时间占比、对 Redis 性能的影响。而且，清理机制还提供了 4 个参数，让我们可以根据实际应用中的数据量需求和性能要求灵活使用，建议你在实践中好好地把这个机制用起来。\n\n\n# 1.5 小结\n\n这一大节主要了解了 Redis 的内存空间效率问题，这里面的一个关键技术点就是要识别和处理内存碎片：\n\n * info memory 命令是一个好工具，可以帮助你查看碎片率的情况；\n * 碎片率阈值是一个好经验，可以帮忙你有效地判断是否要进行碎片清理了；\n * 内存碎片自动清理是一个好方法，可以避免因为碎片导致 Redis 的内存实际利用率降低，提升成本收益率。\n\n内存碎片并不可怕，我们要做的就是了解它，重视它，并借用高效的方法解决它。\n\n最后，我再给你提供一个小贴士：内存碎片自动清理涉及内存拷贝，这对Redis而言，是个潜在的风险。如果你在实践过程中遇到Redis性能变慢，记得通过日志看下是否正在进行碎片清理。如果Redis的确正在清理碎片，那么，我建议你调小active-defrag-cycle-max的值，以减轻对正常请求处理的影响。\n\n\n# 2. 缓冲区：一个可能引发“惨案”的地方\n\n缓冲区的功能其实很简单，主要就是用一块内存空间来暂时存放命令数据，以免出现因为数据和命令的处理速度慢于发送速度而导致的数据丢失和性能问题。但因为缓冲区的内存空间有限，如果往里面写入数据的速度持续地大于从里面读取数据的速度，就会导致缓冲区需要越来越多的内存来暂存数据。当缓冲区占用的内存超出了设定的上限阈值时，就会出现缓冲区溢出。如果发生了溢出，就会丢数据了。\n\n> 可以不给缓冲区的大小设置上限吗？显然不行，随着累积的数据越来越多，缓冲区占用内存空间越来越大，一旦耗尽了Redis实例所在机器的可用内存，就会导致Redis实例崩溃。 所以毫不夸张地说，缓冲区是用来避免请求或数据丢失的惨案的，但也只有用对了，才能真正起到“避免”的作用。\n\nRedis 的两个应用场景：\n\n * 在 client 和 server 进行通信时，用来暂存客户端发送的命令数据，或者是服务器端返回给客户端的数据结果。\n * 在主从节点间进行数据同步时，用来暂存主节点接收的写命令和数据。\n\n这一大节将分别聊聊服务器端和客户端、主从集群间的缓冲区溢出问题，以及应对方案。\n\n\n# 2.1 客户端的输入和输出缓冲区\n\n我们先来看看服务器端和客户端之间的缓冲区。\n\n为了避免客户端和服务器端的请求发送和处理速度不匹配，服务器端给每个连接的客户端都设置了一个输入缓冲区和输出缓冲区，我们称之为客户端输入缓冲区和输出缓冲区。\n\n输入缓冲区会先把客户端发送过来的命令暂存起来，Redis主线程再从输入缓冲区中读取命令，进行处理。当Redis主线程处理完数据后，会把结果写入到输出缓冲区，再通过输出缓冲区返回给客户端，如下图所示：\n\n下面，我们就分别学习下输入缓冲区和输出缓冲区发生溢出的情况，以及相应的应对方案。\n\n# 2.1.1 如何应对输入缓冲区溢出？\n\n输入缓冲区就是用来暂存客户端发送的请求命令的，所以可能导致溢出的情况主要是下面两种：\n\n * 写入了 bigkey，比如一下子写入了多个百万级别的集合类型数据；\n * 服务器端处理请求的速度过慢，例如，Redis 主线程出现了间歇性阻塞，无法及时处理正常发送的请求，导致客户端发送的请求在缓冲区越积越多。\n\n接下来将探讨如何查看输入缓冲区的内存使用情况、如何避免溢出这两个问题。\n\n----------------------------------------\n\n如何查看输入缓冲区的内存使用情况？这可以使用 CLIENT LIST 命令：\n\nCLIENT LIST\nid=5 addr=127.0.0.1:50487 fd=9 name= age=4 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=26 qbuf-free=32742 obl=0 oll=0 omem=0 events=r cmd=client\n\n\n1\n2\n\n\n我们只需要重点关注其中的两类信息：\n\n * 一类是与服务器端连接的客户端的信息。这个案例展示的是一个客户端的输入缓冲区情况，如果有多个客户端，输出结果中的addr会显示不同客户端的IP和端口号。\n * 另一类是与输入缓冲区相关的三个参数：\n   * cmd，表示客户端最新执行的命令。这个例子中执行的是CLIENT命令。\n   * qbuf，表示输入缓冲区已经使用的大小。这个例子中的CLIENT命令已使用了26字节大小的缓冲区。\n   * qbuf-free，表示输入缓冲区尚未使用的大小。这个例子中的CLIENT命令还可以使用32742字节的缓冲区。qbuf和qbuf-free的总和就是，Redis服务器端当前为已连接的这个客户端分配的缓冲区总大小。这个例子中总共分配了 26 + 32742 = 32768字节，也就是32KB的缓冲区。\n\n有了CLIENT LIST命令，我们就可以通过输出结果来判断客户端输入缓冲区的内存占用情况了。如果qbuf很大，而同时qbuf-free很小，就要引起注意了，因为这时候输入缓冲区已经占用了很多内存，而且没有什么空闲空间了。此时，客户端再写入大量命令的话，就会引起客户端输入缓冲区溢出，Redis的处理办法就是把客户端连接关闭，结果就是业务程序无法进行数据存取了。\n\n通常情况下，Redis服务器端不止服务一个客户端，当多个客户端连接占用的内存总量，超过了Redis的maxmemory配置项时（例如4GB），就会触发Redis进行数据淘汰。一旦数据被淘汰出Redis，再要访问这部分数据，就需要去后端数据库读取，这就降低了业务应用的访问性能。此外，更糟糕的是，如果使用多个客户端，导致Redis内存占用过大，也会导致内存溢出（out-of-memory）问题，进而会引起Redis崩溃，给业务应用造成严重影响。\n\nRedis的客户端输入缓冲区大小的上限阈值，在代码中就设定为了1GB。也就是说，Redis服务器端允许为每个客户端最多暂存1GB的命令和数据。1GB的大小，对于一般的生产环境已经是比较合适的了。一方面，这个大小对于处理绝大部分客户端的请求已经够用了；另一方面，如果再大的话，Redis就有可能因为客户端占用了过多的内存资源而崩溃。所以，Redis并没有提供参数让我们调节客户端输入缓冲区的大小。如果要避免输入缓冲区溢出，那我们就只能从数据命令的发送和处理速度入手，也就是前面提到的避免客户端写入bigkey，以及避免Redis主线程阻塞。\n\n# 2.1.2 如何应对输出缓冲区溢出？\n\nRedis 的输出缓冲区暂存的是 Redis 主线程要返回给客户端的数据。一般来说，主线程返回给客户端的数据，既有简单且大小固定的 OK 响应（例如，执行 SET 命令）或报错信息，也有大小不固定的、包含具体数据的执行结果（例如，执行 HGET 命令）。\n\n因此，Redis 为每个客户端设置的输出缓冲区也包括两部分：一部分，是一个大小为 16KB 的固定缓冲空间，用来暂存 OK 响应和出错信息；另一部分，是一个可以动态增加的缓冲空间，用来暂存大小可变的响应结果。\n\n有三种情况可能发生输出缓冲区溢出：\n\n * 服务器端返回 bigkey 的大量结果；\n * 执行了 MONITOR 命令；\n * 缓冲区大小设置得不合理。\n\nMONITOR 命令执行后会持续输出监测到的各个命令操作，其输出结果会占用输出缓冲区，从而可能发生溢出。因此，MONITOR 命令主要用在调试环境中，不要在线上生产环境下持续使用 MONITOR。\n\n接下来，我们看下输出缓冲区大小设置的问题。和输入缓冲区不同，我们可以通过client-output-buffer-limit配置项，来设置缓冲区的大小。具体设置的内容包括两方面：\n\n * 设置缓冲区大小的上限阈值；\n * 设置输出缓冲区持续写入数据的数量上限阈值，和持续写入数据的时间的上限阈值。\n\n在具体使用client-output-buffer-limit来设置缓冲区大小的时候，我们需要先区分下客户端的类型。\n\n主要分两大类：\n\n * 对于和Redis实例进行交互的应用程序来说，主要使用两类客户端和Redis服务器端交互：\n   * 常规和Redis服务器端进行读写命令交互的普通客户端\n   * 订阅了Redis频道的订阅客户端\n * 在Redis主从集群中：\n   * 主节点上也有一类客户端（从节点客户端）用来和从节点进行数据同步。会在介绍主从集群中的缓冲区时，具体介绍。\n\n当我们给普通客户端设置缓冲区大小时，通常可以在Redis配置文件中进行这样的设置：\n\nclient-output-buffer-limit normal 0 0 0\n\n\n1\n\n\n其中，normal 表示当前设置的是普通客户端，第1个0设置的是缓冲区大小限制，第2个0和第3个0分别表示缓冲区持续写入量限制和持续写入时间限制。\n\n对于普通客户端来说，它每发送完一个请求，会等到请求结果返回后，再发送下一个请求，这种发送方式称为阻塞式发送。在这种情况下，如果不是读取体量特别大的bigkey，服务器端的输出缓冲区一般不会被阻塞的。\n\n所以，我们通常把普通客户端的缓冲区大小限制，以及持续写入量限制、持续写入时间限制都设置为0，也就是不做限制。\n\n对于订阅客户端来说，一旦订阅的Redis频道有消息了，服务器端都会通过输出缓冲区把消息发给客户端。所以，订阅客户端和服务器间的消息发送方式，不属于阻塞式发送。不过，如果频道消息较多的话，也会占用较多的输出缓冲区空间。\n\n因此，我们会给订阅客户端设置缓冲区大小限制、缓冲区持续写入量限制，以及持续写入时间限制，可以在Redis配置文件中这样设置：\n\nclient-output-buffer-limit pubsub 8mb 2mb 60\n\n\n1\n\n\n其中，pubsub参数表示当前是对订阅客户端进行设置；8mb表示输出缓冲区的大小上限为8MB，一旦实际占用的缓冲区大小要超过8MB，服务器端就会直接关闭客户端的连接；2mb和60表示，如果连续60秒内对输出缓冲区的写入量超过2MB的话，服务器端也会关闭客户端连接。\n\n> 好像 Redis 对缓冲区快要溢出的问题，最后的解决办法就是：直接关闭客户端的连接，以绝后患...\n\n好了，我们来总结下如何应对输出缓冲区溢出：\n\n * 避免bigkey操作返回大量数据结果；\n * 避免在线上环境中持续使用MONITOR命令。\n * 使用client-output-buffer-limit设置合理的缓冲区大小上限，或是缓冲区连续写入时间和写入量上限。\n\n以上就是关于客户端缓冲区，我们要重点掌握的内容了。我们继续看看在主从集群间使用缓冲区，需要注意什么问题。\n\n\n# 2.2 主从集群中的缓冲区\n\n主从集群间的数据复制包括全量复制和增量复制两种。全量复制是同步所有数据，而增量复制只会把主从库网络断连期间主库收到的命令，同步给从库。无论在哪种形式的复制中，为了保证主从节点的数据一致，都会用到缓冲区。但是，这两种复制场景下的缓冲区，在溢出影响和大小设置方面并不一样。所以，我们分别来学习下吧。\n\n# 2.2.1 全量复制期间--复制缓冲区的溢出问题\n\n在全量复制过程中，主节点在向从节点传输RDB文件的同时，会继续接收客户端发送的写命令请求。这些写命令就会先保存在复制缓冲区中，等RDB文件传输完成后，再发送给从节点去执行。主节点上会为每个从节点都维护一个复制缓冲区，来保证主从节点间的数据同步。\n\n所以，如果在全量复制时，从节点接收和加载RDB较慢，同时主节点接收到了大量的写命令，写命令在复制缓冲区中就会越积越多，最终导致溢出。\n\n其实，主节点上的复制缓冲区，本质上也是一个用于和从节点连接的客户端（我们称之为从节点客户端），使用的输出缓冲区。复制缓冲区一旦发生溢出，主节点也会直接关闭和从节点进行复制操作的连接，导致全量复制失败。那如何避免复制缓冲区发生溢出呢？\n\n一方面，我们可以控制主节点保存的数据量大小。按通常的使用经验，我们会把主节点的数据量控制在2~4GB，这样可以让全量同步执行得更快些，避免复制缓冲区累积过多命令。\n\n另一方面，我们可以使用client-output-buffer-limit配置项，来设置合理的复制缓冲区大小。设置的依据，就是主节点的数据量大小、主节点的写负载压力和主节点本身的内存大小。\n\n我们通过一个具体的例子，来学习下具体怎么设置。在主节点执行如下命令：\n\nconfig set client-output-buffer-limit slave 512mb 128mb 60\n\n\n1\n\n\n其中，slave参数表明该配置项是针对复制缓冲区的。512mb代表将缓冲区大小的上限设置为512MB；128mb和60代表的设置是，如果连续60秒内的写入量超过128MB的话，也会触发缓冲区溢出。\n\n我们再继续看看这个设置对我们有啥用。假设一条写命令数据是1KB，那么，复制缓冲区可以累积512K条（512MB/1KB = 512K）写命令。同时，主节点在全量复制期间，可以承受的写命令速率上限是2000条/s（128MB/1KB/60 约等于2000）。\n\n这样一来，我们就得到了一种方法：在实际应用中设置复制缓冲区的大小时，可以根据写命令数据的大小和应用的实际负载情况（也就是写命令速率），来粗略估计缓冲区中会累积的写命令数据量；然后，再和所设置的复制缓冲区大小进行比较，判断设置的缓冲区大小是否足够支撑累积的写命令数据量。\n\n关于复制缓冲区，我们还会遇到一个问题。主节点上复制缓冲区的内存开销，会是每个从节点客户端输出缓冲区占用内存的总和。如果集群中的从节点数非常多的话，主节点的内存开销就会非常大。所以，我们还必须得控制和主节点连接的从节点个数，不要使用大规模的主从集群。\n\n好了，我们先总结一下这部分的内容。为了避免复制缓冲区累积过多命令造成溢出，引发全量复制失败，我们可以控制主节点保存的数据量大小，并设置合理的复制缓冲区大小。同时，我们需要控制从节点的数量，来避免主节点中复制缓冲区占用过多内存的问题。\n\n# 2.2.2 增量复制期间--复制积压缓冲区的溢出问题\n\n接下来，我们再来看下增量复制时使用的缓冲区，这个缓冲区称为复制积压缓冲区。\n\n主节点在把接收到的写命令同步给从节点时，同时会把这些写命令写入复制积压缓冲区。一旦从节点发生网络闪断，再次和主节点恢复连接后，从节点就会从复制积压缓冲区中，读取断连期间主节点接收到的写命令，进而进行增量同步，如下图所示：\n\n之前也有讲过这个复制积压缓冲区，只不过当时称之为 repl_backlog_buffer。这里将从缓冲区溢出的角度再来回顾下两个重点：复制积压缓冲区溢出的影响，以及如何应对复制积压缓冲区的溢出问题。\n\n * 首先，复制积压缓冲区是一个大小有限的环形缓冲区。当主节点把复制积压缓冲区写满后，会覆盖缓冲区中的旧命令数据。如果从节点还没有同步这些旧命令数据，就会造成主从节点间重新开始执行全量复制。\n\n * 其次，为了应对复制积压缓冲区的溢出问题，我们可以调整复制积压缓冲区的大小，也就是设置repl_backlog_size这个参数的值。具体的调整依据，你可以再看下第6讲中提供的repl_backlog_size大小的计算依据。\n\n\n# 2.3 小结\n\n这一大节主要讲了 Redis 中所使用的缓冲区，使用缓冲区以后，当命令数据的接收方处理速度跟不上发送方的发送速度时，缓冲区可以避免命令数据的丢失。\n\n我们总共将缓冲区分成了四个：\n\n * 客户端的输入缓冲区\n * 客户端的输出缓冲区\n * 主从集群中主节点上的复制缓冲区\n * 主从集群中主节点上的复制积压缓冲区\n\n从缓冲区溢出对Redis的影响的角度，可以将这四个缓冲分成如下两类：\n\n * 缓冲区溢出导致网络连接关闭：普通客户端、订阅客户端，以及从节点客户端，它们使用的缓冲区，本质上都是Redis客户端和服务器端之间，或是主从节点之间为了传输命令数据而维护的。这些缓冲区一旦发生溢出，处理机制都是直接把客户端和服务器端的连接，或是主从节点间的连接关闭。网络连接关闭造成的直接影响，就是业务程序无法读写Redis，或者是主从节点全量同步失败，需要重新执行。\n * 缓冲区溢出导致命令数据丢失：主节点上的复制积压缓冲区属于环形缓冲区，一旦发生溢出，新写入的命令数据就会覆盖旧的命令数据，导致旧命令数据的丢失，进而导致主从节点重新进行全量复制。\n\n从本质上看，缓冲区溢出，无非就是三个原因：命令数据发送过快过大；命令数据处理较慢；缓冲区空间过小。明白了这个，我们就可以有针对性地拿出应对策略了：\n\n * 针对命令数据发送过快过大的问题，对于普通客户端来说可以避免bigkey，而对于复制缓冲区来说，就是避免过大的RDB文件。\n * 针对命令数据处理较慢的问题，解决方案就是减少Redis主线程上的阻塞操作，例如使用异步的删除操作。\n * 针对缓冲区空间过小的问题，解决方案就是使用client-output-buffer-limit配置项设置合理的输出缓冲区、复制缓冲区和复制积压缓冲区大小。当然，我们不要忘了，输入缓冲区的大小默认是固定的，我们无法通过配置来修改它，除非直接去修改Redis源码。\n\n有了上面这些应对方法，我相信你在实际应用时，就可以避免缓冲区溢出带来的命令数据丢失、Redis崩溃的这些“惨案”了。",normalizedContent:"> 参考：\n> \n>  * 20 删除数据后，为什么内存占用率还是很高？| 极客时间\n>  * 21 缓冲区：一个可能引发“惨案”的地方 | 极客时间\n\nredis 因其高性能而被广泛应用，我们需要避免性能异常的情况出现。影响 redis 性能的 5 大方面因素有：\n\n * redis 内部的阻塞式操作\n * cpu 核和 numa 架构的影响\n * redis 关键系统配置\n * redis 内存碎片\n * redis 缓冲区\n\n前面两篇文章分别分析了第一二个和第三个因素，本文分析第四、五个因素。\n\n\n# 1. redis 的内存碎片问题\n\n使用 redis 时经常会遇到这样一个问题：明明做了数据删除，数据量已经不大了，为什么使用top命令查看时，还会发现redis占用了很多内存呢？实际上，这是因为，当数据删除后，redis 释放的内存空间会由内存分配器管理，并不会立即返回给操作系统。所以，操作系统仍然会记录着给redis分配了大量内存。\n\n但是，这往往会伴随一个潜在的风险点：redis 释放的内存空间可能并不是连续的，那么，这些不连续的内存空间很有可能处于一种闲置的状态。这就会导致一个问题：虽然有空闲空间，redis却无法用来保存数据，不仅会减少redis能够实际保存的数据量，还会降低redis运行机器的成本回报率。\n\n这一节将讨论一下 redis 的内存空间存储效率问题，探索一下，为什么数据已经删除了，但内存却闲置着没有用，以及相应的解决方案。\n\n\n# 1.1 什么是内存碎片？\n\n通常情况下，内存空间闲置，往往是因为操作系统发生了较为严重的内存碎片，导致无法继续分配一块连续空间。\n\n内存碎片：内存中还有 5kb 的空余，但都是零散在不同地方，无法满足“申请一块连续 2kb 空间”的要求。\n\n类似于3个人想买连着的火车票，但此时车上只有不连续的三个空座位，因此就换趟车了。\n\n\n# 1.2 内存碎片是如何形成的？\n\n其实，内存碎片的形成有内因和外因两个层面的原因。简单来说，内因是操作系统的内存分配机制，外因是 redis 的负载特征。\n\n# 1.2.1 内因：内存分配器的分配策略\n\n内存分配器的分配策略就决定了操作系统无法做到“按需分配”。这是因为，内存分配器一般是按固定大小来分配内存，而不是完全按照应用程序申请的内存空间大小给程序分配。\n\nredis可以使用libc、jemalloc、tcmalloc多种内存分配器来分配内存，默认使用jemalloc。接下来，我就以jemalloc为例，来具体解释一下。其他分配器也存在类似的问题。\n\njemalloc的分配策略之一，是按照一系列固定的大小划分内存空间，例如8字节、16字节、32字节、48字节，…, 2kb、4kb、8kb等。当程序申请的内存最接近某个固定值时，jemalloc会给它分配相应大小的空间。\n\n这样的分配方式本身是为了减少分配次数。例如，redis申请一个20字节的空间保存数据，jemalloc就会分配32字节，此时，如果应用还要写入10字节的数据，redis就不用再向操作系统申请空间了，因为刚才分配的32字节已经够用了，这就避免了一次分配操作。\n\n但是，如果 redis 每次向分配器申请的内存空间大小不一样，这种分配方式就会有形成碎片的风险，而这正好来源于 redis 的外因了。\n\n# 1.2.2 外因：键值对大小不一样和删改操作\n\n第一个外因：\n\nredis 通常作为共用的缓存系统或键值数据库对外提供服务，所以，不同业务应用的数据都可能保存在 redis 中，这就会带来不同大小的键值对。但内存分配器只能按固定大小分配内存，所以，分配的内存空间一般都会比申请的空间大一些，不会完全一致，这本身就会造成一定的碎片，降低内存空间存储效率。\n\n第二个外因：\n\n第二个外因是，这些键值对会被修改和删除，这会导致空间的扩容和释放。具体来说，一方面，如果修改后的键值对变大或变小了，就需要占用额外的空间或者释放不用的空间。另一方面，删除的键值对就不再需要内存空间了，此时，就会把空间释放出来，形成空闲空间。\n\n但这样频繁操作后，会形成很多碎片空间，它们不是连续的，导致难以被利用。如下图：\n\n----------------------------------------\n\n好了，到这里，我们就知道了造成内存碎片的内外因素，其中，内存分配器策略是内因，而redis的负载属于外因，包括了大小不一的键值对和键值对修改删除带来的内存空间变化。\n\n大量内存碎片的存在，会造成 redis 的内存实际利用率变低，接下来，我们就要来解决这个问题了。不过，在解决问题前，我们要先判断 redis 运行过程中是否存在内存碎片。\n\n\n# 1.3 如何判断是否有内存碎片？\n\n为了让用户能监控到实时的内存使用情况，redis 自身提供了 info 命令，可以用来查询内存使用的详细信息，命令如下：\n\ninfo memory\n# memory\nused_memory:1073741736\nused_memory_human:1024.00m\nused_memory_rss:1997159792\nused_memory_rss_human:1.86g\n…\nmem_fragmentation_ratio:1.86\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n这里有一个 mem_fragmentation_ratio 的指标，它表示的就是 redis 当前的内存碎片率。那么，这个碎片率是怎么计算的呢？其实，就是上面的命令中的两个指标used_memory_rss和used_memory相除的结果：\n\nmem_fragmentation_ratio = used_memory_rss/ used_memory\n\n\n1\n\n * used_memory_rss 是操作系统实际分配给redis的物理内存空间，里面就包含了碎片；\n * used_memory 是 redis 为了保存数据实际申请使用的空间。\n\n这个指标如何使用呢？这里有一些经验阈值：\n\n * mem_fragmentation_ratio 大于 1 但小于 1.5。这种情况是合理的。这是因为，刚才我介绍的那些因素是难以避免的。毕竟，内因的内存分配器是一定要使用的，分配策略都是通用的，不会轻易修改；而外因由redis负载决定，也无法限制。所以，存在内存碎片也是正常的。\n * mem_fragmentation_ratio 大于 1.5 。这表明内存碎片率已经超过了50%。一般情况下，这个时候，我们就需要采取一些措施来降低内存碎片率了。\n\n\n# 1.4 如何清理内存碎片？\n\n# 1.4.1 重启 redis 的方法\n\n当 redis 发生内存碎片后，一个“简单粗暴”的方法就是重启redis实例。当然，这并不是一个“优雅”的方法，毕竟，重启 redis 会带来两个后果：\n\n * 如果 redis 中的数据没有持久化，那么，数据就会丢失；\n * 即使 redis 数据持久化了，我们还需要通过 aof 或 rdb 进行恢复，恢复时长取决于 aof 或 rdb 的大小，如果只有一个 redis 实例，恢复阶段无法提供服务。\n\n# 1.4.2 内存碎片自动清理的方法\n\n所以，还有什么其他好办法吗？幸运的是，从 4.0-rc3 版本以后，redis 自身提供了一种内存碎片自动清理的方法，我们先来看这个方法的基本机制：“搬家让位，合并空间”，用一张图来解释就是：\n\n以刚刚的高铁的例子来看，就是三个人买了不在一起的车票，上车之后和别人调换作为，坐在了一起。\n\n当然，如果数据拷贝后，并没有形成连续的内存空间，这就不能算是清理了。\n\n不过需要注意：碎片清理是有代价的，操作系统需要把多份数据拷贝到新位置，把原有空间释放出来，这会带来时间开销，会阻塞 redis 的线程。\n\n有什么办法可以尽量缓解这个问题吗？这就要提到 redis 专门为自动内存碎片清理机制设置的参数了。我们可以通过设置参数，来控制碎片清理的开始和结束时机，以及占用的cpu比例，从而减少碎片清理对 redis 本身请求处理的性能影响。\n\n# 1.4.3 内存碎片自动清理的相关参数\n\n首先，redis 需要启用自动内存碎片清理，可以把 activedefrag 配置项设置为 yes，命令如下：\n\nconfig set activedefrag yes\n\n\n1\n\n\n这个命令只是启用了自动清理功能，但是，具体什么时候清理，会受到下面这两个参数的控制。这两个参数分别设置了触发内存清理的一个条件，如果同时满足这两个条件，就开始清理。在清理的过程中，只要有一个条件不满足了，就停止自动清理：\n\n * active-defrag-ignore-bytes 100mb：表示内存碎片的字节数达到100mb时，开始清理；\n * active-defrag-threshold-lower 10：表示内存碎片空间占操作系统分配给redis的总空间比例达到10%时，开始清理。\n\n为了尽可能减少碎片清理对 redis 正常请求处理的影响，自动内存碎片清理功能在执行时，还会监控清理操作占用的 cpu 时间，而且还设置了两个参数，分别用于控制清理操作占用的cpu时间比例的上、下限，既保证清理工作能正常进行，又避免了降低 redis 性能。这两个参数具体如下：\n\n * active-defrag-cycle-min 25： 表示自动清理过程所用cpu时间的比例不低于25%，保证清理能正常开展；\n * active-defrag-cycle-max 75：表示自动清理过程所用cpu时间的比例不高于75%，一旦超过，就停止清理，从而避免在清理时，大量的内存拷贝阻塞redis，导致响应延迟升高。\n\n自动内存碎片清理机制在控制碎片清理启停的时机上，既考虑了碎片的空间占比、对 redis 内存使用效率的影响，还考虑了清理机制本身的 cpu 时间占比、对 redis 性能的影响。而且，清理机制还提供了 4 个参数，让我们可以根据实际应用中的数据量需求和性能要求灵活使用，建议你在实践中好好地把这个机制用起来。\n\n\n# 1.5 小结\n\n这一大节主要了解了 redis 的内存空间效率问题，这里面的一个关键技术点就是要识别和处理内存碎片：\n\n * info memory 命令是一个好工具，可以帮助你查看碎片率的情况；\n * 碎片率阈值是一个好经验，可以帮忙你有效地判断是否要进行碎片清理了；\n * 内存碎片自动清理是一个好方法，可以避免因为碎片导致 redis 的内存实际利用率降低，提升成本收益率。\n\n内存碎片并不可怕，我们要做的就是了解它，重视它，并借用高效的方法解决它。\n\n最后，我再给你提供一个小贴士：内存碎片自动清理涉及内存拷贝，这对redis而言，是个潜在的风险。如果你在实践过程中遇到redis性能变慢，记得通过日志看下是否正在进行碎片清理。如果redis的确正在清理碎片，那么，我建议你调小active-defrag-cycle-max的值，以减轻对正常请求处理的影响。\n\n\n# 2. 缓冲区：一个可能引发“惨案”的地方\n\n缓冲区的功能其实很简单，主要就是用一块内存空间来暂时存放命令数据，以免出现因为数据和命令的处理速度慢于发送速度而导致的数据丢失和性能问题。但因为缓冲区的内存空间有限，如果往里面写入数据的速度持续地大于从里面读取数据的速度，就会导致缓冲区需要越来越多的内存来暂存数据。当缓冲区占用的内存超出了设定的上限阈值时，就会出现缓冲区溢出。如果发生了溢出，就会丢数据了。\n\n> 可以不给缓冲区的大小设置上限吗？显然不行，随着累积的数据越来越多，缓冲区占用内存空间越来越大，一旦耗尽了redis实例所在机器的可用内存，就会导致redis实例崩溃。 所以毫不夸张地说，缓冲区是用来避免请求或数据丢失的惨案的，但也只有用对了，才能真正起到“避免”的作用。\n\nredis 的两个应用场景：\n\n * 在 client 和 server 进行通信时，用来暂存客户端发送的命令数据，或者是服务器端返回给客户端的数据结果。\n * 在主从节点间进行数据同步时，用来暂存主节点接收的写命令和数据。\n\n这一大节将分别聊聊服务器端和客户端、主从集群间的缓冲区溢出问题，以及应对方案。\n\n\n# 2.1 客户端的输入和输出缓冲区\n\n我们先来看看服务器端和客户端之间的缓冲区。\n\n为了避免客户端和服务器端的请求发送和处理速度不匹配，服务器端给每个连接的客户端都设置了一个输入缓冲区和输出缓冲区，我们称之为客户端输入缓冲区和输出缓冲区。\n\n输入缓冲区会先把客户端发送过来的命令暂存起来，redis主线程再从输入缓冲区中读取命令，进行处理。当redis主线程处理完数据后，会把结果写入到输出缓冲区，再通过输出缓冲区返回给客户端，如下图所示：\n\n下面，我们就分别学习下输入缓冲区和输出缓冲区发生溢出的情况，以及相应的应对方案。\n\n# 2.1.1 如何应对输入缓冲区溢出？\n\n输入缓冲区就是用来暂存客户端发送的请求命令的，所以可能导致溢出的情况主要是下面两种：\n\n * 写入了 bigkey，比如一下子写入了多个百万级别的集合类型数据；\n * 服务器端处理请求的速度过慢，例如，redis 主线程出现了间歇性阻塞，无法及时处理正常发送的请求，导致客户端发送的请求在缓冲区越积越多。\n\n接下来将探讨如何查看输入缓冲区的内存使用情况、如何避免溢出这两个问题。\n\n----------------------------------------\n\n如何查看输入缓冲区的内存使用情况？这可以使用 client list 命令：\n\nclient list\nid=5 addr=127.0.0.1:50487 fd=9 name= age=4 idle=0 flags=n db=0 sub=0 psub=0 multi=-1 qbuf=26 qbuf-free=32742 obl=0 oll=0 omem=0 events=r cmd=client\n\n\n1\n2\n\n\n我们只需要重点关注其中的两类信息：\n\n * 一类是与服务器端连接的客户端的信息。这个案例展示的是一个客户端的输入缓冲区情况，如果有多个客户端，输出结果中的addr会显示不同客户端的ip和端口号。\n * 另一类是与输入缓冲区相关的三个参数：\n   * cmd，表示客户端最新执行的命令。这个例子中执行的是client命令。\n   * qbuf，表示输入缓冲区已经使用的大小。这个例子中的client命令已使用了26字节大小的缓冲区。\n   * qbuf-free，表示输入缓冲区尚未使用的大小。这个例子中的client命令还可以使用32742字节的缓冲区。qbuf和qbuf-free的总和就是，redis服务器端当前为已连接的这个客户端分配的缓冲区总大小。这个例子中总共分配了 26 + 32742 = 32768字节，也就是32kb的缓冲区。\n\n有了client list命令，我们就可以通过输出结果来判断客户端输入缓冲区的内存占用情况了。如果qbuf很大，而同时qbuf-free很小，就要引起注意了，因为这时候输入缓冲区已经占用了很多内存，而且没有什么空闲空间了。此时，客户端再写入大量命令的话，就会引起客户端输入缓冲区溢出，redis的处理办法就是把客户端连接关闭，结果就是业务程序无法进行数据存取了。\n\n通常情况下，redis服务器端不止服务一个客户端，当多个客户端连接占用的内存总量，超过了redis的maxmemory配置项时（例如4gb），就会触发redis进行数据淘汰。一旦数据被淘汰出redis，再要访问这部分数据，就需要去后端数据库读取，这就降低了业务应用的访问性能。此外，更糟糕的是，如果使用多个客户端，导致redis内存占用过大，也会导致内存溢出（out-of-memory）问题，进而会引起redis崩溃，给业务应用造成严重影响。\n\nredis的客户端输入缓冲区大小的上限阈值，在代码中就设定为了1gb。也就是说，redis服务器端允许为每个客户端最多暂存1gb的命令和数据。1gb的大小，对于一般的生产环境已经是比较合适的了。一方面，这个大小对于处理绝大部分客户端的请求已经够用了；另一方面，如果再大的话，redis就有可能因为客户端占用了过多的内存资源而崩溃。所以，redis并没有提供参数让我们调节客户端输入缓冲区的大小。如果要避免输入缓冲区溢出，那我们就只能从数据命令的发送和处理速度入手，也就是前面提到的避免客户端写入bigkey，以及避免redis主线程阻塞。\n\n# 2.1.2 如何应对输出缓冲区溢出？\n\nredis 的输出缓冲区暂存的是 redis 主线程要返回给客户端的数据。一般来说，主线程返回给客户端的数据，既有简单且大小固定的 ok 响应（例如，执行 set 命令）或报错信息，也有大小不固定的、包含具体数据的执行结果（例如，执行 hget 命令）。\n\n因此，redis 为每个客户端设置的输出缓冲区也包括两部分：一部分，是一个大小为 16kb 的固定缓冲空间，用来暂存 ok 响应和出错信息；另一部分，是一个可以动态增加的缓冲空间，用来暂存大小可变的响应结果。\n\n有三种情况可能发生输出缓冲区溢出：\n\n * 服务器端返回 bigkey 的大量结果；\n * 执行了 monitor 命令；\n * 缓冲区大小设置得不合理。\n\nmonitor 命令执行后会持续输出监测到的各个命令操作，其输出结果会占用输出缓冲区，从而可能发生溢出。因此，monitor 命令主要用在调试环境中，不要在线上生产环境下持续使用 monitor。\n\n接下来，我们看下输出缓冲区大小设置的问题。和输入缓冲区不同，我们可以通过client-output-buffer-limit配置项，来设置缓冲区的大小。具体设置的内容包括两方面：\n\n * 设置缓冲区大小的上限阈值；\n * 设置输出缓冲区持续写入数据的数量上限阈值，和持续写入数据的时间的上限阈值。\n\n在具体使用client-output-buffer-limit来设置缓冲区大小的时候，我们需要先区分下客户端的类型。\n\n主要分两大类：\n\n * 对于和redis实例进行交互的应用程序来说，主要使用两类客户端和redis服务器端交互：\n   * 常规和redis服务器端进行读写命令交互的普通客户端\n   * 订阅了redis频道的订阅客户端\n * 在redis主从集群中：\n   * 主节点上也有一类客户端（从节点客户端）用来和从节点进行数据同步。会在介绍主从集群中的缓冲区时，具体介绍。\n\n当我们给普通客户端设置缓冲区大小时，通常可以在redis配置文件中进行这样的设置：\n\nclient-output-buffer-limit normal 0 0 0\n\n\n1\n\n\n其中，normal 表示当前设置的是普通客户端，第1个0设置的是缓冲区大小限制，第2个0和第3个0分别表示缓冲区持续写入量限制和持续写入时间限制。\n\n对于普通客户端来说，它每发送完一个请求，会等到请求结果返回后，再发送下一个请求，这种发送方式称为阻塞式发送。在这种情况下，如果不是读取体量特别大的bigkey，服务器端的输出缓冲区一般不会被阻塞的。\n\n所以，我们通常把普通客户端的缓冲区大小限制，以及持续写入量限制、持续写入时间限制都设置为0，也就是不做限制。\n\n对于订阅客户端来说，一旦订阅的redis频道有消息了，服务器端都会通过输出缓冲区把消息发给客户端。所以，订阅客户端和服务器间的消息发送方式，不属于阻塞式发送。不过，如果频道消息较多的话，也会占用较多的输出缓冲区空间。\n\n因此，我们会给订阅客户端设置缓冲区大小限制、缓冲区持续写入量限制，以及持续写入时间限制，可以在redis配置文件中这样设置：\n\nclient-output-buffer-limit pubsub 8mb 2mb 60\n\n\n1\n\n\n其中，pubsub参数表示当前是对订阅客户端进行设置；8mb表示输出缓冲区的大小上限为8mb，一旦实际占用的缓冲区大小要超过8mb，服务器端就会直接关闭客户端的连接；2mb和60表示，如果连续60秒内对输出缓冲区的写入量超过2mb的话，服务器端也会关闭客户端连接。\n\n> 好像 redis 对缓冲区快要溢出的问题，最后的解决办法就是：直接关闭客户端的连接，以绝后患...\n\n好了，我们来总结下如何应对输出缓冲区溢出：\n\n * 避免bigkey操作返回大量数据结果；\n * 避免在线上环境中持续使用monitor命令。\n * 使用client-output-buffer-limit设置合理的缓冲区大小上限，或是缓冲区连续写入时间和写入量上限。\n\n以上就是关于客户端缓冲区，我们要重点掌握的内容了。我们继续看看在主从集群间使用缓冲区，需要注意什么问题。\n\n\n# 2.2 主从集群中的缓冲区\n\n主从集群间的数据复制包括全量复制和增量复制两种。全量复制是同步所有数据，而增量复制只会把主从库网络断连期间主库收到的命令，同步给从库。无论在哪种形式的复制中，为了保证主从节点的数据一致，都会用到缓冲区。但是，这两种复制场景下的缓冲区，在溢出影响和大小设置方面并不一样。所以，我们分别来学习下吧。\n\n# 2.2.1 全量复制期间--复制缓冲区的溢出问题\n\n在全量复制过程中，主节点在向从节点传输rdb文件的同时，会继续接收客户端发送的写命令请求。这些写命令就会先保存在复制缓冲区中，等rdb文件传输完成后，再发送给从节点去执行。主节点上会为每个从节点都维护一个复制缓冲区，来保证主从节点间的数据同步。\n\n所以，如果在全量复制时，从节点接收和加载rdb较慢，同时主节点接收到了大量的写命令，写命令在复制缓冲区中就会越积越多，最终导致溢出。\n\n其实，主节点上的复制缓冲区，本质上也是一个用于和从节点连接的客户端（我们称之为从节点客户端），使用的输出缓冲区。复制缓冲区一旦发生溢出，主节点也会直接关闭和从节点进行复制操作的连接，导致全量复制失败。那如何避免复制缓冲区发生溢出呢？\n\n一方面，我们可以控制主节点保存的数据量大小。按通常的使用经验，我们会把主节点的数据量控制在2~4gb，这样可以让全量同步执行得更快些，避免复制缓冲区累积过多命令。\n\n另一方面，我们可以使用client-output-buffer-limit配置项，来设置合理的复制缓冲区大小。设置的依据，就是主节点的数据量大小、主节点的写负载压力和主节点本身的内存大小。\n\n我们通过一个具体的例子，来学习下具体怎么设置。在主节点执行如下命令：\n\nconfig set client-output-buffer-limit slave 512mb 128mb 60\n\n\n1\n\n\n其中，slave参数表明该配置项是针对复制缓冲区的。512mb代表将缓冲区大小的上限设置为512mb；128mb和60代表的设置是，如果连续60秒内的写入量超过128mb的话，也会触发缓冲区溢出。\n\n我们再继续看看这个设置对我们有啥用。假设一条写命令数据是1kb，那么，复制缓冲区可以累积512k条（512mb/1kb = 512k）写命令。同时，主节点在全量复制期间，可以承受的写命令速率上限是2000条/s（128mb/1kb/60 约等于2000）。\n\n这样一来，我们就得到了一种方法：在实际应用中设置复制缓冲区的大小时，可以根据写命令数据的大小和应用的实际负载情况（也就是写命令速率），来粗略估计缓冲区中会累积的写命令数据量；然后，再和所设置的复制缓冲区大小进行比较，判断设置的缓冲区大小是否足够支撑累积的写命令数据量。\n\n关于复制缓冲区，我们还会遇到一个问题。主节点上复制缓冲区的内存开销，会是每个从节点客户端输出缓冲区占用内存的总和。如果集群中的从节点数非常多的话，主节点的内存开销就会非常大。所以，我们还必须得控制和主节点连接的从节点个数，不要使用大规模的主从集群。\n\n好了，我们先总结一下这部分的内容。为了避免复制缓冲区累积过多命令造成溢出，引发全量复制失败，我们可以控制主节点保存的数据量大小，并设置合理的复制缓冲区大小。同时，我们需要控制从节点的数量，来避免主节点中复制缓冲区占用过多内存的问题。\n\n# 2.2.2 增量复制期间--复制积压缓冲区的溢出问题\n\n接下来，我们再来看下增量复制时使用的缓冲区，这个缓冲区称为复制积压缓冲区。\n\n主节点在把接收到的写命令同步给从节点时，同时会把这些写命令写入复制积压缓冲区。一旦从节点发生网络闪断，再次和主节点恢复连接后，从节点就会从复制积压缓冲区中，读取断连期间主节点接收到的写命令，进而进行增量同步，如下图所示：\n\n之前也有讲过这个复制积压缓冲区，只不过当时称之为 repl_backlog_buffer。这里将从缓冲区溢出的角度再来回顾下两个重点：复制积压缓冲区溢出的影响，以及如何应对复制积压缓冲区的溢出问题。\n\n * 首先，复制积压缓冲区是一个大小有限的环形缓冲区。当主节点把复制积压缓冲区写满后，会覆盖缓冲区中的旧命令数据。如果从节点还没有同步这些旧命令数据，就会造成主从节点间重新开始执行全量复制。\n\n * 其次，为了应对复制积压缓冲区的溢出问题，我们可以调整复制积压缓冲区的大小，也就是设置repl_backlog_size这个参数的值。具体的调整依据，你可以再看下第6讲中提供的repl_backlog_size大小的计算依据。\n\n\n# 2.3 小结\n\n这一大节主要讲了 redis 中所使用的缓冲区，使用缓冲区以后，当命令数据的接收方处理速度跟不上发送方的发送速度时，缓冲区可以避免命令数据的丢失。\n\n我们总共将缓冲区分成了四个：\n\n * 客户端的输入缓冲区\n * 客户端的输出缓冲区\n * 主从集群中主节点上的复制缓冲区\n * 主从集群中主节点上的复制积压缓冲区\n\n从缓冲区溢出对redis的影响的角度，可以将这四个缓冲分成如下两类：\n\n * 缓冲区溢出导致网络连接关闭：普通客户端、订阅客户端，以及从节点客户端，它们使用的缓冲区，本质上都是redis客户端和服务器端之间，或是主从节点之间为了传输命令数据而维护的。这些缓冲区一旦发生溢出，处理机制都是直接把客户端和服务器端的连接，或是主从节点间的连接关闭。网络连接关闭造成的直接影响，就是业务程序无法读写redis，或者是主从节点全量同步失败，需要重新执行。\n * 缓冲区溢出导致命令数据丢失：主节点上的复制积压缓冲区属于环形缓冲区，一旦发生溢出，新写入的命令数据就会覆盖旧的命令数据，导致旧命令数据的丢失，进而导致主从节点重新进行全量复制。\n\n从本质上看，缓冲区溢出，无非就是三个原因：命令数据发送过快过大；命令数据处理较慢；缓冲区空间过小。明白了这个，我们就可以有针对性地拿出应对策略了：\n\n * 针对命令数据发送过快过大的问题，对于普通客户端来说可以避免bigkey，而对于复制缓冲区来说，就是避免过大的rdb文件。\n * 针对命令数据处理较慢的问题，解决方案就是减少redis主线程上的阻塞操作，例如使用异步的删除操作。\n * 针对缓冲区空间过小的问题，解决方案就是使用client-output-buffer-limit配置项设置合理的输出缓冲区、复制缓冲区和复制积压缓冲区大小。当然，我们不要忘了，输入缓冲区的大小默认是固定的，我们无法通过配置来修改它，除非直接去修改redis源码。\n\n有了上面这些应对方法，我相信你在实际应用时，就可以避免缓冲区溢出带来的命令数据丢失、redis崩溃的这些“惨案”了。",charsets:{cjk:!0},lastUpdated:"2023/04/10, 13:35:58",lastUpdatedTimestamp:1681133758e3},{title:"Redis 用作缓存",frontmatter:{title:"Redis 用作缓存",date:"2023-04-10T22:18:22.000Z",permalink:"/pages/d403e5/",categories:["中间件","Redis","专栏：Redis 核心技术与实战"],tags:[null]},regularPath:"/%E4%B8%AD%E9%97%B4%E4%BB%B6/05.Redis/05.%E4%B8%93%E6%A0%8F%EF%BC%9ARedis%20%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/23.Redis%20%E7%94%A8%E4%BD%9C%E7%BC%93%E5%AD%98.html",relativePath:"中间件/05.Redis/05.专栏：Redis 核心技术与实战/23.Redis 用作缓存.md",key:"v-29b8baff",path:"/pages/d403e5/",headers:[{level:2,title:"1. 旁路缓存：Redis 是如何工作的？",slug:"_1-旁路缓存-redis-是如何工作的",normalizedTitle:"1. 旁路缓存：redis 是如何工作的？",charIndex:347},{level:3,title:"1.1 缓存的特征",slug:"_1-1-缓存的特征",normalizedTitle:"1.1 缓存的特征",charIndex:423},{level:3,title:"1.2 Redis 缓存处理请求的两种情况",slug:"_1-2-redis-缓存处理请求的两种情况",normalizedTitle:"1.2 redis 缓存处理请求的两种情况",charIndex:854},{level:3,title:"1.3 Redis 作为旁路缓存的使用操作",slug:"_1-3-redis-作为旁路缓存的使用操作",normalizedTitle:"1.3 redis 作为旁路缓存的使用操作",charIndex:1181},{level:3,title:"1.4 缓存的类型",slug:"_1-4-缓存的类型",normalizedTitle:"1.4 缓存的类型",charIndex:2486},{level:4,title:"1.4.1 只读缓存",slug:"_1-4-1-只读缓存",normalizedTitle:"1.4.1 只读缓存",charIndex:2525},{level:4,title:"1.4.2 读写缓存",slug:"_1-4-2-读写缓存",normalizedTitle:"1.4.2 读写缓存",charIndex:2888},{level:2,title:"2. 替换策略：缓存满了怎么办？",slug:"_2-替换策略-缓存满了怎么办",normalizedTitle:"2. 替换策略：缓存满了怎么办？",charIndex:3490},{level:3,title:"2.1 设置多大的缓存容量合适？",slug:"_2-1-设置多大的缓存容量合适",normalizedTitle:"2.1 设置多大的缓存容量合适？",charIndex:3638},{level:3,title:"2.2 Redis 缓存有哪些淘汰策略？",slug:"_2-2-redis-缓存有哪些淘汰策略",normalizedTitle:"2.2 redis 缓存有哪些淘汰策略？",charIndex:4191},{level:3,title:"2.3 如何处理被淘汰的数据？",slug:"_2-3-如何处理被淘汰的数据",normalizedTitle:"2.3 如何处理被淘汰的数据？",charIndex:6373}],headersStr:"1. 旁路缓存：Redis 是如何工作的？ 1.1 缓存的特征 1.2 Redis 缓存处理请求的两种情况 1.3 Redis 作为旁路缓存的使用操作 1.4 缓存的类型 1.4.1 只读缓存 1.4.2 读写缓存 2. 替换策略：缓存满了怎么办？ 2.1 设置多大的缓存容量合适？ 2.2 Redis 缓存有哪些淘汰策略？ 2.3 如何处理被淘汰的数据？",content:"> 参考：\n> \n>  * 23 旁路缓存：Redis 是如何工作的？| 极客时间\n>  * 24 替换策略：缓存满了怎么办？| 极客时间\n\n由于 Redis 提供了高性能的数据存取功能，因此被广泛应用到缓存的场景中，这可以有效提升业务的响应速度，同时避免把压力累积到数据库层面。\n\n掌握缓存需要解决四个关键问题：\n\n * Redis 缓存具体是怎么工作的？(工作原理)\n * Redis 缓存如果满了，该怎么办？(替换策略)\n * 为什么会有缓存一致性、缓存穿透、缓存雪崩、缓存击穿等异常，该如何应对？(异常处理机制)\n * Redis 的内存毕竟有限，如果用快速的固态硬盘来保存数据，可以增加缓存的数据量，那 Redis 缓存可以使用快速固态硬盘吗？(扩展机制)\n\n下面分别介绍。\n\n\n# 1. 旁路缓存：Redis 是如何工作的？\n\n这一大节主要了解下缓存的特征和Redis适用于缓存的天然优势，以及Redis缓存的具体工作机制。\n\n\n# 1.1 缓存的特征\n\n计算机系统中，默认有两种缓存：\n\n * CPU里面的末级缓存，即LLC，用来缓存内存中的数据，避免每次从内存中存取数据；\n * 内存中的高速页缓存，即page cache，用来缓存磁盘中的数据，避免每次从磁盘中存取数据。\n\n具体如下图所示：\n\nLLC的大小是MB级别，page cache的大小是GB级别，而磁盘的大小是TB级别。\n\n缓存的第一个特征：在一个层次化的系统中，缓存一定是一个快速子系统，数据存在缓存中时，能避免每次从慢速子系统中存取数据。对应到互联网应用来说，Redis 就是快速子系统，而数据库就是慢速子系统了。\n\n缓存的第二个特征：缓存系统的容量大小总是小于后端慢速系统的，我们不可能把所有数据都放在缓存系统中。因此缓存和慢速系统之间必然存在数据写回和再读取的交互过程。这你可能会想到 Redis 本身是支持按一定规则淘汰数据的，相当于实现了缓存的数据淘汰，其实，这也是 Redis 适合用作缓存的一个重要原因。\n\n\n# 1.2 Redis 缓存处理请求的两种情况\n\n把 Redis 用作缓存时，我们会把 Redis 部署在数据库的前端，业务应用在访问数据时，会先查询 Redis 中是否保存了相应的数据。此时，根据数据是否存在缓存中，会有两种情况：\n\n * 缓存命中\n * 缓存缺失：这时需要进行缓存更新，这涉及到数据一致性的问题（会在后文讲述）\n\n由此，使用 Redis 作为缓存主要有三个操作：\n\n * 应用读取数据时，需要先读取 Redis；\n * 发生缓存缺失时，需要从数据库读取数据；\n * 发生缓存缺失时，还需要更新缓存。\n\n那么，这些操作具体是由谁来做的呢？这和Redis缓存的使用方式相关。接下来就和你聊聊 Redis 作为旁路缓存的使用操作方式。\n\n\n# 1.3 Redis 作为旁路缓存的使用操作\n\nRedis是一个独立的系统软件，和业务应用程序是两个软件，当我们部署了Redis实例后，它只会被动地等待客户端发送请求，然后再进行处理。所以， 如果应用程序想要使用 Redis 缓存，我们就要在程序中增加相应的缓存操作代码，所以也把 Redis 称为旁路缓存，也就是说，读取缓存、读取数据库和更新缓存的操作都需要在应用程序中来完成。\n\n> 这种旁路缓存与计算机系统中的缓存不太一样，比如计算机系统中的 page cache 并不需要你去显示调用它的 GET 接口等，而是计算机直接将这些缓存放在了程序的数据访问路径上并直接使用。\n\n在使用 Redis 作为缓存时，我们需要在应用程序中增加三方面的代码：\n\n * 当应用程序需要读取数据时，我们需要在代码中显式调用 Redis 的 GET 操作接口，进行查询；\n * 如果缓存缺失了，应用程序需要再和数据库连接，从数据库中读取数据；\n * 当缓存中的数据需要更新时，我们也需要在应用程序中显式地调用 SET 操作接口，把更新的数据写入缓存。\n\n下面是一段在 Web 应用中使用 Redis 缓存的伪代码示例：\n\nString cacheKey = “productid_11010003”;\nString cacheValue = redisCache.get(cacheKey)；\n//缓存命中\nif (cacheValue != NULL)\n   return cacheValue;\n//缓存缺失\nelse\n   cacheValue = getProductFromDB();\n   redisCache.put(cacheValue)  //缓存更新\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n可以看到，为了使用缓存，Web 应用程序需要有一个表示缓存系统的实例对象 redisCache，还需要主动调用 GET 接口，并且要处理缓存命中和缓存缺失时的逻辑，例如在缓存缺失时，需要更新缓存。\n\nRedis并不适用于那些无法获得源码的应用，因为需要新增程序代码来使用缓存。例如一些很早之前开发的应用程序，它们的源码已经没有再维护了，或者是第三方供应商开发的应用，没有提供源码，所以，就不能使用Redis做缓存了。\n\n在使用旁路缓存时，我们需要在应用程序中增加操作代码，增加了使用Redis缓存的额外工作量，但是，也正因为Redis是旁路缓存，是一个独立的系统，我们可以单独对Redis缓存进行扩容或性能优化。而且，只要保持操作接口不变，我们在应用程序中增加的代码就不用再修改了。\n\n应用程序除了读取数据外，还可能对数据进行修改。这时我们既可以在缓存中修改，也可以在后端数据库中进行修改，我们该怎么选择呢？\n\n其实，这就涉及到了Redis缓存的两种类型：\n\n * 只读缓存能加速读请求\n * 读写缓存可以同时加速读写请求。\n\n而且，读写缓存又有两种数据写回策略，可以让我们根据业务需求，在保证性能和保证数据可靠性之间进行选择。所以，接下来，我们来具体了解下 Redis 的缓存类型和相应的写回策略。\n\n\n# 1.4 缓存的类型\n\n按照是否接受写请求，可以分成只读缓存和读写缓存。\n\n# 1.4.1 只读缓存\n\n当Redis用作只读缓存时，应用要读取数据的话，会先调用 Redis GET 接口，查询数据是否存在。而所有的数据写请求，会直接发往后端的数据库，在数据库中增删改。对于删改的数据来说，如果 Redis 已经缓存了相应的数据，应用需要把这些缓存的数据删除，Redis 中就没有这些数据了。\n\n当应用再次读取这些数据时，会发生缓存缺失，应用会把这些数据从数据库中读出来，并写到缓存中。这样一来，这些数据后续再被读取时，就可以直接从缓存中获取了，能起到加速访问的效果。\n\n下图展示了应用修改数据 A 后再次访问 A 的过程：\n\n只读缓存直接在数据库中更新数据的好处是，所有最新的数据都在数据库中，这些数据不会有丢失的风险。当我们需要缓存图片、短视频这些用户只读的数据时，就可以使用只读缓存这个类型了。\n\n# 1.4.2 读写缓存\n\n对于读写缓存来说，除了读请求会发送到缓存进行处理，所有的写请求也会发送到缓存，在缓存中直接对数据进行增删改操作。得益于 Redis 的高性能访问特性，数据的增删改操作可以在缓存中快速完成，处理结果也会快速返回给业务应用，这就可以提升业务应用的响应速度。\n\n但是，和只读缓存不一样的是，在使用读写缓存时，最新的数据是在Redis中，而Redis是内存数据库，一旦出现掉电或宕机，内存中的数据就会丢失。这也就是说，应用的最新数据可能会丢失，给应用业务带来风险。\n\n根据业务应用对数据可靠性和缓存性能的不同要求，有同步直写和异步写回两种策略，如下图所示：\n\n * 同步直写策略优先保证数据可靠性，会降低访问性能\n * 异步写回策略优先提供快速响应，有数据丢失风险\n\n关于是选择只读缓存，还是读写缓存，主要看我们对写请求是否有加速的需求：\n\n * 如果需要对写请求进行加速，我们选择读写缓存；\n * 如果写请求很少，或者是只需要提升读请求的响应速度的话，我们选择只读缓存。\n\n> 举个例子，在商品大促的场景中，商品的库存信息会一直被修改。如果每次修改都需到数据库中处理，就会拖慢整个应用，此时，我们通常会选择读写缓存的模式。而在短视频App的场景中，虽然视频的属性有很多，但是，一般确定后，修改并不频繁，此时，在数据库中进行修改对缓存影响不大，所以只读缓存模式是一个合适的选择。\n\n\n# 2. 替换策略：缓存满了怎么办？\n\n缓存空间有限，这就涉及到了缓存系统的一个重要机制：缓存替换机制。简单来说，数据淘汰机制包括两步：\n\n 1. 根据一定的策略，筛选出对应用访问来说“不重要”的数据；\n 2. 将这些数据从缓存中删除，为新来的数据腾出空间\n\n这一节将主要探讨缓存替换策略。\n\n\n# 2.1 设置多大的缓存容量合适？\n\n缓存容量的设置会直接影响到缓存的性价比。\n\n由于局部性原理，往往一部分数据就支撑了巨大的访问量。如下图：\n\n * 蓝线表示“二八原理”，即20%的数据贡献了80%的访问，而剩余的数据虽然体量很大，但只贡献了20%的访问量。这80%的数据在访问量上就形成了一条长长的尾巴，我们也称为长尾效应。\n * 但实际中随着用户的个性化需求越来越多，不同用户访问的内容可能差别很大，导致可能不再具备二八原理分布特征了，也就是说，20%的数据可能贡献不了80%的访问，而剩余的80%数据反而贡献了更多的访问量，我们称之为重尾效应。\n\n因此，缓存的容量规划不能一概而论，是需要结合应用数据实际访问特征和成本开销来综合考虑的，这里也存在 trade-off。\n\n一般，建议把缓存容量设置为总数据量的15%到30%，兼顾访问性能和内存空间开销。\n\n对于 Redis 来说，一旦确定了缓存最大容量，比如 4GB，你就可以使用下面这个命令来设定缓存的大小了：\n\nCONFIG SET maxmemory 4gb\n\n\n1\n\n\n不过，缓存被写满是不可避免的，所以需要缓存替换。缓存替换需要解决两个问题：决定淘汰哪些数据，如何处理那些被淘汰的数据。接下来就讨论 Redis 中的数据淘汰策略。\n\n\n# 2.2 Redis 缓存有哪些淘汰策略？\n\nRedis 4.0 之后一共有 8 种内存淘汰策略，总结如下图：\n\n默认情况下是 noeviction 策略：Redis 在使用的内存空间超过 maxmemory 值时，并不会淘汰数据，再有写请求的话直接返回错误。因此不把这种方式用到 Redis 缓存中。\n\n我们再分析下 volatile-random、volatile-ttl、volatile-lru 和 volatile-lfu 这四种淘汰策略。它们筛选的候选数据范围，被限制在已经设置了过期时间的键值对上。也正因为此，即使缓存没有写满，这些数据如果过期了，也会被删除。例如，我们使用 EXPIRE 命令对一批键值对设置了过期时间后，无论是这些键值对的过期时间是快到了，还是 Redis 的内存使用量达到了 maxmemory 阈值，Redis 都会进一步按照 volatile-ttl、volatile-random、volatile-lru、volatile-lfu 这四种策略的具体筛选规则进行淘汰：\n\n * volatile-ttl 在筛选时，会针对设置了过期时间的键值对，根据过期时间的先后进行删除，越早过期的越先被删除。\n * volatile-random 就像它的名称一样，在设置了过期时间的键值对中，进行随机删除。\n * volatile-lru 会使用 LRU 算法筛选设置了过期时间的键值对。\n * volatile-lfu 会使用 LFU 算法选择设置了过期时间的键值对。\n\nallkeys-lru、allkeys-random、allkeys-lfu这三种淘汰策略的备选淘汰数据范围，就扩大到了所有键值对，无论这些键值对是否设置了过期时间。它们筛选数据进行淘汰的规则是：\n\n * allkeys-random 策略，从所有键值对中随机选择并删除数据；\n * allkeys-lru 策略，使用 LRU 算法在所有数据中进行筛选。\n * allkeys-lfu 策略，使用 LFU 算法在所有数据中进行筛选。\n\n这也就是说，如果一个键值对被删除策略选中了，即使它的过期时间还没到，也需要被删除。当然，如果它的过期时间到了但未被策略选中，同样也会被删除。\n\n> LRU和LFU都是内存管理的页面置换算法。\n> \n>  * LRU：最近最少使用(最长时间)淘汰算法（Least Recently Used）。LRU是淘汰最长时间没有被使用的页面。\n>  * LFU：最不经常使用(最少次)淘汰算法（Least Frequently Used）。LFU是淘汰一段时间内，使用次数最少的页面。\n\n关于 LRU 算法：\n\n筛选最不常用数据的方法：把所有的数据组织成一个链表，链表的头和尾分别表示MRU端和LRU端，分别代表最近最常使用的数据和最近最不常用的数据。具体如下图：\n\n但是如上方法由于使用链表管理所有的缓存数据，会带来额外的空间开销，且有大量数据被访问时，需要在链表上移动大量数据，很耗时，降低 Redis 缓存性能。\n\nRedis 中，LRU 算法被做了简化，以减轻数据淘汰对缓存性能的影响。具体来说，Redis默认会记录每个数据的最近一次访问的时间戳（由键值对数据结构RedisObject中的lru字段记录）。然后，Redis在决定淘汰的数据时，第一次会随机选出N个数据，把它们作为一个候选集合。接下来，Redis会比较这N个数据的lru字段，把lru字段值最小的数据从缓存中淘汰出去。\n\nRedis提供了一个配置参数maxmemory-samples，这个参数就是Redis选出的数据个数N。例如，我们执行如下命令，可以让Redis选出100个数据作为候选数据集：\n\nCONFIG SET maxmemory-samples 100\n\n\n1\n\n\n当需要再次淘汰数据时，Redis需要挑选数据进入第一次淘汰时创建的候选集合。这儿的挑选标准是： 能进入候选集合的数据的lru字段值必须小于候选集合中最小的lru值。当有新数据进入候选数据集后，如果候选数据集中的数据个数达到了maxmemory-samples，Redis就把候选数据集中lru字段值最小的数据淘汰出去。\n\n这样一来，Redis缓存不用为所有的数据维护一个大链表，也不用在每次数据访问时都移动链表项，提升了缓存的性能。\n\n关于缓存淘汰策略的选取，有如下建议：\n\n * 优先使用 allkeys-lru 策略。这样可以充分利用 LRU 这一经典缓存算法的优势，把最近最常访问的数据留在缓存中，提升应用的访问性能。如果你的业务数据中有明显的冷热数据区分，我建议你使用 allkeys-lru 策略。\n * 如果业务应用中的数据访问频率相差不大，没有明显的冷热数据区分，建议使用allkeys-random策略，随机选择淘汰的数据就行。\n * 如果你的业务中有置顶的需求，比如置顶新闻、置顶视频，那么，可以使用 volatile-lru 策略，同时不给这些置顶数据设置过期时间。这样一来，这些需要置顶的数据一直不会被删除，而其他数据会在过期时根据 LRU 规则进行筛选。\n\n一旦被淘汰的数据被选定后，Redis 怎么处理这些数据呢？这就要说到缓存替换时的具体操作了。\n\n\n# 2.3 如何处理被淘汰的数据？\n\n一般来说，一旦被淘汰的数据选定后，如果这个数据是干净数据，那么我们就直接删除；如果这个数据是脏数据，我们需要把它写回数据库，如下图所示：\n\n * 干净数据：取出来后就没改过\n * 脏数据：和后端数据库不一致了\n\n不过，对于Redis来说，它决定了被淘汰的数据后，会把它们删除。即使淘汰的数据是脏数据，Redis 也不会把它们写回数据库。所以，我们在使用 Redis 缓存时，如果数据被修改了，需要在数据修改时就将它写回数据库。否则，这个脏数据被淘汰时，会被 Redis 删除，而数据库里也没有最新的数据了。",normalizedContent:"> 参考：\n> \n>  * 23 旁路缓存：redis 是如何工作的？| 极客时间\n>  * 24 替换策略：缓存满了怎么办？| 极客时间\n\n由于 redis 提供了高性能的数据存取功能，因此被广泛应用到缓存的场景中，这可以有效提升业务的响应速度，同时避免把压力累积到数据库层面。\n\n掌握缓存需要解决四个关键问题：\n\n * redis 缓存具体是怎么工作的？(工作原理)\n * redis 缓存如果满了，该怎么办？(替换策略)\n * 为什么会有缓存一致性、缓存穿透、缓存雪崩、缓存击穿等异常，该如何应对？(异常处理机制)\n * redis 的内存毕竟有限，如果用快速的固态硬盘来保存数据，可以增加缓存的数据量，那 redis 缓存可以使用快速固态硬盘吗？(扩展机制)\n\n下面分别介绍。\n\n\n# 1. 旁路缓存：redis 是如何工作的？\n\n这一大节主要了解下缓存的特征和redis适用于缓存的天然优势，以及redis缓存的具体工作机制。\n\n\n# 1.1 缓存的特征\n\n计算机系统中，默认有两种缓存：\n\n * cpu里面的末级缓存，即llc，用来缓存内存中的数据，避免每次从内存中存取数据；\n * 内存中的高速页缓存，即page cache，用来缓存磁盘中的数据，避免每次从磁盘中存取数据。\n\n具体如下图所示：\n\nllc的大小是mb级别，page cache的大小是gb级别，而磁盘的大小是tb级别。\n\n缓存的第一个特征：在一个层次化的系统中，缓存一定是一个快速子系统，数据存在缓存中时，能避免每次从慢速子系统中存取数据。对应到互联网应用来说，redis 就是快速子系统，而数据库就是慢速子系统了。\n\n缓存的第二个特征：缓存系统的容量大小总是小于后端慢速系统的，我们不可能把所有数据都放在缓存系统中。因此缓存和慢速系统之间必然存在数据写回和再读取的交互过程。这你可能会想到 redis 本身是支持按一定规则淘汰数据的，相当于实现了缓存的数据淘汰，其实，这也是 redis 适合用作缓存的一个重要原因。\n\n\n# 1.2 redis 缓存处理请求的两种情况\n\n把 redis 用作缓存时，我们会把 redis 部署在数据库的前端，业务应用在访问数据时，会先查询 redis 中是否保存了相应的数据。此时，根据数据是否存在缓存中，会有两种情况：\n\n * 缓存命中\n * 缓存缺失：这时需要进行缓存更新，这涉及到数据一致性的问题（会在后文讲述）\n\n由此，使用 redis 作为缓存主要有三个操作：\n\n * 应用读取数据时，需要先读取 redis；\n * 发生缓存缺失时，需要从数据库读取数据；\n * 发生缓存缺失时，还需要更新缓存。\n\n那么，这些操作具体是由谁来做的呢？这和redis缓存的使用方式相关。接下来就和你聊聊 redis 作为旁路缓存的使用操作方式。\n\n\n# 1.3 redis 作为旁路缓存的使用操作\n\nredis是一个独立的系统软件，和业务应用程序是两个软件，当我们部署了redis实例后，它只会被动地等待客户端发送请求，然后再进行处理。所以， 如果应用程序想要使用 redis 缓存，我们就要在程序中增加相应的缓存操作代码，所以也把 redis 称为旁路缓存，也就是说，读取缓存、读取数据库和更新缓存的操作都需要在应用程序中来完成。\n\n> 这种旁路缓存与计算机系统中的缓存不太一样，比如计算机系统中的 page cache 并不需要你去显示调用它的 get 接口等，而是计算机直接将这些缓存放在了程序的数据访问路径上并直接使用。\n\n在使用 redis 作为缓存时，我们需要在应用程序中增加三方面的代码：\n\n * 当应用程序需要读取数据时，我们需要在代码中显式调用 redis 的 get 操作接口，进行查询；\n * 如果缓存缺失了，应用程序需要再和数据库连接，从数据库中读取数据；\n * 当缓存中的数据需要更新时，我们也需要在应用程序中显式地调用 set 操作接口，把更新的数据写入缓存。\n\n下面是一段在 web 应用中使用 redis 缓存的伪代码示例：\n\nstring cachekey = “productid_11010003”;\nstring cachevalue = rediscache.get(cachekey)；\n//缓存命中\nif (cachevalue != null)\n   return cachevalue;\n//缓存缺失\nelse\n   cachevalue = getproductfromdb();\n   rediscache.put(cachevalue)  //缓存更新\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n可以看到，为了使用缓存，web 应用程序需要有一个表示缓存系统的实例对象 rediscache，还需要主动调用 get 接口，并且要处理缓存命中和缓存缺失时的逻辑，例如在缓存缺失时，需要更新缓存。\n\nredis并不适用于那些无法获得源码的应用，因为需要新增程序代码来使用缓存。例如一些很早之前开发的应用程序，它们的源码已经没有再维护了，或者是第三方供应商开发的应用，没有提供源码，所以，就不能使用redis做缓存了。\n\n在使用旁路缓存时，我们需要在应用程序中增加操作代码，增加了使用redis缓存的额外工作量，但是，也正因为redis是旁路缓存，是一个独立的系统，我们可以单独对redis缓存进行扩容或性能优化。而且，只要保持操作接口不变，我们在应用程序中增加的代码就不用再修改了。\n\n应用程序除了读取数据外，还可能对数据进行修改。这时我们既可以在缓存中修改，也可以在后端数据库中进行修改，我们该怎么选择呢？\n\n其实，这就涉及到了redis缓存的两种类型：\n\n * 只读缓存能加速读请求\n * 读写缓存可以同时加速读写请求。\n\n而且，读写缓存又有两种数据写回策略，可以让我们根据业务需求，在保证性能和保证数据可靠性之间进行选择。所以，接下来，我们来具体了解下 redis 的缓存类型和相应的写回策略。\n\n\n# 1.4 缓存的类型\n\n按照是否接受写请求，可以分成只读缓存和读写缓存。\n\n# 1.4.1 只读缓存\n\n当redis用作只读缓存时，应用要读取数据的话，会先调用 redis get 接口，查询数据是否存在。而所有的数据写请求，会直接发往后端的数据库，在数据库中增删改。对于删改的数据来说，如果 redis 已经缓存了相应的数据，应用需要把这些缓存的数据删除，redis 中就没有这些数据了。\n\n当应用再次读取这些数据时，会发生缓存缺失，应用会把这些数据从数据库中读出来，并写到缓存中。这样一来，这些数据后续再被读取时，就可以直接从缓存中获取了，能起到加速访问的效果。\n\n下图展示了应用修改数据 a 后再次访问 a 的过程：\n\n只读缓存直接在数据库中更新数据的好处是，所有最新的数据都在数据库中，这些数据不会有丢失的风险。当我们需要缓存图片、短视频这些用户只读的数据时，就可以使用只读缓存这个类型了。\n\n# 1.4.2 读写缓存\n\n对于读写缓存来说，除了读请求会发送到缓存进行处理，所有的写请求也会发送到缓存，在缓存中直接对数据进行增删改操作。得益于 redis 的高性能访问特性，数据的增删改操作可以在缓存中快速完成，处理结果也会快速返回给业务应用，这就可以提升业务应用的响应速度。\n\n但是，和只读缓存不一样的是，在使用读写缓存时，最新的数据是在redis中，而redis是内存数据库，一旦出现掉电或宕机，内存中的数据就会丢失。这也就是说，应用的最新数据可能会丢失，给应用业务带来风险。\n\n根据业务应用对数据可靠性和缓存性能的不同要求，有同步直写和异步写回两种策略，如下图所示：\n\n * 同步直写策略优先保证数据可靠性，会降低访问性能\n * 异步写回策略优先提供快速响应，有数据丢失风险\n\n关于是选择只读缓存，还是读写缓存，主要看我们对写请求是否有加速的需求：\n\n * 如果需要对写请求进行加速，我们选择读写缓存；\n * 如果写请求很少，或者是只需要提升读请求的响应速度的话，我们选择只读缓存。\n\n> 举个例子，在商品大促的场景中，商品的库存信息会一直被修改。如果每次修改都需到数据库中处理，就会拖慢整个应用，此时，我们通常会选择读写缓存的模式。而在短视频app的场景中，虽然视频的属性有很多，但是，一般确定后，修改并不频繁，此时，在数据库中进行修改对缓存影响不大，所以只读缓存模式是一个合适的选择。\n\n\n# 2. 替换策略：缓存满了怎么办？\n\n缓存空间有限，这就涉及到了缓存系统的一个重要机制：缓存替换机制。简单来说，数据淘汰机制包括两步：\n\n 1. 根据一定的策略，筛选出对应用访问来说“不重要”的数据；\n 2. 将这些数据从缓存中删除，为新来的数据腾出空间\n\n这一节将主要探讨缓存替换策略。\n\n\n# 2.1 设置多大的缓存容量合适？\n\n缓存容量的设置会直接影响到缓存的性价比。\n\n由于局部性原理，往往一部分数据就支撑了巨大的访问量。如下图：\n\n * 蓝线表示“二八原理”，即20%的数据贡献了80%的访问，而剩余的数据虽然体量很大，但只贡献了20%的访问量。这80%的数据在访问量上就形成了一条长长的尾巴，我们也称为长尾效应。\n * 但实际中随着用户的个性化需求越来越多，不同用户访问的内容可能差别很大，导致可能不再具备二八原理分布特征了，也就是说，20%的数据可能贡献不了80%的访问，而剩余的80%数据反而贡献了更多的访问量，我们称之为重尾效应。\n\n因此，缓存的容量规划不能一概而论，是需要结合应用数据实际访问特征和成本开销来综合考虑的，这里也存在 trade-off。\n\n一般，建议把缓存容量设置为总数据量的15%到30%，兼顾访问性能和内存空间开销。\n\n对于 redis 来说，一旦确定了缓存最大容量，比如 4gb，你就可以使用下面这个命令来设定缓存的大小了：\n\nconfig set maxmemory 4gb\n\n\n1\n\n\n不过，缓存被写满是不可避免的，所以需要缓存替换。缓存替换需要解决两个问题：决定淘汰哪些数据，如何处理那些被淘汰的数据。接下来就讨论 redis 中的数据淘汰策略。\n\n\n# 2.2 redis 缓存有哪些淘汰策略？\n\nredis 4.0 之后一共有 8 种内存淘汰策略，总结如下图：\n\n默认情况下是 noeviction 策略：redis 在使用的内存空间超过 maxmemory 值时，并不会淘汰数据，再有写请求的话直接返回错误。因此不把这种方式用到 redis 缓存中。\n\n我们再分析下 volatile-random、volatile-ttl、volatile-lru 和 volatile-lfu 这四种淘汰策略。它们筛选的候选数据范围，被限制在已经设置了过期时间的键值对上。也正因为此，即使缓存没有写满，这些数据如果过期了，也会被删除。例如，我们使用 expire 命令对一批键值对设置了过期时间后，无论是这些键值对的过期时间是快到了，还是 redis 的内存使用量达到了 maxmemory 阈值，redis 都会进一步按照 volatile-ttl、volatile-random、volatile-lru、volatile-lfu 这四种策略的具体筛选规则进行淘汰：\n\n * volatile-ttl 在筛选时，会针对设置了过期时间的键值对，根据过期时间的先后进行删除，越早过期的越先被删除。\n * volatile-random 就像它的名称一样，在设置了过期时间的键值对中，进行随机删除。\n * volatile-lru 会使用 lru 算法筛选设置了过期时间的键值对。\n * volatile-lfu 会使用 lfu 算法选择设置了过期时间的键值对。\n\nallkeys-lru、allkeys-random、allkeys-lfu这三种淘汰策略的备选淘汰数据范围，就扩大到了所有键值对，无论这些键值对是否设置了过期时间。它们筛选数据进行淘汰的规则是：\n\n * allkeys-random 策略，从所有键值对中随机选择并删除数据；\n * allkeys-lru 策略，使用 lru 算法在所有数据中进行筛选。\n * allkeys-lfu 策略，使用 lfu 算法在所有数据中进行筛选。\n\n这也就是说，如果一个键值对被删除策略选中了，即使它的过期时间还没到，也需要被删除。当然，如果它的过期时间到了但未被策略选中，同样也会被删除。\n\n> lru和lfu都是内存管理的页面置换算法。\n> \n>  * lru：最近最少使用(最长时间)淘汰算法（least recently used）。lru是淘汰最长时间没有被使用的页面。\n>  * lfu：最不经常使用(最少次)淘汰算法（least frequently used）。lfu是淘汰一段时间内，使用次数最少的页面。\n\n关于 lru 算法：\n\n筛选最不常用数据的方法：把所有的数据组织成一个链表，链表的头和尾分别表示mru端和lru端，分别代表最近最常使用的数据和最近最不常用的数据。具体如下图：\n\n但是如上方法由于使用链表管理所有的缓存数据，会带来额外的空间开销，且有大量数据被访问时，需要在链表上移动大量数据，很耗时，降低 redis 缓存性能。\n\nredis 中，lru 算法被做了简化，以减轻数据淘汰对缓存性能的影响。具体来说，redis默认会记录每个数据的最近一次访问的时间戳（由键值对数据结构redisobject中的lru字段记录）。然后，redis在决定淘汰的数据时，第一次会随机选出n个数据，把它们作为一个候选集合。接下来，redis会比较这n个数据的lru字段，把lru字段值最小的数据从缓存中淘汰出去。\n\nredis提供了一个配置参数maxmemory-samples，这个参数就是redis选出的数据个数n。例如，我们执行如下命令，可以让redis选出100个数据作为候选数据集：\n\nconfig set maxmemory-samples 100\n\n\n1\n\n\n当需要再次淘汰数据时，redis需要挑选数据进入第一次淘汰时创建的候选集合。这儿的挑选标准是： 能进入候选集合的数据的lru字段值必须小于候选集合中最小的lru值。当有新数据进入候选数据集后，如果候选数据集中的数据个数达到了maxmemory-samples，redis就把候选数据集中lru字段值最小的数据淘汰出去。\n\n这样一来，redis缓存不用为所有的数据维护一个大链表，也不用在每次数据访问时都移动链表项，提升了缓存的性能。\n\n关于缓存淘汰策略的选取，有如下建议：\n\n * 优先使用 allkeys-lru 策略。这样可以充分利用 lru 这一经典缓存算法的优势，把最近最常访问的数据留在缓存中，提升应用的访问性能。如果你的业务数据中有明显的冷热数据区分，我建议你使用 allkeys-lru 策略。\n * 如果业务应用中的数据访问频率相差不大，没有明显的冷热数据区分，建议使用allkeys-random策略，随机选择淘汰的数据就行。\n * 如果你的业务中有置顶的需求，比如置顶新闻、置顶视频，那么，可以使用 volatile-lru 策略，同时不给这些置顶数据设置过期时间。这样一来，这些需要置顶的数据一直不会被删除，而其他数据会在过期时根据 lru 规则进行筛选。\n\n一旦被淘汰的数据被选定后，redis 怎么处理这些数据呢？这就要说到缓存替换时的具体操作了。\n\n\n# 2.3 如何处理被淘汰的数据？\n\n一般来说，一旦被淘汰的数据选定后，如果这个数据是干净数据，那么我们就直接删除；如果这个数据是脏数据，我们需要把它写回数据库，如下图所示：\n\n * 干净数据：取出来后就没改过\n * 脏数据：和后端数据库不一致了\n\n不过，对于redis来说，它决定了被淘汰的数据后，会把它们删除。即使淘汰的数据是脏数据，redis 也不会把它们写回数据库。所以，我们在使用 redis 缓存时，如果数据被修改了，需要在数据修改时就将它写回数据库。否则，这个脏数据被淘汰时，会被 redis 删除，而数据库里也没有最新的数据了。",charsets:{cjk:!0},lastUpdated:"2023/04/12, 03:21:35",lastUpdatedTimestamp:1681269695e3},{title:"Redis 用作缓存之缓存异常",frontmatter:{title:"Redis 用作缓存之缓存异常",date:"2023-04-11T22:22:14.000Z",permalink:"/pages/cbe81b/",categories:["中间件","Redis","专栏：Redis 核心技术与实战"],tags:[null]},regularPath:"/%E4%B8%AD%E9%97%B4%E4%BB%B6/05.Redis/05.%E4%B8%93%E6%A0%8F%EF%BC%9ARedis%20%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/25.Redis%20%E7%94%A8%E4%BD%9C%E7%BC%93%E5%AD%98%E4%B9%8B%E7%BC%93%E5%AD%98%E5%BC%82%E5%B8%B8.html",relativePath:"中间件/05.Redis/05.专栏：Redis 核心技术与实战/25.Redis 用作缓存之缓存异常.md",key:"v-2a85a268",path:"/pages/cbe81b/",headers:[{level:2,title:"3. 缓存异常（上）：如何解决缓存和数据库的数据不一致问题？",slug:"_3-缓存异常-上-如何解决缓存和数据库的数据不一致问题",normalizedTitle:"3. 缓存异常（上）：如何解决缓存和数据库的数据不一致问题？",charIndex:323},{level:3,title:"3.1 缓存和数据库的数据不一致是如何发生的？",slug:"_3-1-缓存和数据库的数据不一致是如何发生的",normalizedTitle:"3.1 缓存和数据库的数据不一致是如何发生的？",charIndex:436},{level:4,title:"1）新增数据",slug:"_1-新增数据",normalizedTitle:"1）新增数据",charIndex:1028},{level:4,title:"2）删改数据",slug:"_2-删改数据",normalizedTitle:"2）删改数据",charIndex:1104},{level:3,title:"3.2 如何解决数据不一致问题？",slug:"_3-2-如何解决数据不一致问题",normalizedTitle:"3.2 如何解决数据不一致问题？",charIndex:1312},{level:4,title:"3.2.1 重试机制",slug:"_3-2-1-重试机制",normalizedTitle:"3.2.1 重试机制",charIndex:1447},{level:4,title:"3.2.2 订阅 MySQL binlog，再操作缓存",slug:"_3-2-2-订阅-mysql-binlog-再操作缓存",normalizedTitle:"3.2.2 订阅 mysql binlog，再操作缓存",charIndex:1740},{level:4,title:"3.2.3 延迟双删",slug:"_3-2-3-延迟双删",normalizedTitle:"3.2.3 延迟双删",charIndex:2180},{level:3,title:"3.3 小结",slug:"_3-3-小结",normalizedTitle:"3.3 小结",charIndex:3392},{level:2,title:"4. 缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？",slug:"_4-缓存异常-下-如何解决缓存雪崩、击穿、穿透难题",normalizedTitle:"4. 缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？",charIndex:4157},{level:3,title:"4.1 缓存雪崩",slug:"_4-1-缓存雪崩",normalizedTitle:"4.1 缓存雪崩",charIndex:4267},{level:4,title:"4.1.1 原因一：大量数据同时过期",slug:"_4-1-1-原因一-大量数据同时过期",normalizedTitle:"4.1.1 原因一：大量数据同时过期",charIndex:4378},{level:4,title:"4.1.2 原因二：Redis 缓存实例发生宕机",slug:"_4-1-2-原因二-redis-缓存实例发生宕机",normalizedTitle:"4.1.2 原因二：redis 缓存实例发生宕机",charIndex:4965},{level:3,title:"4.2 缓存击穿",slug:"_4-2-缓存击穿",normalizedTitle:"4.2 缓存击穿",charIndex:6214},{level:3,title:"4.3 缓存穿透",slug:"_4-3-缓存穿透",normalizedTitle:"4.3 缓存穿透",charIndex:6535},{level:4,title:"1）方案 1：缓存空值或缺省值",slug:"_1-方案-1-缓存空值或缺省值",normalizedTitle:"1）方案 1：缓存空值或缺省值",charIndex:6839},{level:4,title:"2）方案 2：使用布隆过滤器快速判断数据是否存在，避免从数据库中查询数据是否存在，减轻数据库压力",slug:"_2-方案-2-使用布隆过滤器快速判断数据是否存在-避免从数据库中查询数据是否存在-减轻数据库压力",normalizedTitle:"2）方案 2：使用布隆过滤器快速判断数据是否存在，避免从数据库中查询数据是否存在，减轻数据库压力",charIndex:7005},{level:4,title:"3）方案 3：提前对请求进行合法性检测",slug:"_3-方案-3-提前对请求进行合法性检测",normalizedTitle:"3）方案 3：提前对请求进行合法性检测",charIndex:7830},{level:3,title:"4.4 小结",slug:"_4-4-小结",normalizedTitle:"4.4 小结",charIndex:8149}],headersStr:"3. 缓存异常（上）：如何解决缓存和数据库的数据不一致问题？ 3.1 缓存和数据库的数据不一致是如何发生的？ 1）新增数据 2）删改数据 3.2 如何解决数据不一致问题？ 3.2.1 重试机制 3.2.2 订阅 MySQL binlog，再操作缓存 3.2.3 延迟双删 3.3 小结 4. 缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？ 4.1 缓存雪崩 4.1.1 原因一：大量数据同时过期 4.1.2 原因二：Redis 缓存实例发生宕机 4.2 缓存击穿 4.3 缓存穿透 1）方案 1：缓存空值或缺省值 2）方案 2：使用布隆过滤器快速判断数据是否存在，避免从数据库中查询数据是否存在，减轻数据库压力 3）方案 3：提前对请求进行合法性检测 4.4 小结",content:"> 参考：\n> \n>  * 25 缓存异常（上）：如何解决缓存和数据库的数据不一致问题？| 极客时间\n>  * 26 缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？| 极客时间\n>  * 缓存数据一致性探究 | 阿里开发者\n\n掌握缓存需要解决四个关键问题：\n\n * Redis 缓存具体是怎么工作的？(工作原理)\n * Redis 缓存如果满了，该怎么办？(替换策略)\n * 为什么会有缓存一致性、缓存穿透、缓存雪崩、缓存击穿等异常，该如何应对？(异常处理机制)\n * Redis 的内存毕竟有限，如果用快速的固态硬盘来保存数据，可以增加缓存的数据量，那 Redis 缓存可以使用快速固态硬盘吗？(扩展机制)\n\n下面介绍第三个问题。\n\n\n# 3. 缓存异常（上）：如何解决缓存和数据库的数据不一致问题？\n\nRedis 用作缓存经常有一些异常问题，概括来说有 4 个方面：缓存中的数据和数据库中的不一致；缓存雪崩；缓存击穿和缓存穿透。这一节先看一下第一个问题。\n\n\n# 3.1 缓存和数据库的数据不一致是如何发生的？\n\n这里的数据的一致性其实包含两种情况：\n\n * 缓存中有数据，且与数据库中的相同\n * 缓存中本身没有数据，且数据库中是最新的\n\n不符合这两种情况的，就属于缓存和数据库的数据不一致问题了。当缓存的读写模式不同时，我们的应对方法也不一样。\n\n对于读写缓存来说，数据的 CRUD 要在缓存中进行，同时对原数据库进行写回：\n\n * 若想要保证缓存与数据库的数据一致，就要使用事务机制来使用同步直写策略来一块更新缓存和数据库，保证这俩的更新有原子性。\n * 若对一致性要求没有那么高，就可以使用异步写回策略。\n\n对于只读缓存来说，如果有数据新增，会直接写入数据库；而有数据删改时，就需要把只读缓存中的数据标记为无效。这样一来，应用后续再访问这些增删改的数据时，因为缓存中没有相应的数据，就会发生缓存缺失。此时，应用再从数据库中把数据读入缓存，这样后续再访问数据时，就能够直接从缓存中读取了。这个过程如下图所示：\n\n从图中可以看到，Tomcat上运行的应用，无论是新增（Insert操作）、修改（Update操作）、还是删除（Delete操作）数据X，都会直接在数据库中增改删。当然，如果应用执行的是修改或删除操作，还会删除缓存的数据X。\n\n那这个过程会不会出现数据不一致的情况呢？考虑到新增数据和删改数据的情况不一样，所以我们分开来看：\n\n# 1）新增数据\n\n如果是新增数据，数据会直接写到数据库中，不用对缓存做任何操作，此时，缓存中本身就没有新增数据，而数据库中是最新值，因此是一致的。\n\n# 2）删改数据\n\n此时就要选择是先更新原数据库的数据还是先删除缓存中的数据：\n\n * 如果先删缓存值：可能导致数据库更新失败。导致请求再次访问缓存时，发现缓存缺失，再读 DB 时，从其中读到旧值。\n * 如果先更新数据库的值：可能出现缓存删除失败。导致后续请求因再次缓存命中导致读取缓存旧值。\n\n可以看到，无论这两个操作的执行顺序谁先谁后，只要有一个操作失败了，就会导致客户端读取到旧值。如何解决这个问题呢？\n\n\n# 3.2 如何解决数据不一致问题？\n\n数据不一致出现的原因主要分为两种情况：\n\n * 对 DB/缓存 的操作，第二个失败了 解决方法：\n   * 重试机制\n   * 订阅 MySQL binlog，再操作缓存\n * 复杂的并发场景下，对数据库和缓存的操作都是成功的\n\n# 3.2.1 重试机制\n\n首先一种方法是：重试机制。\n\n具体来说，可以把要删除的缓存值或者是要更新的数据库值暂存到消息队列中（例如使用Kafka消息队列）。当应用没有能够成功地删除缓存值或者是更新数据库值时，可以从消息队列中重新读取这些值，然后再次进行删除或更新。\n\n如果能够成功地删除或更新，我们就要把这些值从消息队列中去除，以免重复操作，此时，我们也可以保证数据库和缓存的数据一致了。否则的话，我们还需要再次进行重试。如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。\n\n图显示了先更新数据库，再删除缓存值时，如果缓存删除失败，再次重试后删除成功的情况：\n\n# 3.2.2 订阅 MySQL binlog，再操作缓存\n\n「先更新数据库，再删缓存」的策略的第一步是更新数据库，那么更新数据库成功，就会产生一条变更日志，记录在 binlog 里。于是我们就可以通过订阅 binlog 日志，拿到具体要操作的数据，然后再执行缓存删除，阿里巴巴开源的 Canal 中间件就是基于这个实现的。\n\nCanal 模拟 MySQL 主从复制的交互协议，把自己伪装成一个 MySQL 的从节点，向 MySQL 主节点发送 dump 请求，MySQL 收到请求后，就会开始推送 Binlog 给 Canal，Canal 解析 Binlog 字节流之后，转换为便于读取的结构化数据，供下游程序订阅使用。\n\n下图是 Canal 的工作原理：\n\n所以，如果要想保证「先更新数据库，再删缓存」策略第二个操作能执行成功，我们可以使用「消息队列来重试缓存的删除」，或者「订阅 MySQL binlog 再操作缓存」，这两种方法有一个共同的特点，都是采用异步操作缓存。\n\n# 3.2.3 延迟双删\n\n刚刚说的是在更新数据库和删除缓存值的过程中，其中一个操作失败的情况，实际上，即使这两个操作第一次执行时都没有失败，当有大量并发请求时，应用还是有可能读到不一致的数据。\n\n同样，我们按照不同的删除和更新顺序，分成两种情况来看。在这两种情况下，我们的解决方法也有所不同。\n\n情况一：先删除缓存，再更新数据库：\n\n假设线程A删除缓存值后，还没有来得及更新数据库（比如说有网络延迟），线程B就开始读取数据了，那么这个时候，线程B会发现缓存缺失，就只能去数据库读取。这会带来两个问题：\n\n 1. 线程B读取到了旧值；\n 2. 线程B是在缓存缺失的情况下读取的数据库，所以，它还会把旧值写入缓存，这可能会导致其他线程从缓存中读到旧值。\n\n等到线程B从数据库读取完数据、更新了缓存后，线程A才开始更新数据库，此时，缓存中的数据是旧值，而数据库中的是最新值，两者就不一致了。这种情况用表格展示如下：\n\n这该怎么办？一种解决方案是：在线程A更新完数据库值以后，我们可以让它先sleep一小段时间，再进行一次缓存删除操作。\n\n之所以要加上sleep的这段时间，就是为了让线程B能够先从数据库读取数据，再把缺失的数据写入缓存，然后，线程A再进行删除。所以，线程A sleep的时间，就需要大于线程B读取数据再写入缓存的时间。这个时间怎么确定呢？建议你在业务程序运行的时候，统计下线程读数据和写缓存的操作时间，以此为基础来进行估算。\n\n这样一来，其它线程读取数据时，会发现缓存缺失，所以会从数据库中读取最新值。因为这个方案会在第一次删除缓存值后，延迟一段时间再次进行删除，所以我们也把它叫做延迟双删。下面是延迟双删的伪代码：\n\nredis.delKey(X)\ndb.update(X)\nThread.sleep(N)\nredis.delKey(X)\n\n\n1\n2\n3\n4\n\n\n情况二：先更新数据库值，再删除缓存值：\n\n如果线程A删除了数据库中的值，但还没来得及删除缓存值，线程B就开始读取数据了，那么此时，线程B查询缓存时，发现缓存命中，就会直接从缓存中读取旧值。不过，在这种情况下，如果其他线程并发读缓存的请求不多，那么，就不会有很多请求读取到旧值。而且，线程A一般也会很快删除缓存值，这样一来，其他线程再次读取时，就会发生缓存缺失，进而从数据库中读取最新值。所以，这种情况对业务的影响较小。\n\n这种情况用表格展示为：\n\n----------------------------------------\n\n到这里我们可以知道，缓存和数据库的数据不一致一般是由两个原因导致的，本节并提供了相应的解决方案：\n\n * 删除缓存值或更新数据库失败而导致数据不一致，你可以使用重试机制确保删除或更新操作成功。\n * 在删除缓存值、更新数据库的这两步操作中，有其他线程的并发读操作，导致其他线程读取到旧值，应对方案是延迟双删。\n\n\n# 3.3 小结\n\n这一大节讲了缓存不一致的问题，可以分成读写缓存和只读缓存两种情况分析。\n\n * 对于读写缓存，同步写回策略就可以保证缓存和数据库中的数据一致。\n * 对于只读缓存，可以总结为下面这张表：\n\n大多数业务中，我们是把 Redis 当做只读缓存来使用，并建议优先使用先更新数据库再删除缓存的方法(cache aside)，原因主要有两个：\n\n 1. 先删除缓存值再更新数据库，有可能导致请求因缓存缺失而访问数据库，给数据库带来压力；\n 2. 如果业务应用中读取数据库和写缓存的时间不好估算，那么，延迟双删中的等待时间就不好设置。\n\n不过，当使用先更新数据库再删除缓存时，也有个地方需要注意，如果业务层要求必须读取一致的数据，那么，我们就需要在更新数据库时，先在Redis缓存客户端暂存并发读请求，等数据库更新完、缓存值删除后，再读取数据，从而保证数据一致性。\n\n----------------------------------------\n\ncatch aside 可以被称之为缓存使用的最佳实践，但与此同时，它引入了缓存的命中率降低的问题，（每次都删除缓存自然导致更不容易命中了），因此它更适用于对缓存命中率要求并不是特别高的场景。如果要求较高的缓存命中率，依然需要采用更新数据库后同时更新缓存的方案。\n\n但是更新数据库后同时更新缓存的方案会在并发场景下出现数据不一致，解决方案有两种：\n\n * 引入分布式锁 在更新缓存之前尝试获取锁，如果已经被占用就先阻塞住线程，等待其他线程释放锁后再尝试更新。但这会影响并发操作的性能。\n * 设置较短缓存时间 设置较短的缓存过期时间能够使得数据不一致问题存在的时间也比较长，对业务的影响相对较小。但是与此同时，其实这也使得缓存命中率降低，又回到了前面的问题里...\n\n\n# 4. 缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？\n\n除了缓存不一致，还有三种可能的缓存异常：缓存雪崩、缓存击穿和缓存穿透。这三个问题一旦发生，会导致大量的请求积压到数据库层，从而导致数据库宕机或者故障。\n\n\n# 4.1 缓存雪崩\n\n缓存雪崩：指大量的应用请求无法在 Redis 缓存中进行处理，紧接着应用将大量请求发送到数据库层，导致数据库层的压力激增。\n\n缓存雪崩一般是由两个原因导致的，应对方案也有所不同，我们一个个来看。\n\n# 4.1.1 原因一：大量数据同时过期\n\n缓存雪崩的第一种原因：缓存中有大量数据同时过期，导致大量请求无法得到处理。\n\n具体来说，当数据保存在缓存中，并且设置了过期时间时，如果在某一个时刻，大量数据同时过期，此时，应用再访问这些数据的话，就会发生缓存缺失。紧接着，应用就会把请求发送给数据库，从数据库中读取数据。如果应用的并发请求量很大，那么数据库的压力也就很大，这会进一步影响到数据库的其他正常业务请求处理。我们来看一个简单的例子，如下图所示：\n\n针对大量数据同时失效带来的缓存雪崩问题，有两种解决方案：\n\n 1. 微调过期时间：业务避免给大量的数据设置相同的过期时间。如果业务层的确要求有些数据同时失效，你可以在用 EXPIRE 命令给每个数据设置过期时间时，给这些数据的过期时间增加一个较小的随机数。这样一来，不同数据的过期时间差别不会太大，既避免了大量数据同时过期，同时也保证了这些数据基本在相近的时间失效，仍然能满足业务需求。\n 2. 服务降级：指发生缓存雪崩时，针对不同的数据采取不同的处理方式：\n    * 当业务应用访问的是非核心数据（例如电商商品属性）时，暂时停止从缓存中查询这些数据，而是直接返回预定义信息、空值或是错误信息；\n    * 当业务应用访问的是核心数据（例如电商商品库存）时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取。\n\n# 4.1.2 原因二：Redis 缓存实例发生宕机\n\n缓存雪崩的第二种原因：Redis 缓存实例发生故障宕机了，无法处理请求，这就会导致大量请求一下子积压到数据库层，从而发生缓存雪崩。\n\n一般来说，一个 Redis 实例可以支持数万级别的请求处理吞吐量，而单个数据库可能只能支持数千级别的请求处理吞吐量，它们两个的处理能力可能相差了近十倍。由于缓存雪崩，Redis 缓存失效，所以，数据库就可能要承受近十倍的请求压力，从而因为压力过大而崩溃。\n\n这种情况下由于 Redis 实例发生了宕机，我们需要通过其他方法来应对缓存雪崩了。我给你提供两个建议：\n\n第一个建议：在业务系统中实现服务熔断或请求限流机制。\n\n所谓的服务熔断，是指在发生缓存雪崩时，为了防止引发连锁的数据库雪崩，甚至是整个系统的崩溃，我们暂停业务应用对缓存系统的接口访问，而是直接返回，等到Redis缓存实例重新恢复服务后，再允许应用请求发送到缓存系统。这样避免了大量请求因缓存缺失而积压到数据库系统。\n\n在业务系统运行时，我们可以监测 Redis 所在机器和数据库所在机器的负载指标，例如每秒请求数、CPU利用率、内存利用率等。如果我们发现 Redis 实例宕机了，而数据库所在机器的负载压力突然增加，此时就发生缓存雪崩了。大量请求被发送到数据库进行处理。我们可以启动服务熔断机制，暂停业务应用对缓存服务的访问，从而降低对数据库的访问压力，如下图所示：\n\n服务熔断虽然可以保证数据库的正常运行，但是暂停了整个缓存系统的访问，对业务应用的影响范围大。为了尽可能减少这种影响，我们也可以进行请求限流：指我们在业务系统的请求入口前端控制每秒进入系统的请求数，避免过多的请求被发送到数据库。\n\n举个例子。假设业务系统正常运行时，请求入口前端允许每秒进入系统的请求是1万个，其中，9000个请求都能在缓存系统中进行处理，只有1000个请求会被应用发送到数据库进行处理。一旦发生了缓存雪崩，数据库的每秒请求数突然增加到每秒1万个，此时，我们就可以启动请求限流机制，在请求入口前端只允许每秒进入系统的请求数为1000个，再多的请求就会在入口前端被直接拒绝服务。所以，使用了请求限流，就可以避免大量并发请求压力传递到数据库层。\n\n使用服务熔断或是请求限流机制，来应对Redis实例宕机导致的缓存雪崩问题，是属于“事后诸葛亮”，也就是已经发生缓存雪崩了，我们使用这两个机制，来降低雪崩对数据库和整个业务系统的影响。\n\n第二个建议：事前预防，构建 Redis 集群。\n\n通过主从节点的方式构建 Redis 缓存高可靠集群。如果 Redis 缓存的主节点故障宕机了，从节点还可以切换成为主节点，继续提供缓存服务，避免了由于缓存实例宕机而导致的缓存雪崩问题。\n\n缓存雪崩是发生在大量数据同时失效的场景下，而接下来我要向你介绍的缓存击穿，是发生在某个热点数据失效的场景下。和缓存雪崩相比，缓存击穿失效的数据数量要小很多，应对方法也不一样，我们来看下。\n\n\n# 4.2 缓存击穿\n\n缓存击穿是指，针对某个访问非常频繁的热点数据的请求，无法在缓存中进行处理，紧接着，访问该数据的大量请求，一下子都发送到了后端数据库，导致了数据库压力激增，会影响数据库处理其他请求。缓存击穿的情况，经常发生在热点数据过期失效时，如下图所示：\n\n为了避免缓存击穿给数据库带来的激增压力，我们的解决方法也比较直接：对于访问特别频繁的热点数据，我们就不设置过期时间了。这样一来，对热点数据的访问请求，都可以在缓存中进行处理，而 Redis 数万级别的高吞吐量可以很好地应对大量的并发请求访问。\n\n以上，缓存雪崩和缓存击穿问题，都是在 DB 中保存了应用要访问的数据的情况。下面要看的缓存穿透是数据也不在 DB 中的情况。\n\n\n# 4.3 缓存穿透\n\n缓存穿透指要访问的数据既不在 Redis 缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据。此时，应用也无法从数据库中读取数据再写入缓存，来服务后续请求，这样一来，缓存也就成了“摆设”，如果应用持续有大量请求访问数据，就会同时给缓存和数据库带来巨大压力，如下图所示：\n\n那么，缓存穿透会发生在什么时候呢？一般来说，有两种情况：\n\n * 业务层误操作：缓存中的数据和数据库中的数据被误删除了，所以缓存和数据库中都没有数据；\n * 恶意攻击：专门访问数据库中没有的数据。\n\n为了避免缓存穿透的影响，我来给你提供三种应对方案。\n\n# 1）方案 1：缓存空值或缺省值\n\n一旦发生缓存穿透，我们就可以针对查询的数据，在Redis中缓存一个空值或是和业务层协商确定的缺省值（例如，库存的缺省值可以设为0）。紧接着，应用发送的后续请求再进行查询时，就可以直接从Redis中读取空值或缺省值，返回给业务应用了，避免了把大量请求发送给数据库处理，保持了数据库的正常运行。\n\n# 2）方案 2：使用布隆过滤器快速判断数据是否存在，避免从数据库中查询数据是否存在，减轻数据库压力\n\n布隆过滤器由一个初值都为0的bit数组和N个哈希函数组成，可以用来快速判断某个数据是否存在。当我们想标记某个数据存在时（例如，数据已被写入数据库），布隆过滤器会通过三个操作完成标记：\n\n * 首先，使用N个哈希函数，分别计算这个数据的哈希值，得到N个哈希值。\n * 然后，我们把这N个哈希值对bit数组的长度取模，得到每个哈希值在数组中的对应位置。\n * 最后，我们把对应位置的bit位设置为1，这就完成了在布隆过滤器中标记数据的操作。\n\n如果数据不存在（例如，数据库里没有写入数据），我们也就没有用布隆过滤器标记过数据，那么，bit数组对应bit位的值仍然为0。\n\n当需要查询某个数据时，我们就执行刚刚说的计算过程，先得到这个数据在bit数组中对应的N个位置。紧接着，我们查看bit数组中这N个位置上的bit值。只要这N个bit值有一个不为1，这就表明布隆过滤器没有对该数据做过标记，所以，查询的数据一定没有在数据库中保存。这个过程如下图：\n\n图中布隆过滤器是一个包含10个bit位的数组，使用了3个哈希函数，当在布隆过滤器中标记数据X时，X会被计算3次哈希值，并对10取模，取模结果分别是1、3、7。所以，bit数组的第1、3、7位被设置为1。当应用想要查询X时，只要查看数组的第1、3、7位是否为1，只要有一个为0，那么，X就肯定不在数据库中。\n\n正是基于布隆过滤器的快速检测特性，我们可以在把数据写入数据库时，使用布隆过滤器做个标记。当缓存缺失后，应用查询数据库时，可以通过查询布隆过滤器快速判断数据是否存在。如果不存在，就不用再去数据库中查询了。这样一来，即使发生缓存穿透了，大量请求只会查询Redis和布隆过滤器，而不会积压到数据库，也就不会影响数据库的正常运行。布隆过滤器可以使用Redis实现，本身就能承担较大的并发访问压力。\n\n# 3）方案 3：提前对请求进行合法性检测\n\n这种方案是在请求入口的前端进行请求检测。缓存穿透的一个原因是有大量的恶意请求访问不存在的数据，所以，一个有效的应对方案是在请求入口前端，对业务系统接收到的请求进行合法性检测，把恶意的请求（例如请求参数不合理、请求参数是非法值、请求字段不存在）直接过滤掉，不让它们访问后端缓存和数据库。这样一来，也就不会出现缓存穿透问题了。\n\n跟缓存雪崩、缓存击穿这两类问题相比，缓存穿透的影响更大一些，希望你能重点关注一下：\n\n * 从预防的角度来说，我们需要避免误删除数据库和缓存中的数据；\n * 从应对角度来说，我们可以在业务系统中使用缓存空值或缺省值、使用布隆过滤器，以及进行恶意请求检测等方法。\n\n\n# 4.4 小结\n\n本节所讲的三个问题如下图所示：\n\n最后强调一下，服务熔断、服务降级、请求限流这些方法都是属于“有损”方案，在保证数据库和整体系统稳定的同时，会对业务应用带来负面影响。例如使用服务降级时，有部分数据的请求就只能得到错误返回信息，无法正常处理。如果使用了服务熔断，那么，整个缓存系统的服务都被暂停了，影响的业务范围更大。而使用了请求限流机制后，整个业务系统的吞吐率会降低，能并发处理的用户请求会减少，会影响到用户体验。\n\n所以建议尽量使用预防式方案：\n\n * 针对缓存雪崩，合理地设置数据过期时间，以及搭建高可靠缓存集群；\n * 针对缓存击穿，在缓存访问非常频繁的热点数据时，不要设置过期时间；\n * 针对缓存穿透，提前在入口前端实现恶意请求检测，或者规范数据库的数据删除操作，避免误删除。",normalizedContent:"> 参考：\n> \n>  * 25 缓存异常（上）：如何解决缓存和数据库的数据不一致问题？| 极客时间\n>  * 26 缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？| 极客时间\n>  * 缓存数据一致性探究 | 阿里开发者\n\n掌握缓存需要解决四个关键问题：\n\n * redis 缓存具体是怎么工作的？(工作原理)\n * redis 缓存如果满了，该怎么办？(替换策略)\n * 为什么会有缓存一致性、缓存穿透、缓存雪崩、缓存击穿等异常，该如何应对？(异常处理机制)\n * redis 的内存毕竟有限，如果用快速的固态硬盘来保存数据，可以增加缓存的数据量，那 redis 缓存可以使用快速固态硬盘吗？(扩展机制)\n\n下面介绍第三个问题。\n\n\n# 3. 缓存异常（上）：如何解决缓存和数据库的数据不一致问题？\n\nredis 用作缓存经常有一些异常问题，概括来说有 4 个方面：缓存中的数据和数据库中的不一致；缓存雪崩；缓存击穿和缓存穿透。这一节先看一下第一个问题。\n\n\n# 3.1 缓存和数据库的数据不一致是如何发生的？\n\n这里的数据的一致性其实包含两种情况：\n\n * 缓存中有数据，且与数据库中的相同\n * 缓存中本身没有数据，且数据库中是最新的\n\n不符合这两种情况的，就属于缓存和数据库的数据不一致问题了。当缓存的读写模式不同时，我们的应对方法也不一样。\n\n对于读写缓存来说，数据的 crud 要在缓存中进行，同时对原数据库进行写回：\n\n * 若想要保证缓存与数据库的数据一致，就要使用事务机制来使用同步直写策略来一块更新缓存和数据库，保证这俩的更新有原子性。\n * 若对一致性要求没有那么高，就可以使用异步写回策略。\n\n对于只读缓存来说，如果有数据新增，会直接写入数据库；而有数据删改时，就需要把只读缓存中的数据标记为无效。这样一来，应用后续再访问这些增删改的数据时，因为缓存中没有相应的数据，就会发生缓存缺失。此时，应用再从数据库中把数据读入缓存，这样后续再访问数据时，就能够直接从缓存中读取了。这个过程如下图所示：\n\n从图中可以看到，tomcat上运行的应用，无论是新增（insert操作）、修改（update操作）、还是删除（delete操作）数据x，都会直接在数据库中增改删。当然，如果应用执行的是修改或删除操作，还会删除缓存的数据x。\n\n那这个过程会不会出现数据不一致的情况呢？考虑到新增数据和删改数据的情况不一样，所以我们分开来看：\n\n# 1）新增数据\n\n如果是新增数据，数据会直接写到数据库中，不用对缓存做任何操作，此时，缓存中本身就没有新增数据，而数据库中是最新值，因此是一致的。\n\n# 2）删改数据\n\n此时就要选择是先更新原数据库的数据还是先删除缓存中的数据：\n\n * 如果先删缓存值：可能导致数据库更新失败。导致请求再次访问缓存时，发现缓存缺失，再读 db 时，从其中读到旧值。\n * 如果先更新数据库的值：可能出现缓存删除失败。导致后续请求因再次缓存命中导致读取缓存旧值。\n\n可以看到，无论这两个操作的执行顺序谁先谁后，只要有一个操作失败了，就会导致客户端读取到旧值。如何解决这个问题呢？\n\n\n# 3.2 如何解决数据不一致问题？\n\n数据不一致出现的原因主要分为两种情况：\n\n * 对 db/缓存 的操作，第二个失败了 解决方法：\n   * 重试机制\n   * 订阅 mysql binlog，再操作缓存\n * 复杂的并发场景下，对数据库和缓存的操作都是成功的\n\n# 3.2.1 重试机制\n\n首先一种方法是：重试机制。\n\n具体来说，可以把要删除的缓存值或者是要更新的数据库值暂存到消息队列中（例如使用kafka消息队列）。当应用没有能够成功地删除缓存值或者是更新数据库值时，可以从消息队列中重新读取这些值，然后再次进行删除或更新。\n\n如果能够成功地删除或更新，我们就要把这些值从消息队列中去除，以免重复操作，此时，我们也可以保证数据库和缓存的数据一致了。否则的话，我们还需要再次进行重试。如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。\n\n图显示了先更新数据库，再删除缓存值时，如果缓存删除失败，再次重试后删除成功的情况：\n\n# 3.2.2 订阅 mysql binlog，再操作缓存\n\n「先更新数据库，再删缓存」的策略的第一步是更新数据库，那么更新数据库成功，就会产生一条变更日志，记录在 binlog 里。于是我们就可以通过订阅 binlog 日志，拿到具体要操作的数据，然后再执行缓存删除，阿里巴巴开源的 canal 中间件就是基于这个实现的。\n\ncanal 模拟 mysql 主从复制的交互协议，把自己伪装成一个 mysql 的从节点，向 mysql 主节点发送 dump 请求，mysql 收到请求后，就会开始推送 binlog 给 canal，canal 解析 binlog 字节流之后，转换为便于读取的结构化数据，供下游程序订阅使用。\n\n下图是 canal 的工作原理：\n\n所以，如果要想保证「先更新数据库，再删缓存」策略第二个操作能执行成功，我们可以使用「消息队列来重试缓存的删除」，或者「订阅 mysql binlog 再操作缓存」，这两种方法有一个共同的特点，都是采用异步操作缓存。\n\n# 3.2.3 延迟双删\n\n刚刚说的是在更新数据库和删除缓存值的过程中，其中一个操作失败的情况，实际上，即使这两个操作第一次执行时都没有失败，当有大量并发请求时，应用还是有可能读到不一致的数据。\n\n同样，我们按照不同的删除和更新顺序，分成两种情况来看。在这两种情况下，我们的解决方法也有所不同。\n\n情况一：先删除缓存，再更新数据库：\n\n假设线程a删除缓存值后，还没有来得及更新数据库（比如说有网络延迟），线程b就开始读取数据了，那么这个时候，线程b会发现缓存缺失，就只能去数据库读取。这会带来两个问题：\n\n 1. 线程b读取到了旧值；\n 2. 线程b是在缓存缺失的情况下读取的数据库，所以，它还会把旧值写入缓存，这可能会导致其他线程从缓存中读到旧值。\n\n等到线程b从数据库读取完数据、更新了缓存后，线程a才开始更新数据库，此时，缓存中的数据是旧值，而数据库中的是最新值，两者就不一致了。这种情况用表格展示如下：\n\n这该怎么办？一种解决方案是：在线程a更新完数据库值以后，我们可以让它先sleep一小段时间，再进行一次缓存删除操作。\n\n之所以要加上sleep的这段时间，就是为了让线程b能够先从数据库读取数据，再把缺失的数据写入缓存，然后，线程a再进行删除。所以，线程a sleep的时间，就需要大于线程b读取数据再写入缓存的时间。这个时间怎么确定呢？建议你在业务程序运行的时候，统计下线程读数据和写缓存的操作时间，以此为基础来进行估算。\n\n这样一来，其它线程读取数据时，会发现缓存缺失，所以会从数据库中读取最新值。因为这个方案会在第一次删除缓存值后，延迟一段时间再次进行删除，所以我们也把它叫做延迟双删。下面是延迟双删的伪代码：\n\nredis.delkey(x)\ndb.update(x)\nthread.sleep(n)\nredis.delkey(x)\n\n\n1\n2\n3\n4\n\n\n情况二：先更新数据库值，再删除缓存值：\n\n如果线程a删除了数据库中的值，但还没来得及删除缓存值，线程b就开始读取数据了，那么此时，线程b查询缓存时，发现缓存命中，就会直接从缓存中读取旧值。不过，在这种情况下，如果其他线程并发读缓存的请求不多，那么，就不会有很多请求读取到旧值。而且，线程a一般也会很快删除缓存值，这样一来，其他线程再次读取时，就会发生缓存缺失，进而从数据库中读取最新值。所以，这种情况对业务的影响较小。\n\n这种情况用表格展示为：\n\n----------------------------------------\n\n到这里我们可以知道，缓存和数据库的数据不一致一般是由两个原因导致的，本节并提供了相应的解决方案：\n\n * 删除缓存值或更新数据库失败而导致数据不一致，你可以使用重试机制确保删除或更新操作成功。\n * 在删除缓存值、更新数据库的这两步操作中，有其他线程的并发读操作，导致其他线程读取到旧值，应对方案是延迟双删。\n\n\n# 3.3 小结\n\n这一大节讲了缓存不一致的问题，可以分成读写缓存和只读缓存两种情况分析。\n\n * 对于读写缓存，同步写回策略就可以保证缓存和数据库中的数据一致。\n * 对于只读缓存，可以总结为下面这张表：\n\n大多数业务中，我们是把 redis 当做只读缓存来使用，并建议优先使用先更新数据库再删除缓存的方法(cache aside)，原因主要有两个：\n\n 1. 先删除缓存值再更新数据库，有可能导致请求因缓存缺失而访问数据库，给数据库带来压力；\n 2. 如果业务应用中读取数据库和写缓存的时间不好估算，那么，延迟双删中的等待时间就不好设置。\n\n不过，当使用先更新数据库再删除缓存时，也有个地方需要注意，如果业务层要求必须读取一致的数据，那么，我们就需要在更新数据库时，先在redis缓存客户端暂存并发读请求，等数据库更新完、缓存值删除后，再读取数据，从而保证数据一致性。\n\n----------------------------------------\n\ncatch aside 可以被称之为缓存使用的最佳实践，但与此同时，它引入了缓存的命中率降低的问题，（每次都删除缓存自然导致更不容易命中了），因此它更适用于对缓存命中率要求并不是特别高的场景。如果要求较高的缓存命中率，依然需要采用更新数据库后同时更新缓存的方案。\n\n但是更新数据库后同时更新缓存的方案会在并发场景下出现数据不一致，解决方案有两种：\n\n * 引入分布式锁 在更新缓存之前尝试获取锁，如果已经被占用就先阻塞住线程，等待其他线程释放锁后再尝试更新。但这会影响并发操作的性能。\n * 设置较短缓存时间 设置较短的缓存过期时间能够使得数据不一致问题存在的时间也比较长，对业务的影响相对较小。但是与此同时，其实这也使得缓存命中率降低，又回到了前面的问题里...\n\n\n# 4. 缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？\n\n除了缓存不一致，还有三种可能的缓存异常：缓存雪崩、缓存击穿和缓存穿透。这三个问题一旦发生，会导致大量的请求积压到数据库层，从而导致数据库宕机或者故障。\n\n\n# 4.1 缓存雪崩\n\n缓存雪崩：指大量的应用请求无法在 redis 缓存中进行处理，紧接着应用将大量请求发送到数据库层，导致数据库层的压力激增。\n\n缓存雪崩一般是由两个原因导致的，应对方案也有所不同，我们一个个来看。\n\n# 4.1.1 原因一：大量数据同时过期\n\n缓存雪崩的第一种原因：缓存中有大量数据同时过期，导致大量请求无法得到处理。\n\n具体来说，当数据保存在缓存中，并且设置了过期时间时，如果在某一个时刻，大量数据同时过期，此时，应用再访问这些数据的话，就会发生缓存缺失。紧接着，应用就会把请求发送给数据库，从数据库中读取数据。如果应用的并发请求量很大，那么数据库的压力也就很大，这会进一步影响到数据库的其他正常业务请求处理。我们来看一个简单的例子，如下图所示：\n\n针对大量数据同时失效带来的缓存雪崩问题，有两种解决方案：\n\n 1. 微调过期时间：业务避免给大量的数据设置相同的过期时间。如果业务层的确要求有些数据同时失效，你可以在用 expire 命令给每个数据设置过期时间时，给这些数据的过期时间增加一个较小的随机数。这样一来，不同数据的过期时间差别不会太大，既避免了大量数据同时过期，同时也保证了这些数据基本在相近的时间失效，仍然能满足业务需求。\n 2. 服务降级：指发生缓存雪崩时，针对不同的数据采取不同的处理方式：\n    * 当业务应用访问的是非核心数据（例如电商商品属性）时，暂时停止从缓存中查询这些数据，而是直接返回预定义信息、空值或是错误信息；\n    * 当业务应用访问的是核心数据（例如电商商品库存）时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取。\n\n# 4.1.2 原因二：redis 缓存实例发生宕机\n\n缓存雪崩的第二种原因：redis 缓存实例发生故障宕机了，无法处理请求，这就会导致大量请求一下子积压到数据库层，从而发生缓存雪崩。\n\n一般来说，一个 redis 实例可以支持数万级别的请求处理吞吐量，而单个数据库可能只能支持数千级别的请求处理吞吐量，它们两个的处理能力可能相差了近十倍。由于缓存雪崩，redis 缓存失效，所以，数据库就可能要承受近十倍的请求压力，从而因为压力过大而崩溃。\n\n这种情况下由于 redis 实例发生了宕机，我们需要通过其他方法来应对缓存雪崩了。我给你提供两个建议：\n\n第一个建议：在业务系统中实现服务熔断或请求限流机制。\n\n所谓的服务熔断，是指在发生缓存雪崩时，为了防止引发连锁的数据库雪崩，甚至是整个系统的崩溃，我们暂停业务应用对缓存系统的接口访问，而是直接返回，等到redis缓存实例重新恢复服务后，再允许应用请求发送到缓存系统。这样避免了大量请求因缓存缺失而积压到数据库系统。\n\n在业务系统运行时，我们可以监测 redis 所在机器和数据库所在机器的负载指标，例如每秒请求数、cpu利用率、内存利用率等。如果我们发现 redis 实例宕机了，而数据库所在机器的负载压力突然增加，此时就发生缓存雪崩了。大量请求被发送到数据库进行处理。我们可以启动服务熔断机制，暂停业务应用对缓存服务的访问，从而降低对数据库的访问压力，如下图所示：\n\n服务熔断虽然可以保证数据库的正常运行，但是暂停了整个缓存系统的访问，对业务应用的影响范围大。为了尽可能减少这种影响，我们也可以进行请求限流：指我们在业务系统的请求入口前端控制每秒进入系统的请求数，避免过多的请求被发送到数据库。\n\n举个例子。假设业务系统正常运行时，请求入口前端允许每秒进入系统的请求是1万个，其中，9000个请求都能在缓存系统中进行处理，只有1000个请求会被应用发送到数据库进行处理。一旦发生了缓存雪崩，数据库的每秒请求数突然增加到每秒1万个，此时，我们就可以启动请求限流机制，在请求入口前端只允许每秒进入系统的请求数为1000个，再多的请求就会在入口前端被直接拒绝服务。所以，使用了请求限流，就可以避免大量并发请求压力传递到数据库层。\n\n使用服务熔断或是请求限流机制，来应对redis实例宕机导致的缓存雪崩问题，是属于“事后诸葛亮”，也就是已经发生缓存雪崩了，我们使用这两个机制，来降低雪崩对数据库和整个业务系统的影响。\n\n第二个建议：事前预防，构建 redis 集群。\n\n通过主从节点的方式构建 redis 缓存高可靠集群。如果 redis 缓存的主节点故障宕机了，从节点还可以切换成为主节点，继续提供缓存服务，避免了由于缓存实例宕机而导致的缓存雪崩问题。\n\n缓存雪崩是发生在大量数据同时失效的场景下，而接下来我要向你介绍的缓存击穿，是发生在某个热点数据失效的场景下。和缓存雪崩相比，缓存击穿失效的数据数量要小很多，应对方法也不一样，我们来看下。\n\n\n# 4.2 缓存击穿\n\n缓存击穿是指，针对某个访问非常频繁的热点数据的请求，无法在缓存中进行处理，紧接着，访问该数据的大量请求，一下子都发送到了后端数据库，导致了数据库压力激增，会影响数据库处理其他请求。缓存击穿的情况，经常发生在热点数据过期失效时，如下图所示：\n\n为了避免缓存击穿给数据库带来的激增压力，我们的解决方法也比较直接：对于访问特别频繁的热点数据，我们就不设置过期时间了。这样一来，对热点数据的访问请求，都可以在缓存中进行处理，而 redis 数万级别的高吞吐量可以很好地应对大量的并发请求访问。\n\n以上，缓存雪崩和缓存击穿问题，都是在 db 中保存了应用要访问的数据的情况。下面要看的缓存穿透是数据也不在 db 中的情况。\n\n\n# 4.3 缓存穿透\n\n缓存穿透指要访问的数据既不在 redis 缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据。此时，应用也无法从数据库中读取数据再写入缓存，来服务后续请求，这样一来，缓存也就成了“摆设”，如果应用持续有大量请求访问数据，就会同时给缓存和数据库带来巨大压力，如下图所示：\n\n那么，缓存穿透会发生在什么时候呢？一般来说，有两种情况：\n\n * 业务层误操作：缓存中的数据和数据库中的数据被误删除了，所以缓存和数据库中都没有数据；\n * 恶意攻击：专门访问数据库中没有的数据。\n\n为了避免缓存穿透的影响，我来给你提供三种应对方案。\n\n# 1）方案 1：缓存空值或缺省值\n\n一旦发生缓存穿透，我们就可以针对查询的数据，在redis中缓存一个空值或是和业务层协商确定的缺省值（例如，库存的缺省值可以设为0）。紧接着，应用发送的后续请求再进行查询时，就可以直接从redis中读取空值或缺省值，返回给业务应用了，避免了把大量请求发送给数据库处理，保持了数据库的正常运行。\n\n# 2）方案 2：使用布隆过滤器快速判断数据是否存在，避免从数据库中查询数据是否存在，减轻数据库压力\n\n布隆过滤器由一个初值都为0的bit数组和n个哈希函数组成，可以用来快速判断某个数据是否存在。当我们想标记某个数据存在时（例如，数据已被写入数据库），布隆过滤器会通过三个操作完成标记：\n\n * 首先，使用n个哈希函数，分别计算这个数据的哈希值，得到n个哈希值。\n * 然后，我们把这n个哈希值对bit数组的长度取模，得到每个哈希值在数组中的对应位置。\n * 最后，我们把对应位置的bit位设置为1，这就完成了在布隆过滤器中标记数据的操作。\n\n如果数据不存在（例如，数据库里没有写入数据），我们也就没有用布隆过滤器标记过数据，那么，bit数组对应bit位的值仍然为0。\n\n当需要查询某个数据时，我们就执行刚刚说的计算过程，先得到这个数据在bit数组中对应的n个位置。紧接着，我们查看bit数组中这n个位置上的bit值。只要这n个bit值有一个不为1，这就表明布隆过滤器没有对该数据做过标记，所以，查询的数据一定没有在数据库中保存。这个过程如下图：\n\n图中布隆过滤器是一个包含10个bit位的数组，使用了3个哈希函数，当在布隆过滤器中标记数据x时，x会被计算3次哈希值，并对10取模，取模结果分别是1、3、7。所以，bit数组的第1、3、7位被设置为1。当应用想要查询x时，只要查看数组的第1、3、7位是否为1，只要有一个为0，那么，x就肯定不在数据库中。\n\n正是基于布隆过滤器的快速检测特性，我们可以在把数据写入数据库时，使用布隆过滤器做个标记。当缓存缺失后，应用查询数据库时，可以通过查询布隆过滤器快速判断数据是否存在。如果不存在，就不用再去数据库中查询了。这样一来，即使发生缓存穿透了，大量请求只会查询redis和布隆过滤器，而不会积压到数据库，也就不会影响数据库的正常运行。布隆过滤器可以使用redis实现，本身就能承担较大的并发访问压力。\n\n# 3）方案 3：提前对请求进行合法性检测\n\n这种方案是在请求入口的前端进行请求检测。缓存穿透的一个原因是有大量的恶意请求访问不存在的数据，所以，一个有效的应对方案是在请求入口前端，对业务系统接收到的请求进行合法性检测，把恶意的请求（例如请求参数不合理、请求参数是非法值、请求字段不存在）直接过滤掉，不让它们访问后端缓存和数据库。这样一来，也就不会出现缓存穿透问题了。\n\n跟缓存雪崩、缓存击穿这两类问题相比，缓存穿透的影响更大一些，希望你能重点关注一下：\n\n * 从预防的角度来说，我们需要避免误删除数据库和缓存中的数据；\n * 从应对角度来说，我们可以在业务系统中使用缓存空值或缺省值、使用布隆过滤器，以及进行恶意请求检测等方法。\n\n\n# 4.4 小结\n\n本节所讲的三个问题如下图所示：\n\n最后强调一下，服务熔断、服务降级、请求限流这些方法都是属于“有损”方案，在保证数据库和整体系统稳定的同时，会对业务应用带来负面影响。例如使用服务降级时，有部分数据的请求就只能得到错误返回信息，无法正常处理。如果使用了服务熔断，那么，整个缓存系统的服务都被暂停了，影响的业务范围更大。而使用了请求限流机制后，整个业务系统的吞吐率会降低，能并发处理的用户请求会减少，会影响到用户体验。\n\n所以建议尽量使用预防式方案：\n\n * 针对缓存雪崩，合理地设置数据过期时间，以及搭建高可靠缓存集群；\n * 针对缓存击穿，在缓存访问非常频繁的热点数据时，不要设置过期时间；\n * 针对缓存穿透，提前在入口前端实现恶意请求检测，或者规范数据库的数据删除操作，避免误删除。",charsets:{cjk:!0},lastUpdated:"2023/06/05, 07:46:08",lastUpdatedTimestamp:1685951168e3},{title:"Redis 用作缓存之缓存污染",frontmatter:{title:"Redis 用作缓存之缓存污染",date:"2023-04-12T10:21:29.000Z",permalink:"/pages/ea52c5/",categories:["中间件","Redis","专栏：Redis 核心技术与实战"],tags:[null]},regularPath:"/%E4%B8%AD%E9%97%B4%E4%BB%B6/05.Redis/05.%E4%B8%93%E6%A0%8F%EF%BC%9ARedis%20%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/27.Redis%20%E7%94%A8%E4%BD%9C%E7%BC%93%E5%AD%98%E4%B9%8B%E7%BC%93%E5%AD%98%E6%B1%A1%E6%9F%93.html",relativePath:"中间件/05.Redis/05.专栏：Redis 核心技术与实战/27.Redis 用作缓存之缓存污染.md",key:"v-ad649dc2",path:"/pages/ea52c5/",headers:[{level:2,title:"5. 缓存被污染了，该怎么办？",slug:"_5-缓存被污染了-该怎么办",normalizedTitle:"5. 缓存被污染了，该怎么办？",charIndex:245},{level:3,title:"5.1 如何解决缓存污染问题",slug:"_5-1-如何解决缓存污染问题",normalizedTitle:"5.1 如何解决缓存污染问题",charIndex:367},{level:3,title:"5.2 LRU 缓存策略",slug:"_5-2-lru-缓存策略",normalizedTitle:"5.2 lru 缓存策略",charIndex:1061},{level:3,title:"5.3 LFU 缓存策略的优化",slug:"_5-3-lfu-缓存策略的优化",normalizedTitle:"5.3 lfu 缓存策略的优化",charIndex:1521},{level:3,title:"5.4 小结",slug:"_5-4-小结",normalizedTitle:"5.4 小结",charIndex:3479}],headersStr:"5. 缓存被污染了，该怎么办？ 5.1 如何解决缓存污染问题 5.2 LRU 缓存策略 5.3 LFU 缓存策略的优化 5.4 小结",content:"> 参考：\n> \n>  * 27 缓存被污染了，该怎么办？| 极客时间\n\n掌握缓存需要解决四个关键问题：\n\n * Redis 缓存具体是怎么工作的？(工作原理)\n * Redis 缓存如果满了，该怎么办？(替换策略)\n * 为什么会有缓存一致性、缓存穿透、缓存雪崩、缓存击穿等异常，该如何应对？(异常处理机制)\n * Redis 的内存毕竟有限，如果用快速的固态硬盘来保存数据，可以增加缓存的数据量，那 Redis 缓存可以使用快速固态硬盘吗？(扩展机制)\n\n下面介绍第四个问题。\n\n\n# 5. 缓存被污染了，该怎么办？\n\n缓存污染：指有些数据很少被访问，这些数据被访问后仍然继续留在缓存中，就只会白白占用缓存空间，这种情况就是缓存污染。\n\n如果缓存污染严重，就会影响 Redis 的性能。这一节就看看如何解决缓存污染问题。\n\n\n# 5.1 如何解决缓存污染问题\n\n要解决缓存污染，我们也能很容易想到解决方案，那就是得把不会再被访问的数据筛选出来并淘汰掉。这样就不用等到缓存被写满以后，再逐一淘汰旧数据之后，才能写入新数据了。而哪些数据能留存在缓存中，是由缓存的淘汰策略决定的。\n\n我们前面说过缓存淘汰策略有 8 种，分别是noeviction、volatile-random、volatile-ttl、volatile-lru、volatile-lfu、allkeys-lru、allkeys-random和allkeys-lfu策略。哪些策略可以解决缓存污染问题呢？我们一一分析下。\n\nnoeviction 策略是不会进行数据淘汰的。所以，它肯定不能用来解决缓存污染问题。\n\n首先先看一下 volatile-random 和 allkeys-random 这两个策略，它们都是采用随机挑选被淘汰的数据。因为这两个策略并不根据数据的访问情况来筛选，因此在避免缓存污染这个问题上的效果非常有限。\n\n再看 volatile-ttl 策略，它把数据中剩余存活时间最短的筛选出来并淘汰掉，但剩余存活时间也不能直接反映数据再次访问的情况，因此也无法有效避免缓存污染。除非应用会根据访问情况来设置过期时间。\n\n讲到这里，我们先小结下。除了在明确知道数据被再次访问的情况下，volatile-ttl可以有效避免缓存污染。在其他情况下，volatile-random、allkeys-random、volatile-ttl这三种策略并不能应对缓存污染问题。\n\n下面再看一下 LRU 和 LFU 策略在解决缓存污染问题上的效果。\n\n\n# 5.2 LRU 缓存策略\n\nLRU 策略的核心思想：如果一个数据刚刚被访问，那么这个数据肯定是热数据，还会被再次访问。\n\nRedis 的 LRU 缓存策略实现方式是在 RedisObject 结构体上设置了一个 lru 字段来记录时间戳，在进行数据淘汰时，LRU 策略会淘汰掉 lru 值最小的数据。\n\n因此在数据被频繁访问的业务场景中，LRU 策略能够有效留存访问时间最近的数据，而且因为这些数据很可能被再次访问，从而可以提升业务应用的访问速度。\n\n但 LRU 这种只看数据访问时间的算法，无法处理“扫描式单次查询操作”导致的缓存污染问题。扫描式单次查询操作指应用对大量数据进行一次全体逐一访问，此时由于被查询的数据都是刚被访问过的，其 lru 值都很大，从而导致很多数据都留在了缓存中产生污染。\n\n所以对于 Redis 的 LRU 策略 而言，扫描式单次查询会造成缓存污染。为了应对这类问题，Redis 4.0 增加了 LFU 淘汰策略，它从时效性和被访问次数两个维度来筛选数据。下面看一下 LFU 策略。\n\n\n# 5.3 LFU 缓存策略的优化\n\nLFU 缓存策略是在 LRU 策略基础上，为每个数据增加了一个计数器，来统计这个数据的访问次数。当使用 LFU 策略筛选淘汰数据时，首先会根据数据的访问次数进行筛选，把访问次数最低的数据淘汰出缓存。如果两个数据的访问次数相同，LFU 策略再比较这两个数据的访问时效性，把距离上一次访问时间更久的数据淘汰出缓存。\n\n和那些被频繁访问的数据相比，扫描式单次查询的数据因为不会被再次访问，所以它们的访问次数不会再增加。因此，LFU 策略会优先把这些访问次数低的数据淘汰出缓存。这样一来，LFU 策略就可以避免这些数据对缓存造成污染了。\n\n----------------------------------------\n\nLFU策略具体又是如何实现的呢？\n\n既然LFU策略是在LRU策略上做的优化，那它们的实现必定有些关系。再复习下第24讲学习过的LRU策略的实现：\n\n * Redis是用RedisObject结构来保存数据的，RedisObject结构中设置了一个lru字段，用来记录数据的访问时间戳；\n * Redis并没有为所有的数据维护一个全局的链表，而是通过随机采样方式，选取一定数量（例如10个）的数据放入候选集合，后续在候选集合中根据lru字段值的大小进行筛选。\n\n在此基础上， Redis在实现LFU策略的时候，只是把原来24bit大小的lru字段，又进一步拆分成了两部分。\n\n 1. ldt值：lru字段的前16bit，表示数据的访问时间戳；\n 2. counter值：lru字段的后8bit，表示数据的访问次数。\n\n总结一下：当LFU策略筛选数据时，Redis会在候选集合中，根据数据lru字段的后8bit选择访问次数最少的数据进行淘汰。当访问次数相同时，再根据lru字段的前16bit值大小，选择访问时间最久远的数据进行淘汰。\n\n但是， Redis只使用了8bit记录数据的访问次数，而8bit记录的最大值是255，这样可以吗？\n\nRedis 在实现LFU策略时，没有采用数据每被访问一次，就给对应的counter值加1的计数规则，而是采用了一个更优化的计数规则：每当数据被访问一次时，首先，用计数器当前的值乘以配置项lfu_log_factor再加1，再取其倒数，得到一个p值；然后，把这个p值和一个取值范围在（0，1）间的随机数r值比大小，只有p值大于r值时，计数器才加1。.\n\n下面这段Redis的部分源码，显示了LFU策略增加计数器值的计算逻辑。其中，baseval是计数器当前的值。计数器的初始值默认是5（由代码中的LFU_INIT_VAL常量设置），而不是0，这样可以避免数据刚被写入缓存，就因为访问次数少而被立即淘汰。\n\ndouble r = (double)rand()/RAND_MAX;\n...\ndouble p = 1.0/(baseval*server.lfu_log_factor+1);\nif (r < p) counter++;\n\n\n1\n2\n3\n4\n\n\n使用了这种计算规则后，我们可以通过设置不同的lfu_log_factor配置项，来控制计数器值增加的速度，避免counter值很快就到255了。\n\n下表记录了当lfu_log_factor取不同值时，在不同的实际访问次数情况下，计数器的值是如何变化的。\n\n正是因为使用了非线性递增的计数器方法，即使缓存数据的访问次数成千上万，LFU策略也可以有效地区分不同的访问次数，从而进行合理的数据筛选。我们在应用LFU策略时，一般可以将lfu_log_factor取值为10。\n\n在一些场景下，有些数据在短时间内被大量访问后就不会再被访问了。那么再按照访问次数来筛选的话，这些数据会被留存在缓存中，但不会提升缓存命中率。为此，Redis在实现LFU策略时，还设计了一个counter值的衰减机制：\n\n * LFU策略使用衰减因子配置项lfu_decay_time来控制访问次数的衰减。LFU策略会计算当前时间和数据最近一次访问时间的差值，并把这个差值换算成以分钟为单位。然后，LFU策略再把这个差值除以lfu_decay_time值，所得的结果就是数据counter要衰减的值。\n\n简单举个例子，假设lfu_decay_time取值为1，如果数据在N分钟内没有被访问，那么它的访问次数就要减N。如果lfu_decay_time取值更大，那么相应的衰减值会变小，衰减效果也会减弱。所以，如果业务应用中有短时高频访问的数据的话，建议把lfu_decay_time值设置为1，这样一来，LFU策略在它们不再被访问后，会较快地衰减它们的访问次数，尽早把它们从缓存中淘汰出去，避免缓存污染。\n\n\n# 5.4 小结\n\n在实际业务应用中，LRU 和LFU 两个策略都有应用。LRU 和 LFU 两个策略关注的数据访问特征各有侧重：\n\n * LRU 策略更加关注数据的时效性；\n * LFU 策略更加关注数据的访问频次。\n\n通常情况下，实际应用的负载具有较好的时间局部性，所以 LRU 策略的应用会更加广泛。但是，在扫描式查询的应用场景中，LFU 策略就可以很好地应对缓存污染问题了，建议你优先使用。\n\n此外，如果业务应用中有短时高频访问的数据，除了LFU策略本身会对数据的访问次数进行自动衰减以外，我再给你个小建议：你可以优先使用volatile-lfu策略，并根据这些数据的访问时限设置它们的过期时间，以免它们留存在缓存中造成污染。",normalizedContent:"> 参考：\n> \n>  * 27 缓存被污染了，该怎么办？| 极客时间\n\n掌握缓存需要解决四个关键问题：\n\n * redis 缓存具体是怎么工作的？(工作原理)\n * redis 缓存如果满了，该怎么办？(替换策略)\n * 为什么会有缓存一致性、缓存穿透、缓存雪崩、缓存击穿等异常，该如何应对？(异常处理机制)\n * redis 的内存毕竟有限，如果用快速的固态硬盘来保存数据，可以增加缓存的数据量，那 redis 缓存可以使用快速固态硬盘吗？(扩展机制)\n\n下面介绍第四个问题。\n\n\n# 5. 缓存被污染了，该怎么办？\n\n缓存污染：指有些数据很少被访问，这些数据被访问后仍然继续留在缓存中，就只会白白占用缓存空间，这种情况就是缓存污染。\n\n如果缓存污染严重，就会影响 redis 的性能。这一节就看看如何解决缓存污染问题。\n\n\n# 5.1 如何解决缓存污染问题\n\n要解决缓存污染，我们也能很容易想到解决方案，那就是得把不会再被访问的数据筛选出来并淘汰掉。这样就不用等到缓存被写满以后，再逐一淘汰旧数据之后，才能写入新数据了。而哪些数据能留存在缓存中，是由缓存的淘汰策略决定的。\n\n我们前面说过缓存淘汰策略有 8 种，分别是noeviction、volatile-random、volatile-ttl、volatile-lru、volatile-lfu、allkeys-lru、allkeys-random和allkeys-lfu策略。哪些策略可以解决缓存污染问题呢？我们一一分析下。\n\nnoeviction 策略是不会进行数据淘汰的。所以，它肯定不能用来解决缓存污染问题。\n\n首先先看一下 volatile-random 和 allkeys-random 这两个策略，它们都是采用随机挑选被淘汰的数据。因为这两个策略并不根据数据的访问情况来筛选，因此在避免缓存污染这个问题上的效果非常有限。\n\n再看 volatile-ttl 策略，它把数据中剩余存活时间最短的筛选出来并淘汰掉，但剩余存活时间也不能直接反映数据再次访问的情况，因此也无法有效避免缓存污染。除非应用会根据访问情况来设置过期时间。\n\n讲到这里，我们先小结下。除了在明确知道数据被再次访问的情况下，volatile-ttl可以有效避免缓存污染。在其他情况下，volatile-random、allkeys-random、volatile-ttl这三种策略并不能应对缓存污染问题。\n\n下面再看一下 lru 和 lfu 策略在解决缓存污染问题上的效果。\n\n\n# 5.2 lru 缓存策略\n\nlru 策略的核心思想：如果一个数据刚刚被访问，那么这个数据肯定是热数据，还会被再次访问。\n\nredis 的 lru 缓存策略实现方式是在 redisobject 结构体上设置了一个 lru 字段来记录时间戳，在进行数据淘汰时，lru 策略会淘汰掉 lru 值最小的数据。\n\n因此在数据被频繁访问的业务场景中，lru 策略能够有效留存访问时间最近的数据，而且因为这些数据很可能被再次访问，从而可以提升业务应用的访问速度。\n\n但 lru 这种只看数据访问时间的算法，无法处理“扫描式单次查询操作”导致的缓存污染问题。扫描式单次查询操作指应用对大量数据进行一次全体逐一访问，此时由于被查询的数据都是刚被访问过的，其 lru 值都很大，从而导致很多数据都留在了缓存中产生污染。\n\n所以对于 redis 的 lru 策略 而言，扫描式单次查询会造成缓存污染。为了应对这类问题，redis 4.0 增加了 lfu 淘汰策略，它从时效性和被访问次数两个维度来筛选数据。下面看一下 lfu 策略。\n\n\n# 5.3 lfu 缓存策略的优化\n\nlfu 缓存策略是在 lru 策略基础上，为每个数据增加了一个计数器，来统计这个数据的访问次数。当使用 lfu 策略筛选淘汰数据时，首先会根据数据的访问次数进行筛选，把访问次数最低的数据淘汰出缓存。如果两个数据的访问次数相同，lfu 策略再比较这两个数据的访问时效性，把距离上一次访问时间更久的数据淘汰出缓存。\n\n和那些被频繁访问的数据相比，扫描式单次查询的数据因为不会被再次访问，所以它们的访问次数不会再增加。因此，lfu 策略会优先把这些访问次数低的数据淘汰出缓存。这样一来，lfu 策略就可以避免这些数据对缓存造成污染了。\n\n----------------------------------------\n\nlfu策略具体又是如何实现的呢？\n\n既然lfu策略是在lru策略上做的优化，那它们的实现必定有些关系。再复习下第24讲学习过的lru策略的实现：\n\n * redis是用redisobject结构来保存数据的，redisobject结构中设置了一个lru字段，用来记录数据的访问时间戳；\n * redis并没有为所有的数据维护一个全局的链表，而是通过随机采样方式，选取一定数量（例如10个）的数据放入候选集合，后续在候选集合中根据lru字段值的大小进行筛选。\n\n在此基础上， redis在实现lfu策略的时候，只是把原来24bit大小的lru字段，又进一步拆分成了两部分。\n\n 1. ldt值：lru字段的前16bit，表示数据的访问时间戳；\n 2. counter值：lru字段的后8bit，表示数据的访问次数。\n\n总结一下：当lfu策略筛选数据时，redis会在候选集合中，根据数据lru字段的后8bit选择访问次数最少的数据进行淘汰。当访问次数相同时，再根据lru字段的前16bit值大小，选择访问时间最久远的数据进行淘汰。\n\n但是， redis只使用了8bit记录数据的访问次数，而8bit记录的最大值是255，这样可以吗？\n\nredis 在实现lfu策略时，没有采用数据每被访问一次，就给对应的counter值加1的计数规则，而是采用了一个更优化的计数规则：每当数据被访问一次时，首先，用计数器当前的值乘以配置项lfu_log_factor再加1，再取其倒数，得到一个p值；然后，把这个p值和一个取值范围在（0，1）间的随机数r值比大小，只有p值大于r值时，计数器才加1。.\n\n下面这段redis的部分源码，显示了lfu策略增加计数器值的计算逻辑。其中，baseval是计数器当前的值。计数器的初始值默认是5（由代码中的lfu_init_val常量设置），而不是0，这样可以避免数据刚被写入缓存，就因为访问次数少而被立即淘汰。\n\ndouble r = (double)rand()/rand_max;\n...\ndouble p = 1.0/(baseval*server.lfu_log_factor+1);\nif (r < p) counter++;\n\n\n1\n2\n3\n4\n\n\n使用了这种计算规则后，我们可以通过设置不同的lfu_log_factor配置项，来控制计数器值增加的速度，避免counter值很快就到255了。\n\n下表记录了当lfu_log_factor取不同值时，在不同的实际访问次数情况下，计数器的值是如何变化的。\n\n正是因为使用了非线性递增的计数器方法，即使缓存数据的访问次数成千上万，lfu策略也可以有效地区分不同的访问次数，从而进行合理的数据筛选。我们在应用lfu策略时，一般可以将lfu_log_factor取值为10。\n\n在一些场景下，有些数据在短时间内被大量访问后就不会再被访问了。那么再按照访问次数来筛选的话，这些数据会被留存在缓存中，但不会提升缓存命中率。为此，redis在实现lfu策略时，还设计了一个counter值的衰减机制：\n\n * lfu策略使用衰减因子配置项lfu_decay_time来控制访问次数的衰减。lfu策略会计算当前时间和数据最近一次访问时间的差值，并把这个差值换算成以分钟为单位。然后，lfu策略再把这个差值除以lfu_decay_time值，所得的结果就是数据counter要衰减的值。\n\n简单举个例子，假设lfu_decay_time取值为1，如果数据在n分钟内没有被访问，那么它的访问次数就要减n。如果lfu_decay_time取值更大，那么相应的衰减值会变小，衰减效果也会减弱。所以，如果业务应用中有短时高频访问的数据的话，建议把lfu_decay_time值设置为1，这样一来，lfu策略在它们不再被访问后，会较快地衰减它们的访问次数，尽早把它们从缓存中淘汰出去，避免缓存污染。\n\n\n# 5.4 小结\n\n在实际业务应用中，lru 和lfu 两个策略都有应用。lru 和 lfu 两个策略关注的数据访问特征各有侧重：\n\n * lru 策略更加关注数据的时效性；\n * lfu 策略更加关注数据的访问频次。\n\n通常情况下，实际应用的负载具有较好的时间局部性，所以 lru 策略的应用会更加广泛。但是，在扫描式查询的应用场景中，lfu 策略就可以很好地应对缓存污染问题了，建议你优先使用。\n\n此外，如果业务应用中有短时高频访问的数据，除了lfu策略本身会对数据的访问次数进行自动衰减以外，我再给你个小建议：你可以优先使用volatile-lfu策略，并根据这些数据的访问时限设置它们的过期时间，以免它们留存在缓存中造成污染。",charsets:{cjk:!0},lastUpdated:"2023/04/12, 03:21:35",lastUpdatedTimestamp:1681269695e3},{title:"Pika：基于SSD实现大容量Redis",frontmatter:{title:"Pika：基于SSD实现大容量Redis",date:"2023-04-18T15:02:38.000Z",permalink:"/pages/8f7740/",categories:["中间件","Redis","专栏：Redis 核心技术与实战"],tags:[null]},regularPath:"/%E4%B8%AD%E9%97%B4%E4%BB%B6/05.Redis/05.%E4%B8%93%E6%A0%8F%EF%BC%9ARedis%20%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/28.Pika%EF%BC%9A%E5%9F%BA%E4%BA%8ESSD%E5%AE%9E%E7%8E%B0%E5%A4%A7%E5%AE%B9%E9%87%8FRedis.html",relativePath:"中间件/05.Redis/05.专栏：Redis 核心技术与实战/28.Pika：基于SSD实现大容量Redis.md",key:"v-3aa5fefb",path:"/pages/8f7740/",headers:[{level:2,title:"1 Pika：如何基于 SSD 实现大容量 Redis？",slug:"_1-pika-如何基于-ssd-实现大容量-redis",normalizedTitle:"1 pika：如何基于 ssd 实现大容量 redis？",charIndex:54},{level:3,title:"1.1 大内存 Redis 实例的潜在问题",slug:"_1-1-大内存-redis-实例的潜在问题",normalizedTitle:"1.1 大内存 redis 实例的潜在问题",charIndex:660},{level:3,title:"1.2 Pika 的整体架构",slug:"_1-2-pika-的整体架构",normalizedTitle:"1.2 pika 的整体架构",charIndex:983},{level:3,title:"1.3 Pika 如何基于 SSD 保存更多数据？",slug:"_1-3-pika-如何基于-ssd-保存更多数据",normalizedTitle:"1.3 pika 如何基于 ssd 保存更多数据？",charIndex:1851},{level:4,title:"1.3.1 使用 RocksDB 来存储数据",slug:"_1-3-1-使用-rocksdb-来存储数据",normalizedTitle:"1.3.1 使用 rocksdb 来存储数据",charIndex:1880},{level:3,title:"1.4 Pika 如何实现 Redis 数据类型兼容？",slug:"_1-4-pika-如何实现-redis-数据类型兼容",normalizedTitle:"1.4 pika 如何实现 redis 数据类型兼容？",charIndex:3258},{level:4,title:"1.4.1 List 类型",slug:"_1-4-1-list-类型",normalizedTitle:"1.4.1 list 类型",charIndex:3641},{level:4,title:"1.4.2 Set 类型",slug:"_1-4-2-set-类型",normalizedTitle:"1.4.2 set 类型",charIndex:4042},{level:4,title:"1.4.3 Hash 类型",slug:"_1-4-3-hash-类型",normalizedTitle:"1.4.3 hash 类型",charIndex:4219},{level:4,title:"1.4.4 Sorted Set 类型",slug:"_1-4-4-sorted-set-类型",normalizedTitle:"1.4.4 sorted set 类型",charIndex:4384},{level:3,title:"1.5 Pika 的其他优势与不足",slug:"_1-5-pika-的其他优势与不足",normalizedTitle:"1.5 pika 的其他优势与不足",charIndex:4859},{level:3,title:"1.6 小结",slug:"_1-6-小结",normalizedTitle:"1.6 小结",charIndex:5790}],headersStr:"1 Pika：如何基于 SSD 实现大容量 Redis？ 1.1 大内存 Redis 实例的潜在问题 1.2 Pika 的整体架构 1.3 Pika 如何基于 SSD 保存更多数据？ 1.3.1 使用 RocksDB 来存储数据 1.4 Pika 如何实现 Redis 数据类型兼容？ 1.4.1 List 类型 1.4.2 Set 类型 1.4.3 Hash 类型 1.4.4 Sorted Set 类型 1.5 Pika 的其他优势与不足 1.6 小结",content:"> 参考：\n> \n>  * 28 Pika：如何基于 SSD 实现大容量 Redis？| 极客时间\n\n\n# 1 Pika：如何基于 SSD 实现大容量 Redis？\n\n在应用 Redis 时，随着业务数据的增加，会需要 Redis 保存更多的数据，这时会想到使用 Redis 切片集群，从而把数据分散保存到多个实例上，但这样会导致集群的实例规模增加，让集群的运维变得复杂。\n\n还有一种方法是增加 Redis 单个实例的内存容量，形成大内存实例，从而减少所需的 Redis 实例的个数。这是个好主意，但并不完美：基于大内存的大容量实例在实例恢复、主从同步过程中会引起一系列潜在问题，例如恢复时间增长、主从切换开销大、缓冲区易溢出。\n\n这该怎么办呢？我推荐你使用固态硬盘（SSD），它成本很低（每 GB 的成本约是内存的十分之一），且容量大，读写速度快，我们可以基于SSD来实现大容量的Redis实例。360公司DBA和基础架构组联合开发的 Pika 键值数据库，正好实现了这一需求。\n\nPika 在刚开始设计时有两个目标：\n\n 1. 单实例可以保存大容量数据，同时避免了实例恢复和主从同步时的潜在问题；\n 2. 和 Redis 数据类型保持兼容，可以支持使用 Redis 的应用平滑地迁移到 Pika 上。\n\n所以，如果你一直在使用 Redis，并且想使用 SSD 来扩展单实例容量，Pika 就是一个很好的选择。\n\n本节将先介绍基于大内存实现大容量 Redis 实例的潜在问题，然后介绍 Pika 的相关设计。\n\n\n# 1.1 大内存 Redis 实例的潜在问题\n\nRedis 使用内存保存数据，内存容量增加后，就会带来两方面的潜在问题：\n\n * 内存快照 RDB 生成和恢复效率低：这会导致 Redis 实例阻塞过久；\n * 主从节点全量同步时长增加：如果 RDB 文件很大，会导致全量同步的时长增加，效率不高，而且还可能会导致复制缓冲区溢出。一旦缓冲区溢出了，主从节点间就会又开始全量同步，影响业务应用的正常使用。如果我们增加复制缓冲区的容量，这又会消耗宝贵的内存资源。\n\n那么，Pika 是如何解决这两方面的问题呢？这就要提到 Pika 中的关键模块 RocksDB、binlog 机制和 Nemo 了，这些模块都是 Pika 架构中的重要组成部分。\n\n\n# 1.2 Pika 的整体架构\n\nPika 键值数据库的整体架构中包括了五部分，分别是网络框架、Pika 线程模块、Nemo 存储模块、RocksDB 和 binlog 机制，如下图所示：\n\n这五个部分分别实现了不同的功能，下面我一个个来介绍下。\n\n首先，网络框架主要负责底层网络请求的接收和发送。Pika的网络框架是对操作系统底层的网络函数进行了封装。Pika在进行网络通信时，可以直接调用网络框架封装好的函数。\n\n其次，Pika 线程模块采用了多线程模型来具体处理客户端请求，包括一个请求分发线程（DispatchThread）、一组工作线程（WorkerThread）以及一个线程池（ThreadPool）。\n\n请求分发线程专门监听网络端口，一旦接收到客户端的连接请求后，就和客户端建立连接，并把连接交由工作线程处理。工作线程负责接收客户端连接上发送的具体命令请求，并把命令请求封装成Task，再交给线程池中的线程，由这些线程进行实际的数据存取处理，如下图所示：\n\n在实际应用Pika的时候，我们可以通过增加工作线程数和线程池中的线程数，来提升Pika的请求处理吞吐率，进而满足业务层对数据处理性能的需求。\n\nNemo 模块很容易理解，它实现了 Pika 和 Redis 的数据类型兼容。这样一来，当我们把 Redis 服务迁移到 Pika 时，不用修改业务应用中操作 Redis 的代码，而且还可以继续应用运维 Redis 的经验，这使得 Pika 的学习成本就较低。Nemo 模块对数据类型的具体转换机制是我们要重点关心的，下面我会具体介绍。\n\n最后，我们再来看看 RocksDB 提供的基于SSD保存数据的功能。它使得 Pika 可以不用大容量的内存，就能保存更多数据，还避免了使用内存快照。而且，Pika使用 binlog 机制记录写命令，用于主从节点的命令同步，避免了刚刚所说的大内存实例在主从同步过程中的潜在问题。\n\n接下来，我们就来具体了解下，Pika 是如何使用 RocksDB 和 binlog 机制的。\n\n\n# 1.3 Pika 如何基于 SSD 保存更多数据？\n\n# 1.3.1 使用 RocksDB 来存储数据\n\n为了把数据保存到 SSD，Pika 使用了持久化 KV 数据库 RocksDB。这里只需要了解 RocksDB 的基本数据读写机制就可以：\n\n * Memtable 是一个小内存空间，大约几MB或几十MB。两个 Memtable 来交替缓存写入数据。\n\n根据上图可以看到，RocksDB 会先用 Memtable 缓存数据，再将数据快速写入SSD，即使数据量再大，所有数据也都能保存到SSD中。而且，Memtable本身容量不大，即使RocksDB使用了两个Memtable，也不会占用过多的内存，这样一来，Pika在保存大容量数据时，也不用占据太大的内存空间了。\n\n数据查找方法：当Pika需要读取数据的时候，RocksDB会先在Memtable中查询是否有要读取的数据。这是因为，最新的数据都是先写入到Memtable中的。如果Memtable中没有要读取的数据，RocksDB会再查询保存在SSD上的数据文件，如下图所示：\n\n到这里，你就了解了，当使用了RocksDB保存数据后，Pika就可以把大量数据保存到大容量的SSD上了，实现了大容量实例。\n\n不过，我刚才向你介绍过，当使用大内存实例保存大量数据时，Redis会面临RDB生成和恢复的效率问题，以及主从同步时的效率和缓冲区溢出问题。那么，当Pika保存大量数据时，还会面临相同的问题吗？其实不会了，接下来分析一下。\n\n * 一方面，Pika基于RocksDB保存了数据文件，直接读取数据文件就能恢复，不需要再通过内存快照进行恢复了。而且，Pika从库在进行全量同步时，可以直接从主库拷贝数据文件，不需要使用内存快照，这样一来，Pika就避免了大内存快照生成效率低的问题。\n * 另一方面，Pika使用了binlog机制实现增量命令同步，既节省了内存，还避免了缓冲区溢出的问题。binlog是保存在SSD上的文件，Pika接收到写命令后，在把数据写入Memtable时，也会把命令操作写到binlog文件中。和Redis类似，当全量同步结束后，从库会从binlog中把尚未同步的命令读取过来，这样就可以和主库的数据保持一致。当进行增量同步时，从库也是把自己已经复制的偏移量发给主库，主库把尚未同步的命令发给从库，来保持主从库的数据一致。\n\n和Redis使用缓冲区相比，使用binlog好处是非常明显的：binlog是保存在SSD上的文件，文件大小不像缓冲区，会受到内存容量的较多限制。而且，当binlog文件增大后，还可以通过轮替操作，生成新的binlog文件，再把旧的binlog文件独立保存。这样一来，即使Pika实例保存了大量的数据，在同步过程中也不会出现缓冲区溢出的问题了。\n\n简单小结下：Pika 使用 RocksDB 把大量数据保存到了 SSD，同时避免了内存快照的生成和恢复问题。而且，Pika 使用 binlog 机制进行主从同步，避免大内存时的影响，Pika 的第一个设计目标就实现了。\n\n接下来，我们再来看 Pika 是如何实现第二个设计目标的，也就是如何和 Redis 兼容。毕竟，如果不兼容的话，原来使用 Redis 的业务就无法平滑迁移到 Pika 上使用了，也就没办法利用 Pika 保存大容量数据的优势了。\n\n\n# 1.4 Pika 如何实现 Redis 数据类型兼容？\n\nPika 的底层存储使用了 RocksDB 来保存数据，但是，RocksDB 只提供了单值的键值对类型，而 Redis 键值对中的值却可以是集合类型。这样，对于集合类型就无法直接存储在 RocksDB 中，需要 Pika 的 Nemo 模块来完成将 Redis 集合类型 -> 单值 kv 的转换。\n\n简单来说，可以将 Redis 的集合类型分成两类：\n\n * 一类是 List 和 Set 类型，它们的集合中每个元素都是单值；\n * 另一类是 Hash 和 Sorted Set 类型，它们的集合中的元素都是 pair，其中，Hash 集合元素是 field-value 类型，而 Sorted Set 集合元素是 member-score 类型。\n\n下面看一下 Nemo 模块是如何做的这种转换。\n\n# 1.4.1 List 类型\n\n在Pika中，List集合的key被嵌入到了单值键值对的键当中，用key字段表示；而List集合的元素值，则被嵌入到单值键值对的值当中，用value字段表示。因为List集合中的元素是有序的，所以，Nemo模块还在单值键值对的key后面增加了sequence字段，表示当前元素在List中的顺序，同时，还在value的前面增加了previous sequence和next sequence这两个字段，分别表示当前元素的前一个元素和后一个元素。\n\n此外，在单值键值对的key前面，Nemo模块还增加了一个值“l”，表示当前数据是List类型，以及增加了一个1字节的size字段，表示List集合key的大小。在单值键值对的value后面，Nemo模块还增加了version和ttl字段，分别表示当前数据的版本号和剩余存活时间（用来支持过期key功能），如下图所示：\n\n# 1.4.2 Set 类型\n\nSet集合的key和元素member值，都被嵌入到了Pika单值键值对的键当中，分别用key和member字段表示。同时，和List集合类似，单值键值对的key前面有值“s”，用来表示数据是Set类型，同时还有size字段，用来表示key的大小。Pika单值键值对的值只保存了数据的版本信息和剩余存活时间，如下图所示：\n\n# 1.4.3 Hash 类型\n\n对于Hash类型来说，Hash集合的key被嵌入到单值键值对的键当中，用key字段表示，而Hash集合元素的field也被嵌入到单值键值对的键当中，紧接着key字段，用field字段表示。Hash集合元素的value则是嵌入到单值键值对的值当中，并且也带有版本信息和剩余存活时间，如下图所示：\n\n# 1.4.4 Sorted Set 类型\n\n对于Sorted Set类型来说，该类型是需要能够按照集合元素的score值排序的，而RocksDB只支持按照单值键值对的键来排序。所以，Nemo模块在转换数据时，就把Sorted Set集合key、元素的score和member值都嵌入到了单值键值对的键当中，此时，单值键值对中的值只保存了数据的版本信息和剩余存活时间，如下图所示：\n\n采用了上面的转换方式之后，Pika不仅能兼容支持Redis的数据类型，而且还保留了这些数据类型的特征，例如List的元素保序、Sorted Set的元素按score排序。了解了Pika的转换机制后，你就会明白，如果你有业务应用计划从使用Redis切换到使用Pika，就不用担心面临因为操作接口不兼容而要修改业务应用的问题了。\n\n----------------------------------------\n\n前面分析了 Pika 的两大优势：\n\n * 基于 SSD 保存大量数据\n * 与 Redis 兼容\n\n接下来看一下 Pika 的其他优势和潜在不足。\n\n\n# 1.5 Pika 的其他优势与不足\n\n跟Redis相比，Pika最大的特点就是使用了SSD来保存数据，这个特点能带来的最直接好处就是，Pika单实例能保存更多的数据了，实现了实例数据扩容。除此之外，Pika 还有两个额外优势：\n\n * 实例重启快。Pika的数据在写入数据库时，是会保存到SSD上的。当Pika实例重启时，可以直接从SSD上的数据文件中读取数据，不需要像Redis一样，从RDB文件全部重新加载数据或是从AOF文件中全部回放操作，这极大地提高了Pika实例的重启速度，可以快速处理业务应用请求。\n * 主从库重新执行全量同步的风险低。Pika通过binlog机制实现写命令的增量同步，不再受内存缓冲区大小的限制，所以，即使在数据量很大导致主从库同步耗时很长的情况下，Pika也不用担心缓冲区溢出而触发的主从库重新全量同步。\n\n但 Pika 也有一些不足：\n\n虽然它保持了Redis操作接口，也能实现数据库扩容，但当把数据保存到SSD上后，会降低数据的访问性能。这是因为，数据操作毕竟不能在内存中直接执行了，而是要在底层的SSD中进行存取，这肯定会影响，Pika的性能。而且，我们还需要把binlog机制记录的写命令同步到SSD上，这会降低Pika的写性能。\n\n不过，Pika的多线程模型，可以同时使用多个线程进行数据读写，这在一定程度上弥补了从SSD存取数据造成的性能损失。当然，你也可以使用高配的SSD来提升访问性能，进而减少读写SSD对Pika性能的影响。\n\n为了帮助你更直观地了解Pika的性能情况，我再给你提供一张表，这是Pika 官网 上提供的测试数据：\n\n这些数据是在Pika 3.2版本中，String和Hash类型在多线程情况下的基本操作性能结果。从表中可以看到，在不写binlog时，Pika的SET/GET、HSET/HGET的性能都能达到200K OPS以上，而一旦增加了写binlog操作，SET和HSET操作性能大约下降了41%，只有约120K OPS。\n\n所以，我们在使用Pika时，需要在单实例扩容的必要性和可能的性能损失间做个权衡。如果保存大容量数据是我们的首要需求，那么，Pika是一个不错的解决方案。\n\n\n# 1.6 小结\n\n这节课，我们学习了基于SSD给Redis单实例进行扩容的技术方案Pika。跟Redis相比，Pika的好处非常明显：既支持Redis操作接口，又能支持保存大容量的数据。如果你原来就在应用Redis，现在想进行扩容，那么，Pika无疑是一个很好的选择，无论是代码迁移还是运维管理，Pika基本不需要额外的工作量。\n\n不过，Pika毕竟是把数据保存到了SSD上，数据访问要读写SSD，所以，读写性能要弱于Redis。针对这一点，我给你提供两个降低读写SSD对Pika的性能影响的小建议：\n\n 1. 利用Pika的多线程模型，增加线程数量，提升Pika的并发请求处理能力；\n 2. 为Pika配置高配的SSD，提升SSD自身的访问性能。\n\n最后，我想再给你一个小提示。Pika本身提供了很多工具，可以帮助我们把Redis数据迁移到Pika，或者是把Redis请求转发给Pika。比如说，我们使用aof_to_pika命令，并且指定Redis的AOF文件以及Pika的连接信息，就可以把Redis数据迁移到Pika中了，如下所示：\n\naof_to_pika -i [Redis AOF文件] -h [Pika IP] -p [Pika port] -a [认证信息]\n\n\n1\n\n\n关于这些工具的信息，你都可以直接在Pika的 GitHub 上找到。而且，Pika本身也还在迭代开发中，我也建议你多去看看GitHub，进一步地了解它。这样，你就可以获得Pika的最新进展，也能更好地把它应用到你的业务实践中。",normalizedContent:"> 参考：\n> \n>  * 28 pika：如何基于 ssd 实现大容量 redis？| 极客时间\n\n\n# 1 pika：如何基于 ssd 实现大容量 redis？\n\n在应用 redis 时，随着业务数据的增加，会需要 redis 保存更多的数据，这时会想到使用 redis 切片集群，从而把数据分散保存到多个实例上，但这样会导致集群的实例规模增加，让集群的运维变得复杂。\n\n还有一种方法是增加 redis 单个实例的内存容量，形成大内存实例，从而减少所需的 redis 实例的个数。这是个好主意，但并不完美：基于大内存的大容量实例在实例恢复、主从同步过程中会引起一系列潜在问题，例如恢复时间增长、主从切换开销大、缓冲区易溢出。\n\n这该怎么办呢？我推荐你使用固态硬盘（ssd），它成本很低（每 gb 的成本约是内存的十分之一），且容量大，读写速度快，我们可以基于ssd来实现大容量的redis实例。360公司dba和基础架构组联合开发的 pika 键值数据库，正好实现了这一需求。\n\npika 在刚开始设计时有两个目标：\n\n 1. 单实例可以保存大容量数据，同时避免了实例恢复和主从同步时的潜在问题；\n 2. 和 redis 数据类型保持兼容，可以支持使用 redis 的应用平滑地迁移到 pika 上。\n\n所以，如果你一直在使用 redis，并且想使用 ssd 来扩展单实例容量，pika 就是一个很好的选择。\n\n本节将先介绍基于大内存实现大容量 redis 实例的潜在问题，然后介绍 pika 的相关设计。\n\n\n# 1.1 大内存 redis 实例的潜在问题\n\nredis 使用内存保存数据，内存容量增加后，就会带来两方面的潜在问题：\n\n * 内存快照 rdb 生成和恢复效率低：这会导致 redis 实例阻塞过久；\n * 主从节点全量同步时长增加：如果 rdb 文件很大，会导致全量同步的时长增加，效率不高，而且还可能会导致复制缓冲区溢出。一旦缓冲区溢出了，主从节点间就会又开始全量同步，影响业务应用的正常使用。如果我们增加复制缓冲区的容量，这又会消耗宝贵的内存资源。\n\n那么，pika 是如何解决这两方面的问题呢？这就要提到 pika 中的关键模块 rocksdb、binlog 机制和 nemo 了，这些模块都是 pika 架构中的重要组成部分。\n\n\n# 1.2 pika 的整体架构\n\npika 键值数据库的整体架构中包括了五部分，分别是网络框架、pika 线程模块、nemo 存储模块、rocksdb 和 binlog 机制，如下图所示：\n\n这五个部分分别实现了不同的功能，下面我一个个来介绍下。\n\n首先，网络框架主要负责底层网络请求的接收和发送。pika的网络框架是对操作系统底层的网络函数进行了封装。pika在进行网络通信时，可以直接调用网络框架封装好的函数。\n\n其次，pika 线程模块采用了多线程模型来具体处理客户端请求，包括一个请求分发线程（dispatchthread）、一组工作线程（workerthread）以及一个线程池（threadpool）。\n\n请求分发线程专门监听网络端口，一旦接收到客户端的连接请求后，就和客户端建立连接，并把连接交由工作线程处理。工作线程负责接收客户端连接上发送的具体命令请求，并把命令请求封装成task，再交给线程池中的线程，由这些线程进行实际的数据存取处理，如下图所示：\n\n在实际应用pika的时候，我们可以通过增加工作线程数和线程池中的线程数，来提升pika的请求处理吞吐率，进而满足业务层对数据处理性能的需求。\n\nnemo 模块很容易理解，它实现了 pika 和 redis 的数据类型兼容。这样一来，当我们把 redis 服务迁移到 pika 时，不用修改业务应用中操作 redis 的代码，而且还可以继续应用运维 redis 的经验，这使得 pika 的学习成本就较低。nemo 模块对数据类型的具体转换机制是我们要重点关心的，下面我会具体介绍。\n\n最后，我们再来看看 rocksdb 提供的基于ssd保存数据的功能。它使得 pika 可以不用大容量的内存，就能保存更多数据，还避免了使用内存快照。而且，pika使用 binlog 机制记录写命令，用于主从节点的命令同步，避免了刚刚所说的大内存实例在主从同步过程中的潜在问题。\n\n接下来，我们就来具体了解下，pika 是如何使用 rocksdb 和 binlog 机制的。\n\n\n# 1.3 pika 如何基于 ssd 保存更多数据？\n\n# 1.3.1 使用 rocksdb 来存储数据\n\n为了把数据保存到 ssd，pika 使用了持久化 kv 数据库 rocksdb。这里只需要了解 rocksdb 的基本数据读写机制就可以：\n\n * memtable 是一个小内存空间，大约几mb或几十mb。两个 memtable 来交替缓存写入数据。\n\n根据上图可以看到，rocksdb 会先用 memtable 缓存数据，再将数据快速写入ssd，即使数据量再大，所有数据也都能保存到ssd中。而且，memtable本身容量不大，即使rocksdb使用了两个memtable，也不会占用过多的内存，这样一来，pika在保存大容量数据时，也不用占据太大的内存空间了。\n\n数据查找方法：当pika需要读取数据的时候，rocksdb会先在memtable中查询是否有要读取的数据。这是因为，最新的数据都是先写入到memtable中的。如果memtable中没有要读取的数据，rocksdb会再查询保存在ssd上的数据文件，如下图所示：\n\n到这里，你就了解了，当使用了rocksdb保存数据后，pika就可以把大量数据保存到大容量的ssd上了，实现了大容量实例。\n\n不过，我刚才向你介绍过，当使用大内存实例保存大量数据时，redis会面临rdb生成和恢复的效率问题，以及主从同步时的效率和缓冲区溢出问题。那么，当pika保存大量数据时，还会面临相同的问题吗？其实不会了，接下来分析一下。\n\n * 一方面，pika基于rocksdb保存了数据文件，直接读取数据文件就能恢复，不需要再通过内存快照进行恢复了。而且，pika从库在进行全量同步时，可以直接从主库拷贝数据文件，不需要使用内存快照，这样一来，pika就避免了大内存快照生成效率低的问题。\n * 另一方面，pika使用了binlog机制实现增量命令同步，既节省了内存，还避免了缓冲区溢出的问题。binlog是保存在ssd上的文件，pika接收到写命令后，在把数据写入memtable时，也会把命令操作写到binlog文件中。和redis类似，当全量同步结束后，从库会从binlog中把尚未同步的命令读取过来，这样就可以和主库的数据保持一致。当进行增量同步时，从库也是把自己已经复制的偏移量发给主库，主库把尚未同步的命令发给从库，来保持主从库的数据一致。\n\n和redis使用缓冲区相比，使用binlog好处是非常明显的：binlog是保存在ssd上的文件，文件大小不像缓冲区，会受到内存容量的较多限制。而且，当binlog文件增大后，还可以通过轮替操作，生成新的binlog文件，再把旧的binlog文件独立保存。这样一来，即使pika实例保存了大量的数据，在同步过程中也不会出现缓冲区溢出的问题了。\n\n简单小结下：pika 使用 rocksdb 把大量数据保存到了 ssd，同时避免了内存快照的生成和恢复问题。而且，pika 使用 binlog 机制进行主从同步，避免大内存时的影响，pika 的第一个设计目标就实现了。\n\n接下来，我们再来看 pika 是如何实现第二个设计目标的，也就是如何和 redis 兼容。毕竟，如果不兼容的话，原来使用 redis 的业务就无法平滑迁移到 pika 上使用了，也就没办法利用 pika 保存大容量数据的优势了。\n\n\n# 1.4 pika 如何实现 redis 数据类型兼容？\n\npika 的底层存储使用了 rocksdb 来保存数据，但是，rocksdb 只提供了单值的键值对类型，而 redis 键值对中的值却可以是集合类型。这样，对于集合类型就无法直接存储在 rocksdb 中，需要 pika 的 nemo 模块来完成将 redis 集合类型 -> 单值 kv 的转换。\n\n简单来说，可以将 redis 的集合类型分成两类：\n\n * 一类是 list 和 set 类型，它们的集合中每个元素都是单值；\n * 另一类是 hash 和 sorted set 类型，它们的集合中的元素都是 pair，其中，hash 集合元素是 field-value 类型，而 sorted set 集合元素是 member-score 类型。\n\n下面看一下 nemo 模块是如何做的这种转换。\n\n# 1.4.1 list 类型\n\n在pika中，list集合的key被嵌入到了单值键值对的键当中，用key字段表示；而list集合的元素值，则被嵌入到单值键值对的值当中，用value字段表示。因为list集合中的元素是有序的，所以，nemo模块还在单值键值对的key后面增加了sequence字段，表示当前元素在list中的顺序，同时，还在value的前面增加了previous sequence和next sequence这两个字段，分别表示当前元素的前一个元素和后一个元素。\n\n此外，在单值键值对的key前面，nemo模块还增加了一个值“l”，表示当前数据是list类型，以及增加了一个1字节的size字段，表示list集合key的大小。在单值键值对的value后面，nemo模块还增加了version和ttl字段，分别表示当前数据的版本号和剩余存活时间（用来支持过期key功能），如下图所示：\n\n# 1.4.2 set 类型\n\nset集合的key和元素member值，都被嵌入到了pika单值键值对的键当中，分别用key和member字段表示。同时，和list集合类似，单值键值对的key前面有值“s”，用来表示数据是set类型，同时还有size字段，用来表示key的大小。pika单值键值对的值只保存了数据的版本信息和剩余存活时间，如下图所示：\n\n# 1.4.3 hash 类型\n\n对于hash类型来说，hash集合的key被嵌入到单值键值对的键当中，用key字段表示，而hash集合元素的field也被嵌入到单值键值对的键当中，紧接着key字段，用field字段表示。hash集合元素的value则是嵌入到单值键值对的值当中，并且也带有版本信息和剩余存活时间，如下图所示：\n\n# 1.4.4 sorted set 类型\n\n对于sorted set类型来说，该类型是需要能够按照集合元素的score值排序的，而rocksdb只支持按照单值键值对的键来排序。所以，nemo模块在转换数据时，就把sorted set集合key、元素的score和member值都嵌入到了单值键值对的键当中，此时，单值键值对中的值只保存了数据的版本信息和剩余存活时间，如下图所示：\n\n采用了上面的转换方式之后，pika不仅能兼容支持redis的数据类型，而且还保留了这些数据类型的特征，例如list的元素保序、sorted set的元素按score排序。了解了pika的转换机制后，你就会明白，如果你有业务应用计划从使用redis切换到使用pika，就不用担心面临因为操作接口不兼容而要修改业务应用的问题了。\n\n----------------------------------------\n\n前面分析了 pika 的两大优势：\n\n * 基于 ssd 保存大量数据\n * 与 redis 兼容\n\n接下来看一下 pika 的其他优势和潜在不足。\n\n\n# 1.5 pika 的其他优势与不足\n\n跟redis相比，pika最大的特点就是使用了ssd来保存数据，这个特点能带来的最直接好处就是，pika单实例能保存更多的数据了，实现了实例数据扩容。除此之外，pika 还有两个额外优势：\n\n * 实例重启快。pika的数据在写入数据库时，是会保存到ssd上的。当pika实例重启时，可以直接从ssd上的数据文件中读取数据，不需要像redis一样，从rdb文件全部重新加载数据或是从aof文件中全部回放操作，这极大地提高了pika实例的重启速度，可以快速处理业务应用请求。\n * 主从库重新执行全量同步的风险低。pika通过binlog机制实现写命令的增量同步，不再受内存缓冲区大小的限制，所以，即使在数据量很大导致主从库同步耗时很长的情况下，pika也不用担心缓冲区溢出而触发的主从库重新全量同步。\n\n但 pika 也有一些不足：\n\n虽然它保持了redis操作接口，也能实现数据库扩容，但当把数据保存到ssd上后，会降低数据的访问性能。这是因为，数据操作毕竟不能在内存中直接执行了，而是要在底层的ssd中进行存取，这肯定会影响，pika的性能。而且，我们还需要把binlog机制记录的写命令同步到ssd上，这会降低pika的写性能。\n\n不过，pika的多线程模型，可以同时使用多个线程进行数据读写，这在一定程度上弥补了从ssd存取数据造成的性能损失。当然，你也可以使用高配的ssd来提升访问性能，进而减少读写ssd对pika性能的影响。\n\n为了帮助你更直观地了解pika的性能情况，我再给你提供一张表，这是pika 官网 上提供的测试数据：\n\n这些数据是在pika 3.2版本中，string和hash类型在多线程情况下的基本操作性能结果。从表中可以看到，在不写binlog时，pika的set/get、hset/hget的性能都能达到200k ops以上，而一旦增加了写binlog操作，set和hset操作性能大约下降了41%，只有约120k ops。\n\n所以，我们在使用pika时，需要在单实例扩容的必要性和可能的性能损失间做个权衡。如果保存大容量数据是我们的首要需求，那么，pika是一个不错的解决方案。\n\n\n# 1.6 小结\n\n这节课，我们学习了基于ssd给redis单实例进行扩容的技术方案pika。跟redis相比，pika的好处非常明显：既支持redis操作接口，又能支持保存大容量的数据。如果你原来就在应用redis，现在想进行扩容，那么，pika无疑是一个很好的选择，无论是代码迁移还是运维管理，pika基本不需要额外的工作量。\n\n不过，pika毕竟是把数据保存到了ssd上，数据访问要读写ssd，所以，读写性能要弱于redis。针对这一点，我给你提供两个降低读写ssd对pika的性能影响的小建议：\n\n 1. 利用pika的多线程模型，增加线程数量，提升pika的并发请求处理能力；\n 2. 为pika配置高配的ssd，提升ssd自身的访问性能。\n\n最后，我想再给你一个小提示。pika本身提供了很多工具，可以帮助我们把redis数据迁移到pika，或者是把redis请求转发给pika。比如说，我们使用aof_to_pika命令，并且指定redis的aof文件以及pika的连接信息，就可以把redis数据迁移到pika中了，如下所示：\n\naof_to_pika -i [redis aof文件] -h [pika ip] -p [pika port] -a [认证信息]\n\n\n1\n\n\n关于这些工具的信息，你都可以直接在pika的 github 上找到。而且，pika本身也还在迭代开发中，我也建议你多去看看github，进一步地了解它。这样，你就可以获得pika的最新进展，也能更好地把它应用到你的业务实践中。",charsets:{cjk:!0},lastUpdated:"2023/04/18, 14:13:32",lastUpdatedTimestamp:1681827212e3},{title:"无锁的原子操作和分布式锁",frontmatter:{title:"无锁的原子操作和分布式锁",date:"2023-04-18T20:18:11.000Z",permalink:"/pages/5a1b01/",categories:["中间件","Redis","专栏：Redis 核心技术与实战"],tags:[null]},regularPath:"/%E4%B8%AD%E9%97%B4%E4%BB%B6/05.Redis/05.%E4%B8%93%E6%A0%8F%EF%BC%9ARedis%20%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/29.%E6%97%A0%E9%94%81%E7%9A%84%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C%E5%92%8C%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81.html",relativePath:"中间件/05.Redis/05.专栏：Redis 核心技术与实战/29.无锁的原子操作和分布式锁.md",key:"v-35ef0b3a",path:"/pages/5a1b01/",headers:[{level:2,title:"1. 无锁的原子操作",slug:"_1-无锁的原子操作",normalizedTitle:"1. 无锁的原子操作",charIndex:252},{level:3,title:"1.1 并发访问中需要对什么进行控制？",slug:"_1-1-并发访问中需要对什么进行控制",normalizedTitle:"1.1 并发访问中需要对什么进行控制？",charIndex:357},{level:3,title:"1.2 Redis 的两种原子操作方法",slug:"_1-2-redis-的两种原子操作方法",normalizedTitle:"1.2 redis 的两种原子操作方法",charIndex:1119},{level:4,title:"1.2.1 Redis 本身的单命令操作",slug:"_1-2-1-redis-本身的单命令操作",normalizedTitle:"1.2.1 redis 本身的单命令操作",charIndex:1261},{level:4,title:"1.2.2 Lua 脚本",slug:"_1-2-2-lua-脚本",normalizedTitle:"1.2.2 lua 脚本",charIndex:1660},{level:2,title:"2. 如何使用 Redis 实现分布式锁？",slug:"_2-如何使用-redis-实现分布式锁",normalizedTitle:"2. 如何使用 redis 实现分布式锁？",charIndex:3305},{level:3,title:"2.1 单机上的锁和分布式锁的联系与区别",slug:"_2-1-单机上的锁和分布式锁的联系与区别",normalizedTitle:"2.1 单机上的锁和分布式锁的联系与区别",charIndex:3561},{level:3,title:"2.2 基于单个 Redis 节点实现分布式锁",slug:"_2-2-基于单个-redis-节点实现分布式锁",normalizedTitle:"2.2 基于单个 redis 节点实现分布式锁",charIndex:4276},{level:3,title:"2.3 基于多个 Redis 节点实现高可靠的分布式锁",slug:"_2-3-基于多个-redis-节点实现高可靠的分布式锁",normalizedTitle:"2.3 基于多个 redis 节点实现高可靠的分布式锁",charIndex:6518},{level:3,title:"2.4 小结",slug:"_2-4-小结",normalizedTitle:"2.4 小结",charIndex:7713}],headersStr:"1. 无锁的原子操作 1.1 并发访问中需要对什么进行控制？ 1.2 Redis 的两种原子操作方法 1.2.1 Redis 本身的单命令操作 1.2.2 Lua 脚本 2. 如何使用 Redis 实现分布式锁？ 2.1 单机上的锁和分布式锁的联系与区别 2.2 基于单个 Redis 节点实现分布式锁 2.3 基于多个 Redis 节点实现高可靠的分布式锁 2.4 小结",content:'> 参考：\n> \n>  * 29 无锁的原子操作：Redis 如何应对并发访问？| 极客时间\n>  * 30 如何使用 Redis 实现分布式锁？| 极客时间\n\n并发访问控制：是指对多个客户端访问操作同一份数据的过程进行控制，以保证任何一个客户端发送的操作在Redis实例上执行时具有互斥性。例如，客户端A的访问操作在执行时，客户端B的操作不能执行，需要等到A的操作结束后，才能执行。\n\n业务系统不可避免会遇到并发访问的问题，为保证并发访问的正确性，Redis 提供了两种方法：加锁和原子操作。\n\n\n# 1. 无锁的原子操作\n\n原子操作是一种提供并发访问控制的方法，是指执行过程保持原子性的操作，而且原子操作执行时并不需要再加锁，实现了无锁操作。这样一来，既能保证并发控制，还能减少对系统并发性能的影响。\n\n\n# 1.1 并发访问中需要对什么进行控制？\n\n并发访问控制对应的操作主要是数据修改操作。当客户端需要修改数据时，基本流程分成两步：\n\n 1. 客户端先把数据读取到本地，在本地进行修改；\n 2. 客户端修改完数据后，再写回 Redis。\n\n这个流程被称为 Read-Modify-Write（RMW）操作。当有多个客户端对同一份数据执行RMW操作的话，我们就需要让RMW操作涉及的代码以原子性方式执行。访问同一份数据的RMW操作代码，就叫做临界区代码。\n\n不过，当有多个客户端并发执行临界区代码时，就会存在一些潜在问题，接下来，我用一个多客户端更新商品库存的例子来解释一下。\n\n我们先看下临界区代码。假设客户端要对商品库存执行扣减1的操作，伪代码如下所示：\n\ncurrent = GET(id)\ncurrent--\nSET(id, current)\n\n\n1\n2\n3\n\n\n如果我们对临界区代码的执行没有控制机制，就可能出现数据更新错误。如下图是两个客户端同时执行临界区代码而导致的错误：\n\n上图相比于正确的处理逻辑，库存值明显更新错了。出现这个现象的原因是：多个客户端的 RMW 这三个操作在执行时不具有互斥性，两个客户端基于相同的初始值进行修改，而不是基于前一个客户端修改后的值再修改。\n\n为了保证数据并发修改的正确性，我们可以使用锁来控制临界区代码的执行情况，如下所示：\n\n \n\n\n\n \n\n\nLOCK()\ncurrent = GET(id)\ncurrent--\nSET(id, current)\nUNLOCK()\n\n\n1\n2\n3\n4\n5\n\n\n虽然加锁保证了互斥性，但是加锁会降低并发性能。\n\n和加锁类似，原子操作也能实现并发控制，但是原子操作对系统并发性能的影响较小，接下来，我们就来了解下 Redis 中的原子操作。\n\n\n# 1.2 Redis 的两种原子操作方法\n\n为了实现并发控制要求的临界区代码互斥执行，Redis的原子操作采用了两种方法：\n\n 1. 把多个操作在 Redis 中实现成一个操作，也就是单命令操作；\n 2. 把多个操作写到一个 Lua 脚本中，以原子性方式执行单个 Lua 脚本。\n\n# 1.2.1 Redis 本身的单命令操作\n\nRedis 是使用单线程来串行处理客户端的请求操作命令的，所以，当 Redis 执行某个命令操作时，其他命令是无法执行的，这相当于命令操作是互斥执行的。当然，Redis 的快照生成、AOF 重写这些操作，可以使用后台线程或者是子进程执行，也就是和主线程的操作并行执行。不过，这些操作只是读取数据，不会修改数据，所以，我们并不需要对它们做并发控制。\n\n另外，Redis 还提供了 INCR/DECR 命令对数据进行增值/减值操作。，这个命令将 RMW 三个操作变为一个原子操作了。\n\n比如说，在刚才的库存扣减例子中，客户端可以使用下面的代码，直接完成对商品id的库存值减1操作。即使有多个客户端执行下面的代码，也不用担心出现库存值扣减错误的问题：\n\nDECR id\n\n\n1\n\n\n但当我们想要将更复杂的操作变成原子操作时，就需要使用 Lua 脚本了。\n\n# 1.2.2 Lua 脚本\n\nRedis 会把整个 Lua 脚本作为一个整体使用 EVAL 命令来执行，在执行的过程中不会被其他命令打断，从而保证了 Lua 脚本中操作的原子性。\n\n下面举个例子来解释 Lua 的使用。当一个业务应用的访问用户增加时，我们有时需要限制某个客户端在一定时间范围内的访问次数，比如爆款商品的购买限流、社交网络中的每分钟点赞次数限制等。\n\n那该怎么限制呢？我们可以把客户端IP作为key，把客户端的访问次数作为value，保存到Redis中。客户端每访问一次后，我们就用INCR增加访问次数。不过，在这种场景下，客户端限流其实同时包含了对访问次数和时间范围的限制，例如每分钟的访问次数不能超过20。所以，我们可以在客户端第一次访问时，给对应键值对设置过期时间，例如设置为60s后过期。同时，在客户端每次访问时，我们读取客户端当前的访问次数，如果次数超过阈值，就报错，限制客户端再次访问。你可以看下下面的这段代码，它实现了对客户端每分钟访问次数不超过20次的限制。伪代码如下：\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n//获取ip对应的访问次数\ncurrent = GET(ip)\n//如果超过访问次数超过20次，则报错\nIF current != NULL AND current > 20 THEN\n    ERROR "exceed 20 accesses per second"\nELSE\n    //如果访问次数不足20次，增加一次访问计数\n    value = INCR(ip)\n    //如果是第一次访问，将键值对的过期时间设置为60s后\n    IF value == 1 THEN\n        EXPIRE(ip,60)\n    END\n    //执行其他操作\n    DO THINGS\nEND\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n尽管例子使用了 INCR 来原子性地增加计数，但客户端限流的逻辑不只有计数，还包括访问次数判断和过期时间设置。对于这些操作，我们同样需要保证它们的原子性。否则，如果客户端使用多线程访问，访问次数初始值为0，第一个线程执行了INCR(ip)操作后，第二个线程紧接着也执行了INCR(ip)，此时，ip对应的访问次数就被增加到了2，我们就无法再对这个ip设置过期时间了。这样就会导致，这个ip对应的客户端访问次数达到20次之后，就无法再进行访问了。即使过了60s，也不能再继续访问，显然不符合业务要求。\n\n由于这种复杂的逻辑无法使用单个命令来解决，此时就需要使用 Lua 脚本来保证并发控制。我们可以把访问次数加1、判断访问次数是否为1，以及设置过期时间这三个操作写入一个Lua脚本，如下所示：\n\nlocal current\ncurrent = redis.call("incr",KEYS[1])\nif tonumber(current) == 1 then\n    redis.call("expire",KEYS[1],60)\nend\n\n\n1\n2\n3\n4\n5\n\n\n假设我们编写的脚本名称为 lua.script，我们接着就可以使用 Redis 客户端，带上 eval 选项，来执行该脚本。脚本所需的参数将通过以下命令中的 keys 和 args 进行传递：\n\nredis-cli  --eval lua.script  keys , args\n\n\n1\n\n\n这样一来，访问次数加1、判断访问次数是否为1，以及设置过期时间这三个操作就可以原子性地执行了。即使客户端有多个线程同时执行这个脚本，Redis也会依次串行执行脚本代码，避免了并发操作带来的数据错误。\n\n注意，如果把很多操作都放在Lua脚本中原子执行，会导致Redis执行脚本的时间增加，同样也会降低Redis的并发性能。所以建议：在编写Lua脚本时，你要避免把不需要做并发控制的操作写入脚本中。\n\n\n# 2. 如何使用 Redis 实现分布式锁？\n\n前面提到，加锁也能实现临界区代码的互斥执行，但 Redis 属于分布式系统，当有多个客户端需要争抢锁的时候，这把锁就不能是某个客户端本地的锁，而是每个客户端都能访问到的锁。\n\n在分布式系统中，当有多个客户端需要获取锁的时候，我们就需要一个分布式锁，它保存在一个共享存储系统中，可以被多个客户端共享访问和获取。\n\n而 Redis 本身就是一个共享存储系统，可以用来保存分布式锁，而且可以应对高并发的锁操作场景。这一节将讨论如何基于 Redis 实现分布式锁。\n\n\n# 2.1 单机上的锁和分布式锁的联系与区别\n\n----------------------------------------\n\n先看一下单机上的锁的实现。对于在单机上运行的多线程程序来说，锁本身可以用一个变量表示：\n\n * 变量为 0：表示没有线程获取锁\n * 变量为 1：表示已经有线程获取到锁了\n\n而线程的加锁/释放锁就是检查这个变量并修改的操作。用一段代码来展示加锁和释放锁的操作：\n\nacquire_lock() {\n  if lock == 0\n     lock = 1\n     return 1\n  else        # 已经有别的线程获取到锁了，加锁失败 \n     return 0\n}\n\nrelease_lock() {\n  lock = 0\n  return 1\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n而在分布式场景下，分布式锁的变量由一个共享存储系统来维护，这样多个客户端就可以访问分布式锁了，由此，加锁和释放锁的操作就变成了读取、判断和设置共享存储系统中的锁变量值。\n\n这样，我们就可以得出实现分布式锁的两个要求：\n\n * 要求一：分布式锁的加锁和释放锁的过程，涉及多个操作。所以，在实现分布式锁时，我们需要保证这些锁操作的原子性；\n * 要求二：共享存储系统保存了锁变量，如果共享存储系统发生故障或宕机，那么客户端也就无法进行锁操作了。在实现分布式锁时，我们需要考虑保证共享存储系统的可靠性，进而保证锁的可靠性。\n\n下面看一下如何实现分布式锁。我们既可以基于单个Redis节点来实现，也可以使用多个Redis节点实现。在这两种情况下，锁的可靠性是不一样的。\n\n\n# 2.2 基于单个 Redis 节点实现分布式锁\n\n作为分布式锁实现过程中的共享存储系统，Redis 可以使用键值对来保存锁变量，再接收和处理不同客户端发送的加锁和释放锁的操作请求。\n\n我们要赋予锁变量一个变量名，把这个变量名作为键值对的键，而锁变量的值，则是键值对的值，这样一来，Redis 就能保存锁变量了，客户端也就可以通过Redis的命令操作来实现锁操作。\n\n加锁过程：\n\n分析：图中，A和C同时请求加锁。因为Redis使用单线程处理请求，所以，即使客户端A和C同时把加锁请求发给了Redis，Redis也会串行处理它们的请求。\n\n释放锁：\n\n因为加锁包含了三个操作（读取锁变量、判断锁变量值以及把锁变量值设置为 1），为了保证这三个操作的原子性，在 Redis 中可以使用单指令操作或使用 Lua 脚本。\n\n我们看下 Redis 可以用哪些单命令操作实现加锁操作。\n\n首先是 SETNX 命令：用于设置键值对的值，这个命令在执行时会判断键值对是否存在，如果不存在，就设置键值对的值，如果存在，就不做任何操作。\n\n对于释放锁操作来说，我们可以在执行完业务逻辑后，使用 DEL 命令删除锁变量。不过，你不用担心锁变量被删除后，其他客户端无法请求加锁了。因为SETNX命令在执行时，如果要设置的键值对（也就是锁变量）不存在，SETNX命令会先创建键值对，然后设置它的值。所以，释放锁之后，再有客户端请求加锁时，SETNX命令会创建保存锁变量的键值对，并设置锁变量的值，完成加锁。\n\n总结来说，我们就可以用 SETNX 和 DEL 命令组合来实现加锁和释放锁操作。下面的伪代码示例显示了锁操作的过程：\n\n// 加锁\nSETNX lock_key 1\n// 业务逻辑\nDO THINGS\n// 释放锁\nDEL lock_key\n\n\n1\n2\n3\n4\n5\n6\n\n\n不过，使用 SETNX 和 DEL 命令组合实现分布锁，存在两个潜在的风险：\n\n * 风险一：假如某个客户端在执行了SETNX命令、加锁之后，紧接着却在操作共享数据时发生了异常，结果一直没有执行最后的DEL命令释放锁。因此，锁就一直被这个客户端持有，其它客户端无法拿到锁，也无法访问共享数据和执行后续操作，这会给业务应用带来影响。\n   * 解决方法：给锁变量设置一个过期时间\n * 风险二：如果客户端A执行了SETNX命令加锁后，假设客户端B执行了DEL命令释放锁，此时，客户端A的锁就被误释放了。如果客户端C正好也在申请加锁，就可以成功获得锁，进而开始操作共享数据。这样一来，客户端A和C同时在对共享数据进行操作，数据就会被修改错误，这也是业务层不能接受的。\n   * 解决方法：SETNX 加锁时将 value 设置为某客户端的唯一 ID 值，并在释放时判断该 ID 是否与自己的相等。\n\n知道了针对风险二的解决方法，下面看一下在 Redis 具体如何实现。\n\n为了能达到和SETNX命令一样的效果，Redis给SET命令提供了类似的选项NX，用来实现“不存在即设置”。如果使用了NX选项，SET命令只有在键值对不存在时，才会进行设置，否则不做赋值操作。此外，SET命令在执行时还可以带上EX或PX选项，用来设置键值对的过期时间。比如，执行下面的命令时，只有key不存在时，SET才会创建key，并对key进行赋值。另外，key的存活时间由seconds或者milliseconds选项值来决定：\n\nSET key value [EX seconds | PX milliseconds]  [NX]\n\n\n1\n\n\n有了SET命令的NX和EX/PX选项后，我们就可以用下面的命令来实现加锁操作了：\n\n// 加锁, unique_value作为客户端唯一性的标识\nSET lock_key unique_value NX PX 10000\n\n\n1\n2\n\n\n其中，unique_value是客户端的唯一标识，可以用一个随机生成的字符串来表示，PX 10000则表示lock_key会在10s后过期，以免客户端在这期间发生异常而无法释放锁。\n\n因为在加锁操作中，每个客户端都使用了一个唯一标识，所以在释放锁操作时，我们需要判断锁变量的值，是否等于执行释放锁操作的客户端的唯一标识，如下所示：\n\n// 释放锁 比较unique_value是否相等，避免误释放\nif redis.call("get",KEYS[1]) == ARGV[1] then\n    return redis.call("del",KEYS[1])\nelse\n    return 0\nend\n\n\n1\n2\n3\n4\n5\n6\n\n\n这是使用Lua脚本（unlock.script）实现的释放锁操作的伪代码，其中，KEYS[1]表示lock_key，ARGV[1]是当前客户端的唯一标识，这两个值都是我们在执行Lua脚本时作为参数传入的。\n\n最后，我们执行下面的命令，就可以完成锁释放操作了：\n\nredis-cli  --eval  unlock.script lock_key , unique_value\n\n\n1\n\n\n通过 Lua 脚本保证了 Redis 在进行读取锁变量、判断值、删除锁变量的多个操作能够原子性地执行。\n\n到此，我们实现了使用 Redis 实例来实现分布式锁。但是为了避免单点故障，我们还要基于多个 Redis 节点来实现分布式锁。\n\n\n# 2.3 基于多个 Redis 节点实现高可靠的分布式锁\n\n当我们要实现高可靠的分布式锁时，就不能只依赖单个的命令操作了，我们需要按照一定的步骤和规则进行加解锁操作，否则，就可能会出现锁无法工作的情况。这里说的“一定的步骤和规则”就是指的分布式锁的算法。\n\n为了避免 Redis 实例故障而导致的锁无法工作的问题，Redis 的开发者 Antirez 提出了分布式锁算法 Redlock。\n\nRedlock 算法的基本思路：是让客户端和多个独立的Redis实例依次请求加锁，如果客户端能够和半数以上的实例成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁了，否则加锁失败。这样一来，即使有单个Redis实例发生故障，因为锁变量在其它实例上也有保存，所以，客户端仍然可以正常地进行锁操作，锁变量并不会丢失。\n\n我们来具体看下 Redlock 算法的执行步骤。Redlock 算法的实现需要有 N 个独立的 Redis 实例。接下来，我们可以分成 3 步来完成加锁操作：\n\n第一步：客户端获取当前时间。\n\n第二步：客户端按顺序依次向 N 个 Redis 实例执行加锁操作。\n\n这里的加锁操作和在单实例上执行的加锁操作一样，使用SET命令，带上NX，EX/PX选项，以及带上客户端的唯一标识。当然，如果某个Redis实例发生故障了，为了保证在这种情况下，Redlock算法能够继续运行，我们需要给加锁操作设置一个超时时间。\n\n如果客户端在和一个Redis实例请求加锁时，一直到超时都没有成功，那么此时，客户端会和下一个Redis实例继续请求加锁。加锁操作的超时时间需要远远地小于锁的有效时间，一般也就是设置为几十毫秒。\n\n第三步：一旦客户端完成了和所有 Redis 实例的加锁操作，客户端就要计算整个加锁过程的总耗时。\n\n客户端只有在满足下面的这两个条件时，才能认为是加锁成功。\n\n * 条件一：客户端从超过半数（大于等于 N/2+1）的 Redis 实例上成功获取到了锁；\n * 条件二：客户端获取锁的总耗时没有超过锁的有效时间。\n\n在满足了这两个条件后，我们需要重新计算这把锁的有效时间，计算的结果是锁的最初有效时间减去客户端为获取锁的总耗时。如果锁的有效时间已经来不及完成共享数据的操作了，我们可以释放锁，以免出现还没完成数据操作，锁就过期了的情况。\n\n当然，如果客户端在和所有实例执行完加锁操作后，没能同时满足这两个条件，那么，客户端向所有Redis节点发起释放锁的操作。\n\n在Redlock算法中，释放锁的操作和在单实例上释放锁的操作一样，只要执行释放锁的Lua脚本就可以了。这样一来，只要N个Redis实例中的半数以上实例能正常工作，就能保证分布式锁的正常工作了。\n\n所以，在实际的业务应用中，如果你想要提升分布式锁的可靠性，就可以通过 Redlock 算法来实现。\n\n\n# 2.4 小结\n\n分布式锁是由共享存储系统维护的变量，多个客户端可以向共享存储系统发送命令进行加锁或释放锁操作。Redis 作为一个共享存储系统，可以用来实现分布式锁。\n\n在基于单个Redis实例实现分布式锁时，对于加锁操作，我们需要满足三个条件。\n\n 1. 加锁包括了读取锁变量、检查锁变量值和设置锁变量值三个操作，但需要以原子操作的方式完成，所以，我们使用SET命令带上NX选项来实现加锁；\n 2. 锁变量需要设置过期时间，以免客户端拿到锁后发生异常，导致锁一直无法释放，所以，我们在SET命令执行时加上EX/PX选项，设置其过期时间；\n 3. 锁变量的值需要能区分来自不同客户端的加锁操作，以免在释放锁时，出现误释放操作，所以，我们使用SET命令设置锁变量值时，每个客户端设置的值是一个唯一值，用于标识客户端。\n\n和加锁类似，释放锁也包含了读取锁变量值、判断锁变量值和删除锁变量三个操作，不过，我们无法使用单个命令来实现，所以，我们可以采用Lua脚本执行释放锁操作，通过Redis原子性地执行Lua脚本，来保证释放锁操作的原子性。\n\n不过，基于单个 Redis 实例实现分布式锁时，会面临实例异常或崩溃的情况，这会导致实例无法提供锁操作，正因为此，Redis 也提供了 Redlock 算法，用来实现基于多个实例的分布式锁。这样一来，锁变量由多个实例维护，即使有实例发生了故障，锁变量仍然是存在的，客户端还是可以完成锁操作。Redlock 算法是实现高可靠分布式锁的一种有效解决方案，你可以在实际应用中把它用起来。',normalizedContent:'> 参考：\n> \n>  * 29 无锁的原子操作：redis 如何应对并发访问？| 极客时间\n>  * 30 如何使用 redis 实现分布式锁？| 极客时间\n\n并发访问控制：是指对多个客户端访问操作同一份数据的过程进行控制，以保证任何一个客户端发送的操作在redis实例上执行时具有互斥性。例如，客户端a的访问操作在执行时，客户端b的操作不能执行，需要等到a的操作结束后，才能执行。\n\n业务系统不可避免会遇到并发访问的问题，为保证并发访问的正确性，redis 提供了两种方法：加锁和原子操作。\n\n\n# 1. 无锁的原子操作\n\n原子操作是一种提供并发访问控制的方法，是指执行过程保持原子性的操作，而且原子操作执行时并不需要再加锁，实现了无锁操作。这样一来，既能保证并发控制，还能减少对系统并发性能的影响。\n\n\n# 1.1 并发访问中需要对什么进行控制？\n\n并发访问控制对应的操作主要是数据修改操作。当客户端需要修改数据时，基本流程分成两步：\n\n 1. 客户端先把数据读取到本地，在本地进行修改；\n 2. 客户端修改完数据后，再写回 redis。\n\n这个流程被称为 read-modify-write（rmw）操作。当有多个客户端对同一份数据执行rmw操作的话，我们就需要让rmw操作涉及的代码以原子性方式执行。访问同一份数据的rmw操作代码，就叫做临界区代码。\n\n不过，当有多个客户端并发执行临界区代码时，就会存在一些潜在问题，接下来，我用一个多客户端更新商品库存的例子来解释一下。\n\n我们先看下临界区代码。假设客户端要对商品库存执行扣减1的操作，伪代码如下所示：\n\ncurrent = get(id)\ncurrent--\nset(id, current)\n\n\n1\n2\n3\n\n\n如果我们对临界区代码的执行没有控制机制，就可能出现数据更新错误。如下图是两个客户端同时执行临界区代码而导致的错误：\n\n上图相比于正确的处理逻辑，库存值明显更新错了。出现这个现象的原因是：多个客户端的 rmw 这三个操作在执行时不具有互斥性，两个客户端基于相同的初始值进行修改，而不是基于前一个客户端修改后的值再修改。\n\n为了保证数据并发修改的正确性，我们可以使用锁来控制临界区代码的执行情况，如下所示：\n\n \n\n\n\n \n\n\nlock()\ncurrent = get(id)\ncurrent--\nset(id, current)\nunlock()\n\n\n1\n2\n3\n4\n5\n\n\n虽然加锁保证了互斥性，但是加锁会降低并发性能。\n\n和加锁类似，原子操作也能实现并发控制，但是原子操作对系统并发性能的影响较小，接下来，我们就来了解下 redis 中的原子操作。\n\n\n# 1.2 redis 的两种原子操作方法\n\n为了实现并发控制要求的临界区代码互斥执行，redis的原子操作采用了两种方法：\n\n 1. 把多个操作在 redis 中实现成一个操作，也就是单命令操作；\n 2. 把多个操作写到一个 lua 脚本中，以原子性方式执行单个 lua 脚本。\n\n# 1.2.1 redis 本身的单命令操作\n\nredis 是使用单线程来串行处理客户端的请求操作命令的，所以，当 redis 执行某个命令操作时，其他命令是无法执行的，这相当于命令操作是互斥执行的。当然，redis 的快照生成、aof 重写这些操作，可以使用后台线程或者是子进程执行，也就是和主线程的操作并行执行。不过，这些操作只是读取数据，不会修改数据，所以，我们并不需要对它们做并发控制。\n\n另外，redis 还提供了 incr/decr 命令对数据进行增值/减值操作。，这个命令将 rmw 三个操作变为一个原子操作了。\n\n比如说，在刚才的库存扣减例子中，客户端可以使用下面的代码，直接完成对商品id的库存值减1操作。即使有多个客户端执行下面的代码，也不用担心出现库存值扣减错误的问题：\n\ndecr id\n\n\n1\n\n\n但当我们想要将更复杂的操作变成原子操作时，就需要使用 lua 脚本了。\n\n# 1.2.2 lua 脚本\n\nredis 会把整个 lua 脚本作为一个整体使用 eval 命令来执行，在执行的过程中不会被其他命令打断，从而保证了 lua 脚本中操作的原子性。\n\n下面举个例子来解释 lua 的使用。当一个业务应用的访问用户增加时，我们有时需要限制某个客户端在一定时间范围内的访问次数，比如爆款商品的购买限流、社交网络中的每分钟点赞次数限制等。\n\n那该怎么限制呢？我们可以把客户端ip作为key，把客户端的访问次数作为value，保存到redis中。客户端每访问一次后，我们就用incr增加访问次数。不过，在这种场景下，客户端限流其实同时包含了对访问次数和时间范围的限制，例如每分钟的访问次数不能超过20。所以，我们可以在客户端第一次访问时，给对应键值对设置过期时间，例如设置为60s后过期。同时，在客户端每次访问时，我们读取客户端当前的访问次数，如果次数超过阈值，就报错，限制客户端再次访问。你可以看下下面的这段代码，它实现了对客户端每分钟访问次数不超过20次的限制。伪代码如下：\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n//获取ip对应的访问次数\ncurrent = get(ip)\n//如果超过访问次数超过20次，则报错\nif current != null and current > 20 then\n    error "exceed 20 accesses per second"\nelse\n    //如果访问次数不足20次，增加一次访问计数\n    value = incr(ip)\n    //如果是第一次访问，将键值对的过期时间设置为60s后\n    if value == 1 then\n        expire(ip,60)\n    end\n    //执行其他操作\n    do things\nend\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n尽管例子使用了 incr 来原子性地增加计数，但客户端限流的逻辑不只有计数，还包括访问次数判断和过期时间设置。对于这些操作，我们同样需要保证它们的原子性。否则，如果客户端使用多线程访问，访问次数初始值为0，第一个线程执行了incr(ip)操作后，第二个线程紧接着也执行了incr(ip)，此时，ip对应的访问次数就被增加到了2，我们就无法再对这个ip设置过期时间了。这样就会导致，这个ip对应的客户端访问次数达到20次之后，就无法再进行访问了。即使过了60s，也不能再继续访问，显然不符合业务要求。\n\n由于这种复杂的逻辑无法使用单个命令来解决，此时就需要使用 lua 脚本来保证并发控制。我们可以把访问次数加1、判断访问次数是否为1，以及设置过期时间这三个操作写入一个lua脚本，如下所示：\n\nlocal current\ncurrent = redis.call("incr",keys[1])\nif tonumber(current) == 1 then\n    redis.call("expire",keys[1],60)\nend\n\n\n1\n2\n3\n4\n5\n\n\n假设我们编写的脚本名称为 lua.script，我们接着就可以使用 redis 客户端，带上 eval 选项，来执行该脚本。脚本所需的参数将通过以下命令中的 keys 和 args 进行传递：\n\nredis-cli  --eval lua.script  keys , args\n\n\n1\n\n\n这样一来，访问次数加1、判断访问次数是否为1，以及设置过期时间这三个操作就可以原子性地执行了。即使客户端有多个线程同时执行这个脚本，redis也会依次串行执行脚本代码，避免了并发操作带来的数据错误。\n\n注意，如果把很多操作都放在lua脚本中原子执行，会导致redis执行脚本的时间增加，同样也会降低redis的并发性能。所以建议：在编写lua脚本时，你要避免把不需要做并发控制的操作写入脚本中。\n\n\n# 2. 如何使用 redis 实现分布式锁？\n\n前面提到，加锁也能实现临界区代码的互斥执行，但 redis 属于分布式系统，当有多个客户端需要争抢锁的时候，这把锁就不能是某个客户端本地的锁，而是每个客户端都能访问到的锁。\n\n在分布式系统中，当有多个客户端需要获取锁的时候，我们就需要一个分布式锁，它保存在一个共享存储系统中，可以被多个客户端共享访问和获取。\n\n而 redis 本身就是一个共享存储系统，可以用来保存分布式锁，而且可以应对高并发的锁操作场景。这一节将讨论如何基于 redis 实现分布式锁。\n\n\n# 2.1 单机上的锁和分布式锁的联系与区别\n\n----------------------------------------\n\n先看一下单机上的锁的实现。对于在单机上运行的多线程程序来说，锁本身可以用一个变量表示：\n\n * 变量为 0：表示没有线程获取锁\n * 变量为 1：表示已经有线程获取到锁了\n\n而线程的加锁/释放锁就是检查这个变量并修改的操作。用一段代码来展示加锁和释放锁的操作：\n\nacquire_lock() {\n  if lock == 0\n     lock = 1\n     return 1\n  else        # 已经有别的线程获取到锁了，加锁失败 \n     return 0\n}\n\nrelease_lock() {\n  lock = 0\n  return 1\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n而在分布式场景下，分布式锁的变量由一个共享存储系统来维护，这样多个客户端就可以访问分布式锁了，由此，加锁和释放锁的操作就变成了读取、判断和设置共享存储系统中的锁变量值。\n\n这样，我们就可以得出实现分布式锁的两个要求：\n\n * 要求一：分布式锁的加锁和释放锁的过程，涉及多个操作。所以，在实现分布式锁时，我们需要保证这些锁操作的原子性；\n * 要求二：共享存储系统保存了锁变量，如果共享存储系统发生故障或宕机，那么客户端也就无法进行锁操作了。在实现分布式锁时，我们需要考虑保证共享存储系统的可靠性，进而保证锁的可靠性。\n\n下面看一下如何实现分布式锁。我们既可以基于单个redis节点来实现，也可以使用多个redis节点实现。在这两种情况下，锁的可靠性是不一样的。\n\n\n# 2.2 基于单个 redis 节点实现分布式锁\n\n作为分布式锁实现过程中的共享存储系统，redis 可以使用键值对来保存锁变量，再接收和处理不同客户端发送的加锁和释放锁的操作请求。\n\n我们要赋予锁变量一个变量名，把这个变量名作为键值对的键，而锁变量的值，则是键值对的值，这样一来，redis 就能保存锁变量了，客户端也就可以通过redis的命令操作来实现锁操作。\n\n加锁过程：\n\n分析：图中，a和c同时请求加锁。因为redis使用单线程处理请求，所以，即使客户端a和c同时把加锁请求发给了redis，redis也会串行处理它们的请求。\n\n释放锁：\n\n因为加锁包含了三个操作（读取锁变量、判断锁变量值以及把锁变量值设置为 1），为了保证这三个操作的原子性，在 redis 中可以使用单指令操作或使用 lua 脚本。\n\n我们看下 redis 可以用哪些单命令操作实现加锁操作。\n\n首先是 setnx 命令：用于设置键值对的值，这个命令在执行时会判断键值对是否存在，如果不存在，就设置键值对的值，如果存在，就不做任何操作。\n\n对于释放锁操作来说，我们可以在执行完业务逻辑后，使用 del 命令删除锁变量。不过，你不用担心锁变量被删除后，其他客户端无法请求加锁了。因为setnx命令在执行时，如果要设置的键值对（也就是锁变量）不存在，setnx命令会先创建键值对，然后设置它的值。所以，释放锁之后，再有客户端请求加锁时，setnx命令会创建保存锁变量的键值对，并设置锁变量的值，完成加锁。\n\n总结来说，我们就可以用 setnx 和 del 命令组合来实现加锁和释放锁操作。下面的伪代码示例显示了锁操作的过程：\n\n// 加锁\nsetnx lock_key 1\n// 业务逻辑\ndo things\n// 释放锁\ndel lock_key\n\n\n1\n2\n3\n4\n5\n6\n\n\n不过，使用 setnx 和 del 命令组合实现分布锁，存在两个潜在的风险：\n\n * 风险一：假如某个客户端在执行了setnx命令、加锁之后，紧接着却在操作共享数据时发生了异常，结果一直没有执行最后的del命令释放锁。因此，锁就一直被这个客户端持有，其它客户端无法拿到锁，也无法访问共享数据和执行后续操作，这会给业务应用带来影响。\n   * 解决方法：给锁变量设置一个过期时间\n * 风险二：如果客户端a执行了setnx命令加锁后，假设客户端b执行了del命令释放锁，此时，客户端a的锁就被误释放了。如果客户端c正好也在申请加锁，就可以成功获得锁，进而开始操作共享数据。这样一来，客户端a和c同时在对共享数据进行操作，数据就会被修改错误，这也是业务层不能接受的。\n   * 解决方法：setnx 加锁时将 value 设置为某客户端的唯一 id 值，并在释放时判断该 id 是否与自己的相等。\n\n知道了针对风险二的解决方法，下面看一下在 redis 具体如何实现。\n\n为了能达到和setnx命令一样的效果，redis给set命令提供了类似的选项nx，用来实现“不存在即设置”。如果使用了nx选项，set命令只有在键值对不存在时，才会进行设置，否则不做赋值操作。此外，set命令在执行时还可以带上ex或px选项，用来设置键值对的过期时间。比如，执行下面的命令时，只有key不存在时，set才会创建key，并对key进行赋值。另外，key的存活时间由seconds或者milliseconds选项值来决定：\n\nset key value [ex seconds | px milliseconds]  [nx]\n\n\n1\n\n\n有了set命令的nx和ex/px选项后，我们就可以用下面的命令来实现加锁操作了：\n\n// 加锁, unique_value作为客户端唯一性的标识\nset lock_key unique_value nx px 10000\n\n\n1\n2\n\n\n其中，unique_value是客户端的唯一标识，可以用一个随机生成的字符串来表示，px 10000则表示lock_key会在10s后过期，以免客户端在这期间发生异常而无法释放锁。\n\n因为在加锁操作中，每个客户端都使用了一个唯一标识，所以在释放锁操作时，我们需要判断锁变量的值，是否等于执行释放锁操作的客户端的唯一标识，如下所示：\n\n// 释放锁 比较unique_value是否相等，避免误释放\nif redis.call("get",keys[1]) == argv[1] then\n    return redis.call("del",keys[1])\nelse\n    return 0\nend\n\n\n1\n2\n3\n4\n5\n6\n\n\n这是使用lua脚本（unlock.script）实现的释放锁操作的伪代码，其中，keys[1]表示lock_key，argv[1]是当前客户端的唯一标识，这两个值都是我们在执行lua脚本时作为参数传入的。\n\n最后，我们执行下面的命令，就可以完成锁释放操作了：\n\nredis-cli  --eval  unlock.script lock_key , unique_value\n\n\n1\n\n\n通过 lua 脚本保证了 redis 在进行读取锁变量、判断值、删除锁变量的多个操作能够原子性地执行。\n\n到此，我们实现了使用 redis 实例来实现分布式锁。但是为了避免单点故障，我们还要基于多个 redis 节点来实现分布式锁。\n\n\n# 2.3 基于多个 redis 节点实现高可靠的分布式锁\n\n当我们要实现高可靠的分布式锁时，就不能只依赖单个的命令操作了，我们需要按照一定的步骤和规则进行加解锁操作，否则，就可能会出现锁无法工作的情况。这里说的“一定的步骤和规则”就是指的分布式锁的算法。\n\n为了避免 redis 实例故障而导致的锁无法工作的问题，redis 的开发者 antirez 提出了分布式锁算法 redlock。\n\nredlock 算法的基本思路：是让客户端和多个独立的redis实例依次请求加锁，如果客户端能够和半数以上的实例成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁了，否则加锁失败。这样一来，即使有单个redis实例发生故障，因为锁变量在其它实例上也有保存，所以，客户端仍然可以正常地进行锁操作，锁变量并不会丢失。\n\n我们来具体看下 redlock 算法的执行步骤。redlock 算法的实现需要有 n 个独立的 redis 实例。接下来，我们可以分成 3 步来完成加锁操作：\n\n第一步：客户端获取当前时间。\n\n第二步：客户端按顺序依次向 n 个 redis 实例执行加锁操作。\n\n这里的加锁操作和在单实例上执行的加锁操作一样，使用set命令，带上nx，ex/px选项，以及带上客户端的唯一标识。当然，如果某个redis实例发生故障了，为了保证在这种情况下，redlock算法能够继续运行，我们需要给加锁操作设置一个超时时间。\n\n如果客户端在和一个redis实例请求加锁时，一直到超时都没有成功，那么此时，客户端会和下一个redis实例继续请求加锁。加锁操作的超时时间需要远远地小于锁的有效时间，一般也就是设置为几十毫秒。\n\n第三步：一旦客户端完成了和所有 redis 实例的加锁操作，客户端就要计算整个加锁过程的总耗时。\n\n客户端只有在满足下面的这两个条件时，才能认为是加锁成功。\n\n * 条件一：客户端从超过半数（大于等于 n/2+1）的 redis 实例上成功获取到了锁；\n * 条件二：客户端获取锁的总耗时没有超过锁的有效时间。\n\n在满足了这两个条件后，我们需要重新计算这把锁的有效时间，计算的结果是锁的最初有效时间减去客户端为获取锁的总耗时。如果锁的有效时间已经来不及完成共享数据的操作了，我们可以释放锁，以免出现还没完成数据操作，锁就过期了的情况。\n\n当然，如果客户端在和所有实例执行完加锁操作后，没能同时满足这两个条件，那么，客户端向所有redis节点发起释放锁的操作。\n\n在redlock算法中，释放锁的操作和在单实例上释放锁的操作一样，只要执行释放锁的lua脚本就可以了。这样一来，只要n个redis实例中的半数以上实例能正常工作，就能保证分布式锁的正常工作了。\n\n所以，在实际的业务应用中，如果你想要提升分布式锁的可靠性，就可以通过 redlock 算法来实现。\n\n\n# 2.4 小结\n\n分布式锁是由共享存储系统维护的变量，多个客户端可以向共享存储系统发送命令进行加锁或释放锁操作。redis 作为一个共享存储系统，可以用来实现分布式锁。\n\n在基于单个redis实例实现分布式锁时，对于加锁操作，我们需要满足三个条件。\n\n 1. 加锁包括了读取锁变量、检查锁变量值和设置锁变量值三个操作，但需要以原子操作的方式完成，所以，我们使用set命令带上nx选项来实现加锁；\n 2. 锁变量需要设置过期时间，以免客户端拿到锁后发生异常，导致锁一直无法释放，所以，我们在set命令执行时加上ex/px选项，设置其过期时间；\n 3. 锁变量的值需要能区分来自不同客户端的加锁操作，以免在释放锁时，出现误释放操作，所以，我们使用set命令设置锁变量值时，每个客户端设置的值是一个唯一值，用于标识客户端。\n\n和加锁类似，释放锁也包含了读取锁变量值、判断锁变量值和删除锁变量三个操作，不过，我们无法使用单个命令来实现，所以，我们可以采用lua脚本执行释放锁操作，通过redis原子性地执行lua脚本，来保证释放锁操作的原子性。\n\n不过，基于单个 redis 实例实现分布式锁时，会面临实例异常或崩溃的情况，这会导致实例无法提供锁操作，正因为此，redis 也提供了 redlock 算法，用来实现基于多个实例的分布式锁。这样一来，锁变量由多个实例维护，即使有实例发生了故障，锁变量仍然是存在的，客户端还是可以完成锁操作。redlock 算法是实现高可靠分布式锁的一种有效解决方案，你可以在实际应用中把它用起来。',charsets:{cjk:!0},lastUpdated:"2023/04/18, 14:13:32",lastUpdatedTimestamp:1681827212e3},{title:"Redis 的事务机制",frontmatter:{title:"Redis 的事务机制",date:"2023-04-18T22:17:42.000Z",permalink:"/pages/932816/",categories:["中间件","Redis","专栏：Redis 核心技术与实战"],tags:[null]},regularPath:"/%E4%B8%AD%E9%97%B4%E4%BB%B6/05.Redis/05.%E4%B8%93%E6%A0%8F%EF%BC%9ARedis%20%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/31.Redis%20%E7%9A%84%E4%BA%8B%E5%8A%A1%E6%9C%BA%E5%88%B6.html",relativePath:"中间件/05.Redis/05.专栏：Redis 核心技术与实战/31.Redis 的事务机制.md",key:"v-2f859720",path:"/pages/932816/",headers:[{level:2,title:"1. 事务机制：Redis 能实现 ACID 属性吗？",slug:"_1-事务机制-redis-能实现-acid-属性吗",normalizedTitle:"1. 事务机制：redis 能实现 acid 属性吗？",charIndex:49},{level:3,title:"1.1 ACID 属性的要求",slug:"_1-1-acid-属性的要求",normalizedTitle:"1.1 acid 属性的要求",charIndex:128},{level:3,title:"1.2 Redis 如何实现事务？",slug:"_1-2-redis-如何实现事务",normalizedTitle:"1.2 redis 如何实现事务？",charIndex:163},{level:3,title:"1.3 Redis 的事务机制能保证哪些属性？",slug:"_1-3-redis-的事务机制能保证哪些属性",normalizedTitle:"1.3 redis 的事务机制能保证哪些属性？",charIndex:796},{level:4,title:"1.3.1 原子性",slug:"_1-3-1-原子性",normalizedTitle:"1.3.1 原子性",charIndex:834},{level:4,title:"1.3.2 一致性",slug:"_1-3-2-一致性",normalizedTitle:"1.3.2 一致性",charIndex:2595},{level:4,title:"1.3.3 隔离性",slug:"_1-3-3-隔离性",normalizedTitle:"1.3.3 隔离性",charIndex:3197},{level:4,title:"1.3.4 持久性",slug:"_1-3-4-持久性",normalizedTitle:"1.3.4 持久性",charIndex:3953},{level:3,title:"1.4 小结",slug:"_1-4-小结",normalizedTitle:"1.4 小结",charIndex:4257}],headersStr:"1. 事务机制：Redis 能实现 ACID 属性吗？ 1.1 ACID 属性的要求 1.2 Redis 如何实现事务？ 1.3 Redis 的事务机制能保证哪些属性？ 1.3.1 原子性 1.3.2 一致性 1.3.3 隔离性 1.3.4 持久性 1.4 小结",content:'> 参考：\n> \n>  * 31 事务机制：Redis能实现ACID属性吗？| 极客时间\n\n\n# 1. 事务机制：Redis 能实现 ACID 属性吗？\n\n事务提供了对数据读写的 ACID 的保证，那 Redis 可以完全保证 ACID 属性吗？\n\n\n# 1.1 ACID 属性的要求\n\n可以参考 事务 这一篇文章。\n\n\n# 1.2 Redis 如何实现事务？\n\n事务的执行过程包含三个步骤，Redis 提供了 MULTI、EXEC 两个命令来完成这三个步骤。下面看一下：\n\n 1. 第一步：客户端要使用 MULTI 命令来显式地表示一个事务的开启。\n 2. 第二步：客户端把事务本身要执行的具体操作（例如增删改数据）发送给服务器端。这些操作就是 Redis 本身提供的数据读写命令，例如 GET、SET 等。不过，这些命令虽然被客户端发送到了服务器端，但 Redis 实例只是把这些命令暂存到一个命令队列中，并不会立即执行。\n 3. 第三步：客户端向 Redis 发送 EXEC 命令来执行事务提交，让数据库实际执行第二步中发送的具体操作。\n\n如下代码是使用 MULTI 和 EXEC 执行一个事务的过程：\n\n# 开启事务\n127.0.0.1:6379> MULTI\nOK\n# 将a:stock减1，\n127.0.0.1:6379> DECR a:stock\nQUEUED\n# 将b:stock减1\n127.0.0.1:6379> DECR b:stock\nQUEUED\n# 实际执行事务\n127.0.0.1:6379> EXEC\n1) (integer) 4\n2) (integer) 9\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n好了，通过使用 MULTI 和 EXEC 命令，我们可以实现多个操作的共同执行，但是这符合事务要求的 ACID 属性吗？\n\n\n# 1.3 Redis 的事务机制能保证哪些属性？\n\n这里分别分析一下。\n\n# 1.3.1 原子性\n\n如果事务执行出现错误，原子性还能保证吗？这要分三种情况来看待。\n\n * 第一种情况是，在执行EXEC命令前，客户端发送的操作命令本身就有错误（比如语法错误，使用了不存在的命令），在命令入队时就被 Redis 实例判断出来了。此时 Redis 会拒绝执行所有提交的命令，从而保证了原子性。\n   * 例子：\n\n#开启事务\n127.0.0.1:6379> MULTI\nOK\n#发送事务中的第一个操作，但是Redis不支持该命令，返回报错信息\n127.0.0.1:6379> PUT a:stock 5\n(error) ERR unknown command `PUT`, with args beginning with: `a:stock`, `5`,\n#发送事务中的第二个操作，这个操作是正确的命令，Redis把该命令入队\n127.0.0.1:6379> DECR b:stock\nQUEUED\n#实际执行事务，但是之前命令有错误，所以Redis拒绝执行\n127.0.0.1:6379> EXEC\n(error) EXECABORT Transaction discarded because of previous errors.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n * 第二种情况是，某个命令在事务执行期间出现错误，如命令和操作的数据类型不匹配，在操作入队时没有被 Redis 实例检查出错误。这时尽管 Redis 会对单个命令报错，但还是会把这个事务接下来的所有命令执行完。在这种情况下，事务的原子性就无法得到保证了。\n   * 例子：\n\n#开启事务\n127.0.0.1:6379> MULTI\nOK\n#发送事务中的第一个操作，LPOP命令操作的数据类型不匹配，此时并不报错\n127.0.0.1:6379> LPOP a:stock\nQUEUED\n#发送事务中的第二个操作\n127.0.0.1:6379> DECR b:stock\nQUEUED\n#实际执行事务，事务第一个操作执行报错\n127.0.0.1:6379> EXEC\n1) (error) WRONGTYPE Operation against a key holding the wrong kind of value\n2) (integer) 8\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n * 第三种情况是，事务执行期间 Redis 实例发生了故障，导致事务执行失败。在这种情况下：\n   * 如果Redis开启了AOF日志，那么，只会有部分的事务操作被记录到AOF日志中。我们需要使用redis-check-aof工具检查AOF日志文件，这个工具可以把未完成的事务操作从AOF文件中去除。这样一来，我们使用AOF恢复实例后，事务操作不会再被执行，从而保证了原子性。\n   * 如果AOF日志并没有开启，那么实例重启后，数据也都没法恢复了，此时，也就谈不上原子性了。\n\nRedis 也没有提供回滚机制。虽然 Redis 提供了 DISCARD 命令，但这个命令只能用来主动放弃事务的执行，把暂存的命令队列清空，起不到回滚的效果。下面代码展示 DISCARD 命令的使用：\n\n#读取a:stock的值4\n127.0.0.1:6379> GET a:stock\n"4"\n#开启事务\n127.0.0.1:6379> MULTI\nOK\n#发送事务的第一个操作，对a:stock减1\n127.0.0.1:6379> DECR a:stock\nQUEUED\n#执行DISCARD命令，主动放弃事务\n127.0.0.1:6379> DISCARD\nOK\n#再次读取a:stock的值，值没有被修改\n127.0.0.1:6379> GET a:stock\n"4"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n这里总结一下 Redis 对事务原子性的保证情况：\n\n * 命令入队时就报错，会放弃事务执行，保证原子性；\n * 命令入队时没报错，实际执行时报错，不保证原子性；\n * EXEC 命令执行时实例故障，如果开启了 AOF 日志，可以保证原子性。\n\n# 1.3.2 一致性\n\n我们按照命令出错和实例故障的发生时机，分成三种情况来看：\n\n 1. 情况一：命令入队时就报错。在这种情况下，事务本身就会被放弃执行，所以可以保证数据库的一致性。\n 2. 情况二：命令入队时没报错，实际执行时报错。在这种情况下，有错误的命令不会被执行，正确的命令可以正常执行，也不会改变数据库的一致性。\n 3. 情况三：EXEC 命令执行时实例发生故障。在这种情况下，实例故障后会进行重启，这就和数据恢复的方式有关了，我们要根据实例是否开启了RDB或AOF来分情况讨论下。\n    * 若没有开启 RDB 或 AOF 日志：那实例故障重启后，数据都没有了，数据库是一致的。\n    * 若使用了 RDB 快照：因为RDB快照不会在事务执行时执行，所以，事务命令操作的结果不会被保存到 RDB 快照中，使用 RDB 快照进行恢复时，数据库里的数据也是一致的。\n    * 若使用了 AOF 日志：\n      * 如果事务操作还没有被记录到AOF日志时，实例就发生了故障，那么，使用AOF日志恢复的数据库数据是一致的。\n      * 如果只有部分操作被记录到了AOF日志，我们可以使用redis-check-aof清除事务中已经完成的操作，数据库恢复后也是一致的。\n\n所以，总结来说，在命令执行错误或 Redis 发生故障的情况下，Redis 事务机制对一致性属性是有保证的。\n\n# 1.3.3 隔离性\n\n事务的隔离性保证，会受到和事务一起执行的并发操作的影响。而事务执行又可以分成命令入队（EXEC 命令执行前）和命令实际执行（EXEC 命令执行后）两个阶段，所以，我们就针对这两个阶段，分成两种情况来分析：\n\n 1. 并发操作在 EXEC 命令前执行，此时，隔离性的保证要使用 WATCH 机制来实现，否则隔离性无法保证；\n 2. 并发操作在 EXEC 命令后执行，此时，隔离性可以保证。\n\n我们先来看第一种情况。一个事务的 EXEC 命令还没有执行时，事务的命令操作是暂存在命令队列中的。此时，如果有其它的并发操作，我们就需要看事务是否使用了 WATCH 机制。\n\nWATCH 机制的作用是，在事务执行前，监控一个或多个键的值变化情况，当事务调用 EXEC 命令执行时，WATCH 机制会先检查监控的键是否被其它客户端修改了。如果修改了，就放弃事务执行，避免事务的隔离性被破坏。然后，客户端可以再次执行事务，此时，如果没有并发修改事务数据的操作了，事务就能正常执行，隔离性也得到了保证。\n\nWATCH机制的具体实现是由WATCH命令实现的，我给你举个例子，你可以看下下面的图，进一步理解下WATCH命令的使用：\n\n当然，如果没有使用WATCH机制，在EXEC命令前执行的并发操作是会对数据进行读写的。而且，在执行EXEC命令的时候，事务要操作的数据已经改变了，在这种情况下，Redis并没有做到让事务对其它操作隔离，隔离性也就没有得到保障。下面这张图显示了没有WATCH机制时的情况：\n\n对于第二种情况，因为 Redis 是用单线程执行命令，而且，EXEC 命令执行后，Redis 会保证先把命令队列中的所有命令执行完。所以，在这种情况下，并发操作不会破坏事务的隔离性，如下图所示：\n\n# 1.3.4 持久性\n\n因为 Redis 是内存数据库，所以，数据是否持久化保存完全取决于 Redis 的持久化配置模式。\n\n如果Redis没有使用RDB或AOF，那么事务的持久化属性肯定得不到保证。如果Redis使用了RDB模式，那么，在一个事务执行后，而下一次的RDB快照还未执行前，如果发生了实例宕机，这种情况下，事务修改的数据也是不能保证持久化的。\n\n如果Redis采用了AOF模式，因为AOF模式的三种配置选项no、everysec和always都会存在数据丢失的情况，所以，事务的持久性属性也还是得不到保证。\n\n所以，不管 Redis 采用什么持久化模式，事务的持久性属性是得不到保证的。\n\n\n# 1.4 小结\n\n这一节学习了 Redis 的事务实现，它通过 MULTI、EXEC、DISCARD 和 WATCH 四个命令来支持事务机制，总结如下：\n\n事务的ACID属性是我们使用事务进行正确操作的基本要求。通过这节课的分析，我们了解到了，Redis的事务机制可以保证一致性和隔离性，但是无法保证持久性。不过，因为Redis本身是内存数据库，持久性并不是一个必须的属性，我们更加关注的还是原子性、一致性和隔离性这三个属性。\n\n原子性的情况比较复杂，只有当事务中使用的命令语法有误时，原子性得不到保证，在其它情况下，事务都可以原子性执行。\n\n建议：严格按照 Redis 的命令规范进行程序开发，并且通过 code review 确保命令的正确性。这样一来，Redis 的事务机制就能被应用在实践中，保证多操作的正确执行。',normalizedContent:'> 参考：\n> \n>  * 31 事务机制：redis能实现acid属性吗？| 极客时间\n\n\n# 1. 事务机制：redis 能实现 acid 属性吗？\n\n事务提供了对数据读写的 acid 的保证，那 redis 可以完全保证 acid 属性吗？\n\n\n# 1.1 acid 属性的要求\n\n可以参考 事务 这一篇文章。\n\n\n# 1.2 redis 如何实现事务？\n\n事务的执行过程包含三个步骤，redis 提供了 multi、exec 两个命令来完成这三个步骤。下面看一下：\n\n 1. 第一步：客户端要使用 multi 命令来显式地表示一个事务的开启。\n 2. 第二步：客户端把事务本身要执行的具体操作（例如增删改数据）发送给服务器端。这些操作就是 redis 本身提供的数据读写命令，例如 get、set 等。不过，这些命令虽然被客户端发送到了服务器端，但 redis 实例只是把这些命令暂存到一个命令队列中，并不会立即执行。\n 3. 第三步：客户端向 redis 发送 exec 命令来执行事务提交，让数据库实际执行第二步中发送的具体操作。\n\n如下代码是使用 multi 和 exec 执行一个事务的过程：\n\n# 开启事务\n127.0.0.1:6379> multi\nok\n# 将a:stock减1，\n127.0.0.1:6379> decr a:stock\nqueued\n# 将b:stock减1\n127.0.0.1:6379> decr b:stock\nqueued\n# 实际执行事务\n127.0.0.1:6379> exec\n1) (integer) 4\n2) (integer) 9\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n好了，通过使用 multi 和 exec 命令，我们可以实现多个操作的共同执行，但是这符合事务要求的 acid 属性吗？\n\n\n# 1.3 redis 的事务机制能保证哪些属性？\n\n这里分别分析一下。\n\n# 1.3.1 原子性\n\n如果事务执行出现错误，原子性还能保证吗？这要分三种情况来看待。\n\n * 第一种情况是，在执行exec命令前，客户端发送的操作命令本身就有错误（比如语法错误，使用了不存在的命令），在命令入队时就被 redis 实例判断出来了。此时 redis 会拒绝执行所有提交的命令，从而保证了原子性。\n   * 例子：\n\n#开启事务\n127.0.0.1:6379> multi\nok\n#发送事务中的第一个操作，但是redis不支持该命令，返回报错信息\n127.0.0.1:6379> put a:stock 5\n(error) err unknown command `put`, with args beginning with: `a:stock`, `5`,\n#发送事务中的第二个操作，这个操作是正确的命令，redis把该命令入队\n127.0.0.1:6379> decr b:stock\nqueued\n#实际执行事务，但是之前命令有错误，所以redis拒绝执行\n127.0.0.1:6379> exec\n(error) execabort transaction discarded because of previous errors.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n * 第二种情况是，某个命令在事务执行期间出现错误，如命令和操作的数据类型不匹配，在操作入队时没有被 redis 实例检查出错误。这时尽管 redis 会对单个命令报错，但还是会把这个事务接下来的所有命令执行完。在这种情况下，事务的原子性就无法得到保证了。\n   * 例子：\n\n#开启事务\n127.0.0.1:6379> multi\nok\n#发送事务中的第一个操作，lpop命令操作的数据类型不匹配，此时并不报错\n127.0.0.1:6379> lpop a:stock\nqueued\n#发送事务中的第二个操作\n127.0.0.1:6379> decr b:stock\nqueued\n#实际执行事务，事务第一个操作执行报错\n127.0.0.1:6379> exec\n1) (error) wrongtype operation against a key holding the wrong kind of value\n2) (integer) 8\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n * 第三种情况是，事务执行期间 redis 实例发生了故障，导致事务执行失败。在这种情况下：\n   * 如果redis开启了aof日志，那么，只会有部分的事务操作被记录到aof日志中。我们需要使用redis-check-aof工具检查aof日志文件，这个工具可以把未完成的事务操作从aof文件中去除。这样一来，我们使用aof恢复实例后，事务操作不会再被执行，从而保证了原子性。\n   * 如果aof日志并没有开启，那么实例重启后，数据也都没法恢复了，此时，也就谈不上原子性了。\n\nredis 也没有提供回滚机制。虽然 redis 提供了 discard 命令，但这个命令只能用来主动放弃事务的执行，把暂存的命令队列清空，起不到回滚的效果。下面代码展示 discard 命令的使用：\n\n#读取a:stock的值4\n127.0.0.1:6379> get a:stock\n"4"\n#开启事务\n127.0.0.1:6379> multi\nok\n#发送事务的第一个操作，对a:stock减1\n127.0.0.1:6379> decr a:stock\nqueued\n#执行discard命令，主动放弃事务\n127.0.0.1:6379> discard\nok\n#再次读取a:stock的值，值没有被修改\n127.0.0.1:6379> get a:stock\n"4"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n这里总结一下 redis 对事务原子性的保证情况：\n\n * 命令入队时就报错，会放弃事务执行，保证原子性；\n * 命令入队时没报错，实际执行时报错，不保证原子性；\n * exec 命令执行时实例故障，如果开启了 aof 日志，可以保证原子性。\n\n# 1.3.2 一致性\n\n我们按照命令出错和实例故障的发生时机，分成三种情况来看：\n\n 1. 情况一：命令入队时就报错。在这种情况下，事务本身就会被放弃执行，所以可以保证数据库的一致性。\n 2. 情况二：命令入队时没报错，实际执行时报错。在这种情况下，有错误的命令不会被执行，正确的命令可以正常执行，也不会改变数据库的一致性。\n 3. 情况三：exec 命令执行时实例发生故障。在这种情况下，实例故障后会进行重启，这就和数据恢复的方式有关了，我们要根据实例是否开启了rdb或aof来分情况讨论下。\n    * 若没有开启 rdb 或 aof 日志：那实例故障重启后，数据都没有了，数据库是一致的。\n    * 若使用了 rdb 快照：因为rdb快照不会在事务执行时执行，所以，事务命令操作的结果不会被保存到 rdb 快照中，使用 rdb 快照进行恢复时，数据库里的数据也是一致的。\n    * 若使用了 aof 日志：\n      * 如果事务操作还没有被记录到aof日志时，实例就发生了故障，那么，使用aof日志恢复的数据库数据是一致的。\n      * 如果只有部分操作被记录到了aof日志，我们可以使用redis-check-aof清除事务中已经完成的操作，数据库恢复后也是一致的。\n\n所以，总结来说，在命令执行错误或 redis 发生故障的情况下，redis 事务机制对一致性属性是有保证的。\n\n# 1.3.3 隔离性\n\n事务的隔离性保证，会受到和事务一起执行的并发操作的影响。而事务执行又可以分成命令入队（exec 命令执行前）和命令实际执行（exec 命令执行后）两个阶段，所以，我们就针对这两个阶段，分成两种情况来分析：\n\n 1. 并发操作在 exec 命令前执行，此时，隔离性的保证要使用 watch 机制来实现，否则隔离性无法保证；\n 2. 并发操作在 exec 命令后执行，此时，隔离性可以保证。\n\n我们先来看第一种情况。一个事务的 exec 命令还没有执行时，事务的命令操作是暂存在命令队列中的。此时，如果有其它的并发操作，我们就需要看事务是否使用了 watch 机制。\n\nwatch 机制的作用是，在事务执行前，监控一个或多个键的值变化情况，当事务调用 exec 命令执行时，watch 机制会先检查监控的键是否被其它客户端修改了。如果修改了，就放弃事务执行，避免事务的隔离性被破坏。然后，客户端可以再次执行事务，此时，如果没有并发修改事务数据的操作了，事务就能正常执行，隔离性也得到了保证。\n\nwatch机制的具体实现是由watch命令实现的，我给你举个例子，你可以看下下面的图，进一步理解下watch命令的使用：\n\n当然，如果没有使用watch机制，在exec命令前执行的并发操作是会对数据进行读写的。而且，在执行exec命令的时候，事务要操作的数据已经改变了，在这种情况下，redis并没有做到让事务对其它操作隔离，隔离性也就没有得到保障。下面这张图显示了没有watch机制时的情况：\n\n对于第二种情况，因为 redis 是用单线程执行命令，而且，exec 命令执行后，redis 会保证先把命令队列中的所有命令执行完。所以，在这种情况下，并发操作不会破坏事务的隔离性，如下图所示：\n\n# 1.3.4 持久性\n\n因为 redis 是内存数据库，所以，数据是否持久化保存完全取决于 redis 的持久化配置模式。\n\n如果redis没有使用rdb或aof，那么事务的持久化属性肯定得不到保证。如果redis使用了rdb模式，那么，在一个事务执行后，而下一次的rdb快照还未执行前，如果发生了实例宕机，这种情况下，事务修改的数据也是不能保证持久化的。\n\n如果redis采用了aof模式，因为aof模式的三种配置选项no、everysec和always都会存在数据丢失的情况，所以，事务的持久性属性也还是得不到保证。\n\n所以，不管 redis 采用什么持久化模式，事务的持久性属性是得不到保证的。\n\n\n# 1.4 小结\n\n这一节学习了 redis 的事务实现，它通过 multi、exec、discard 和 watch 四个命令来支持事务机制，总结如下：\n\n事务的acid属性是我们使用事务进行正确操作的基本要求。通过这节课的分析，我们了解到了，redis的事务机制可以保证一致性和隔离性，但是无法保证持久性。不过，因为redis本身是内存数据库，持久性并不是一个必须的属性，我们更加关注的还是原子性、一致性和隔离性这三个属性。\n\n原子性的情况比较复杂，只有当事务中使用的命令语法有误时，原子性得不到保证，在其它情况下，事务都可以原子性执行。\n\n建议：严格按照 redis 的命令规范进行程序开发，并且通过 code review 确保命令的正确性。这样一来，redis 的事务机制就能被应用在实践中，保证多操作的正确执行。',charsets:{cjk:!0},lastUpdated:"2023/04/19, 02:34:41",lastUpdatedTimestamp:1681871681e3},{title:"Redis 主从同步的坑",frontmatter:{title:"Redis 主从同步的坑",date:"2023-04-19T10:35:28.000Z",permalink:"/pages/4140fe/",categories:["中间件","Redis","专栏：Redis 核心技术与实战"],tags:[null]},regularPath:"/%E4%B8%AD%E9%97%B4%E4%BB%B6/05.Redis/05.%E4%B8%93%E6%A0%8F%EF%BC%9ARedis%20%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/32.Redis%20%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E7%9A%84%E5%9D%91.html",relativePath:"中间件/05.Redis/05.专栏：Redis 核心技术与实战/32.Redis 主从同步的坑.md",key:"v-3622e3e6",path:"/pages/4140fe/",headers:[{level:2,title:"1. Redis 主从同步与故障切换，有哪些坑？",slug:"_1-redis-主从同步与故障切换-有哪些坑",normalizedTitle:"1. redis 主从同步与故障切换，有哪些坑？",charIndex:109},{level:3,title:"1.1 主从数据不一致",slug:"_1-1-主从数据不一致",normalizedTitle:"1.1 主从数据不一致",charIndex:270},{level:3,title:"1.2 读取过期数据",slug:"_1-2-读取过期数据",normalizedTitle:"1.2 读取过期数据",charIndex:905},{level:3,title:"1.3 不合理配置项导致的服务挂掉",slug:"_1-3-不合理配置项导致的服务挂掉",normalizedTitle:"1.3 不合理配置项导致的服务挂掉",charIndex:2321},{level:4,title:"1）protected-mode 配置项",slug:"_1-protected-mode-配置项",normalizedTitle:"1）protected-mode 配置项",charIndex:2399},{level:4,title:"2）cluster-node-timeout 配置项",slug:"_2-cluster-node-timeout-配置项",normalizedTitle:"2）cluster-node-timeout 配置项",charIndex:2886},{level:3,title:"1.4 小结",slug:"_1-4-小结",normalizedTitle:"1.4 小结",charIndex:3249},{level:2,title:"2. 脑裂：一次奇怪的数据丢失",slug:"_2-脑裂-一次奇怪的数据丢失",normalizedTitle:"2. 脑裂：一次奇怪的数据丢失",charIndex:3576},{level:3,title:"2.1 为什么会发生脑裂？",slug:"_2-1-为什么会发生脑裂",normalizedTitle:"2.1 为什么会发生脑裂？",charIndex:3822},{level:4,title:"2.1.1 第一步：确认是不是数据同步出现了问题",slug:"_2-1-1-第一步-确认是不是数据同步出现了问题",normalizedTitle:"2.1.1 第一步：确认是不是数据同步出现了问题",charIndex:3909},{level:4,title:"2.1.2 第二步：排查客户端的操作日志，发现脑裂现象",slug:"_2-1-2-第二步-排查客户端的操作日志-发现脑裂现象",normalizedTitle:"2.1.2 第二步：排查客户端的操作日志，发现脑裂现象",charIndex:4266},{level:4,title:"2.1.3 第三步：发现是原主库假故障导致的脑裂",slug:"_2-1-3-第三步-发现是原主库假故障导致的脑裂",normalizedTitle:"2.1.3 第三步：发现是原主库假故障导致的脑裂",charIndex:4611},{level:3,title:"2.2 为什么脑裂会导致数据丢失？",slug:"_2-2-为什么脑裂会导致数据丢失",normalizedTitle:"2.2 为什么脑裂会导致数据丢失？",charIndex:5322},{level:3,title:"2.3 如何应对脑裂问题？",slug:"_2-3-如何应对脑裂问题",normalizedTitle:"2.3 如何应对脑裂问题？",charIndex:5669},{level:3,title:"2.4 小结",slug:"_2-4-小结",normalizedTitle:"2.4 小结",charIndex:6660}],headersStr:"1. Redis 主从同步与故障切换，有哪些坑？ 1.1 主从数据不一致 1.2 读取过期数据 1.3 不合理配置项导致的服务挂掉 1）protected-mode 配置项 2）cluster-node-timeout 配置项 1.4 小结 2. 脑裂：一次奇怪的数据丢失 2.1 为什么会发生脑裂？ 2.1.1 第一步：确认是不是数据同步出现了问题 2.1.2 第二步：排查客户端的操作日志，发现脑裂现象 2.1.3 第三步：发现是原主库假故障导致的脑裂 2.2 为什么脑裂会导致数据丢失？ 2.3 如何应对脑裂问题？ 2.4 小结",content:"> 参考：\n> \n>  * 32 Redis 主从同步与故障切换，有哪些坑？| 极客时间\n>  * 33 脑裂：一次奇怪的数据丢失| 极客时间\n> \n> 另外：\n> \n> 这篇博文讲同步讲的不错，都串起来了。\n\n\n# 1. Redis 主从同步与故障切换，有哪些坑？\n\nRedis 的主从同步机制不仅可以让从库服务更多的读请求，分担主库的压力，而且还能在主库发生故障时，进行主从库切换，提供高可靠服务。不过在使用主从机制时可能会遇到一些坑，这里主要介绍三个坑：主从数据不一致、读到过期数据，以及配置项设置得不合理从而导致服务挂掉。\n\n\n# 1.1 主从数据不一致\n\n主从数据不一致，就是指客户端从从库中读取到的值和主库中的最新值并不一致。\n\n出现的原因就是主从之间的数据复制是异步进行的。从库出现滞后的两个主要原因：\n\n 1. 网络延迟\n 2. 从库因其他操作而阻塞较长时间\n\n应对方法主要有两个：\n\n 1. 硬件方面，尽量保证主从库间的网络状况良好。例如，我们要避免把主从库部署在不同的机房，或者是避免把网络通信密集的应用（例如数据分析应用）和Redis主从库部署在一起。\n 2. 还可以开发一个外部程序来监控主从库间的复制进度。下面介绍方法。\n\n因为Redis的INFO replication命令可以查看主库接收写命令的进度信息（master_repl_offset）和从库复制写命令的进度信息（slave_repl_offset），所以，我们就可以开发一个监控程序，先用INFO replication命令查到主、从库的进度，然后，我们用master_repl_offset减去slave_repl_offset，这样就能得到从库和主库间的复制进度差值了。\n\n如果某个从库的进度差值大于我们预设的阈值，我们可以让客户端不再和这个从库连接进行数据读取，这样就可以减少读到不一致数据的情况。不过，为了避免出现客户端和所有从库都不能连接的情况，我们需要把复制进度差值的阈值设置得大一些。 当然，监控程序可以一直监控着从库的复制进度，当从库的复制进度又赶上主库时，我们就允许客户端再次跟这些从库连接。\n\n\n# 1.2 读取过期数据\n\n我们在使用 Redis 主从集群时，有时会读到过期数据。例如，数据 X 的过期时间是 202010240900，但是客户端在 202010240910 时，仍然可以从从库中读到数据 X。一个数据过期后，应该是被删除的，客户端不能再读取到该数据，但是，Redis 为什么还能在从库中读到过期的数据呢？\n\n其实，这个问题是由Redis的过期数据删除策略引起的。\n\nRedis 同时使用了两种策略来删除过期数据：\n\n 1. 惰性删除策略：当一个数据的过期时间到了以后，并不会立即删除数据，而是等到再有请求来读写这个数据时，对数据进行检查，如果发现数据已经过期了，再删除这个数据。\n    * 这种方法减少了删除数据对 CPU 资源的使用，但会导致大量已过期数据留在内存中。\n 2. 定期删除策略：Redis 每隔一段时间（默认100ms），就会随机选出一定数量的数据，检查它们是否过期，并把其中过期的数据删除，这样就可以及时释放一些内存。\n\n清楚了这两个删除策略，我们再来看看它们为什么会导致读取到过期数据。\n\n * 定期删除策略只会随机检查一部分数据，仍会存在过期数据残留的问题。\n * 惰性删除策略只在数据再次被访问时才会实际删除。如果客户端从主库上读取留存的过期数据，主库会触发删除操作，此时，客户端并不会读到过期数据。但是，从库本身不会执行删除操作，如果客户端在从库中访问留存的过期数据，从库并不会触发数据删除。那么，从库会给客户端返回过期数据吗？这就和你使用的Redis版本有关了。如果你使用的是Redis 3.2之前的版本，那么，从库在服务读请求时，并不会判断数据是否过期，而是会返回过期数据。在3.2版本后，Redis做了改进，如果读取的数据已经过期了，从库虽然不会删除，但是会返回空值，这就避免了客户端读到过期数据。所以，在应用主从集群时，尽量使用 Redis 3.2 及以上版本。\n\n那只要使用了Redis 3.2 后的版本，就不会读到过期数据了吗？其实还是会的。原因跟 Redis 用于设置过期时间的命令有关系，有些命令给数据设置的过期时间在从库上可能会被延后，导致应该过期的数据又在从库上被读取到了，我来给你具体解释下。\n\n设置数据过期时间的命令一共有4个，我们可以把它们分成两类：\n\n * EXPIRE 和 PEXPIRE：它们给数据设置的是从命令执行时开始计算的存活时间；\n * EXPIREAT 和 PEXPIREAT：它们会直接把数据的过期时间设置为具体的一个时间点。\n\n这 4 个命令的参数和含义如下表所示：\n\n示例：\n\n * EXPIRE testkey 60：把 testkey 的过期时间设置为 60s 后\n * EXPIREAT testkey 1603501200：让testkey在2020年10月24日上午9点过期，命令中的1603501200就是以秒数时间戳表示的10月24日上午9点。\n\n由于网络延迟，使用 EXPIRE 可能会让主从库的过期时间点不一样。因此建议：在业务应用中使用 EXPIREAT/PEXPIREAT 命令，把数据的过期时间设置为具体的时间点，避免读到过期数据。另外注意，EXPIREAT/PEXPIREAT 设置的是时间点，所以主从节点上的时钟要保持一致，具体的做法是，让主从节点和相同的 NTP 服务器(时间服务器)进行时钟同步。\n\n\n# 1.3 不合理配置项导致的服务挂掉\n\n这里涉及到的配置项有两个，分别是 protected-mode 和 cluster-node-timeout。\n\n# 1）protected-mode 配置项\n\n这个配置项的作用是限定哨兵实例能否被其他服务器访问：\n\n * yes：哨兵实例只能在部署的服务器本地进行访问\n * no：其他服务器也可以访问这个哨兵实例\n\n正因为这样，如果protected-mode被设置为yes，而其余哨兵实例部署在其它服务器，那么，这些哨兵实例间就无法通信。当主库故障时，哨兵无法判断主库下线，也无法进行主从切换，最终Redis服务不可用。\n\n所以，我们在应用主从集群时，要注意将 protected-mode 配置项设置为no，并且将bind配置项设置为其它哨兵实例的IP地址。这样一来，只有在bind中设置了IP地址的哨兵，才可以访问当前实例，既保证了实例间能够通信进行主从切换，也保证了哨兵的安全性。\n\n我们来看一个简单的小例子。如果设置了下面的配置项，那么，部署在192.168.10.3/4/5这三台服务器上的哨兵实例就可以相互通信，执行主从切换：\n\nprotected-mode no\nbind 192.168.10.3 192.168.10.4 192.168.10.5\n\n\n1\n2\n\n\n# 2）cluster-node-timeout 配置项\n\n这个配置项设置了Redis Cluster中实例响应心跳消息的超时时间。\n\n当我们在Redis Cluster集群中为每个实例配置了“一主一从”模式时，如果主实例发生故障，从实例会切换为主实例，受网络延迟和切换操作执行的影响，切换时间可能较长，就会导致实例的心跳超时（超出cluster-node-timeout）。实例超时后，就会被Redis Cluster判断为异常。而Redis Cluster正常运行的条件就是，有半数以上的实例都能正常运行。\n\n所以，如果执行主从切换的实例超过半数，而主从切换时间又过长的话，就可能有半数以上的实例心跳超时，从而可能导致整个集群挂掉。所以，我建议你将cluster-node-timeout调大些（例如10到20秒）。\n\n\n# 1.4 小结\n\n这一节主要讲了 Redis 做主从同步时可能出现的 3 个坑：主从数据不一致、读取到过期数据和不合理配置项导致服务挂掉。总结如下：\n\n最后，关于主从库数据不一致的问题，我还想再给你提一个小建议：Redis中的slave-serve-stale-data配置项设置了从库能否处理数据读写命令，你可以把它设置为no。这样一来，从库只能服务INFO、SLAVEOF命令，这就可以避免在从库中读到不一致的数据了。\n\n不过，你要注意下这个配置项和slave-read-only的区别，slave-read-only是设置从库能否处理写命令，slave-read-only设置为yes时，从库只能处理读请求，无法处理写请求，你可不要搞混了。\n\n\n# 2. 脑裂：一次奇怪的数据丢失\n\n> 在使用主从集群时，我曾遇到过这样一个问题：我们的主从集群有1个主库、5个从库和3个哨兵实例，在使用的过程中，我们发现客户端发送的一些数据丢失了，这直接影响到了业务层的数据可靠性。通过排查才知道，这其实是主从集群中脑裂问题导致的。\n\n脑裂：指在主从集群中，同时有两个主节点，它们都能接收写请求。而脑裂最直接的影响，就是客户端不知道应该往哪个主节点写入数据，结果就是不同的客户端会往不同的主节点上写入数据。而且，严重的话，脑裂会进一步导致数据丢失。\n\n\n# 2.1 为什么会发生脑裂？\n\n刚才我提到，我最初发现的问题是，在主从集群中，客户端发送的数据丢失了。所以，我们首先要弄明白，为什么数据会丢失？是不是数据同步出了问题？\n\n# 2.1.1 第一步：确认是不是数据同步出现了问题\n\n在主从集群中发生数据丢失，最常见的原因就是：主库的数据还没有同步到从库，结果主库发生了故障，等从库升级为主库后，未同步的数据就丢失了。\n\n如果是这种情况的数据丢失，我们可以通过比对主从库上的复制进度差值来进行判断，也就是计算master_repl_offset和slave_repl_offset的差值。如果从库上的slave_repl_offset小于原主库的master_repl_offset，那么，我们就可以认定数据丢失是由数据同步未完成导致的。\n\n在背景问题中，我们如上做了检查，发现并不是这个问题。那么我们想到，所有的数据操作都是从客户端发送给Redis实例的，那么，是不是可以从客户端操作日志中发现问题呢？紧接着，我们就把目光转到了客户端。\n\n# 2.1.2 第二步：排查客户端的操作日志，发现脑裂现象\n\n在排查客户端的操作日志时，我们发现，在主从切换后的一段时间内，有一个客户端仍然在和原主库通信，并没有和升级的新主库进行交互。这就相当于主从集群中同时有了两个主库。根据这个迹象，我们就想到了在分布式主从集群发生故障时会出现的一个问题：脑裂。\n\n但是，不同客户端给两个主库发送数据写操作，按道理来说，只会导致新数据会分布在不同的主库上，并不会造成数据丢失。那么，为什么我们的数据仍然丢失了呢？\n\n到这里，我们的排查思路又一次中断了。不过，在分析问题时，我们一直认为“从原理出发是追本溯源的好方法”。脑裂是发生在主从切换的过程中，我们猜测，肯定是漏掉了主从集群切换过程中的某个环节，所以，我们把研究的焦点投向了主从切换的执行过程。\n\n# 2.1.3 第三步：发现是原主库假故障导致的脑裂\n\n我们是采用哨兵机制进行主从切换的，当主从切换发生时，一定是有超过预设数量（quorum配置项）的哨兵实例和主库的心跳都超时了，才会把主库判断为客观下线，然后，哨兵开始执行切换操作。哨兵切换完成后，客户端会和新主库进行通信，发送请求操作。\n\n但是，在切换过程中，既然客户端仍然和原主库通信，这就表明，原主库并没有真的发生故障（例如主库进程挂掉）。我们猜测，主库是由于某些原因无法处理请求，也没有响应哨兵的心跳，才被哨兵错误地判断为客观下线的。结果，在被判断下线之后，原主库又重新开始处理请求了，而此时，哨兵还没有完成主从切换，客户端仍然可以和原主库通信，客户端发送的写操作就会在原主库上写入数据了。\n\n为了验证原主库只是“假故障”，我们也查看了原主库所在服务器的资源使用监控记录。\n\n的确，我们看到原主库所在的机器有一段时间的CPU利用率突然特别高，这是我们在机器上部署的一个数据采集程序导致的。因为这个程序基本把机器的CPU都用满了，导致Redis主库无法响应心跳了，在这个期间内，哨兵就把主库判断为客观下线，开始主从切换了。不过，这个数据采集程序很快恢复正常，CPU的使用率也降下来了。此时，原主库又开始正常服务请求了。\n\n正因为原主库并没有真的发生故障，我们在客户端操作日志中就看到了和原主库的通信记录。等到从库被升级为新主库后，主从集群里就有两个主库了，到这里，我们就把脑裂发生的原因摸清楚了。\n\n为了帮助你加深理解，我再画一张图，展示一下脑裂的发生过程：\n\n弄清楚了脑裂发生的原因后，我们又结合主从切换的原理过程进行了分析，很快就找到数据丢失的原因了。\n\n\n# 2.2 为什么脑裂会导致数据丢失？\n\n主从切换后，从库一旦升级为新主库，哨兵就会让原主库执行slave of命令，和新主库重新进行全量同步。而在全量同步执行的最后阶段，原主库需要清空本地的数据，加载新主库发送的RDB文件，这样一来，原主库在主从切换期间保存的新写数据就丢失了。\n\n下面这张图直观地展示了原主库数据丢失的过程：\n\n到这里，我们就完全弄明白了这个问题的发生过程和原因。\n\n在主从切换的过程中，如果原主库只是“假故障”，它会触发哨兵启动主从切换，一旦等它从假故障中恢复后，又开始处理请求，这样一来，就会和新主库同时存在，形成脑裂。等到哨兵让原主库和新主库做全量同步后，原主库在切换期间保存的数据就丢失了。\n\n看到这里，你肯定会很关心，我们该怎么应对脑裂造成的数据丢失问题呢？\n\n\n# 2.3 如何应对脑裂问题？\n\n刚刚说了，主从集群中的数据丢失事件，归根结底是因为发生了脑裂。所以，我们必须要找到应对脑裂问题的策略。\n\n既然问题是出在原主库发生假故障后仍然能接收请求上，我们就开始在主从集群机制的配置项中查找是否有限制主库接收请求的设置。\n\n通过查找，我们发现，Redis 已经提供了两个配置项来限制主库的请求处理，分别是 min-slaves-to-write 和 min-slaves-max-lag：\n\n * min-slaves-to-write：这个配置项设置了主库能进行数据同步的最少从库数量；\n * min-slaves-max-lag：这个配置项设置了主从库间进行数据复制时，从库给主库发送 ACK 消息的最大延迟（以秒为单位）。\n\n有了这两个配置项后，我们就可以轻松地应对脑裂问题了。具体咋做呢？我们可以把min-slaves-to-write和min-slaves-max-lag这两个配置项搭配起来使用，分别给它们设置一定的阈值，假设为N和T。这两个配置项组合后的要求是，主库连接的从库中至少有N个从库，和主库进行数据复制时的ACK消息延迟不能超过T秒，否则，主库就不会再接收客户端的请求了。\n\n即使原主库是假故障，它在假故障期间也无法响应哨兵心跳，也不能和从库进行同步，自然也就无法和从库进行ACK确认了。这样一来，min-slaves-to-write和min-slaves-max-lag的组合要求就无法得到满足，原主库就会被限制接收客户端请求，客户端也就不能在原主库中写入新数据了。\n\n等到新主库上线时，就只有新主库能接收和处理客户端请求，此时，新写的数据会被直接写到新主库中。而原主库会被哨兵降为从库，即使它的数据被清空了，也不会有新数据丢失。\n\n我再来给你举个例子。\n\n假设我们将min-slaves-to-write设置为1，把min-slaves-max-lag设置为12s，把哨兵的down-after-milliseconds设置为10s，主库因为某些原因卡住了15s，导致哨兵判断主库客观下线，开始进行主从切换。同时，因为原主库卡住了15s，没有一个从库能和原主库在12s内进行数据复制，原主库也无法接收客户端请求了。这样一来，主从切换完成后，也只有新主库能接收请求，不会发生脑裂，也就不会发生数据丢失的问题了。\n\n\n# 2.4 小结\n\n这节课，我们学习了主从切换时可能遇到的脑裂问题。脑裂是指在主从集群中，同时有两个主库都能接收写请求。在Redis的主从切换过程中，如果发生了脑裂，客户端数据就会写入到原主库，如果原主库被降为从库，这些新写入的数据就丢失了。\n\n脑裂发生的原因主要是原主库发生了假故障，我们来总结下假故障的两个原因。\n\n 1. 和主库部署在同一台服务器上的其他程序临时占用了大量资源（例如CPU资源），导致主库资源使用受限，短时间内无法响应心跳。其它程序不再使用资源时，主库又恢复正常。\n 2. 主库自身遇到了阻塞的情况，例如，处理bigkey或是发生内存swap，短时间内无法响应心跳，等主库阻塞解除后，又恢复正常的请求处理了。\n\n为了应对脑裂，你可以在主从集群部署时，通过合理地配置参数min-slaves-to-write和min-slaves-max-lag，来预防脑裂的发生。\n\n在实际应用中，可能会因为网络暂时拥塞导致从库暂时和主库的ACK消息超时。在这种情况下，并不是主库假故障，我们也不用禁止主库接收请求。\n\n所以，我给你的建议是，假设从库有K个，可以将min-slaves-to-write设置为K/2+1（如果K等于1，就设为1），将min-slaves-max-lag设置为十几秒（例如10～20s），在这个配置下，如果有一半以上的从库和主库进行的ACK消息延迟超过十几秒，我们就禁止主库接收客户端写请求。\n\n这样一来，我们可以避免脑裂带来数据丢失的情况，而且，也不会因为只有少数几个从库因为网络阻塞连不上主库，就禁止主库接收请求，增加了系统的鲁棒性。",normalizedContent:"> 参考：\n> \n>  * 32 redis 主从同步与故障切换，有哪些坑？| 极客时间\n>  * 33 脑裂：一次奇怪的数据丢失| 极客时间\n> \n> 另外：\n> \n> 这篇博文讲同步讲的不错，都串起来了。\n\n\n# 1. redis 主从同步与故障切换，有哪些坑？\n\nredis 的主从同步机制不仅可以让从库服务更多的读请求，分担主库的压力，而且还能在主库发生故障时，进行主从库切换，提供高可靠服务。不过在使用主从机制时可能会遇到一些坑，这里主要介绍三个坑：主从数据不一致、读到过期数据，以及配置项设置得不合理从而导致服务挂掉。\n\n\n# 1.1 主从数据不一致\n\n主从数据不一致，就是指客户端从从库中读取到的值和主库中的最新值并不一致。\n\n出现的原因就是主从之间的数据复制是异步进行的。从库出现滞后的两个主要原因：\n\n 1. 网络延迟\n 2. 从库因其他操作而阻塞较长时间\n\n应对方法主要有两个：\n\n 1. 硬件方面，尽量保证主从库间的网络状况良好。例如，我们要避免把主从库部署在不同的机房，或者是避免把网络通信密集的应用（例如数据分析应用）和redis主从库部署在一起。\n 2. 还可以开发一个外部程序来监控主从库间的复制进度。下面介绍方法。\n\n因为redis的info replication命令可以查看主库接收写命令的进度信息（master_repl_offset）和从库复制写命令的进度信息（slave_repl_offset），所以，我们就可以开发一个监控程序，先用info replication命令查到主、从库的进度，然后，我们用master_repl_offset减去slave_repl_offset，这样就能得到从库和主库间的复制进度差值了。\n\n如果某个从库的进度差值大于我们预设的阈值，我们可以让客户端不再和这个从库连接进行数据读取，这样就可以减少读到不一致数据的情况。不过，为了避免出现客户端和所有从库都不能连接的情况，我们需要把复制进度差值的阈值设置得大一些。 当然，监控程序可以一直监控着从库的复制进度，当从库的复制进度又赶上主库时，我们就允许客户端再次跟这些从库连接。\n\n\n# 1.2 读取过期数据\n\n我们在使用 redis 主从集群时，有时会读到过期数据。例如，数据 x 的过期时间是 202010240900，但是客户端在 202010240910 时，仍然可以从从库中读到数据 x。一个数据过期后，应该是被删除的，客户端不能再读取到该数据，但是，redis 为什么还能在从库中读到过期的数据呢？\n\n其实，这个问题是由redis的过期数据删除策略引起的。\n\nredis 同时使用了两种策略来删除过期数据：\n\n 1. 惰性删除策略：当一个数据的过期时间到了以后，并不会立即删除数据，而是等到再有请求来读写这个数据时，对数据进行检查，如果发现数据已经过期了，再删除这个数据。\n    * 这种方法减少了删除数据对 cpu 资源的使用，但会导致大量已过期数据留在内存中。\n 2. 定期删除策略：redis 每隔一段时间（默认100ms），就会随机选出一定数量的数据，检查它们是否过期，并把其中过期的数据删除，这样就可以及时释放一些内存。\n\n清楚了这两个删除策略，我们再来看看它们为什么会导致读取到过期数据。\n\n * 定期删除策略只会随机检查一部分数据，仍会存在过期数据残留的问题。\n * 惰性删除策略只在数据再次被访问时才会实际删除。如果客户端从主库上读取留存的过期数据，主库会触发删除操作，此时，客户端并不会读到过期数据。但是，从库本身不会执行删除操作，如果客户端在从库中访问留存的过期数据，从库并不会触发数据删除。那么，从库会给客户端返回过期数据吗？这就和你使用的redis版本有关了。如果你使用的是redis 3.2之前的版本，那么，从库在服务读请求时，并不会判断数据是否过期，而是会返回过期数据。在3.2版本后，redis做了改进，如果读取的数据已经过期了，从库虽然不会删除，但是会返回空值，这就避免了客户端读到过期数据。所以，在应用主从集群时，尽量使用 redis 3.2 及以上版本。\n\n那只要使用了redis 3.2 后的版本，就不会读到过期数据了吗？其实还是会的。原因跟 redis 用于设置过期时间的命令有关系，有些命令给数据设置的过期时间在从库上可能会被延后，导致应该过期的数据又在从库上被读取到了，我来给你具体解释下。\n\n设置数据过期时间的命令一共有4个，我们可以把它们分成两类：\n\n * expire 和 pexpire：它们给数据设置的是从命令执行时开始计算的存活时间；\n * expireat 和 pexpireat：它们会直接把数据的过期时间设置为具体的一个时间点。\n\n这 4 个命令的参数和含义如下表所示：\n\n示例：\n\n * expire testkey 60：把 testkey 的过期时间设置为 60s 后\n * expireat testkey 1603501200：让testkey在2020年10月24日上午9点过期，命令中的1603501200就是以秒数时间戳表示的10月24日上午9点。\n\n由于网络延迟，使用 expire 可能会让主从库的过期时间点不一样。因此建议：在业务应用中使用 expireat/pexpireat 命令，把数据的过期时间设置为具体的时间点，避免读到过期数据。另外注意，expireat/pexpireat 设置的是时间点，所以主从节点上的时钟要保持一致，具体的做法是，让主从节点和相同的 ntp 服务器(时间服务器)进行时钟同步。\n\n\n# 1.3 不合理配置项导致的服务挂掉\n\n这里涉及到的配置项有两个，分别是 protected-mode 和 cluster-node-timeout。\n\n# 1）protected-mode 配置项\n\n这个配置项的作用是限定哨兵实例能否被其他服务器访问：\n\n * yes：哨兵实例只能在部署的服务器本地进行访问\n * no：其他服务器也可以访问这个哨兵实例\n\n正因为这样，如果protected-mode被设置为yes，而其余哨兵实例部署在其它服务器，那么，这些哨兵实例间就无法通信。当主库故障时，哨兵无法判断主库下线，也无法进行主从切换，最终redis服务不可用。\n\n所以，我们在应用主从集群时，要注意将 protected-mode 配置项设置为no，并且将bind配置项设置为其它哨兵实例的ip地址。这样一来，只有在bind中设置了ip地址的哨兵，才可以访问当前实例，既保证了实例间能够通信进行主从切换，也保证了哨兵的安全性。\n\n我们来看一个简单的小例子。如果设置了下面的配置项，那么，部署在192.168.10.3/4/5这三台服务器上的哨兵实例就可以相互通信，执行主从切换：\n\nprotected-mode no\nbind 192.168.10.3 192.168.10.4 192.168.10.5\n\n\n1\n2\n\n\n# 2）cluster-node-timeout 配置项\n\n这个配置项设置了redis cluster中实例响应心跳消息的超时时间。\n\n当我们在redis cluster集群中为每个实例配置了“一主一从”模式时，如果主实例发生故障，从实例会切换为主实例，受网络延迟和切换操作执行的影响，切换时间可能较长，就会导致实例的心跳超时（超出cluster-node-timeout）。实例超时后，就会被redis cluster判断为异常。而redis cluster正常运行的条件就是，有半数以上的实例都能正常运行。\n\n所以，如果执行主从切换的实例超过半数，而主从切换时间又过长的话，就可能有半数以上的实例心跳超时，从而可能导致整个集群挂掉。所以，我建议你将cluster-node-timeout调大些（例如10到20秒）。\n\n\n# 1.4 小结\n\n这一节主要讲了 redis 做主从同步时可能出现的 3 个坑：主从数据不一致、读取到过期数据和不合理配置项导致服务挂掉。总结如下：\n\n最后，关于主从库数据不一致的问题，我还想再给你提一个小建议：redis中的slave-serve-stale-data配置项设置了从库能否处理数据读写命令，你可以把它设置为no。这样一来，从库只能服务info、slaveof命令，这就可以避免在从库中读到不一致的数据了。\n\n不过，你要注意下这个配置项和slave-read-only的区别，slave-read-only是设置从库能否处理写命令，slave-read-only设置为yes时，从库只能处理读请求，无法处理写请求，你可不要搞混了。\n\n\n# 2. 脑裂：一次奇怪的数据丢失\n\n> 在使用主从集群时，我曾遇到过这样一个问题：我们的主从集群有1个主库、5个从库和3个哨兵实例，在使用的过程中，我们发现客户端发送的一些数据丢失了，这直接影响到了业务层的数据可靠性。通过排查才知道，这其实是主从集群中脑裂问题导致的。\n\n脑裂：指在主从集群中，同时有两个主节点，它们都能接收写请求。而脑裂最直接的影响，就是客户端不知道应该往哪个主节点写入数据，结果就是不同的客户端会往不同的主节点上写入数据。而且，严重的话，脑裂会进一步导致数据丢失。\n\n\n# 2.1 为什么会发生脑裂？\n\n刚才我提到，我最初发现的问题是，在主从集群中，客户端发送的数据丢失了。所以，我们首先要弄明白，为什么数据会丢失？是不是数据同步出了问题？\n\n# 2.1.1 第一步：确认是不是数据同步出现了问题\n\n在主从集群中发生数据丢失，最常见的原因就是：主库的数据还没有同步到从库，结果主库发生了故障，等从库升级为主库后，未同步的数据就丢失了。\n\n如果是这种情况的数据丢失，我们可以通过比对主从库上的复制进度差值来进行判断，也就是计算master_repl_offset和slave_repl_offset的差值。如果从库上的slave_repl_offset小于原主库的master_repl_offset，那么，我们就可以认定数据丢失是由数据同步未完成导致的。\n\n在背景问题中，我们如上做了检查，发现并不是这个问题。那么我们想到，所有的数据操作都是从客户端发送给redis实例的，那么，是不是可以从客户端操作日志中发现问题呢？紧接着，我们就把目光转到了客户端。\n\n# 2.1.2 第二步：排查客户端的操作日志，发现脑裂现象\n\n在排查客户端的操作日志时，我们发现，在主从切换后的一段时间内，有一个客户端仍然在和原主库通信，并没有和升级的新主库进行交互。这就相当于主从集群中同时有了两个主库。根据这个迹象，我们就想到了在分布式主从集群发生故障时会出现的一个问题：脑裂。\n\n但是，不同客户端给两个主库发送数据写操作，按道理来说，只会导致新数据会分布在不同的主库上，并不会造成数据丢失。那么，为什么我们的数据仍然丢失了呢？\n\n到这里，我们的排查思路又一次中断了。不过，在分析问题时，我们一直认为“从原理出发是追本溯源的好方法”。脑裂是发生在主从切换的过程中，我们猜测，肯定是漏掉了主从集群切换过程中的某个环节，所以，我们把研究的焦点投向了主从切换的执行过程。\n\n# 2.1.3 第三步：发现是原主库假故障导致的脑裂\n\n我们是采用哨兵机制进行主从切换的，当主从切换发生时，一定是有超过预设数量（quorum配置项）的哨兵实例和主库的心跳都超时了，才会把主库判断为客观下线，然后，哨兵开始执行切换操作。哨兵切换完成后，客户端会和新主库进行通信，发送请求操作。\n\n但是，在切换过程中，既然客户端仍然和原主库通信，这就表明，原主库并没有真的发生故障（例如主库进程挂掉）。我们猜测，主库是由于某些原因无法处理请求，也没有响应哨兵的心跳，才被哨兵错误地判断为客观下线的。结果，在被判断下线之后，原主库又重新开始处理请求了，而此时，哨兵还没有完成主从切换，客户端仍然可以和原主库通信，客户端发送的写操作就会在原主库上写入数据了。\n\n为了验证原主库只是“假故障”，我们也查看了原主库所在服务器的资源使用监控记录。\n\n的确，我们看到原主库所在的机器有一段时间的cpu利用率突然特别高，这是我们在机器上部署的一个数据采集程序导致的。因为这个程序基本把机器的cpu都用满了，导致redis主库无法响应心跳了，在这个期间内，哨兵就把主库判断为客观下线，开始主从切换了。不过，这个数据采集程序很快恢复正常，cpu的使用率也降下来了。此时，原主库又开始正常服务请求了。\n\n正因为原主库并没有真的发生故障，我们在客户端操作日志中就看到了和原主库的通信记录。等到从库被升级为新主库后，主从集群里就有两个主库了，到这里，我们就把脑裂发生的原因摸清楚了。\n\n为了帮助你加深理解，我再画一张图，展示一下脑裂的发生过程：\n\n弄清楚了脑裂发生的原因后，我们又结合主从切换的原理过程进行了分析，很快就找到数据丢失的原因了。\n\n\n# 2.2 为什么脑裂会导致数据丢失？\n\n主从切换后，从库一旦升级为新主库，哨兵就会让原主库执行slave of命令，和新主库重新进行全量同步。而在全量同步执行的最后阶段，原主库需要清空本地的数据，加载新主库发送的rdb文件，这样一来，原主库在主从切换期间保存的新写数据就丢失了。\n\n下面这张图直观地展示了原主库数据丢失的过程：\n\n到这里，我们就完全弄明白了这个问题的发生过程和原因。\n\n在主从切换的过程中，如果原主库只是“假故障”，它会触发哨兵启动主从切换，一旦等它从假故障中恢复后，又开始处理请求，这样一来，就会和新主库同时存在，形成脑裂。等到哨兵让原主库和新主库做全量同步后，原主库在切换期间保存的数据就丢失了。\n\n看到这里，你肯定会很关心，我们该怎么应对脑裂造成的数据丢失问题呢？\n\n\n# 2.3 如何应对脑裂问题？\n\n刚刚说了，主从集群中的数据丢失事件，归根结底是因为发生了脑裂。所以，我们必须要找到应对脑裂问题的策略。\n\n既然问题是出在原主库发生假故障后仍然能接收请求上，我们就开始在主从集群机制的配置项中查找是否有限制主库接收请求的设置。\n\n通过查找，我们发现，redis 已经提供了两个配置项来限制主库的请求处理，分别是 min-slaves-to-write 和 min-slaves-max-lag：\n\n * min-slaves-to-write：这个配置项设置了主库能进行数据同步的最少从库数量；\n * min-slaves-max-lag：这个配置项设置了主从库间进行数据复制时，从库给主库发送 ack 消息的最大延迟（以秒为单位）。\n\n有了这两个配置项后，我们就可以轻松地应对脑裂问题了。具体咋做呢？我们可以把min-slaves-to-write和min-slaves-max-lag这两个配置项搭配起来使用，分别给它们设置一定的阈值，假设为n和t。这两个配置项组合后的要求是，主库连接的从库中至少有n个从库，和主库进行数据复制时的ack消息延迟不能超过t秒，否则，主库就不会再接收客户端的请求了。\n\n即使原主库是假故障，它在假故障期间也无法响应哨兵心跳，也不能和从库进行同步，自然也就无法和从库进行ack确认了。这样一来，min-slaves-to-write和min-slaves-max-lag的组合要求就无法得到满足，原主库就会被限制接收客户端请求，客户端也就不能在原主库中写入新数据了。\n\n等到新主库上线时，就只有新主库能接收和处理客户端请求，此时，新写的数据会被直接写到新主库中。而原主库会被哨兵降为从库，即使它的数据被清空了，也不会有新数据丢失。\n\n我再来给你举个例子。\n\n假设我们将min-slaves-to-write设置为1，把min-slaves-max-lag设置为12s，把哨兵的down-after-milliseconds设置为10s，主库因为某些原因卡住了15s，导致哨兵判断主库客观下线，开始进行主从切换。同时，因为原主库卡住了15s，没有一个从库能和原主库在12s内进行数据复制，原主库也无法接收客户端请求了。这样一来，主从切换完成后，也只有新主库能接收请求，不会发生脑裂，也就不会发生数据丢失的问题了。\n\n\n# 2.4 小结\n\n这节课，我们学习了主从切换时可能遇到的脑裂问题。脑裂是指在主从集群中，同时有两个主库都能接收写请求。在redis的主从切换过程中，如果发生了脑裂，客户端数据就会写入到原主库，如果原主库被降为从库，这些新写入的数据就丢失了。\n\n脑裂发生的原因主要是原主库发生了假故障，我们来总结下假故障的两个原因。\n\n 1. 和主库部署在同一台服务器上的其他程序临时占用了大量资源（例如cpu资源），导致主库资源使用受限，短时间内无法响应心跳。其它程序不再使用资源时，主库又恢复正常。\n 2. 主库自身遇到了阻塞的情况，例如，处理bigkey或是发生内存swap，短时间内无法响应心跳，等主库阻塞解除后，又恢复正常的请求处理了。\n\n为了应对脑裂，你可以在主从集群部署时，通过合理地配置参数min-slaves-to-write和min-slaves-max-lag，来预防脑裂的发生。\n\n在实际应用中，可能会因为网络暂时拥塞导致从库暂时和主库的ack消息超时。在这种情况下，并不是主库假故障，我们也不用禁止主库接收请求。\n\n所以，我给你的建议是，假设从库有k个，可以将min-slaves-to-write设置为k/2+1（如果k等于1，就设为1），将min-slaves-max-lag设置为十几秒（例如10～20s），在这个配置下，如果有一半以上的从库和主库进行的ack消息延迟超过十几秒，我们就禁止主库接收客户端写请求。\n\n这样一来，我们可以避免脑裂带来数据丢失的情况，而且，也不会因为只有少数几个从库因为网络阻塞连不上主库，就禁止主库接收请求，增加了系统的鲁棒性。",charsets:{cjk:!0},lastUpdated:"2023/04/19, 03:43:04",lastUpdatedTimestamp:1681875784e3},{title:"秒杀场景下的应用",frontmatter:{title:"秒杀场景下的应用",date:"2023-04-21T16:39:06.000Z",permalink:"/pages/b6efd0/",categories:["中间件","Redis","专栏：Redis 核心技术与实战"],tags:[null]},regularPath:"/%E4%B8%AD%E9%97%B4%E4%BB%B6/05.Redis/05.%E4%B8%93%E6%A0%8F%EF%BC%9ARedis%20%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/36.%E7%A7%92%E6%9D%80%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E5%BA%94%E7%94%A8.html",relativePath:"中间件/05.Redis/05.专栏：Redis 核心技术与实战/36.秒杀场景下的应用.md",key:"v-c6d294b8",path:"/pages/b6efd0/",headers:[{level:2,title:"1. Redis 支撑秒杀场景的关键技术和实践都有哪些？",slug:"_1-redis-支撑秒杀场景的关键技术和实践都有哪些",normalizedTitle:"1. redis 支撑秒杀场景的关键技术和实践都有哪些？",charIndex:53},{level:3,title:"1.1 秒杀场景的负载特征对支撑系统的要求",slug:"_1-1-秒杀场景的负载特征对支撑系统的要求",normalizedTitle:"1.1 秒杀场景的负载特征对支撑系统的要求",charIndex:252},{level:3,title:"1.2 Redis 可以在秒杀场景的哪些环节发挥作用？",slug:"_1-2-redis-可以在秒杀场景的哪些环节发挥作用",normalizedTitle:"1.2 redis 可以在秒杀场景的哪些环节发挥作用？",charIndex:606},{level:4,title:"1.2.1 第一阶段：秒杀活动前",slug:"_1-2-1-第一阶段-秒杀活动前",normalizedTitle:"1.2.1 第一阶段：秒杀活动前",charIndex:680},{level:4,title:"1.2.2 第二阶段：秒杀开始",slug:"_1-2-2-第二阶段-秒杀开始",normalizedTitle:"1.2.2 第二阶段：秒杀开始",charIndex:838},{level:4,title:"1.2.3 第三阶段：秒杀活动结束后",slug:"_1-2-3-第三阶段-秒杀活动结束后",normalizedTitle:"1.2.3 第三阶段：秒杀活动结束后",charIndex:1686},{level:3,title:"1.3 Redis 的哪些方法可以支撑秒杀场景？",slug:"_1-3-redis-的哪些方法可以支撑秒杀场景",normalizedTitle:"1.3 redis 的哪些方法可以支撑秒杀场景？",charIndex:2017},{level:4,title:"1.3.1 基于原子操作支撑秒杀场景",slug:"_1-3-1-基于原子操作支撑秒杀场景",normalizedTitle:"1.3.1 基于原子操作支撑秒杀场景",charIndex:2193},{level:4,title:"1.3.2 基于分布式锁来支撑秒杀场景",slug:"_1-3-2-基于分布式锁来支撑秒杀场景",normalizedTitle:"1.3.2 基于分布式锁来支撑秒杀场景",charIndex:3010},{level:3,title:"1.4 小结",slug:"_1-4-小结",normalizedTitle:"1.4 小结",charIndex:3908}],headersStr:"1. Redis 支撑秒杀场景的关键技术和实践都有哪些？ 1.1 秒杀场景的负载特征对支撑系统的要求 1.2 Redis 可以在秒杀场景的哪些环节发挥作用？ 1.2.1 第一阶段：秒杀活动前 1.2.2 第二阶段：秒杀开始 1.2.3 第三阶段：秒杀活动结束后 1.3 Redis 的哪些方法可以支撑秒杀场景？ 1.3.1 基于原子操作支撑秒杀场景 1.3.2 基于分布式锁来支撑秒杀场景 1.4 小结",content:'> 参考：\n> \n>  * 36 Redis 支撑秒杀场景的关键技术和实践都有哪些？| 极客时间\n\n\n# 1. Redis 支撑秒杀场景的关键技术和实践都有哪些？\n\n秒杀是一个非常典型的活动场景，业务特点是限时限量，业务系统要处理瞬时的大量高并发请求，而Redis就经常被用来支撑秒杀活动。\n\n不过，秒杀场景包含了多个环节，可以分成秒杀前、秒杀中和秒杀后三个阶段，每个阶段的请求处理需求并不相同，Redis 并不能支撑秒杀场景的每一个环节。这一节大将看一下 Redis 如何应用到秒杀的场景中。\n\n\n# 1.1 秒杀场景的负载特征对支撑系统的要求\n\n秒杀活动的特点：商品库存量却远远小于购买该商品的用户数，而且会限定用户只能在一定的时间段内购买。\n\n秒杀系统有两个明显的负载特征：\n\n 1. 瞬时并发访问量非常高。一般数据库每秒只能支撑千级别的并发请求，而Redis的并发处理能力（每秒处理请求数）能达到万级别，甚至更高。所以，当有大量并发请求涌入秒杀系统时，我们就需要使用Redis先拦截大部分请求，避免大量请求直接发送给数据库，把数据库压垮。\n 2. 读多写少，而且读操作是简单的查询操作。商品库存查询操作（读操作）要多于库存扣减和下单操作（写操作）。\n\n查验库存是实际秒杀场景中的其中一个环节。Redis 具体可以在整个秒杀场景中哪些环节发挥作用呢？这就要说到秒杀活动的整体流程了，我们来分析下。\n\n\n# 1.2 Redis 可以在秒杀场景的哪些环节发挥作用？\n\n我们一般可以把秒杀活动分成三个阶段。在每一个阶段，Redis所发挥的作用也不一样。\n\n# 1.2.1 第一阶段：秒杀活动前\n\n在这个阶段，用户会不断刷新商品详情页，这会导致详情页的瞬时请求量剧增。这个阶段的应对方案，一般是尽量 把商品详情页的页面元素静态化，然后使用CDN或是浏览器把这些静态化的元素缓存起来。这个阶段往往使用 CDN + 浏览器把商品详情页缓存下来就足够了，还不需要 Redis。\n\n# 1.2.2 第二阶段：秒杀开始\n\n此时，大量用户点击商品详情页上的秒杀按钮，会产生大量的并发请求查询库存。一旦某个请求查询到有库存，紧接着系统就会进行库存扣减。然后，系统会生成实际订单，并进行后续处理，例如订单支付和物流服务。如果请求查不到库存，就会返回。用户通常会继续点击秒杀按钮，继续查询库存。\n\n简单来说，这个阶段的操作就是三个：库存查验、库存扣减和订单处理。因为每个秒杀请求都会查询库存，而请求只有查到有库存余量后，后续的库存扣减和订单处理才会被执行。所以，这个阶段中最大的并发压力都在库存查验操作上。为了支撑大量高并发的库存查验请求，我们需要在这个环节使用 Redis 保存库存量，这样一来，请求可以直接从Redis中读取库存并进行查验。\n\n那么，库存扣减和订单处理是否都可以交给后端的数据库来执行呢?\n\n * 订单处理可以交给数据库执行。因为订单处理往往涉及支付、出库等多个关联操作，需要使用数据库的事务。而且订单处理时请求压力已经不大了，数据库可以支撑这些请求。\n * 库存扣减不能交给数据库执行，而是直接在 Redis 中执行。因为一旦用户查询到有库存就会下单，那么就会发起购买的请求，如果把库存扣减的操作放到数据库来执行，就会带来两个问题：\n   1. 额外的开销。Redis 中保存了库存量，而库存量的最新值又是数据库在维护，所以数据库更新后，还需要和Redis进行同步，这个过程增加了额外的操作逻辑，也带来了额外的开销。\n   2. 下单量超过实际库存量，出现超售。由于数据库的处理速度较慢，不能及时更新库存余量，这就会导致大量库存查验的请求读取到旧的库存值，并进行下单。此时，就会出现下单数量大于实际的库存量，导致出现超售，这就不符合业务层的要求了。\n\n所以，我们就需要直接在Redis中进行库存扣减。具体的操作是，当库存查验完成后，一旦库存有余量，我们就立即在Redis中扣减库存。而且，为了避免请求查询到旧的库存值，库存查验和库存扣减这两个操作需要保证原子性。\n\n# 1.2.3 第三阶段：秒杀活动结束后\n\n在这个阶段，可能还会有部分用户刷新商品详情页，尝试等待有其他用户退单。而已经成功下单的用户会刷新订单详情，跟踪订单的进展。不过，这个阶段中的用户请求量已经下降很多了，服务器端一般都能支撑，我们就不重点讨论了。\n\n这里总结下秒杀场景对 Redis 的需求：秒杀场景分成秒杀前、秒杀中和秒杀后三个阶段。秒杀开始前后，高并发压力没有那么大，我们不需要使用Redis，但在秒杀进行中，需要查验和扣减商品库存，库存查验面临大量的高并发请求，而库存扣减又需要和库存查验一起执行，以保证原子性。这就是秒杀对Redis的需求。\n\n下图展示了秒杀场景需要 Redis 参与的两个环节：\n\n下面介绍 Redis 支撑秒杀场景的方法。\n\n\n# 1.3 Redis 的哪些方法可以支撑秒杀场景？\n\n秒杀场景对 Redis 操作的根本要求有两个：\n\n 1. 支持高并发。Redis 本身支持高并发，但注意如果有多个秒杀商品，我们可以使用切片集群来将压力分散开。\n 2. 保证库存查验和库存扣减原子性执行。针对这条要求，我们就可以使用 Redis 的原子操作或是分布式锁这两个功能特性来支撑了。\n\n# 1.3.1 基于原子操作支撑秒杀场景\n\n在秒杀场景中，一个商品的库存对应了两个信息，分别是总库存量和已秒杀量。这种数据模型正好是一个key（商品ID）对应了两个属性（总库存量和已秒杀量），所以，我们可以使用一个Hash类型的键值对来保存库存的这两个信息，如下所示：\n\nkey: itemID\nvalue: {total: N, ordered: M}\n\n\n1\n2\n\n * 其中，itemID是商品的编号，total是总库存量，ordered是已秒杀量。\n\n因为库存查验和库存扣减这两个操作要保证一起执行，一个直接的方法就是使用Redis的原子操作。原子操作可以是 Redis 自身提供的原子命令，也可以是 Lua 脚本。由于这里逻辑较为复杂，因此采用 Lua 脚本来原子性地执行这两个操作：\n\n# 获取商品库存信息\nlocal counts = redis.call("HMGET", KEYS[1], "total", "ordered");\n# 将总库存转换为数值\nlocal total = tonumber(counts[1])\n# 将已被秒杀的库存转换为数值\nlocal ordered = tonumber(counts[2])\n# 如果当前请求的库存量加上已被秒杀的库存量仍然小于总库存量，就可以更新库存\nif ordered + k <= total then\n    # 更新已秒杀的库存量\n    redis.call("HINCRBY",KEYS[1],"ordered",k)\n    return k;\nend\nreturn 0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n有了 Lua 脚本后，我们就可以在 Redis 客户端，使用 EVAL 命令来执行这个脚本了。最后，客户端会根据脚本的返回值，来确定秒杀是成功还是失败了。如果返回值是k，就是成功了；如果是0，就是失败。\n\n# 1.3.2 基于分布式锁来支撑秒杀场景\n\n使用分布式锁来支撑秒杀场景的具体做法是：先让客户端向 Redis 申请分布式锁，只有拿到锁的客户端才能执行库存查验和库存扣减。这样一来，大量的秒杀请求就会在争夺分布式锁时被过滤掉。而且，库存查验和扣减也不用使用原子操作了，因为多个并发客户端只有一个客户端能够拿到锁，已经保证了客户端并发访问的互斥性。\n\n下面的伪代码显示了使用分布式锁来执行库存查验和扣减的过程：\n\n# 使用商品ID作为key\nkey = itemID\n# 使用客户端唯一标识作为value\nval = clientUniqueID\n# 申请分布式锁，Timeout是超时时间\nlock =acquireLock(key, val, Timeout)\n# 当拿到锁后，才能进行库存查验和扣减\nif (lock == True) {\n   # 库存查验和扣减\n   availStock = DECR(key, k)\n   # 库存已经扣减完了，释放锁，返回秒杀失败\n   if (availStock < 0) {\n      releaseLock(key, val)\n      return error\n   }\n   # 库存扣减成功，释放锁\n   else{\n     releaseLock(key, val)\n     # 订单处理\n   }\n}\n# 没有拿到锁，直接返回\nelse\n   return\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n需要提醒你的是，在使用分布式锁时，客户端需要先向 Redis 请求锁，只有请求到了锁，才能进行库存查验等操作，这样一来，客户端在争抢分布式锁时，大部分秒杀请求本身就会因为抢不到锁而被拦截。所以这里有一个小建议：我们可以使用切片集群中的不同实例来分别保存分布式锁和商品库存信息。使用这种保存方式后，秒杀请求会首先访问保存分布式锁的实例。如果客户端没有拿到锁，这些客户端就不会查询商品库存，这就可以减轻保存库存信息的实例的压力了。\n\n\n# 1.4 小结\n\n这节课，我们学习了Redis在秒杀场景中的具体应用。秒杀场景有2个负载特征，分别是瞬时高并发请求和读多写少。Redis 良好的高并发处理能力，以及高效的键值对读写特性，正好可以满足秒杀场景的需求。我们通过使用 Redis 的原子操作和分布式锁两个功能特性有效地支撑秒杀场景的需求。\n\n当然，对于秒杀场景来说，只用 Redis 是不够的。秒杀系统是一个系统性工程，Redis 实现了对库存查验和扣减这个环节的支撑，除此之外，还有 4 个环节需要我们处理好：\n\n 1. 前端静态页面的设计。秒杀页面上能静态化处理的页面元素，我们都要尽量静态化，这样可以充分利用CDN或浏览器缓存服务秒杀开始前的请求。\n 2. 请求拦截和流控。在秒杀系统的接入层，对恶意请求进行拦截，避免对系统的恶意攻击，例如使用黑名单禁止恶意IP进行访问。如果Redis实例的访问压力过大，为了避免实例崩溃，我们也需要在接入层进行限流，控制进入秒杀系统的请求数量。\n 3. 库存信息过期时间处理。Redis中保存的库存信息其实是数据库的缓存，为了避免缓存击穿问题，我们不要给库存信息设置过期时间。\n 4. 数据库订单异常处理。如果数据库没能成功处理订单，可以增加订单重试功能，保证订单最终能被成功处理。\n\n最后，我也再给你一个小建议：秒杀活动带来的请求流量巨大，我们需要把秒杀商品的库存信息用单独的实例保存，而不要和日常业务系统的数据保存在同一个实例上，这样可以避免干扰业务系统的正常运行。',normalizedContent:'> 参考：\n> \n>  * 36 redis 支撑秒杀场景的关键技术和实践都有哪些？| 极客时间\n\n\n# 1. redis 支撑秒杀场景的关键技术和实践都有哪些？\n\n秒杀是一个非常典型的活动场景，业务特点是限时限量，业务系统要处理瞬时的大量高并发请求，而redis就经常被用来支撑秒杀活动。\n\n不过，秒杀场景包含了多个环节，可以分成秒杀前、秒杀中和秒杀后三个阶段，每个阶段的请求处理需求并不相同，redis 并不能支撑秒杀场景的每一个环节。这一节大将看一下 redis 如何应用到秒杀的场景中。\n\n\n# 1.1 秒杀场景的负载特征对支撑系统的要求\n\n秒杀活动的特点：商品库存量却远远小于购买该商品的用户数，而且会限定用户只能在一定的时间段内购买。\n\n秒杀系统有两个明显的负载特征：\n\n 1. 瞬时并发访问量非常高。一般数据库每秒只能支撑千级别的并发请求，而redis的并发处理能力（每秒处理请求数）能达到万级别，甚至更高。所以，当有大量并发请求涌入秒杀系统时，我们就需要使用redis先拦截大部分请求，避免大量请求直接发送给数据库，把数据库压垮。\n 2. 读多写少，而且读操作是简单的查询操作。商品库存查询操作（读操作）要多于库存扣减和下单操作（写操作）。\n\n查验库存是实际秒杀场景中的其中一个环节。redis 具体可以在整个秒杀场景中哪些环节发挥作用呢？这就要说到秒杀活动的整体流程了，我们来分析下。\n\n\n# 1.2 redis 可以在秒杀场景的哪些环节发挥作用？\n\n我们一般可以把秒杀活动分成三个阶段。在每一个阶段，redis所发挥的作用也不一样。\n\n# 1.2.1 第一阶段：秒杀活动前\n\n在这个阶段，用户会不断刷新商品详情页，这会导致详情页的瞬时请求量剧增。这个阶段的应对方案，一般是尽量 把商品详情页的页面元素静态化，然后使用cdn或是浏览器把这些静态化的元素缓存起来。这个阶段往往使用 cdn + 浏览器把商品详情页缓存下来就足够了，还不需要 redis。\n\n# 1.2.2 第二阶段：秒杀开始\n\n此时，大量用户点击商品详情页上的秒杀按钮，会产生大量的并发请求查询库存。一旦某个请求查询到有库存，紧接着系统就会进行库存扣减。然后，系统会生成实际订单，并进行后续处理，例如订单支付和物流服务。如果请求查不到库存，就会返回。用户通常会继续点击秒杀按钮，继续查询库存。\n\n简单来说，这个阶段的操作就是三个：库存查验、库存扣减和订单处理。因为每个秒杀请求都会查询库存，而请求只有查到有库存余量后，后续的库存扣减和订单处理才会被执行。所以，这个阶段中最大的并发压力都在库存查验操作上。为了支撑大量高并发的库存查验请求，我们需要在这个环节使用 redis 保存库存量，这样一来，请求可以直接从redis中读取库存并进行查验。\n\n那么，库存扣减和订单处理是否都可以交给后端的数据库来执行呢?\n\n * 订单处理可以交给数据库执行。因为订单处理往往涉及支付、出库等多个关联操作，需要使用数据库的事务。而且订单处理时请求压力已经不大了，数据库可以支撑这些请求。\n * 库存扣减不能交给数据库执行，而是直接在 redis 中执行。因为一旦用户查询到有库存就会下单，那么就会发起购买的请求，如果把库存扣减的操作放到数据库来执行，就会带来两个问题：\n   1. 额外的开销。redis 中保存了库存量，而库存量的最新值又是数据库在维护，所以数据库更新后，还需要和redis进行同步，这个过程增加了额外的操作逻辑，也带来了额外的开销。\n   2. 下单量超过实际库存量，出现超售。由于数据库的处理速度较慢，不能及时更新库存余量，这就会导致大量库存查验的请求读取到旧的库存值，并进行下单。此时，就会出现下单数量大于实际的库存量，导致出现超售，这就不符合业务层的要求了。\n\n所以，我们就需要直接在redis中进行库存扣减。具体的操作是，当库存查验完成后，一旦库存有余量，我们就立即在redis中扣减库存。而且，为了避免请求查询到旧的库存值，库存查验和库存扣减这两个操作需要保证原子性。\n\n# 1.2.3 第三阶段：秒杀活动结束后\n\n在这个阶段，可能还会有部分用户刷新商品详情页，尝试等待有其他用户退单。而已经成功下单的用户会刷新订单详情，跟踪订单的进展。不过，这个阶段中的用户请求量已经下降很多了，服务器端一般都能支撑，我们就不重点讨论了。\n\n这里总结下秒杀场景对 redis 的需求：秒杀场景分成秒杀前、秒杀中和秒杀后三个阶段。秒杀开始前后，高并发压力没有那么大，我们不需要使用redis，但在秒杀进行中，需要查验和扣减商品库存，库存查验面临大量的高并发请求，而库存扣减又需要和库存查验一起执行，以保证原子性。这就是秒杀对redis的需求。\n\n下图展示了秒杀场景需要 redis 参与的两个环节：\n\n下面介绍 redis 支撑秒杀场景的方法。\n\n\n# 1.3 redis 的哪些方法可以支撑秒杀场景？\n\n秒杀场景对 redis 操作的根本要求有两个：\n\n 1. 支持高并发。redis 本身支持高并发，但注意如果有多个秒杀商品，我们可以使用切片集群来将压力分散开。\n 2. 保证库存查验和库存扣减原子性执行。针对这条要求，我们就可以使用 redis 的原子操作或是分布式锁这两个功能特性来支撑了。\n\n# 1.3.1 基于原子操作支撑秒杀场景\n\n在秒杀场景中，一个商品的库存对应了两个信息，分别是总库存量和已秒杀量。这种数据模型正好是一个key（商品id）对应了两个属性（总库存量和已秒杀量），所以，我们可以使用一个hash类型的键值对来保存库存的这两个信息，如下所示：\n\nkey: itemid\nvalue: {total: n, ordered: m}\n\n\n1\n2\n\n * 其中，itemid是商品的编号，total是总库存量，ordered是已秒杀量。\n\n因为库存查验和库存扣减这两个操作要保证一起执行，一个直接的方法就是使用redis的原子操作。原子操作可以是 redis 自身提供的原子命令，也可以是 lua 脚本。由于这里逻辑较为复杂，因此采用 lua 脚本来原子性地执行这两个操作：\n\n# 获取商品库存信息\nlocal counts = redis.call("hmget", keys[1], "total", "ordered");\n# 将总库存转换为数值\nlocal total = tonumber(counts[1])\n# 将已被秒杀的库存转换为数值\nlocal ordered = tonumber(counts[2])\n# 如果当前请求的库存量加上已被秒杀的库存量仍然小于总库存量，就可以更新库存\nif ordered + k <= total then\n    # 更新已秒杀的库存量\n    redis.call("hincrby",keys[1],"ordered",k)\n    return k;\nend\nreturn 0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n有了 lua 脚本后，我们就可以在 redis 客户端，使用 eval 命令来执行这个脚本了。最后，客户端会根据脚本的返回值，来确定秒杀是成功还是失败了。如果返回值是k，就是成功了；如果是0，就是失败。\n\n# 1.3.2 基于分布式锁来支撑秒杀场景\n\n使用分布式锁来支撑秒杀场景的具体做法是：先让客户端向 redis 申请分布式锁，只有拿到锁的客户端才能执行库存查验和库存扣减。这样一来，大量的秒杀请求就会在争夺分布式锁时被过滤掉。而且，库存查验和扣减也不用使用原子操作了，因为多个并发客户端只有一个客户端能够拿到锁，已经保证了客户端并发访问的互斥性。\n\n下面的伪代码显示了使用分布式锁来执行库存查验和扣减的过程：\n\n# 使用商品id作为key\nkey = itemid\n# 使用客户端唯一标识作为value\nval = clientuniqueid\n# 申请分布式锁，timeout是超时时间\nlock =acquirelock(key, val, timeout)\n# 当拿到锁后，才能进行库存查验和扣减\nif (lock == true) {\n   # 库存查验和扣减\n   availstock = decr(key, k)\n   # 库存已经扣减完了，释放锁，返回秒杀失败\n   if (availstock < 0) {\n      releaselock(key, val)\n      return error\n   }\n   # 库存扣减成功，释放锁\n   else{\n     releaselock(key, val)\n     # 订单处理\n   }\n}\n# 没有拿到锁，直接返回\nelse\n   return\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n需要提醒你的是，在使用分布式锁时，客户端需要先向 redis 请求锁，只有请求到了锁，才能进行库存查验等操作，这样一来，客户端在争抢分布式锁时，大部分秒杀请求本身就会因为抢不到锁而被拦截。所以这里有一个小建议：我们可以使用切片集群中的不同实例来分别保存分布式锁和商品库存信息。使用这种保存方式后，秒杀请求会首先访问保存分布式锁的实例。如果客户端没有拿到锁，这些客户端就不会查询商品库存，这就可以减轻保存库存信息的实例的压力了。\n\n\n# 1.4 小结\n\n这节课，我们学习了redis在秒杀场景中的具体应用。秒杀场景有2个负载特征，分别是瞬时高并发请求和读多写少。redis 良好的高并发处理能力，以及高效的键值对读写特性，正好可以满足秒杀场景的需求。我们通过使用 redis 的原子操作和分布式锁两个功能特性有效地支撑秒杀场景的需求。\n\n当然，对于秒杀场景来说，只用 redis 是不够的。秒杀系统是一个系统性工程，redis 实现了对库存查验和扣减这个环节的支撑，除此之外，还有 4 个环节需要我们处理好：\n\n 1. 前端静态页面的设计。秒杀页面上能静态化处理的页面元素，我们都要尽量静态化，这样可以充分利用cdn或浏览器缓存服务秒杀开始前的请求。\n 2. 请求拦截和流控。在秒杀系统的接入层，对恶意请求进行拦截，避免对系统的恶意攻击，例如使用黑名单禁止恶意ip进行访问。如果redis实例的访问压力过大，为了避免实例崩溃，我们也需要在接入层进行限流，控制进入秒杀系统的请求数量。\n 3. 库存信息过期时间处理。redis中保存的库存信息其实是数据库的缓存，为了避免缓存击穿问题，我们不要给库存信息设置过期时间。\n 4. 数据库订单异常处理。如果数据库没能成功处理订单，可以增加订单重试功能，保证订单最终能被成功处理。\n\n最后，我也再给你一个小建议：秒杀活动带来的请求流量巨大，我们需要把秒杀商品的库存信息用单独的实例保存，而不要和日常业务系统的数据保存在同一个实例上，这样可以避免干扰业务系统的正常运行。',charsets:{cjk:!0},lastUpdated:"2023/04/21, 09:05:13",lastUpdatedTimestamp:1682067913e3},{title:"集群的数据倾斜和通信开销问题",frontmatter:{title:"集群的数据倾斜和通信开销问题",date:"2023-04-21T17:05:34.000Z",permalink:"/pages/d3d97d/",categories:["中间件","Redis","专栏：Redis 核心技术与实战"],tags:[null]},regularPath:"/%E4%B8%AD%E9%97%B4%E4%BB%B6/05.Redis/05.%E4%B8%93%E6%A0%8F%EF%BC%9ARedis%20%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/37.%E9%9B%86%E7%BE%A4%E7%9A%84%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E5%92%8C%E9%80%9A%E4%BF%A1%E5%BC%80%E9%94%80%E9%97%AE%E9%A2%98.html",relativePath:"中间件/05.Redis/05.专栏：Redis 核心技术与实战/37.集群的数据倾斜和通信开销问题.md",key:"v-aa603976",path:"/pages/d3d97d/",headers:[{level:2,title:"1. 数据分布优化：如何应对数据倾斜？",slug:"_1-数据分布优化-如何应对数据倾斜",normalizedTitle:"1. 数据分布优化：如何应对数据倾斜？",charIndex:86},{level:3,title:"1.1 数据量倾斜的成因和应对方法",slug:"_1-1-数据量倾斜的成因和应对方法",normalizedTitle:"1.1 数据量倾斜的成因和应对方法",charIndex:416},{level:4,title:"1.1.1 bigkey 导致倾斜",slug:"_1-1-1-bigkey-导致倾斜",normalizedTitle:"1.1.1 bigkey 导致倾斜",charIndex:588},{level:4,title:"1.1.2 Slot 分配不均衡导致倾斜",slug:"_1-1-2-slot-分配不均衡导致倾斜",normalizedTitle:"1.1.2 slot 分配不均衡导致倾斜",charIndex:1004},{level:4,title:"1.1.3 Hash Tag 导致倾斜",slug:"_1-1-3-hash-tag-导致倾斜",normalizedTitle:"1.1.3 hash tag 导致倾斜",charIndex:2952},{level:3,title:"1.2 数据访问倾斜的成因和应对方法",slug:"_1-2-数据访问倾斜的成因和应对方法",normalizedTitle:"1.2 数据访问倾斜的成因和应对方法",charIndex:3910},{level:3,title:"1.3 小结",slug:"_1-3-小结",normalizedTitle:"1.3 小结",charIndex:4446},{level:2,title:"2. 通信开销：限制 Redis Cluster 规模的关键因素",slug:"_2-通信开销-限制-redis-cluster-规模的关键因素",normalizedTitle:"2. 通信开销：限制 redis cluster 规模的关键因素",charIndex:4793},{level:3,title:"2.1 实例通信方法和对集群规模的影响",slug:"_2-1-实例通信方法和对集群规模的影响",normalizedTitle:"2.1 实例通信方法和对集群规模的影响",charIndex:5070},{level:4,title:"2.1.1 Gossip 消息大小",slug:"_2-1-1-gossip-消息大小",normalizedTitle:"2.1.1 gossip 消息大小",charIndex:5666},{level:4,title:"2.1.2 实例间通信频率",slug:"_2-1-2-实例间通信频率",normalizedTitle:"2.1.2 实例间通信频率",charIndex:6871},{level:3,title:"2.2 如何降低实例间的通信开销？",slug:"_2-2-如何降低实例间的通信开销",normalizedTitle:"2.2 如何降低实例间的通信开销？",charIndex:7764}],headersStr:"1. 数据分布优化：如何应对数据倾斜？ 1.1 数据量倾斜的成因和应对方法 1.1.1 bigkey 导致倾斜 1.1.2 Slot 分配不均衡导致倾斜 1.1.3 Hash Tag 导致倾斜 1.2 数据访问倾斜的成因和应对方法 1.3 小结 2. 通信开销：限制 Redis Cluster 规模的关键因素 2.1 实例通信方法和对集群规模的影响 2.1.1 Gossip 消息大小 2.1.2 实例间通信频率 2.2 如何降低实例间的通信开销？",content:'> 参考：\n> \n>  * 37 数据分布优化：如何应对数据倾斜？| 极客时间\n>  * 38 通信开销：限制Redis Cluster规模的关键因素| 极客时间\n\n\n# 1. 数据分布优化：如何应对数据倾斜？\n\n在 Redis 切片集群中，数据都会按照 CRC 算法的计算值对 Slot 取模，然后再映射到某个实例上。这种方法虽然实现简单，但容易导致一个问题：数据倾斜。\n\n数据倾斜有两类：\n\n * 数据量倾斜：在某些情况下，实例上的数据分布不均衡，某个实例上的数据特别多。\n * 数据访问倾斜：虽然每个集群实例上的数据量相差不大，但是某个实例上的数据是热点数据，被访问得非常频繁。\n\n如果发生了数据倾斜，那么保存了大量数据，或者是保存了热点数据的实例的处理压力就会增大，速度变慢，甚至还可能会引起这个实例的内存资源耗尽，从而崩溃。这是我们在应用切片集群时要避免的。\n\n这一大节将讨论数据倾斜是如何发生的，以及如何应对。\n\n\n# 1.1 数据量倾斜的成因和应对方法\n\n当数据量倾斜发生时，数据在切片集群的多个实例上分布不均衡，大量数据集中到了一个或几个实例上，如下图所示：\n\n那么，数据量倾斜是怎么产生的呢？这主要有三个原因，分别是某个实例上保存了bigkey、Slot分配不均衡以及Hash Tag。接下来，我们就一个一个来分析，同时我还会给你讲解相应的解决方案。\n\n# 1.1.1 bigkey 导致倾斜\n\n第一个原因是，某个实例上正好保存了bigkey。bigkey的value值很大（String类型），或者是bigkey保存了大量集合元素（集合类型），会导致这个实例的数据量增加，内存资源消耗也相应增加。\n\n而且，bigkey的操作一般都会造成实例IO线程阻塞，如果bigkey的访问量比较大，就会影响到这个实例上的其它请求被处理的速度。\n\n其实，bigkey已经是我们课程中反复提到的一个关键点了。为了避免bigkey造成的数据倾斜，一个根本的应对方法是，我们在业务层生成数据时，要尽量避免把过多的数据保存在同一个键值对中。此外，如果 bigkey 正好是集合类型，那可以把它拆成多个小的集合类型数据，分散保存在不同的实例上。把一个bigkey化整为零、分散保存了，避免了bigkey给单个切片实例带来的访问压力。\n\n需要注意的是，当 bigkey 访问量较大时，也会造成数据访问倾斜。\n\n# 1.1.2 Slot 分配不均衡导致倾斜\n\n如果集群运维人员没有均衡地分配 Slot，就会有大量的数据被分配到同一个 Slot 中，而同一个 Slot 只会在一个实例上分布，这就会导致，大量数据被集中到一个实例上，造成数据倾斜。\n\n为了应对这个问题，我们可以通过运维规范，在分配之前，我们就要避免把过多的 Slot 分配到同一个实例。如果是已经分配好Slot的集群，我们可以先查看Slot和实例的具体分配关系，从而判断是否有过多的Slot集中到了同一个实例。如果有的话，就将部分Slot迁移到其它实例，从而避免数据倾斜。\n\n不同集群上查看Slot分配情况的方式不同：如果是Redis Cluster，就用CLUSTER SLOTS命令；如果是Codis，就可以在codis dashboard上查看。\n\nRedis Cluster 中 slot 的迁移\n\n比如说，我们执行CLUSTER SLOTS命令查看Slot分配情况。命令返回结果显示，Slot 0 到Slot 4095被分配到了实例192.168.10.3上，而Slot 12288到Slot 16383被分配到了实例192.168.10.5上。\n\n127.0.0.1:6379> cluster slots\n1) 1) (integer) 0\n   1) (integer) 4095\n   2) 1) "192.168.10.3"\n      1) (integer) 6379\n2) 1) (integer) 12288\n   1) (integer) 16383\n   2) 1) "192.168.10.5"\n      1) (integer) 6379\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n如果某一个实例上有太多的Slot，我们就可以使用迁移命令把这些Slot迁移到其它实例上。在Redis Cluster中，我们可以使用3个命令完成Slot迁移。\n\n 1. CLUSTER SETSLOT：使用不同的选项进行三种设置，分别是设置Slot要迁入的目标实例，Slot要迁出的源实例，以及Slot所属的实例。\n 2. CLUSTER GETKEYSINSLOT：获取某个Slot中一定数量的key。\n 3. MIGRATE：把一个key从源实例实际迁移到目标实例。\n\n我来借助一个例子，带你了解下这三个命令怎么用。\n\n假设我们要把Slot 300从源实例（ID为3）迁移到目标实例（ID为5），那要怎么做呢？\n\n实际上，我们可以分成5步。\n\n第1步，我们先在目标实例5上执行下面的命令，将Slot 300的源实例设置为实例3，表示要从实例3上迁入Slot 300。\n\nCLUSTER SETSLOT 300 IMPORTING 3\n\n\n1\n\n\n第2步，在源实例3上，我们把Slot 300的目标实例设置为5，这表示，Slot 300要迁出到实例5上，如下所示：\n\nCLUSTER SETSLOT 300 MIGRATING 5\n\n\n1\n\n\n第3步，从Slot 300中获取100 个key。因为Slot中的key数量可能很多，所以我们需要在客户端上多次执行下面的这条命令，分批次获得并迁移key。\n\nCLUSTER GETKEYSINSLOT 300 100\n\n\n1\n\n\n第4步，我们把刚才获取的100个key中的key1迁移到目标实例5上（IP为192.168.10.5），同时把要迁入的数据库设置为0号数据库，把迁移的超时时间设置为timeout。我们重复执行MIGRATE命令，把100个key都迁移完。\n\nMIGRATE 192.168.10.5 6379 key1 0 timeout\n\n\n1\n\n\n最后，我们重复执行第3和第4步，直到Slot中的所有key都迁移完成。\n\n从Redis 3.0.6开始，你也可以使用KEYS选项，一次迁移多个key（key1、2、3），这样可以提升迁移效率。\n\nMIGRATE 192.168.10.5 6379 "" 0 timeout KEYS key1 key2 key3\n\n\n1\n\n\n对于Codis来说，我们可以执行下面的命令进行数据迁移。其中，我们把dashboard组件的连接地址设置为ADDR，并且把Slot 300迁移到编号为6的codis server group上。\n\ncodis-admin --dashboard=ADDR -slot-action --create --sid=300 --gid=6\n\n\n1\n\n\n除了 bigkey 和 Slot 分配不均衡会导致数据量倾斜，还有一个导致倾斜的原因，就是使用了 Hash Tag 进行数据切片。\n\n# 1.1.3 Hash Tag 导致倾斜\n\nHash Tag 是指加在键值对 key 中的一对花括号 {}。这对括号会把 key 的一部分括起来，客户端在计算 key 的 CRC16 值时，只对 Hash Tag 花括号中的 key 内容进行计算。如果没用 Hash Tag 的话，客户端计算整个 key 的 CRC16 的值。\n\n> 举个例子，假设key是user:profile:3231，我们把其中的3231作为Hash Tag，此时，key就变成了user:profile:{3231}。当客户端计算这个key的CRC16值时，就只会计算3231的CRC16值。否则，客户端会计算整个“user:profile:3231”的CRC16值。\n\n使用 Hash Tag 的好处是，如果不同 key 的 Hash Tag 内容都是一样的，那么，这些 key 对应的数据会被映射到同一个 Slot 中，同时会被分配到同一个实例上。\n\nHash Tag 主要是用在 Redis Cluster 和 Codis 中，支持事务操作和范围查询。因为 Redis Cluster 和 Codis 本身并不支持跨实例的事务操作和范围查询，当业务应用有这些需求时，就只能先把这些数据读取到业务层进行事务处理，或者是逐个查询每个实例，得到范围查询的结果。这样操作起来非常麻烦，所以，我们可以使用 Hash Tag 把要执行事务操作或是范围查询的数据映射到同一个实例上，这样就能很轻松地实现事务或范围查询了。\n\n但是，使用Hash Tag的潜在问题，就是大量的数据可能被集中到一个实例上，导致数据倾斜，集群中的负载不均衡。那么，该怎么应对这种问题呢？我们就需要在范围查询、事务执行的需求和数据倾斜带来的访问压力之间，进行取舍了。\n\n我的建议是，如果使用Hash Tag进行切片的数据会带来较大的访问压力，就优先考虑避免数据倾斜，最好不要使用Hash Tag进行数据切片。因为事务和范围查询都还可以放在客户端来执行，而数据倾斜会导致实例不稳定，造成服务不可用。\n\n----------------------------------------\n\n以上介绍了数据量倾斜的原因以及应对方法。下面看一下数据访问倾斜的原因和应对方法。\n\n\n# 1.2 数据访问倾斜的成因和应对方法\n\n发生数据访问倾斜的根本原因，就是实例上存在热点数据。一旦热点数据被存在了某个实例中，那么，这个实例的请求访问量就会远高于其它实例，面临巨大的访问压力。如下图所示：\n\n如何应对呢？和数据量倾斜不同，热点数据通常是一个或几个数据，所以，直接重新分配 Slot 并不能解决热点数据的问题。\n\n通常来说，热点数据以服务读操作为主，在这种情况下，我们可以采用热点数据多副本的方法来应对。这个方法的具体做法是，我们把热点数据复制多份，在每一个数据副本的key中增加一个随机前缀，让它和其它副本数据不会被映射到同一个Slot中。这样一来，热点数据既有多个副本可以同时服务请求，同时，这些副本数据的key又不一样，会被映射到不同的Slot中。在给这些Slot分配实例时，我们也要注意把它们分配到不同的实例上，那么，热点数据的访问压力就被分散到不同的实例上了。\n\n这里，有个地方需要注意下，热点数据多副本方法只能针对只读的热点数据。如果热点数据是有读有写的话，就不适合采用多副本方法了，因为要保证多副本间的数据一致性，会带来额外的开销。\n\n对于有读有写的热点数据，我们就要给实例本身增加资源了，例如使用配置更高的机器，来应对大量的访问压力。\n\n\n# 1.3 小结\n\n这一大节介绍了数据倾斜的两种情况：数据量倾斜和数据访问倾斜。\n\n造成数据量倾斜的原因主要有三个：\n\n 1. 数据中有bigkey，导致某个实例的数据量增加；\n 2. Slot手工分配不均，导致某个或某些实例上有大量数据；\n 3. 使用了Hash Tag，导致数据集中到某些实例上。\n\n而数据访问倾斜的主要原因就是有热点数据存在，导致大量访问请求集中到了热点数据所在的实例上。\n\n下表对以上情况进行了总结：\n\n如果已经发生了数据倾斜，我们可以通过数据迁移来缓解数据倾斜的影响。\n\n最后，关于集群的实例资源配置，我再给你一个小建议：在构建切片集群时，尽量使用大小配置相同的实例（例如实例内存配置保持相同），这样可以避免因实例资源不均衡而在不同实例上分配不同数量的Slot。\n\n\n# 2. 通信开销：限制 Redis Cluster 规模的关键因素\n\nRedis Cluster能保存的数据量以及支撑的吞吐量，跟集群的实例规模密切相关。Redis官方给出了Redis Cluster的规模上限，就是一个集群运行1000个实例。\n\n限制 Redis 集群数量的一个关键因素就是：实例间的通信开销会随着实例规模增加而增大。在集群超过一定规模时（比如 800 节点），集群吞吐量反而会下降。所以，集群的实际规模会受到限制。\n\n这一大节将讨论集群实例间的通信开销是如何影响Redis Cluster规模的，以及如何降低实例间的通信开销。\n\n\n# 2.1 实例通信方法和对集群规模的影响\n\nRedis Cluster 在运行时，每个实例上都会保存 Slot 和实例的对应关系（也就是Slot映射表），以及自身的状态信息。实例之间为了互通这些状态信息，会使用 Gossip 协议来进行通信。\n\nGossip协议的工作原理可以概括成两点。\n\n * 一是，每个实例之间会按照一定的频率，从集群中随机挑选一些实例，把PING消息发送给挑选出来的实例，用来检测这些实例是否在线，并交换彼此的状态信息。PING消息中封装了发送消息的实例自身的状态信息、部分其它实例的状态信息，以及Slot映射表。\n * 二是，一个实例在接收到PING消息后，会给发送PING消息的实例，发送一个PONG消息。PONG消息包含的内容和PING消息一样。\n\n下图显示了两个实例间进行 PING、PONG 消息传递的情况：\n\nGossip 协议可以保证在一段时间后，集群中的每一个实例都能获得其它所有实例的状态信息。这样一来，即使有新节点加入、节点故障、Slot 变更等事件发生，实例间也可以通过 PING、PONG 消息的传递，完成集群状态在每个实例上的同步。\n\n可以直观看到，实例之间使用 Gossip 协议通信时，通信开销会受到通信消息大小和通信频率这两方面的影响，消息越大、频率越高，相应的通信开销也就越大。如果想要实现高效的通信，可以从这两方面入手去调优。\n\n# 2.1.1 Gossip 消息大小\n\nRedis 实例发送的 PING 消息的消息体是由 clusterMsgDataGossip 结构体组成的，这个结构体的定义如下所示：\n\ntypedef struct {\n    char nodename[CLUSTER_NAMELEN];  //40字节\n    uint32_t ping_sent; //4字节\n    uint32_t pong_received; //4字节\n    char ip[NET_IP_STR_LEN]; //46字节\n    uint16_t port;  //2字节\n    uint16_t cport;  //2字节\n    uint16_t flags;  //2字节\n    uint32_t notused1; //4字节\n} clusterMsgDataGossip;\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n其中，CLUSTER_NAMELEN和NET_IP_STR_LEN的值分别是40和46，分别表示，nodename和ip这两个字节数组的长度是40字节和46字节，我们再把结构体中其它信息的大小加起来，就可以得到一个Gossip消息的大小了，即104字节。\n\n每个实例在发送一个Gossip消息时，除了会传递自身的状态信息，默认还会传递集群十分之一实例的状态信息。\n\n所以，对于一个包含了1000个实例的集群来说，每个实例发送一个PING消息时，会包含100个实例的状态信息，总的数据量是 10400字节，再加上发送实例自身的信息，一个Gossip消息大约是10KB。\n\n此外，为了让Slot映射表能够在不同实例间传播，PING消息中还带有一个长度为 16,384 bit 的 Bitmap，这个Bitmap的每一位对应了一个Slot，如果某一位为1，就表示这个Slot属于当前实例。这个Bitmap大小换算成字节后，是2KB。我们把实例状态信息和Slot分配信息相加，就可以得到一个PING消息的大小了，大约是12KB。\n\nPONG消息和PING消息的内容一样，所以，它的大小大约是12KB。每个实例发送了PING消息后，还会收到返回的PONG消息，两个消息加起来有24KB。\n\n虽然从绝对值上来看，24KB 并不算很大，但是，如果实例正常处理的单个请求只有几KB的话，那么，实例为了维护集群状态一致传输的PING/PONG消息，就要比单个业务请求大了。而且，每个实例都会给其它实例发送PING/PONG消息。随着集群规模增加，这些心跳消息的数量也会越多，会占据一部分集群的网络通信带宽，进而会降低集群服务正常客户端请求的吞吐量。\n\n除了心跳消息大小会影响到通信开销，如果实例间通信非常频繁，也会导致集群网络带宽被频繁占用。那么，Redis Cluster 中实例的通信频率是什么样的呢？\n\n# 2.1.2 实例间通信频率\n\nRedis Cluster 的实例启动后，默认会每秒从本地的实例列表中随机选出5个实例，再从这5个实例中找出一个最久没有通信的实例，把PING消息发送给该实例。这是实例周期性发送PING消息的基本做法。\n\n但是，这里有一个问题：实例选出来的这个最久没有通信的实例，毕竟是从随机选出的5个实例中挑选的，这并不能保证这个实例就一定是整个集群中最久没有通信的实例。所以，这有可能会出现，有些实例一直没有被发送PING消息，导致它们维护的集群状态已经过期了。\n\n为了避免这种情况，Redis Cluster的实例会按照每100ms一次的频率，扫描本地的实例列表，如果发现有实例最近一次接收 PONG消息的时间，已经大于配置项 cluster-node-timeout的一半了（cluster-node-timeout/2），就会立刻给该实例发送 PING消息，更新这个实例上的集群状态信息。\n\n当集群规模扩大之后，因为网络拥塞或是不同服务器间的流量竞争，会导致实例间的网络通信延迟增加。如果有部分实例无法收到其它实例发送的PONG消息，就会引起实例之间频繁地发送PING消息，这又会对集群网络通信带来额外的开销了。\n\n我们来总结下单实例每秒会发送的PING消息数量，如下所示：\n\n> PING消息发送数量 = 1 + 10 * 实例数（最近一次接收PONG消息的时间超出cluster-node-timeout/2） 其中，1是指单实例常规按照每1秒发送一个PING消息，10是指每1秒内实例会执行10次检查，每次检查后会给PONG消息超时的实例发送消息。\n\n我来借助一个例子，带你分析一下在这种通信频率下，PING消息占用集群带宽的情况。\n\n假设单个实例检测发现，每100毫秒有10个实例的PONG消息接收超时，那么，这个实例每秒就会发送101个PING消息，约占1.2MB/s带宽。如果集群中有30个实例按照这种频率发送消息，就会占用36MB/s带宽，这就会挤占集群中用于服务正常请求的带宽。\n\n所以，我们要想办法降低实例间的通信开销，那该怎么做呢？\n\n\n# 2.2 如何降低实例间的通信开销？\n\n为了降低实例间的通信开销，从原理上说，我们可以减小实例传输的消息大小（PING/PONG消息、Slot分配信息），但是，因为集群实例依赖PING、PONG消息和Slot分配信息，来维持集群状态的统一，一旦减小了传递的消息大小，就会导致实例间的通信信息减少，不利于集群维护，所以，我们不能采用这种方式。\n\n那么，我们能不能降低实例间发送消息的频率呢？我们先来分析一下。\n\n经过刚才的学习，我们现在知道，实例间发送消息的频率有两个。\n\n * 每个实例每1秒发送一条PING消息。这个频率不算高，如果再降低该频率的话，集群中各实例的状态可能就没办法及时传播了。\n * 每个实例每100毫秒会做一次检测，给PONG消息接收超过cluster-node-timeout/2的节点发送PING消息。实例按照每100毫秒进行检测的频率，是Redis实例默认的周期性检查任务的统一频率，我们一般不需要修改它。\n\n那么，就只有cluster-node-timeout这个配置项可以修改了。\n\n配置项cluster-node-timeout定义了集群实例被判断为故障的心跳超时时间，默认是15秒。如果cluster-node-timeout值比较小，那么，在大规模集群中，就会比较频繁地出现PONG消息接收超时的情况，从而导致实例每秒要执行10次“给PONG消息超时的实例发送PING消息”这个操作。\n\n所以，为了避免过多的心跳消息挤占集群带宽，我们可以调大cluster-node-timeout值，比如说调大到20秒或25秒。这样一来， PONG消息接收超时的情况就会有所缓解，单实例也不用频繁地每秒执行10次心跳发送操作了。\n\n当然，我们也不要把cluster-node-timeout调得太大，否则，如果实例真的发生了故障，我们就需要等待cluster-node-timeout时长后，才能检测出这个故障，这又会导致实际的故障恢复时间被延长，会影响到集群服务的正常使用。\n\n为了验证调整cluster-node-timeout值后，是否能减少心跳消息占用的集群网络带宽，我给你提个小建议：你可以在调整cluster-node-timeout值的前后，使用tcpdump命令抓取实例发送心跳信息网络包的情况。\n\n例如，执行下面的命令后，我们可以抓取到192.168.10.3机器上的实例从16379端口发送的心跳网络包，并把网络包的内容保存到r1.cap文件中：\n\ntcpdump host 192.168.10.3 port 16379 -i 网卡名 -w /tmp/r1.cap\n\n\n1\n\n\n通过分析网络包的数量和大小，就可以判断调整cluster-node-timeout值前后，心跳消息占用的带宽情况了。\n\n建议：如果不是特别需要大容量集群，最好 把Redis Cluster 的规模控制在 400~500 个实例。\n\n假设单个实例每秒能支撑8万请求操作（8万QPS），每个主实例配置1个从实例，那么，400~ 500个实例可支持 1600万~2000万QPS（200/250个主实例*8万QPS=1600/2000万QPS），这个吞吐量性能可以满足不少业务应用的需求。',normalizedContent:'> 参考：\n> \n>  * 37 数据分布优化：如何应对数据倾斜？| 极客时间\n>  * 38 通信开销：限制redis cluster规模的关键因素| 极客时间\n\n\n# 1. 数据分布优化：如何应对数据倾斜？\n\n在 redis 切片集群中，数据都会按照 crc 算法的计算值对 slot 取模，然后再映射到某个实例上。这种方法虽然实现简单，但容易导致一个问题：数据倾斜。\n\n数据倾斜有两类：\n\n * 数据量倾斜：在某些情况下，实例上的数据分布不均衡，某个实例上的数据特别多。\n * 数据访问倾斜：虽然每个集群实例上的数据量相差不大，但是某个实例上的数据是热点数据，被访问得非常频繁。\n\n如果发生了数据倾斜，那么保存了大量数据，或者是保存了热点数据的实例的处理压力就会增大，速度变慢，甚至还可能会引起这个实例的内存资源耗尽，从而崩溃。这是我们在应用切片集群时要避免的。\n\n这一大节将讨论数据倾斜是如何发生的，以及如何应对。\n\n\n# 1.1 数据量倾斜的成因和应对方法\n\n当数据量倾斜发生时，数据在切片集群的多个实例上分布不均衡，大量数据集中到了一个或几个实例上，如下图所示：\n\n那么，数据量倾斜是怎么产生的呢？这主要有三个原因，分别是某个实例上保存了bigkey、slot分配不均衡以及hash tag。接下来，我们就一个一个来分析，同时我还会给你讲解相应的解决方案。\n\n# 1.1.1 bigkey 导致倾斜\n\n第一个原因是，某个实例上正好保存了bigkey。bigkey的value值很大（string类型），或者是bigkey保存了大量集合元素（集合类型），会导致这个实例的数据量增加，内存资源消耗也相应增加。\n\n而且，bigkey的操作一般都会造成实例io线程阻塞，如果bigkey的访问量比较大，就会影响到这个实例上的其它请求被处理的速度。\n\n其实，bigkey已经是我们课程中反复提到的一个关键点了。为了避免bigkey造成的数据倾斜，一个根本的应对方法是，我们在业务层生成数据时，要尽量避免把过多的数据保存在同一个键值对中。此外，如果 bigkey 正好是集合类型，那可以把它拆成多个小的集合类型数据，分散保存在不同的实例上。把一个bigkey化整为零、分散保存了，避免了bigkey给单个切片实例带来的访问压力。\n\n需要注意的是，当 bigkey 访问量较大时，也会造成数据访问倾斜。\n\n# 1.1.2 slot 分配不均衡导致倾斜\n\n如果集群运维人员没有均衡地分配 slot，就会有大量的数据被分配到同一个 slot 中，而同一个 slot 只会在一个实例上分布，这就会导致，大量数据被集中到一个实例上，造成数据倾斜。\n\n为了应对这个问题，我们可以通过运维规范，在分配之前，我们就要避免把过多的 slot 分配到同一个实例。如果是已经分配好slot的集群，我们可以先查看slot和实例的具体分配关系，从而判断是否有过多的slot集中到了同一个实例。如果有的话，就将部分slot迁移到其它实例，从而避免数据倾斜。\n\n不同集群上查看slot分配情况的方式不同：如果是redis cluster，就用cluster slots命令；如果是codis，就可以在codis dashboard上查看。\n\nredis cluster 中 slot 的迁移\n\n比如说，我们执行cluster slots命令查看slot分配情况。命令返回结果显示，slot 0 到slot 4095被分配到了实例192.168.10.3上，而slot 12288到slot 16383被分配到了实例192.168.10.5上。\n\n127.0.0.1:6379> cluster slots\n1) 1) (integer) 0\n   1) (integer) 4095\n   2) 1) "192.168.10.3"\n      1) (integer) 6379\n2) 1) (integer) 12288\n   1) (integer) 16383\n   2) 1) "192.168.10.5"\n      1) (integer) 6379\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n如果某一个实例上有太多的slot，我们就可以使用迁移命令把这些slot迁移到其它实例上。在redis cluster中，我们可以使用3个命令完成slot迁移。\n\n 1. cluster setslot：使用不同的选项进行三种设置，分别是设置slot要迁入的目标实例，slot要迁出的源实例，以及slot所属的实例。\n 2. cluster getkeysinslot：获取某个slot中一定数量的key。\n 3. migrate：把一个key从源实例实际迁移到目标实例。\n\n我来借助一个例子，带你了解下这三个命令怎么用。\n\n假设我们要把slot 300从源实例（id为3）迁移到目标实例（id为5），那要怎么做呢？\n\n实际上，我们可以分成5步。\n\n第1步，我们先在目标实例5上执行下面的命令，将slot 300的源实例设置为实例3，表示要从实例3上迁入slot 300。\n\ncluster setslot 300 importing 3\n\n\n1\n\n\n第2步，在源实例3上，我们把slot 300的目标实例设置为5，这表示，slot 300要迁出到实例5上，如下所示：\n\ncluster setslot 300 migrating 5\n\n\n1\n\n\n第3步，从slot 300中获取100 个key。因为slot中的key数量可能很多，所以我们需要在客户端上多次执行下面的这条命令，分批次获得并迁移key。\n\ncluster getkeysinslot 300 100\n\n\n1\n\n\n第4步，我们把刚才获取的100个key中的key1迁移到目标实例5上（ip为192.168.10.5），同时把要迁入的数据库设置为0号数据库，把迁移的超时时间设置为timeout。我们重复执行migrate命令，把100个key都迁移完。\n\nmigrate 192.168.10.5 6379 key1 0 timeout\n\n\n1\n\n\n最后，我们重复执行第3和第4步，直到slot中的所有key都迁移完成。\n\n从redis 3.0.6开始，你也可以使用keys选项，一次迁移多个key（key1、2、3），这样可以提升迁移效率。\n\nmigrate 192.168.10.5 6379 "" 0 timeout keys key1 key2 key3\n\n\n1\n\n\n对于codis来说，我们可以执行下面的命令进行数据迁移。其中，我们把dashboard组件的连接地址设置为addr，并且把slot 300迁移到编号为6的codis server group上。\n\ncodis-admin --dashboard=addr -slot-action --create --sid=300 --gid=6\n\n\n1\n\n\n除了 bigkey 和 slot 分配不均衡会导致数据量倾斜，还有一个导致倾斜的原因，就是使用了 hash tag 进行数据切片。\n\n# 1.1.3 hash tag 导致倾斜\n\nhash tag 是指加在键值对 key 中的一对花括号 {}。这对括号会把 key 的一部分括起来，客户端在计算 key 的 crc16 值时，只对 hash tag 花括号中的 key 内容进行计算。如果没用 hash tag 的话，客户端计算整个 key 的 crc16 的值。\n\n> 举个例子，假设key是user:profile:3231，我们把其中的3231作为hash tag，此时，key就变成了user:profile:{3231}。当客户端计算这个key的crc16值时，就只会计算3231的crc16值。否则，客户端会计算整个“user:profile:3231”的crc16值。\n\n使用 hash tag 的好处是，如果不同 key 的 hash tag 内容都是一样的，那么，这些 key 对应的数据会被映射到同一个 slot 中，同时会被分配到同一个实例上。\n\nhash tag 主要是用在 redis cluster 和 codis 中，支持事务操作和范围查询。因为 redis cluster 和 codis 本身并不支持跨实例的事务操作和范围查询，当业务应用有这些需求时，就只能先把这些数据读取到业务层进行事务处理，或者是逐个查询每个实例，得到范围查询的结果。这样操作起来非常麻烦，所以，我们可以使用 hash tag 把要执行事务操作或是范围查询的数据映射到同一个实例上，这样就能很轻松地实现事务或范围查询了。\n\n但是，使用hash tag的潜在问题，就是大量的数据可能被集中到一个实例上，导致数据倾斜，集群中的负载不均衡。那么，该怎么应对这种问题呢？我们就需要在范围查询、事务执行的需求和数据倾斜带来的访问压力之间，进行取舍了。\n\n我的建议是，如果使用hash tag进行切片的数据会带来较大的访问压力，就优先考虑避免数据倾斜，最好不要使用hash tag进行数据切片。因为事务和范围查询都还可以放在客户端来执行，而数据倾斜会导致实例不稳定，造成服务不可用。\n\n----------------------------------------\n\n以上介绍了数据量倾斜的原因以及应对方法。下面看一下数据访问倾斜的原因和应对方法。\n\n\n# 1.2 数据访问倾斜的成因和应对方法\n\n发生数据访问倾斜的根本原因，就是实例上存在热点数据。一旦热点数据被存在了某个实例中，那么，这个实例的请求访问量就会远高于其它实例，面临巨大的访问压力。如下图所示：\n\n如何应对呢？和数据量倾斜不同，热点数据通常是一个或几个数据，所以，直接重新分配 slot 并不能解决热点数据的问题。\n\n通常来说，热点数据以服务读操作为主，在这种情况下，我们可以采用热点数据多副本的方法来应对。这个方法的具体做法是，我们把热点数据复制多份，在每一个数据副本的key中增加一个随机前缀，让它和其它副本数据不会被映射到同一个slot中。这样一来，热点数据既有多个副本可以同时服务请求，同时，这些副本数据的key又不一样，会被映射到不同的slot中。在给这些slot分配实例时，我们也要注意把它们分配到不同的实例上，那么，热点数据的访问压力就被分散到不同的实例上了。\n\n这里，有个地方需要注意下，热点数据多副本方法只能针对只读的热点数据。如果热点数据是有读有写的话，就不适合采用多副本方法了，因为要保证多副本间的数据一致性，会带来额外的开销。\n\n对于有读有写的热点数据，我们就要给实例本身增加资源了，例如使用配置更高的机器，来应对大量的访问压力。\n\n\n# 1.3 小结\n\n这一大节介绍了数据倾斜的两种情况：数据量倾斜和数据访问倾斜。\n\n造成数据量倾斜的原因主要有三个：\n\n 1. 数据中有bigkey，导致某个实例的数据量增加；\n 2. slot手工分配不均，导致某个或某些实例上有大量数据；\n 3. 使用了hash tag，导致数据集中到某些实例上。\n\n而数据访问倾斜的主要原因就是有热点数据存在，导致大量访问请求集中到了热点数据所在的实例上。\n\n下表对以上情况进行了总结：\n\n如果已经发生了数据倾斜，我们可以通过数据迁移来缓解数据倾斜的影响。\n\n最后，关于集群的实例资源配置，我再给你一个小建议：在构建切片集群时，尽量使用大小配置相同的实例（例如实例内存配置保持相同），这样可以避免因实例资源不均衡而在不同实例上分配不同数量的slot。\n\n\n# 2. 通信开销：限制 redis cluster 规模的关键因素\n\nredis cluster能保存的数据量以及支撑的吞吐量，跟集群的实例规模密切相关。redis官方给出了redis cluster的规模上限，就是一个集群运行1000个实例。\n\n限制 redis 集群数量的一个关键因素就是：实例间的通信开销会随着实例规模增加而增大。在集群超过一定规模时（比如 800 节点），集群吞吐量反而会下降。所以，集群的实际规模会受到限制。\n\n这一大节将讨论集群实例间的通信开销是如何影响redis cluster规模的，以及如何降低实例间的通信开销。\n\n\n# 2.1 实例通信方法和对集群规模的影响\n\nredis cluster 在运行时，每个实例上都会保存 slot 和实例的对应关系（也就是slot映射表），以及自身的状态信息。实例之间为了互通这些状态信息，会使用 gossip 协议来进行通信。\n\ngossip协议的工作原理可以概括成两点。\n\n * 一是，每个实例之间会按照一定的频率，从集群中随机挑选一些实例，把ping消息发送给挑选出来的实例，用来检测这些实例是否在线，并交换彼此的状态信息。ping消息中封装了发送消息的实例自身的状态信息、部分其它实例的状态信息，以及slot映射表。\n * 二是，一个实例在接收到ping消息后，会给发送ping消息的实例，发送一个pong消息。pong消息包含的内容和ping消息一样。\n\n下图显示了两个实例间进行 ping、pong 消息传递的情况：\n\ngossip 协议可以保证在一段时间后，集群中的每一个实例都能获得其它所有实例的状态信息。这样一来，即使有新节点加入、节点故障、slot 变更等事件发生，实例间也可以通过 ping、pong 消息的传递，完成集群状态在每个实例上的同步。\n\n可以直观看到，实例之间使用 gossip 协议通信时，通信开销会受到通信消息大小和通信频率这两方面的影响，消息越大、频率越高，相应的通信开销也就越大。如果想要实现高效的通信，可以从这两方面入手去调优。\n\n# 2.1.1 gossip 消息大小\n\nredis 实例发送的 ping 消息的消息体是由 clustermsgdatagossip 结构体组成的，这个结构体的定义如下所示：\n\ntypedef struct {\n    char nodename[cluster_namelen];  //40字节\n    uint32_t ping_sent; //4字节\n    uint32_t pong_received; //4字节\n    char ip[net_ip_str_len]; //46字节\n    uint16_t port;  //2字节\n    uint16_t cport;  //2字节\n    uint16_t flags;  //2字节\n    uint32_t notused1; //4字节\n} clustermsgdatagossip;\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n其中，cluster_namelen和net_ip_str_len的值分别是40和46，分别表示，nodename和ip这两个字节数组的长度是40字节和46字节，我们再把结构体中其它信息的大小加起来，就可以得到一个gossip消息的大小了，即104字节。\n\n每个实例在发送一个gossip消息时，除了会传递自身的状态信息，默认还会传递集群十分之一实例的状态信息。\n\n所以，对于一个包含了1000个实例的集群来说，每个实例发送一个ping消息时，会包含100个实例的状态信息，总的数据量是 10400字节，再加上发送实例自身的信息，一个gossip消息大约是10kb。\n\n此外，为了让slot映射表能够在不同实例间传播，ping消息中还带有一个长度为 16,384 bit 的 bitmap，这个bitmap的每一位对应了一个slot，如果某一位为1，就表示这个slot属于当前实例。这个bitmap大小换算成字节后，是2kb。我们把实例状态信息和slot分配信息相加，就可以得到一个ping消息的大小了，大约是12kb。\n\npong消息和ping消息的内容一样，所以，它的大小大约是12kb。每个实例发送了ping消息后，还会收到返回的pong消息，两个消息加起来有24kb。\n\n虽然从绝对值上来看，24kb 并不算很大，但是，如果实例正常处理的单个请求只有几kb的话，那么，实例为了维护集群状态一致传输的ping/pong消息，就要比单个业务请求大了。而且，每个实例都会给其它实例发送ping/pong消息。随着集群规模增加，这些心跳消息的数量也会越多，会占据一部分集群的网络通信带宽，进而会降低集群服务正常客户端请求的吞吐量。\n\n除了心跳消息大小会影响到通信开销，如果实例间通信非常频繁，也会导致集群网络带宽被频繁占用。那么，redis cluster 中实例的通信频率是什么样的呢？\n\n# 2.1.2 实例间通信频率\n\nredis cluster 的实例启动后，默认会每秒从本地的实例列表中随机选出5个实例，再从这5个实例中找出一个最久没有通信的实例，把ping消息发送给该实例。这是实例周期性发送ping消息的基本做法。\n\n但是，这里有一个问题：实例选出来的这个最久没有通信的实例，毕竟是从随机选出的5个实例中挑选的，这并不能保证这个实例就一定是整个集群中最久没有通信的实例。所以，这有可能会出现，有些实例一直没有被发送ping消息，导致它们维护的集群状态已经过期了。\n\n为了避免这种情况，redis cluster的实例会按照每100ms一次的频率，扫描本地的实例列表，如果发现有实例最近一次接收 pong消息的时间，已经大于配置项 cluster-node-timeout的一半了（cluster-node-timeout/2），就会立刻给该实例发送 ping消息，更新这个实例上的集群状态信息。\n\n当集群规模扩大之后，因为网络拥塞或是不同服务器间的流量竞争，会导致实例间的网络通信延迟增加。如果有部分实例无法收到其它实例发送的pong消息，就会引起实例之间频繁地发送ping消息，这又会对集群网络通信带来额外的开销了。\n\n我们来总结下单实例每秒会发送的ping消息数量，如下所示：\n\n> ping消息发送数量 = 1 + 10 * 实例数（最近一次接收pong消息的时间超出cluster-node-timeout/2） 其中，1是指单实例常规按照每1秒发送一个ping消息，10是指每1秒内实例会执行10次检查，每次检查后会给pong消息超时的实例发送消息。\n\n我来借助一个例子，带你分析一下在这种通信频率下，ping消息占用集群带宽的情况。\n\n假设单个实例检测发现，每100毫秒有10个实例的pong消息接收超时，那么，这个实例每秒就会发送101个ping消息，约占1.2mb/s带宽。如果集群中有30个实例按照这种频率发送消息，就会占用36mb/s带宽，这就会挤占集群中用于服务正常请求的带宽。\n\n所以，我们要想办法降低实例间的通信开销，那该怎么做呢？\n\n\n# 2.2 如何降低实例间的通信开销？\n\n为了降低实例间的通信开销，从原理上说，我们可以减小实例传输的消息大小（ping/pong消息、slot分配信息），但是，因为集群实例依赖ping、pong消息和slot分配信息，来维持集群状态的统一，一旦减小了传递的消息大小，就会导致实例间的通信信息减少，不利于集群维护，所以，我们不能采用这种方式。\n\n那么，我们能不能降低实例间发送消息的频率呢？我们先来分析一下。\n\n经过刚才的学习，我们现在知道，实例间发送消息的频率有两个。\n\n * 每个实例每1秒发送一条ping消息。这个频率不算高，如果再降低该频率的话，集群中各实例的状态可能就没办法及时传播了。\n * 每个实例每100毫秒会做一次检测，给pong消息接收超过cluster-node-timeout/2的节点发送ping消息。实例按照每100毫秒进行检测的频率，是redis实例默认的周期性检查任务的统一频率，我们一般不需要修改它。\n\n那么，就只有cluster-node-timeout这个配置项可以修改了。\n\n配置项cluster-node-timeout定义了集群实例被判断为故障的心跳超时时间，默认是15秒。如果cluster-node-timeout值比较小，那么，在大规模集群中，就会比较频繁地出现pong消息接收超时的情况，从而导致实例每秒要执行10次“给pong消息超时的实例发送ping消息”这个操作。\n\n所以，为了避免过多的心跳消息挤占集群带宽，我们可以调大cluster-node-timeout值，比如说调大到20秒或25秒。这样一来， pong消息接收超时的情况就会有所缓解，单实例也不用频繁地每秒执行10次心跳发送操作了。\n\n当然，我们也不要把cluster-node-timeout调得太大，否则，如果实例真的发生了故障，我们就需要等待cluster-node-timeout时长后，才能检测出这个故障，这又会导致实际的故障恢复时间被延长，会影响到集群服务的正常使用。\n\n为了验证调整cluster-node-timeout值后，是否能减少心跳消息占用的集群网络带宽，我给你提个小建议：你可以在调整cluster-node-timeout值的前后，使用tcpdump命令抓取实例发送心跳信息网络包的情况。\n\n例如，执行下面的命令后，我们可以抓取到192.168.10.3机器上的实例从16379端口发送的心跳网络包，并把网络包的内容保存到r1.cap文件中：\n\ntcpdump host 192.168.10.3 port 16379 -i 网卡名 -w /tmp/r1.cap\n\n\n1\n\n\n通过分析网络包的数量和大小，就可以判断调整cluster-node-timeout值前后，心跳消息占用的带宽情况了。\n\n建议：如果不是特别需要大容量集群，最好 把redis cluster 的规模控制在 400~500 个实例。\n\n假设单个实例每秒能支撑8万请求操作（8万qps），每个主实例配置1个从实例，那么，400~ 500个实例可支持 1600万~2000万qps（200/250个主实例*8万qps=1600/2000万qps），这个吞吐量性能可以满足不少业务应用的需求。',charsets:{cjk:!0},lastUpdated:"2023/04/22, 02:59:51",lastUpdatedTimestamp:1682132391e3},{title:"基础架构：一条SQL查询语句是如何执行的？",frontmatter:{title:"基础架构：一条SQL查询语句是如何执行的？",date:"2023-05-17T09:33:36.000Z",permalink:"/pages/473452/",categories:["中间件","MySQL","专栏：MySQL 实战 45 讲"],tags:[null]},regularPath:"/%E4%B8%AD%E9%97%B4%E4%BB%B6/06.MySQL/05.%E4%B8%93%E6%A0%8F%EF%BC%9AMySQL%20%E5%AE%9E%E6%88%98%2045%20%E8%AE%B2/01.%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84%EF%BC%9A%E4%B8%80%E6%9D%A1SQL%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84%EF%BC%9F.html",relativePath:"中间件/06.MySQL/05.专栏：MySQL 实战 45 讲/01.基础架构：一条SQL查询语句是如何执行的？.md",key:"v-1823a466",path:"/pages/473452/",headers:[{level:2,title:"1. MySQL 整体架构",slug:"_1-mysql-整体架构",normalizedTitle:"1. mysql 整体架构",charIndex:42},{level:2,title:"2. 一个 SQL 的执行流程",slug:"_2-一个-sql-的执行流程",normalizedTitle:"2. 一个 sql 的执行流程",charIndex:617},{level:3,title:"2.1 连接器",slug:"_2-1-连接器",normalizedTitle:"2.1 连接器",charIndex:637},{level:3,title:"2.2 查询缓存",slug:"_2-2-查询缓存",normalizedTitle:"2.2 查询缓存",charIndex:1696},{level:3,title:"2.3 分析器",slug:"_2-3-分析器",normalizedTitle:"2.3 分析器",charIndex:2282},{level:3,title:"2.4 优化器",slug:"_2-4-优化器",normalizedTitle:"2.4 优化器",charIndex:2514},{level:3,title:"2.5 执行器",slug:"_2-5-执行器",normalizedTitle:"2.5 执行器",charIndex:2882},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:3613},{level:2,title:"QA",slug:"qa",normalizedTitle:"qa",charIndex:3680}],headersStr:"1. MySQL 整体架构 2. 一个 SQL 的执行流程 2.1 连接器 2.2 查询缓存 2.3 分析器 2.4 优化器 2.5 执行器 Summary QA",content:"> 参考 01 | 基础架构：一条SQL查询语句是如何执行的？| 极客时间\n\n\n# 1. MySQL 整体架构\n\n假如你有个最简单的表，表里只有一个 ID 字段，在执行下面这个查询语句时：\n\nmysql> select * from T where ID=10；\n\n\n1\n\n\nMySQL 内部的执行过程是怎样的呢？这篇文章就看一下一条 SQL 在 MySQL 中是如何执行的。\n\nMySQL 的基本架构示意图如下：\n\n大体来说，MySQL 可以分为 Server 层和存储引擎层两部分。\n\n * Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。\n\n * 存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。可以在 create table 语句中创建表时，使用 engine=memory 来指定使用内存引擎创建表。\n\n可以看出，不同的存储引擎共用一个 Server 层，也就是从连接器到执行器的部分。下面将结合开头给出的 SQL 语句，带你走一遍整个执行流程，依次看下每个组件的作用。\n\n\n# 2. 一个 SQL 的执行流程\n\n\n# 2.1 连接器\n\n第一步，你会先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接。连接命令一般是这么写的：\n\nmysql -h$ip -P$port -u$user -p\n\n\n1\n\n\n连接命令中的 mysql 是客户端工具，用来跟服务端建立连接。在完成经典的 TCP 握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码。\n\n * 如果用户名或密码不对，你就会收到一个\"Access denied for user\"的错误，然后客户端程序结束执行。\n * 如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。\n\n这就意味着，一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。\n\n连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在 show processlist 命令中看到它：\n\n * Command 列有一个显示“Sleep”的行，表示现在系统里面有一个空闲连接\n\n客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数 wait_timeout 控制的，默认值是 8 小时。\n\n数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。\n\n建立连接的过程通常是比较复杂的，所以我建议你在使用中要尽量减少建立连接的动作，也就是尽量使用长连接。\n\n> 但是全部使用长连接后，你可能会发现，有些时候 MySQL 占用内存涨得特别快，这是因为 MySQL 在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是 MySQL 异常重启了。 怎么解决这个问题呢？你可以考虑以下两种方案。\n\n * 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。\n\n * 如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。\n\n\n# 2.2 查询缓存\n\n连接建立完成后，你就可以执行 select 语句了。执行逻辑就会来到第二步：查询缓存。\n\nMySQL 拿到一个查询请求后，会先到查询缓存看看，缓存可能会以 key-value 对的形式存在于内存中，命中则直接返回。key 是查询的语句，value 是查询的结果。\n\n但是大多数情况下我会建议你不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利。\n\n查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。\n\n好在 MySQL 也提供了这种“按需使用”的方式。你可以将参数 query_cache_type 设置成 DEMAND，这样对于默认的 SQL 语句都不使用查询缓存。而对于你确定要使用查询缓存的语句，可以用 SQL_CACHE 显式指定，像下面这个语句一样：\n\nmysql> select SQL_CACHE * from T where ID=10；\n\n\n1\n\n\n需要注意的是，MySQL 8.0 版本直接将查询缓存的整块功能删掉了，也就是说 8.0 开始彻底没有这个功能了。\n\n\n# 2.3 分析器\n\n如果没有命中查询缓存，就要开始真正执行语句了。首先，MySQL 需要知道你要做什么，因此需要使用分析器对 SQL 语句做解析。\n\n 1. 【词法分析】识别出 SQL 中每个词代表什么。比如将 select 识别出来这是一个查询语句， 并将对应的表名和列名识别出来。\n 2. 【语法分析】判断 SQL 是否符合语法要求。\n\n如果你的语句不对，就会收到“You have an error in your SQL syntax”的错误提醒。\n\n\n# 2.4 优化器\n\n经过了分析器，MySQL 就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。\n\n优化器优化 SQL 具体执行的方案。比如索引的选择、join 的顺序等。\n\n> 举例：\n> \n> mysql> select * from t1 join t2 using(ID) where t1.c=10 and t2.d=20;\n> \n> \n> 1\n> \n>  * 既可以先从表 t1 里面取出 c=10 的记录的 ID 值，再根据 ID 值关联到表 t2，再判断 t2 里面 d 的值是否等于 20。\n>  * 也可以先从表 t2 里面取出 d=20 的记录的 ID 值，再根据 ID 值关联到 t1，再判断 t1 里面 c 的值是否等于 10。\n> \n> 这两种方案的结果一样，优化器根据效率来决定使用哪种。\n\n\n# 2.5 执行器\n\nMySQL 通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。\n\n开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误，如下所示 (在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用 precheck 验证权限)。\n\nmysql> select * from T where ID=10;\nERROR 1142 (42000): SELECT command denied to user 'b'@'localhost' for table 'T'\n\n\n1\n2\n\n\n如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。\n\n比如我们这个例子中的表 T 中，ID 字段没有索引，那么执行器的执行流程是这样的：\n\n 1. 调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中；\n 2. 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。\n 3. 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。\n\n你会在数据库的慢查询日志中看到一个 rows_examined 的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟 rows_examined 并不是完全相同的。我们后面会专门有一篇文章来讲存储引擎的内部机制，里面会有详细的说明。\n\n\n# Summary\n\n今天介绍了 MySQL 的逻辑架构，并希望你对一个 SQL 语句完整执行流程的各个阶段有了一个初步的印象。\n\n\n# QA\n\nQ：为什么对权限的检查不在优化器之前做？\n\nA：有些时候，SQL 语句要操作的表不只是 SQL 字面上那些。比如如果有个触发器，得在执行器阶段（过程中）才能确定。优化器阶段前是无能为力的。\n\n----------------------------------------\n\nQ：如果表 T 中没有字段 k，而你执行了这个语句 select * from T where k=1, 那肯定是会报“不存在这个列”的错误： “Unknown column ‘k’ in ‘where clause’”。你觉得这个错误是在我们上面提到的哪个阶段报出来的呢？\n\nA：应当是“优化器”。优化器会进行优化分析，比如用先执行哪个条件，使用哪个索引。如果没有对应的字段就会报错的。有人认为是执行器，给出的原因是执行的时候才打开表获取数据，但是表的字段不是数据啊，是事先定义好的，所以可以直接读取的，不需要打开表。",normalizedContent:"> 参考 01 | 基础架构：一条sql查询语句是如何执行的？| 极客时间\n\n\n# 1. mysql 整体架构\n\n假如你有个最简单的表，表里只有一个 id 字段，在执行下面这个查询语句时：\n\nmysql> select * from t where id=10；\n\n\n1\n\n\nmysql 内部的执行过程是怎样的呢？这篇文章就看一下一条 sql 在 mysql 中是如何执行的。\n\nmysql 的基本架构示意图如下：\n\n大体来说，mysql 可以分为 server 层和存储引擎层两部分。\n\n * server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 mysql 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。\n\n * 存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 innodb、myisam、memory 等多个存储引擎。现在最常用的存储引擎是 innodb，它从 mysql 5.5.5 版本开始成为了默认存储引擎。可以在 create table 语句中创建表时，使用 engine=memory 来指定使用内存引擎创建表。\n\n可以看出，不同的存储引擎共用一个 server 层，也就是从连接器到执行器的部分。下面将结合开头给出的 sql 语句，带你走一遍整个执行流程，依次看下每个组件的作用。\n\n\n# 2. 一个 sql 的执行流程\n\n\n# 2.1 连接器\n\n第一步，你会先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接。连接命令一般是这么写的：\n\nmysql -h$ip -p$port -u$user -p\n\n\n1\n\n\n连接命令中的 mysql 是客户端工具，用来跟服务端建立连接。在完成经典的 tcp 握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码。\n\n * 如果用户名或密码不对，你就会收到一个\"access denied for user\"的错误，然后客户端程序结束执行。\n * 如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。\n\n这就意味着，一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。\n\n连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在 show processlist 命令中看到它：\n\n * command 列有一个显示“sleep”的行，表示现在系统里面有一个空闲连接\n\n客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数 wait_timeout 控制的，默认值是 8 小时。\n\n数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。\n\n建立连接的过程通常是比较复杂的，所以我建议你在使用中要尽量减少建立连接的动作，也就是尽量使用长连接。\n\n> 但是全部使用长连接后，你可能会发现，有些时候 mysql 占用内存涨得特别快，这是因为 mysql 在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（oom），从现象看就是 mysql 异常重启了。 怎么解决这个问题呢？你可以考虑以下两种方案。\n\n * 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。\n\n * 如果你用的是 mysql 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。\n\n\n# 2.2 查询缓存\n\n连接建立完成后，你就可以执行 select 语句了。执行逻辑就会来到第二步：查询缓存。\n\nmysql 拿到一个查询请求后，会先到查询缓存看看，缓存可能会以 key-value 对的形式存在于内存中，命中则直接返回。key 是查询的语句，value 是查询的结果。\n\n但是大多数情况下我会建议你不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利。\n\n查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。\n\n好在 mysql 也提供了这种“按需使用”的方式。你可以将参数 query_cache_type 设置成 demand，这样对于默认的 sql 语句都不使用查询缓存。而对于你确定要使用查询缓存的语句，可以用 sql_cache 显式指定，像下面这个语句一样：\n\nmysql> select sql_cache * from t where id=10；\n\n\n1\n\n\n需要注意的是，mysql 8.0 版本直接将查询缓存的整块功能删掉了，也就是说 8.0 开始彻底没有这个功能了。\n\n\n# 2.3 分析器\n\n如果没有命中查询缓存，就要开始真正执行语句了。首先，mysql 需要知道你要做什么，因此需要使用分析器对 sql 语句做解析。\n\n 1. 【词法分析】识别出 sql 中每个词代表什么。比如将 select 识别出来这是一个查询语句， 并将对应的表名和列名识别出来。\n 2. 【语法分析】判断 sql 是否符合语法要求。\n\n如果你的语句不对，就会收到“you have an error in your sql syntax”的错误提醒。\n\n\n# 2.4 优化器\n\n经过了分析器，mysql 就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。\n\n优化器优化 sql 具体执行的方案。比如索引的选择、join 的顺序等。\n\n> 举例：\n> \n> mysql> select * from t1 join t2 using(id) where t1.c=10 and t2.d=20;\n> \n> \n> 1\n> \n>  * 既可以先从表 t1 里面取出 c=10 的记录的 id 值，再根据 id 值关联到表 t2，再判断 t2 里面 d 的值是否等于 20。\n>  * 也可以先从表 t2 里面取出 d=20 的记录的 id 值，再根据 id 值关联到 t1，再判断 t1 里面 c 的值是否等于 10。\n> \n> 这两种方案的结果一样，优化器根据效率来决定使用哪种。\n\n\n# 2.5 执行器\n\nmysql 通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。\n\n开始执行的时候，要先判断一下你对这个表 t 有没有执行查询的权限，如果没有，就会返回没有权限的错误，如下所示 (在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用 precheck 验证权限)。\n\nmysql> select * from t where id=10;\nerror 1142 (42000): select command denied to user 'b'@'localhost' for table 't'\n\n\n1\n2\n\n\n如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。\n\n比如我们这个例子中的表 t 中，id 字段没有索引，那么执行器的执行流程是这样的：\n\n 1. 调用 innodb 引擎接口取这个表的第一行，判断 id 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中；\n 2. 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。\n 3. 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。\n\n你会在数据库的慢查询日志中看到一个 rows_examined 的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟 rows_examined 并不是完全相同的。我们后面会专门有一篇文章来讲存储引擎的内部机制，里面会有详细的说明。\n\n\n# summary\n\n今天介绍了 mysql 的逻辑架构，并希望你对一个 sql 语句完整执行流程的各个阶段有了一个初步的印象。\n\n\n# qa\n\nq：为什么对权限的检查不在优化器之前做？\n\na：有些时候，sql 语句要操作的表不只是 sql 字面上那些。比如如果有个触发器，得在执行器阶段（过程中）才能确定。优化器阶段前是无能为力的。\n\n----------------------------------------\n\nq：如果表 t 中没有字段 k，而你执行了这个语句 select * from t where k=1, 那肯定是会报“不存在这个列”的错误： “unknown column ‘k’ in ‘where clause’”。你觉得这个错误是在我们上面提到的哪个阶段报出来的呢？\n\na：应当是“优化器”。优化器会进行优化分析，比如用先执行哪个条件，使用哪个索引。如果没有对应的字段就会报错的。有人认为是执行器，给出的原因是执行的时候才打开表获取数据，但是表的字段不是数据啊，是事先定义好的，所以可以直接读取的，不需要打开表。",charsets:{cjk:!0},lastUpdated:"2023/05/17, 02:42:28",lastUpdatedTimestamp:1684291348e3},{title:"日志系统：一条SQL更新语句是如何执行的？",frontmatter:{title:"日志系统：一条SQL更新语句是如何执行的？",date:"2023-05-17T10:44:26.000Z",permalink:"/pages/38bad9/",categories:["中间件","MySQL","专栏：MySQL 实战 45 讲"],tags:[null]},regularPath:"/%E4%B8%AD%E9%97%B4%E4%BB%B6/06.MySQL/05.%E4%B8%93%E6%A0%8F%EF%BC%9AMySQL%20%E5%AE%9E%E6%88%98%2045%20%E8%AE%B2/02.%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F%EF%BC%9A%E4%B8%80%E6%9D%A1SQL%E6%9B%B4%E6%96%B0%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84%EF%BC%9F.html",relativePath:"中间件/06.MySQL/05.专栏：MySQL 实战 45 讲/02.日志系统：一条SQL更新语句是如何执行的？.md",key:"v-55200187",path:"/pages/38bad9/",headers:[{level:2,title:"1. 重要的日志模块：redo log",slug:"_1-重要的日志模块-redo-log",normalizedTitle:"1. 重要的日志模块：redo log",charIndex:625},{level:2,title:"2. 重要的日志模块：binlog",slug:"_2-重要的日志模块-binlog",normalizedTitle:"2. 重要的日志模块：binlog",charIndex:1876},{level:2,title:"3. 两阶段提交",slug:"_3-两阶段提交",normalizedTitle:"3. 两阶段提交",charIndex:3165},{level:3,title:"3.1 数据库的恢复",slug:"_3-1-数据库的恢复",normalizedTitle:"3.1 数据库的恢复",charIndex:3257},{level:3,title:"3.2 为什么需要两阶段提交",slug:"_3-2-为什么需要两阶段提交",normalizedTitle:"3.2 为什么需要两阶段提交",charIndex:3715},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:4905},{level:2,title:"补充",slug:"补充",normalizedTitle:"补充",charIndex:5292}],headersStr:"1. 重要的日志模块：redo log 2. 重要的日志模块：binlog 3. 两阶段提交 3.1 数据库的恢复 3.2 为什么需要两阶段提交 Summary 补充",content:'> 参考 02 | 日志系统：一条SQL更新语句是如何执行的？| 极客时间\n\n前面介绍了一个查询语句的执行流程：一般是经过连接器、分析器、优化器、执行器等功能模块，最后到达存储引擎。那一条更新语句的执行流程又是怎样的呢？\n\n> 之前你可能经常听 DBA 同事说，MySQL 可以恢复到半个月内任意一秒的状态，惊叹的同时，你是不是心中也会不免会好奇，这是怎样做到的呢？\n\n我们还是从一个表的一条更新语句说起，下面是这个表的创建语句，这个表有一个主键 ID 和一个整型字段 c：\n\nmysql> create table T(ID int primary key, c int);\n\n\n1\n\n\n如果要将 ID=2 这一行的值加 1，SQL 语句就会这么写：\n\nmysql> update T set c=c+1 where ID=2;\n\n\n1\n\n\n其实，查询语句的那一套流程，更新语句也会同样走一遍，下图是之前的架构图：\n\n * 先通过连接器来连数据库\n * 在一个表上有更新的时候，跟这个表有关的查询缓存会失效，所以这条语句就会把表 T 上所有缓存结果都清空\n * 接下来，分析器会解析得知这是一条更新语句\n * 优化器决定执行方案，决定使用 ID 这个索引\n * 执行器负责具体执行，找到这一行，然后更新\n\n与查询流程不一样的是，更新流程还涉及两个重要的日志模块：redo log（重做日志）和 binlog（归档日志），它俩是本文的主角。\n\n\n# 1. 重要的日志模块：redo log\n\n还记得《孔乙己》吗，酒店掌柜有一个粉板，专门用来记录客人的赊账记录。如果赊账的人不多，那么他可以把顾客名和账目写在板上。但如果赊账的人多了，粉板总会有记不下的时候，这个时候掌柜一定还有一个专门记录赊账的账本。\n\n如果有人要赊账或者还账的话，掌柜一般有两种做法：\n\n * 一种做法是直接把账本翻出来，更新账本；\n * 另一种做法是先在粉板上记下账，等空闲再把账本翻出来核算。\n\n平时生意忙的时候，掌柜一定会选后者，毕竟前者太麻烦了，这么大的账本去找一个人很费时间。相比之下，还是先在粉板上记一下方便。同样，在 MySQL 里也有这个问题，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高。为了解决这个问题，MySQL 的设计者就也采用了类似酒店掌柜的做法。\n\n粉板和账本配合的整个过程，其实就是 MySQL 中常说的 WAL（预写日志）技术。WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，等空闲时再写磁盘。\n\n具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log 里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。\n\n> 注意，只要写入 redo log，那这个数据库就算做了这个事情，也就是做了相应的更新，尽管可能还没真的去做，但对外来看就是做了。\n\n类似于掌柜的粉板会写满，InnoDB 的 redo log 也是固定大小的。比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么这块“粉板”总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示：\n\n * write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。\n * checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。\n\nwrite pos 和 checkpoint 之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。\n\n有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 crash-safe。\n\n> 要理解 crash-safe 这个概念，可以想想我们前面赊账记录的例子。只要赊账记录记在了粉板上或写在了账本上，之后即使掌柜忘记了，比如突然停业几天，恢复生意后依然可以通过账本和粉板上的数据明确赊账账目。\n> \n> 所以我们说了，只要往 redo log 写了，就算数据库做过这件事了。\n\n\n# 2. 重要的日志模块：binlog\n\n前面我们讲过，MySQL 整体来看，其实就有两块：一块是 Server 层，它主要做的是 MySQL 功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜。上面我们聊到的粉板 redo log 是 InnoDB 引擎特有的日志，而 Server 层也有自己的日志，称为 binlog（归档日志）。\n\n> 也许你会问：为什么会有两份日志呢？\n> \n> 因为最开始 MySQL 里并没有 InnoDB 引擎。MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用另外一套日志系统——也就是 redo log 来实现 crash-safe 能力。\n\nredo log 与 binlog 有以下三点不同：\n\n 1. redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。\n 2. redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。\n 3. redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。\n\n有了对这两个日志的概念性理解，我们再来看执行器和 InnoDB 引擎在执行这个简单的 update 语句时的内部流程：\n\n 1. 执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。\n 2. 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。\n 3. 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。\n 4. 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。\n 5. 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。\n\n下面给出这个 update 语句的执行流程图，图中浅色框表示是在 InnoDB 内部执行的，深色框表示是在执行器中执行的。\n\n你可能注意到了，最后三步看上去有点“绕”，将 redo log 的写入拆成了两个步骤：prepare 和 commit，这就是"两阶段提交"。\n\n> 这与 DDIA 中在分布式事务的原子提交中才讲的“两阶段提交”有点区别，这里不是分布式事务的。\n\n\n# 3. 两阶段提交\n\n为什么必须有“两阶段提交”呢？这是为了让两份日志之间的逻辑一致。要说明这个问题，我们得从文章开头的那个问题说起：怎样让数据库恢复到半个月内任意一秒的状态？\n\n\n# 3.1 数据库的恢复\n\n前面我们说过了，binlog 会记录所有的逻辑操作，并且是采用“追加写”的形式。如果你的 DBA 承诺说半个月内可以恢复，那么备份系统中一定会保存最近半个月的所有 binlog，同时系统会定期做整库备份。这里的“定期”取决于系统的重要性，可以是一天一备，也可以是一周一备。\n\n> 具体的备份频率，需要考虑 RTO（恢复时间目标）这个指标。太频繁会消耗太多存储空间，但太久会使得 RTO 太大。\n\n当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据，那你可以这么做：\n\n * 首先找到最近的一次全量备份\n * 然后从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻\n\n这样你的临时库就跟误删之前的线上库一样了，然后你可以把表数据从临时库取出来，按需要恢复到线上库去。\n\n除了恢复误删的表，有时候还需要增加从节点副本来增加读性能，现在常见的做法也是用全量备份加上应用 binlog 来实现的。因此，这个操作十分重要。\n\n\n# 3.2 为什么需要两阶段提交\n\n说完了数据恢复过程，我们回来说说，为什么日志需要“两阶段提交”。\n\n这里不妨用反证法来进行解释。由于 redo log 和 binlog 是两个独立的逻辑，如果不用两阶段提交，要么就是先写完 redo log 再写 binlog，要么采用反过来的顺序。我们看看这两种方式会有什么问题：\n\n * 先写 redo log 后写 binlog：假设在 redo log 写完，binlog 还没有写完的时候，MySQL 进程异常重启。由于我们前面说过的，redo log 写完之后，就算数据库做了这件事了，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。但是由于 binlog 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句。然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。\n * 先写 binlog 后写 redo log：如果在 binlog 写完之后 crash，由于 redo log 还没写，所以数据库就算还没做这件事，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了“把 c 从 0 改成 1”这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同。\n\n可以看到，如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。在采用了两阶段提交之后，可以分成这么三个过程：1. prepare 阶段 2. 写 binlog 3. commit，那：\n\n * 如果在 2 之前崩溃：重启恢复：恢复后发现没有 commit，事务回滚，备份恢复时没有 binlog，两者一致。\n * 如果在 3 之前崩溃：虽然没 commit，但满足 prepare 和 binlog 完整，所以重启后会自动 commit，备份恢复时有 binlog，两者一致。\n\n> 要理清这里的关系。当发生崩溃时，重启恢复是只依靠 redo log 来实现的安全。而当需要备份或恢复时，是需要 binlog 来实现，毕竟 binlog 的记录主要就是用于备份，它有完整的逻辑记录。我们要实现的目标是重启恢复和备份恢复两个状况恢复得到的库是一样的状态，这样就不用担心日志写错了。\n\n如果不用两阶段提交，那崩溃恢复后的主库可能与备份出来的从库产生数据不一致现象。\n\n简单说，redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。\n\n\n# Summary\n\n今天介绍了 MySQL 中最重要的两个日志：物理日志 redo log 和逻辑日志 binlog。\n\n * redo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数我建议你设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。\n * binlog 有完整的逻辑记录，就可以用于备份恢复，sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数我也建议你设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。\n\n两阶段提交是跨系统维持数据逻辑一致性时常用的一个方案，即使你不做数据库内核开发，日常开发中也有可能会用到。\n\n\n# 补充\n\nInnoDB 使用 redo log 的原因：其内部有一个 Buffer Pool 的结构，是用于缓存 MySQL 磁盘数据的内存空间。此时会涉及到 Buffer Pool 中的数据还没来得及刷盘，内存中的数据因断电就已丢失的问题。故每次修改后的值记录到磁盘上的 redo log 中，可以保证突然断电，也可以根据 redo log 来恢复 Buffer Pool，这样用到了 Buffer Pool 的内存高效性，也保证了数据不会丢失。\n\n都是磁盘操作，为什么不直接将修改的数据写到数据文件里面去呢？ 因为 redo log 是磁盘顺序写，数据刷盘是磁盘随机写，磁盘的顺序写比随机写高效的多。',normalizedContent:'> 参考 02 | 日志系统：一条sql更新语句是如何执行的？| 极客时间\n\n前面介绍了一个查询语句的执行流程：一般是经过连接器、分析器、优化器、执行器等功能模块，最后到达存储引擎。那一条更新语句的执行流程又是怎样的呢？\n\n> 之前你可能经常听 dba 同事说，mysql 可以恢复到半个月内任意一秒的状态，惊叹的同时，你是不是心中也会不免会好奇，这是怎样做到的呢？\n\n我们还是从一个表的一条更新语句说起，下面是这个表的创建语句，这个表有一个主键 id 和一个整型字段 c：\n\nmysql> create table t(id int primary key, c int);\n\n\n1\n\n\n如果要将 id=2 这一行的值加 1，sql 语句就会这么写：\n\nmysql> update t set c=c+1 where id=2;\n\n\n1\n\n\n其实，查询语句的那一套流程，更新语句也会同样走一遍，下图是之前的架构图：\n\n * 先通过连接器来连数据库\n * 在一个表上有更新的时候，跟这个表有关的查询缓存会失效，所以这条语句就会把表 t 上所有缓存结果都清空\n * 接下来，分析器会解析得知这是一条更新语句\n * 优化器决定执行方案，决定使用 id 这个索引\n * 执行器负责具体执行，找到这一行，然后更新\n\n与查询流程不一样的是，更新流程还涉及两个重要的日志模块：redo log（重做日志）和 binlog（归档日志），它俩是本文的主角。\n\n\n# 1. 重要的日志模块：redo log\n\n还记得《孔乙己》吗，酒店掌柜有一个粉板，专门用来记录客人的赊账记录。如果赊账的人不多，那么他可以把顾客名和账目写在板上。但如果赊账的人多了，粉板总会有记不下的时候，这个时候掌柜一定还有一个专门记录赊账的账本。\n\n如果有人要赊账或者还账的话，掌柜一般有两种做法：\n\n * 一种做法是直接把账本翻出来，更新账本；\n * 另一种做法是先在粉板上记下账，等空闲再把账本翻出来核算。\n\n平时生意忙的时候，掌柜一定会选后者，毕竟前者太麻烦了，这么大的账本去找一个人很费时间。相比之下，还是先在粉板上记一下方便。同样，在 mysql 里也有这个问题，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 io 成本、查找成本都很高。为了解决这个问题，mysql 的设计者就也采用了类似酒店掌柜的做法。\n\n粉板和账本配合的整个过程，其实就是 mysql 中常说的 wal（预写日志）技术。wal 的全称是 write-ahead logging，它的关键点就是先写日志，等空闲时再写磁盘。\n\n具体来说，当有一条记录需要更新的时候，innodb 引擎就会先把记录写到 redo log 里面，并更新内存，这个时候更新就算完成了。同时，innodb 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。\n\n> 注意，只要写入 redo log，那这个数据库就算做了这个事情，也就是做了相应的更新，尽管可能还没真的去做，但对外来看就是做了。\n\n类似于掌柜的粉板会写满，innodb 的 redo log 也是固定大小的。比如可以配置为一组 4 个文件，每个文件的大小是 1gb，那么这块“粉板”总共就可以记录 4gb 的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示：\n\n * write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。\n * checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。\n\nwrite pos 和 checkpoint 之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。\n\n有了 redo log，innodb 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 crash-safe。\n\n> 要理解 crash-safe 这个概念，可以想想我们前面赊账记录的例子。只要赊账记录记在了粉板上或写在了账本上，之后即使掌柜忘记了，比如突然停业几天，恢复生意后依然可以通过账本和粉板上的数据明确赊账账目。\n> \n> 所以我们说了，只要往 redo log 写了，就算数据库做过这件事了。\n\n\n# 2. 重要的日志模块：binlog\n\n前面我们讲过，mysql 整体来看，其实就有两块：一块是 server 层，它主要做的是 mysql 功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜。上面我们聊到的粉板 redo log 是 innodb 引擎特有的日志，而 server 层也有自己的日志，称为 binlog（归档日志）。\n\n> 也许你会问：为什么会有两份日志呢？\n> \n> 因为最开始 mysql 里并没有 innodb 引擎。mysql 自带的引擎是 myisam，但是 myisam 没有 crash-safe 的能力，binlog 日志只能用于归档。而 innodb 是另一个公司以插件形式引入 mysql 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 innodb 使用另外一套日志系统——也就是 redo log 来实现 crash-safe 能力。\n\nredo log 与 binlog 有以下三点不同：\n\n 1. redo log 是 innodb 引擎特有的；binlog 是 mysql 的 server 层实现的，所有引擎都可以使用。\n 2. redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 id=2 这一行的 c 字段加 1 ”。\n 3. redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。\n\n有了对这两个日志的概念性理解，我们再来看执行器和 innodb 引擎在执行这个简单的 update 语句时的内部流程：\n\n 1. 执行器先找引擎取 id=2 这一行。id 是主键，引擎直接用树搜索找到这一行。如果 id=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。\n 2. 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 n，现在就是 n+1，得到新的一行数据，再调用引擎接口写入这行新数据。\n 3. 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。\n 4. 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。\n 5. 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。\n\n下面给出这个 update 语句的执行流程图，图中浅色框表示是在 innodb 内部执行的，深色框表示是在执行器中执行的。\n\n你可能注意到了，最后三步看上去有点“绕”，将 redo log 的写入拆成了两个步骤：prepare 和 commit，这就是"两阶段提交"。\n\n> 这与 ddia 中在分布式事务的原子提交中才讲的“两阶段提交”有点区别，这里不是分布式事务的。\n\n\n# 3. 两阶段提交\n\n为什么必须有“两阶段提交”呢？这是为了让两份日志之间的逻辑一致。要说明这个问题，我们得从文章开头的那个问题说起：怎样让数据库恢复到半个月内任意一秒的状态？\n\n\n# 3.1 数据库的恢复\n\n前面我们说过了，binlog 会记录所有的逻辑操作，并且是采用“追加写”的形式。如果你的 dba 承诺说半个月内可以恢复，那么备份系统中一定会保存最近半个月的所有 binlog，同时系统会定期做整库备份。这里的“定期”取决于系统的重要性，可以是一天一备，也可以是一周一备。\n\n> 具体的备份频率，需要考虑 rto（恢复时间目标）这个指标。太频繁会消耗太多存储空间，但太久会使得 rto 太大。\n\n当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据，那你可以这么做：\n\n * 首先找到最近的一次全量备份\n * 然后从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻\n\n这样你的临时库就跟误删之前的线上库一样了，然后你可以把表数据从临时库取出来，按需要恢复到线上库去。\n\n除了恢复误删的表，有时候还需要增加从节点副本来增加读性能，现在常见的做法也是用全量备份加上应用 binlog 来实现的。因此，这个操作十分重要。\n\n\n# 3.2 为什么需要两阶段提交\n\n说完了数据恢复过程，我们回来说说，为什么日志需要“两阶段提交”。\n\n这里不妨用反证法来进行解释。由于 redo log 和 binlog 是两个独立的逻辑，如果不用两阶段提交，要么就是先写完 redo log 再写 binlog，要么采用反过来的顺序。我们看看这两种方式会有什么问题：\n\n * 先写 redo log 后写 binlog：假设在 redo log 写完，binlog 还没有写完的时候，mysql 进程异常重启。由于我们前面说过的，redo log 写完之后，就算数据库做了这件事了，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。但是由于 binlog 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句。然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。\n * 先写 binlog 后写 redo log：如果在 binlog 写完之后 crash，由于 redo log 还没写，所以数据库就算还没做这件事，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了“把 c 从 0 改成 1”这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同。\n\n可以看到，如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。在采用了两阶段提交之后，可以分成这么三个过程：1. prepare 阶段 2. 写 binlog 3. commit，那：\n\n * 如果在 2 之前崩溃：重启恢复：恢复后发现没有 commit，事务回滚，备份恢复时没有 binlog，两者一致。\n * 如果在 3 之前崩溃：虽然没 commit，但满足 prepare 和 binlog 完整，所以重启后会自动 commit，备份恢复时有 binlog，两者一致。\n\n> 要理清这里的关系。当发生崩溃时，重启恢复是只依靠 redo log 来实现的安全。而当需要备份或恢复时，是需要 binlog 来实现，毕竟 binlog 的记录主要就是用于备份，它有完整的逻辑记录。我们要实现的目标是重启恢复和备份恢复两个状况恢复得到的库是一样的状态，这样就不用担心日志写错了。\n\n如果不用两阶段提交，那崩溃恢复后的主库可能与备份出来的从库产生数据不一致现象。\n\n简单说，redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。\n\n\n# summary\n\n今天介绍了 mysql 中最重要的两个日志：物理日志 redo log 和逻辑日志 binlog。\n\n * redo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数我建议你设置成 1，这样可以保证 mysql 异常重启之后数据不丢失。\n * binlog 有完整的逻辑记录，就可以用于备份恢复，sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数我也建议你设置成 1，这样可以保证 mysql 异常重启之后 binlog 不丢失。\n\n两阶段提交是跨系统维持数据逻辑一致性时常用的一个方案，即使你不做数据库内核开发，日常开发中也有可能会用到。\n\n\n# 补充\n\ninnodb 使用 redo log 的原因：其内部有一个 buffer pool 的结构，是用于缓存 mysql 磁盘数据的内存空间。此时会涉及到 buffer pool 中的数据还没来得及刷盘，内存中的数据因断电就已丢失的问题。故每次修改后的值记录到磁盘上的 redo log 中，可以保证突然断电，也可以根据 redo log 来恢复 buffer pool，这样用到了 buffer pool 的内存高效性，也保证了数据不会丢失。\n\n都是磁盘操作，为什么不直接将修改的数据写到数据文件里面去呢？ 因为 redo log 是磁盘顺序写，数据刷盘是磁盘随机写，磁盘的顺序写比随机写高效的多。',charsets:{cjk:!0},lastUpdated:"2023/05/17, 03:30:36",lastUpdatedTimestamp:1684294236e3},{title:"事务隔离",frontmatter:{title:"事务隔离",date:"2023-05-17T14:40:59.000Z",permalink:"/pages/b99352/",categories:["中间件","MySQL","专栏：MySQL 实战 45 讲"],tags:[null]},regularPath:"/%E4%B8%AD%E9%97%B4%E4%BB%B6/06.MySQL/05.%E4%B8%93%E6%A0%8F%EF%BC%9AMySQL%20%E5%AE%9E%E6%88%98%2045%20%E8%AE%B2/03.%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB.html",relativePath:"中间件/06.MySQL/05.专栏：MySQL 实战 45 讲/03.事务隔离.md",key:"v-66f73835",path:"/pages/b99352/",headers:[{level:2,title:"1. 隔离性与隔离级别",slug:"_1-隔离性与隔离级别",normalizedTitle:"1. 隔离性与隔离级别",charIndex:251},{level:2,title:"2. 事务隔离的实现",slug:"_2-事务隔离的实现",normalizedTitle:"2. 事务隔离的实现",charIndex:2740},{level:2,title:"3. 事务的启动方式",slug:"_3-事务的启动方式",normalizedTitle:"3. 事务的启动方式",charIndex:3566},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:4449},{level:2,title:"4. 事务到底隔离还是不隔离？",slug:"_4-事务到底隔离还是不隔离",normalizedTitle:"4. 事务到底隔离还是不隔离？",charIndex:4559},{level:3,title:"4.1 snapshot 在 MVCC 里是怎样工作的？",slug:"_4-1-snapshot-在-mvcc-里是怎样工作的",normalizedTitle:"4.1 snapshot 在 mvcc 里是怎样工作的？",charIndex:5539},{level:3,title:"4.2 更新逻辑",slug:"_4-2-更新逻辑",normalizedTitle:"4.2 更新逻辑",charIndex:8723},{level:3,title:"4.3 Summary",slug:"_4-3-summary",normalizedTitle:"4.3 summary",charIndex:10522},{level:2,title:"QA",slug:"qa",normalizedTitle:"qa",charIndex:10858}],headersStr:"1. 隔离性与隔离级别 2. 事务隔离的实现 3. 事务的启动方式 Summary 4. 事务到底隔离还是不隔离？ 4.1 snapshot 在 MVCC 里是怎样工作的？ 4.2 更新逻辑 4.3 Summary QA",content:"> 参考：\n> \n>  * 03 | 事务隔离：为什么你改了我还看不见？| 极客时间\n>  * 08 | 事务到底是隔离的还是不隔离的？| 极客时间\n\n简单来说，事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在 MySQL 中，事务支持是在引擎层实现的。MySQL 原生的 MyISAM 引擎就不支持事务，这也是 MyISAM 被 InnoDB 取代的重要原因之一。\n\n今天的文章将以 InnoDB 为例，剖析 MySQL 在事务支持方面的特定实现，并基于原理给出相应的实践建议。\n\n\n# 1. 隔离性与隔离级别\n\n提到事务，你肯定会想到 ACID，今天主要要讲的是其中的 I，也就是隔离性。\n\n当数据库上有多个事务同时执行的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题，为了解决这些问题，就有了“隔离级别”的概念。在谈隔离级别之前，你首先要知道，你隔离得越严实，效率就会越低。因此很多时候，我们都要在二者之间做 trade-off。\n\n并发事务可能发生的异常情况\n * 脏写：一个事务覆盖了另一个仍在运行中、尚未提交的事务写入的值（破坏数据的完整性约束，使系统无法正确回滚事务）\n * 脏读：一个事务读到了另一个尚未提交的事务写入的值（由于其他事务回滚造成的）\n * 不可重复读：在一个事务中查询一个值两次，但两次查询返回的值不同（读到的是其他事务已经提交的数据）\n * 幻读：当一个事务进行条件查询时，另一个事务在中间插入或删除了匹配该条件的数据，此时事务再去读，就会发生幻读\n * 更新丢失：两个事务读取同一个值，都试图将其更新为新的不同的值时，会发生更新丢失。其结果是两个更新只有一个会生效，但执行更新的另一个事务并未被告知其更新没有生效\n * 读倾斜：读到了数据一致性约束被破坏的数据。（B读数据期间，A对数据进行了写入，导致在B看来不满足约束条件）\n * 写倾斜：两个并发事务都读到了相同的数据集，但随后各自修改了不相干的数据集，导致数据的一致性约束被破坏。（A B 都有写导致的，如 DDIA 值班的例子）\n\nSQL 标准的事务隔离级别包括：\n\n * 读未提交（read uncommitted）：指一个事务还没提交时，它做的变更就能被别的事务看到。\n * 读提交（read committed）：一个事务提交之后，它做的变更才会被其他事务看到。\n * 可重复读（repeatable read）：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。\n * 可串行化（serializable）：顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。\n\n其中“读提交”和“可重复读”比较难理解，所以我用一个例子说明这几种隔离级别。假设数据表 T 中只有一列，其中一行的值为 1，下面是按照时间顺序执行两个事务的行为。\n\nmysql> create table T(c int) engine=InnoDB;\nmysql> insert into T(c) values(1);\n\n\n1\n2\n\n\n我们来看看在不同的隔离级别下，事务 A 会有哪些不同的返回结果，也就是图里面 V1、V2、V3 的返回值分别是什么：\n\n * 若隔离级别是“读未提交”， 则 V1 的值就是 2。这时候事务 B 虽然还没有提交，但是结果已经被 A 看到了。因此，V2、V3 也都是 2。\n * 若隔离级别是“读提交”，则 V1 是 1，V2 的值是 2。事务 B 的更新在提交后才能被 A 看到。所以， V3 的值也是 2。\n * 若隔离级别是“可重复读”，则 V1、V2 是 1，V3 是 2。之所以 V2 还是 1，遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的。\n * 若隔离级别是“串行化”，则在事务 B 执行“将 1 改成 2”的时候，会被锁住。直到事务 A 提交后，事务 B 才可以继续执行。所以从 A 的角度看， V1、V2 值是 1，V3 的值是 2。\n\n在实现上，数据库里面会创建一个视图（快照），访问的时候以视图的逻辑结果为准。在“可重复读”隔离级别下，这个视图（快照）是在事务启动时创建的，整个事务存在期间都用这个静态视图。在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；而“串行化”隔离级别下直接用加锁的方式来避免并行访问。\n\n> 这里所说的“视图”就是 DDIA 中所讲的“快照级别隔离”的快照。\n\n我们可以看到在不同的隔离级别下，数据库行为是有所不同的。Oracle 数据库的默认隔离级别其实就是“读提交”，因此对于一些从 Oracle 迁移到 MySQL 的应用，为保证数据库隔离级别的一致，你一定要记得将 MySQL 的隔离级别设置为“读提交”。\n\n配置的方式是，将启动参数 transaction-isolation 的值设置成 READ-COMMITTED。你可以用 show variables 来查看当前的值。\n\nmysql> show variables like 'transaction_isolation';\n+-----------------------+----------------+\n| Variable_name | Value |\n+-----------------------+----------------+\n| transaction_isolation | READ-COMMITTED |\n+-----------------------+----------------+\n\n\n1\n2\n3\n4\n5\n6\n\n\n总结来说，存在即合理，每种隔离级别都有自己的使用场景，你要根据自己的业务情况来定。\n\n你可能会问那什么时候需要“可重复读”的场景呢？我们来看一个数据校对逻辑的案例。假设你在管理一个个人银行账户表。一个表存了账户余额，一个表存了账单明细。到了月底你要做数据校对，也就是判断上个月的余额和当前余额的差额，是否与本月的账单明细一致。你一定希望在校对过程中，即使有用户发生了一笔新的交易，也不影响你的校对结果。这时候使用“可重复读”隔离级别就很方便。事务启动时的视图可以认为是静态的，不受其他事务更新的影响。\n\n\n# 2. 事务隔离的实现\n\n理解了事务的隔离级别，我们再来看看事务隔离具体是怎么实现的。这里我们展开说明“可重复读”。\n\n在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。\n\n假设一个值从 1 被按顺序改成了 2、3、4，在回滚日志里面就会有类似下面的记录：\n\n当前值是 4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的 read-view。如图中看到的，在视图 A、B、C 里面，这一个记录的值分别是 1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于 read-view A，要得到 1，就必须将当前值依次执行图中所有的回滚操作得到。\n\n同时你会发现，即使现在有另外一个事务正在将 4 改成 5，这个事务跟 read-view A、B、C 对应的事务是不会冲突的。\n\n你一定会问，回滚日志总不能一直保留吧，什么时候删除呢？答案是，在不需要的时候才删除。也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的 read-view 的时候。\n\n基于上面的说明，我们来讨论一下为什么建议你尽量不要使用长事务:\n\n * 长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。\n * 在 MySQL 5.5 及以前的版本，回滚日志是跟数据字典一起放在 ibdata 文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。我见过数据只有 20GB，而回滚段有 200GB 的库。最终只好为了清理回滚段，重建整个库。\n * 除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库，这个我们会在后面讲锁的时候展开。\n\n\n# 3. 事务的启动方式\n\n如前面所述，长事务有这些潜在风险，我当然是建议你尽量避免。其实很多时候业务开发同学并不是有意使用长事务，通常是由于误用所致。MySQL 的事务启动方式有以下几种：\n\n 1. 显式启动事务语句， begin 或 start transaction。配套的提交语句是 commit，回滚语句是 rollback。\n 2. set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。\n\n有些客户端连接框架会默认连接成功后先执行一个 set autocommit=0 的命令。这就导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。\n\n因此，我会建议你总是使用 set autocommit=1, 通过显式语句的方式来启动事务。\n\n但是有的开发同学会纠结“多一次交互”的问题。对于一个需要频繁使用事务的业务，第二种方式每个事务在开始时都不需要主动执行一次 “begin”，减少了语句的交互次数。如果你也有这个顾虑，我建议你使用 commit work and chain 语法：在 autocommit 为 1 的情况下，用 begin 显式启动的事务，如果执行 commit 则提交事务。如果执行 commit work and chain，则是提交事务并自动启动下一个事务，这样也省去了再次执行 begin 语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。\n\n你可以在 information_schema 库的 innodb_trx 这个表中查询长事务，比如下面这个语句，用于查找持续时间超过 60s 的事务：\n\nselect * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60\n\n\n1\n\n\n\n# Summary\n\n以上介绍了 MySQL 的事务隔离级别的现象和实现，根据实现原理分析了长事务存在的风险，以及如何用正确的方式避免长事务。希望我举的例子能够帮助你理解事务，并更好地使用 MySQL 的事务特性。\n\n\n# 4. 事务到底隔离还是不隔离？\n\n前面说了，如果是可重复读隔离级别，事务 T 启动的时候会创建一个视图 read-view，之后事务 T 执行期间，即使有其他事务修改了数据，事务 T 看到的仍然跟在启动时看到的一样。但在全局锁、表级锁和行锁中提到，一个事务要更新一行，如果刚好有另外一个事务拥有这一行的行锁，它又不能这么独身事外了，它会被锁住，进入等待状态。问题是❓，既然进入了等待状态，那么等到这个事务自己获取到行锁要更新数据的时候，它读到的值又是什么呢？\n\n举一个例子，下面是一个只有两行的表的初始化语句：\n\nmysql> CREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `k` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\n\ninsert into t(id, k) values(1,1),(2,2);\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n事务 A、B、C 的流程如下：\n\n这里，我们需要注意的是事务的启动时机。begin/start transaction 命令并不是一个事务的起点，在执行到它们之后的第一个操作 InnoDB 表的语句，事务才真正启动。如果你想要马上启动一个事务，可以使用 start transaction with consistent snapshot 这个命令。\n\n * 第一种启动方式：一致性视图是在执行第一个快照读语句时创建的；\n * 第二种启动方式，一致性视图是在执行 start transaction with consistent snapshot 时创建的。\n\n还需注意的是，之后如果没有特别说明，都默认 autocommit=1，也就是即使没有手动 start transaction 开启事务，mysql 默认也会将用户的操作当做事务即时提交。\n\n> 本例中的事务 C 没有显式地使用 begin/commit，表示这个 update 语句本身就是一个事务，语句完成的时候会自动提交。\n\n现在你知道 A、B 事务看到的值是什么吗。这一大节就把这个疑惑解开，更深一步地理解 MVCC。\n\n> 本例中事务 A 查到的 k 值是 1，事务 B 查到的 k 值是 3。有点晕就往下看 ~\n\n\n# 4.1 snapshot 在 MVCC 里是怎样工作的？\n\n在可重复读隔离级别下，事务在启动的时候就“拍了个快照”。注意，这个快照是基于整库的。\n\n但真的要给全库拍快照又不太可行，一个数据库有 100G，怎么可能每个事务都先复制 100G 数据出来。实际上，DB 并不需要真的拷贝这 100G 数据。我们看一下这个 snapshot 是怎么实现的。\n\nInnoDB 里面每个事务有一个唯一的事务 ID，叫作 transaction id。它是在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。\n\n> 也就是说，数据表中的一行记录，其实可能有多个版本 (row)，每个版本有自己的 row trx_id。\n\n下图就是一个记录被多个事务连续更新后的状态：\n\n图中虚线框里是同一行数据的 4 个版本，当前最新版本是 V4，k 的值是 22，它是被 transaction id 为 25 的事务更新的，因此它的 row trx_id 也是 25。\n\n其实，图中的三个绿色虚线箭头就是 undo log（回滚日志），而且 旧版本 V1、V2、V3 并不是物理上真实存在的，而是每次需要的时候根据当前版本和 undo log 计算出来的。比如在需要 V2 的时候，就是通过 V4 依次执行 U3、U2 算出来。\n\n明白了多版本和 row trx_id 的概念后，我们再来想一下，InnoDB 是怎么定义那个“100G”的快照的❓。\n\n按照可重复读的定义，一个事务启动的时候，能够看到所有已经提交的事务结果。但是之后，这个事务执行期间，其他事务的更新对它不可见。因此，一个事务只需要在启动后只承认那些位于自己启动之前的数据版本和自己更新的数据就好了。\n\n在实现上，InnoDB 为每个事务构造了一个视图数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务 ID。“活跃”指的就是，启动了但还没提交。数组里面事务 ID 的最小值记为低水位，当前系统里面已经创建过的事务 ID 的最大值加 1 记为高水位。这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）。而数据版本的可见性规则，就是基于数据的 row trx_id 和这个一致性视图的对比结果得到的。\n\nMySQL 中有两个“视图”的概念：\n * 一个是 view。它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是 create view …，而它的查询方法与表一样。\n * 另一个是 InnoDB 在实现 MVCC 时用到的一致性读视图(read-view)，即 consistent read view，用于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复读）隔离级别的实现。\n\n这个视图数组把所有的 row trx_id 分成了几种不同的情况：\n\n这样，对于当前事务的启动瞬间来说，一个数据版本的 row trx_id，有以下几种可能：\n\n 1. 如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；\n 2. 如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的；\n 3. 如果落在黄色部分，那就包括两种情况：\n    * 若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见\n    * 若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见\n\n> 易混：落在黄色区域意味着是事务 ID 在低水位和高水位这个范围里面，而真正是是否可见，看黄色区域是否有这个值。如果黄色区域没有这个事务 ID，则可见，如果有，则不可见。在这个范围里面并不意味这这个范围里有这个值，比如 [1,2,3,5]，4 在这个数组 1-5 的范围里，却没在这个数组里面。\n\n比如，对于图 2 中的数据来说，如果有一个事务，它的低水位是 18，那么当它访问这一行数据时，就会从 V4 通过 U3 计算出 V3，所以在它看来，这一行的值是 11。\n\n有了这个可见性规则，系统里面随后发生的更新就与这个事务看到的内容无关了，所以这个事务的 snapshot 就是“静态”的了。所以你现在知道了，InnoDB 利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。\n\n现在借助于这个知识，我们对之前的例子进行分析，看看为什么事务 A 返回的结果是 k=1。我们不妨假设：\n\n 1. 事务 A 开始前，系统里面只有一个活跃事务 ID 是 99；\n 2. 事务 A、B、C 的版本号分别是 100、101、102，且当前系统里只有这四个事务；\n 3. 三个事务开始前，(1,1）这一行数据的 row trx_id 是 90。\n\n这样，事务 A 的视图数组就是[99,100], 事务 B 的视图数组是[99,100,101], 事务 C 的视图数组是[99,100,101,102]。为了简化分析，我先把其他干扰语句去掉，只画出跟事务 A 查询逻辑有关的操作：\n\n从图中可以看到，第一个有效更新是事务 C，把数据从 (1,1) 改成了 (1,2)。这时候，这个数据的最新版本的 row trx_id 是 102，而 90 这个版本已经成为了历史版本。第二个有效更新是事务 B，把数据从 (1,2) 改成了 (1,3)。这时候，这个数据的最新版本（即 row trx_id）是 101，而 102 又成为了历史版本。你可能注意到了，在事务 A 查询的时候，其实事务 B 还没有提交，但是它生成的 (1,3) 这个版本已经变成当前版本了。但这个版本对事务 A 必须是不可见的，否则就变成脏读了。好，现在事务 A 要来读数据了，它的视图数组是[99,100]。当然了，读数据都是从当前版本读起的。\n\n所以，事务 A 查询语句的读数据流程是这样的：\n\n * 找到 (1,3) 的时候，判断出 row trx_id=101，比高水位大，处于红色区域，不可见；\n * 接着，找到上一个历史版本，一看 row trx_id=102，比高水位大，处于红色区域，不可见；\n * 再往前找，终于找到了（1,1)，它的 row trx_id=90，比低水位小，处于绿色区域，可见。\n\n这样执行下来，虽然期间这一行数据被修改过，但是事务 A 不论在什么时候查询，看到这行数据的结果都是一致的，所以我们称之为一致性读。\n\n这个判断规则是从代码逻辑直接转译过来的，但是正如你所见，用于人肉分析可见性很麻烦。所以，用更直观的话说：一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：\n\n * 版本未提交，不可见；\n * 版本已提交，但是是在视图创建后提交的，不可见；\n * 版本已提交，而且是在视图创建前提交的，可见。\n\n现在，我们用这个规则来判断示例中的查询结果，事务 A 的查询语句的视图数组是在事务 A 启动的时候生成的，这时候：\n\n * (1,3) 还没提交，属于情况 1，不可见；\n * (1,2) 虽然提交了，但是是在视图数组创建之后提交的，属于情况 2，不可见；\n * (1,1) 是在视图数组创建之前提交的，可见。\n\n你看，去掉数字对比后，只用时间先后顺序来判断，分析起来是不是轻松多了。所以，后面我们就都用这个规则来分析。\n\n\n# 4.2 更新逻辑\n\n更细心的话，可以提出这样一个疑问：事务 B 的 update 语句，如果按照一致性读，好像结果不对哦？你看图 5 中，事务 B 的视图数组是先生成的，之后事务 C 才提交，不是应该看不见 (1,2) 吗，怎么能算出 (1,3) 来？\n\n是的，如果事务 B 在更新之前查询一次数据，这个查询返回的 k 的值确实是 1。但是，当它要去更新数据的时候，就不能再在历史版本上更新了，否则事务 C 的更新就丢失了。因此，事务 B 此时的 set k=k+1 是在（1,2）的基础上进行的操作。\n\n所以，这里就用到了这样一条规则：更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。\n\n因此，在更新的时候，当前读拿到的数据是 (1,2)，更新后生成了新版本的数据 (1,3)，这个新版本的 row trx_id 是 101。所以，在执行事务 B 查询语句的时候，一看自己的版本号是 101，最新数据的版本号也是 101，是自己的更新，可以直接使用，所以查询得到的 k 的值是 3。\n\n这里我们提到了一个概念，叫作当前读。其实，除了 update 语句外，select 语句如果加锁，也是当前读。所以，如果把事务 A 的查询语句 select * from t where id=1 修改一下，加上 lock in share mode 或 for update，也都可以读到版本号是 101 的数据，返回的 k 的值是 3。下面这两个 select 语句，就是分别加了读锁（S 锁，共享锁）和写锁（X 锁，排他锁）：\n\nmysql> select k from t where id=1 lock in share mode;\nmysql> select k from t where id=1 for update;\n\n\n1\n2\n\n\n再往前一步，假设事务 C 不是马上提交的，而是变成了下面的事务 C’，会怎么样呢？\n\n事务 C’的不同是，更新后并没有马上提交，在它提交前，事务 B 的更新语句先发起了。前面说过了，虽然事务 C’还没提交，但是 (1,2) 这个版本也已经生成了，并且是当前的最新版本。那么，事务 B 的更新语句会怎么处理呢？\n\n这时候，我们在上一篇文章中提到的“两阶段锁协议”就要上场了。事务 C’ 没提交，也就是说 (1,2) 这个版本上的写锁还没释放。而事务 B 是当前读，必须要读最新版本，而且必须加锁，因此就被锁住了，必须等到事务 C’ 释放这个锁，才能继续它的当前读。\n\n到这里，我们把一致性读、当前读和行锁就串起来了。\n\n现在，我们再回到文章开头的问题：事务的可重复读的能力是怎么实现的？❓可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。\n\n而读提交的逻辑和可重复读的逻辑类似，它们最主要的区别是：\n\n * 在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图；\n * 在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。\n\n那么，我们再看一下，在读提交隔离级别下，事务 A 和事务 B 的查询语句查到的 k，分别应该是多少呢？\n\n> 这里需要说明一下，“start transaction with consistent snapshot; ”的意思是从这个语句开始，创建一个持续整个事务的一致性快照。所以，在读提交隔离级别下，这个用法就没意义了，等效于普通的 start transaction。\n\n下面是读提交时的状态图，可以看到这两个查询语句的创建视图数组的时机发生了变化，就是图中的 read view 框。（注意：这里，我们用的还是事务 C 的逻辑直接提交，而不是事务 C’）\n\n这时，事务 A 的查询语句的视图数组是在执行这个语句的时候创建的，时序上 (1,2)、(1,3) 的生成时间都在创建这个视图数组的时刻之前。但是，在这个时刻：\n\n * (1,3) 还没提交，属于情况 1，不可见；\n * (1,2) 提交了，属于情况 3，可见。\n\n所以，这时候事务 A 查询语句返回的是 k=2。显然地，事务 B 查询结果 k=3。\n\n\n# 4.3 Summary\n\nInnoDB 的行数据有多个版本，每个数据版本有自己的 row trx_id，每个事务或者语句有自己的一致性视图。普通查询语句是一致性读，一致性读会根据 row trx_id 和一致性视图确定数据版本的可见性。\n\n * 对于可重复读，查询只承认在事务启动前就已经提交完成的数据；\n * 对于读提交，查询只承认在语句启动前就已经提交完成的数据；\n\n而当前读，总是读取已经提交完成的最新版本。\n\n你也可以想一下，为什么表结构不支持“可重复读”？这是因为表结构没有对应的行数据，也没有 row trx_id，因此只能遵循当前读的逻辑。\n\n当然，MySQL 8.0 已经可以把表结构放在 InnoDB 字典里了，也许以后会支持表结构的可重复读。\n\n\n# QA\n\nQ：你现在知道了系统里面应该避免长事务，如果你是业务开发负责人同时也是数据库负责人，你会有什么方案来避免出现或者处理这种情况呢？\n\nA：这个问题，我们可以从应用开发端和数据库端来看：\n\n * 从应用开发端来看：\n   1. 确认是否使用了 set autocommit=0。这个确认工作可以在测试环境中开展，把 MySQL 的 general_log 开起来，然后随便跑一个业务逻辑，通过 general_log 的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成 1。\n   2. 确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用 begin/commit 框起来。我见过有些是业务并没有这个需要，但是也把好几个 select 语句放到了事务中。这种只读事务可以去掉。\n   3. 业务连接数据库的时候，根据业务本身的预估，通过 SET MAX_EXECUTION_TIME 命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。\n * 从数据库端来看：\n   1. 监控 information_schema.Innodb_trx 表，设置长事务阈值，超过就报警 / 或者 kill；\n   2. Percona 的 pt-kill 这个工具不错，推荐使用；\n   3. 在业务功能测试阶段要求输出所有的 general_log，分析日志行为提前发现问题；\n   4. 如果使用的是 MySQL 5.6 或者更新版本，把 innodb_undo_tablespaces 设置成 2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。",normalizedContent:"> 参考：\n> \n>  * 03 | 事务隔离：为什么你改了我还看不见？| 极客时间\n>  * 08 | 事务到底是隔离的还是不隔离的？| 极客时间\n\n简单来说，事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在 mysql 中，事务支持是在引擎层实现的。mysql 原生的 myisam 引擎就不支持事务，这也是 myisam 被 innodb 取代的重要原因之一。\n\n今天的文章将以 innodb 为例，剖析 mysql 在事务支持方面的特定实现，并基于原理给出相应的实践建议。\n\n\n# 1. 隔离性与隔离级别\n\n提到事务，你肯定会想到 acid，今天主要要讲的是其中的 i，也就是隔离性。\n\n当数据库上有多个事务同时执行的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题，为了解决这些问题，就有了“隔离级别”的概念。在谈隔离级别之前，你首先要知道，你隔离得越严实，效率就会越低。因此很多时候，我们都要在二者之间做 trade-off。\n\n并发事务可能发生的异常情况\n * 脏写：一个事务覆盖了另一个仍在运行中、尚未提交的事务写入的值（破坏数据的完整性约束，使系统无法正确回滚事务）\n * 脏读：一个事务读到了另一个尚未提交的事务写入的值（由于其他事务回滚造成的）\n * 不可重复读：在一个事务中查询一个值两次，但两次查询返回的值不同（读到的是其他事务已经提交的数据）\n * 幻读：当一个事务进行条件查询时，另一个事务在中间插入或删除了匹配该条件的数据，此时事务再去读，就会发生幻读\n * 更新丢失：两个事务读取同一个值，都试图将其更新为新的不同的值时，会发生更新丢失。其结果是两个更新只有一个会生效，但执行更新的另一个事务并未被告知其更新没有生效\n * 读倾斜：读到了数据一致性约束被破坏的数据。（b读数据期间，a对数据进行了写入，导致在b看来不满足约束条件）\n * 写倾斜：两个并发事务都读到了相同的数据集，但随后各自修改了不相干的数据集，导致数据的一致性约束被破坏。（a b 都有写导致的，如 ddia 值班的例子）\n\nsql 标准的事务隔离级别包括：\n\n * 读未提交（read uncommitted）：指一个事务还没提交时，它做的变更就能被别的事务看到。\n * 读提交（read committed）：一个事务提交之后，它做的变更才会被其他事务看到。\n * 可重复读（repeatable read）：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。\n * 可串行化（serializable）：顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。\n\n其中“读提交”和“可重复读”比较难理解，所以我用一个例子说明这几种隔离级别。假设数据表 t 中只有一列，其中一行的值为 1，下面是按照时间顺序执行两个事务的行为。\n\nmysql> create table t(c int) engine=innodb;\nmysql> insert into t(c) values(1);\n\n\n1\n2\n\n\n我们来看看在不同的隔离级别下，事务 a 会有哪些不同的返回结果，也就是图里面 v1、v2、v3 的返回值分别是什么：\n\n * 若隔离级别是“读未提交”， 则 v1 的值就是 2。这时候事务 b 虽然还没有提交，但是结果已经被 a 看到了。因此，v2、v3 也都是 2。\n * 若隔离级别是“读提交”，则 v1 是 1，v2 的值是 2。事务 b 的更新在提交后才能被 a 看到。所以， v3 的值也是 2。\n * 若隔离级别是“可重复读”，则 v1、v2 是 1，v3 是 2。之所以 v2 还是 1，遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的。\n * 若隔离级别是“串行化”，则在事务 b 执行“将 1 改成 2”的时候，会被锁住。直到事务 a 提交后，事务 b 才可以继续执行。所以从 a 的角度看， v1、v2 值是 1，v3 的值是 2。\n\n在实现上，数据库里面会创建一个视图（快照），访问的时候以视图的逻辑结果为准。在“可重复读”隔离级别下，这个视图（快照）是在事务启动时创建的，整个事务存在期间都用这个静态视图。在“读提交”隔离级别下，这个视图是在每个 sql 语句开始执行的时候创建的。这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；而“串行化”隔离级别下直接用加锁的方式来避免并行访问。\n\n> 这里所说的“视图”就是 ddia 中所讲的“快照级别隔离”的快照。\n\n我们可以看到在不同的隔离级别下，数据库行为是有所不同的。oracle 数据库的默认隔离级别其实就是“读提交”，因此对于一些从 oracle 迁移到 mysql 的应用，为保证数据库隔离级别的一致，你一定要记得将 mysql 的隔离级别设置为“读提交”。\n\n配置的方式是，将启动参数 transaction-isolation 的值设置成 read-committed。你可以用 show variables 来查看当前的值。\n\nmysql> show variables like 'transaction_isolation';\n+-----------------------+----------------+\n| variable_name | value |\n+-----------------------+----------------+\n| transaction_isolation | read-committed |\n+-----------------------+----------------+\n\n\n1\n2\n3\n4\n5\n6\n\n\n总结来说，存在即合理，每种隔离级别都有自己的使用场景，你要根据自己的业务情况来定。\n\n你可能会问那什么时候需要“可重复读”的场景呢？我们来看一个数据校对逻辑的案例。假设你在管理一个个人银行账户表。一个表存了账户余额，一个表存了账单明细。到了月底你要做数据校对，也就是判断上个月的余额和当前余额的差额，是否与本月的账单明细一致。你一定希望在校对过程中，即使有用户发生了一笔新的交易，也不影响你的校对结果。这时候使用“可重复读”隔离级别就很方便。事务启动时的视图可以认为是静态的，不受其他事务更新的影响。\n\n\n# 2. 事务隔离的实现\n\n理解了事务的隔离级别，我们再来看看事务隔离具体是怎么实现的。这里我们展开说明“可重复读”。\n\n在 mysql 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。\n\n假设一个值从 1 被按顺序改成了 2、3、4，在回滚日志里面就会有类似下面的记录：\n\n当前值是 4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的 read-view。如图中看到的，在视图 a、b、c 里面，这一个记录的值分别是 1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（mvcc）。对于 read-view a，要得到 1，就必须将当前值依次执行图中所有的回滚操作得到。\n\n同时你会发现，即使现在有另外一个事务正在将 4 改成 5，这个事务跟 read-view a、b、c 对应的事务是不会冲突的。\n\n你一定会问，回滚日志总不能一直保留吧，什么时候删除呢？答案是，在不需要的时候才删除。也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的 read-view 的时候。\n\n基于上面的说明，我们来讨论一下为什么建议你尽量不要使用长事务:\n\n * 长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。\n * 在 mysql 5.5 及以前的版本，回滚日志是跟数据字典一起放在 ibdata 文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。我见过数据只有 20gb，而回滚段有 200gb 的库。最终只好为了清理回滚段，重建整个库。\n * 除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库，这个我们会在后面讲锁的时候展开。\n\n\n# 3. 事务的启动方式\n\n如前面所述，长事务有这些潜在风险，我当然是建议你尽量避免。其实很多时候业务开发同学并不是有意使用长事务，通常是由于误用所致。mysql 的事务启动方式有以下几种：\n\n 1. 显式启动事务语句， begin 或 start transaction。配套的提交语句是 commit，回滚语句是 rollback。\n 2. set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。\n\n有些客户端连接框架会默认连接成功后先执行一个 set autocommit=0 的命令。这就导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。\n\n因此，我会建议你总是使用 set autocommit=1, 通过显式语句的方式来启动事务。\n\n但是有的开发同学会纠结“多一次交互”的问题。对于一个需要频繁使用事务的业务，第二种方式每个事务在开始时都不需要主动执行一次 “begin”，减少了语句的交互次数。如果你也有这个顾虑，我建议你使用 commit work and chain 语法：在 autocommit 为 1 的情况下，用 begin 显式启动的事务，如果执行 commit 则提交事务。如果执行 commit work and chain，则是提交事务并自动启动下一个事务，这样也省去了再次执行 begin 语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。\n\n你可以在 information_schema 库的 innodb_trx 这个表中查询长事务，比如下面这个语句，用于查找持续时间超过 60s 的事务：\n\nselect * from information_schema.innodb_trx where time_to_sec(timediff(now(),trx_started))>60\n\n\n1\n\n\n\n# summary\n\n以上介绍了 mysql 的事务隔离级别的现象和实现，根据实现原理分析了长事务存在的风险，以及如何用正确的方式避免长事务。希望我举的例子能够帮助你理解事务，并更好地使用 mysql 的事务特性。\n\n\n# 4. 事务到底隔离还是不隔离？\n\n前面说了，如果是可重复读隔离级别，事务 t 启动的时候会创建一个视图 read-view，之后事务 t 执行期间，即使有其他事务修改了数据，事务 t 看到的仍然跟在启动时看到的一样。但在全局锁、表级锁和行锁中提到，一个事务要更新一行，如果刚好有另外一个事务拥有这一行的行锁，它又不能这么独身事外了，它会被锁住，进入等待状态。问题是❓，既然进入了等待状态，那么等到这个事务自己获取到行锁要更新数据的时候，它读到的值又是什么呢？\n\n举一个例子，下面是一个只有两行的表的初始化语句：\n\nmysql> create table `t` (\n  `id` int(11) not null,\n  `k` int(11) default null,\n  primary key (`id`)\n) engine=innodb;\n\ninsert into t(id, k) values(1,1),(2,2);\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n事务 a、b、c 的流程如下：\n\n这里，我们需要注意的是事务的启动时机。begin/start transaction 命令并不是一个事务的起点，在执行到它们之后的第一个操作 innodb 表的语句，事务才真正启动。如果你想要马上启动一个事务，可以使用 start transaction with consistent snapshot 这个命令。\n\n * 第一种启动方式：一致性视图是在执行第一个快照读语句时创建的；\n * 第二种启动方式，一致性视图是在执行 start transaction with consistent snapshot 时创建的。\n\n还需注意的是，之后如果没有特别说明，都默认 autocommit=1，也就是即使没有手动 start transaction 开启事务，mysql 默认也会将用户的操作当做事务即时提交。\n\n> 本例中的事务 c 没有显式地使用 begin/commit，表示这个 update 语句本身就是一个事务，语句完成的时候会自动提交。\n\n现在你知道 a、b 事务看到的值是什么吗。这一大节就把这个疑惑解开，更深一步地理解 mvcc。\n\n> 本例中事务 a 查到的 k 值是 1，事务 b 查到的 k 值是 3。有点晕就往下看 ~\n\n\n# 4.1 snapshot 在 mvcc 里是怎样工作的？\n\n在可重复读隔离级别下，事务在启动的时候就“拍了个快照”。注意，这个快照是基于整库的。\n\n但真的要给全库拍快照又不太可行，一个数据库有 100g，怎么可能每个事务都先复制 100g 数据出来。实际上，db 并不需要真的拷贝这 100g 数据。我们看一下这个 snapshot 是怎么实现的。\n\ninnodb 里面每个事务有一个唯一的事务 id，叫作 transaction id。它是在事务开始的时候向 innodb 的事务系统申请的，是按申请顺序严格递增的。而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 id，记为 row trx_id。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。\n\n> 也就是说，数据表中的一行记录，其实可能有多个版本 (row)，每个版本有自己的 row trx_id。\n\n下图就是一个记录被多个事务连续更新后的状态：\n\n图中虚线框里是同一行数据的 4 个版本，当前最新版本是 v4，k 的值是 22，它是被 transaction id 为 25 的事务更新的，因此它的 row trx_id 也是 25。\n\n其实，图中的三个绿色虚线箭头就是 undo log（回滚日志），而且 旧版本 v1、v2、v3 并不是物理上真实存在的，而是每次需要的时候根据当前版本和 undo log 计算出来的。比如在需要 v2 的时候，就是通过 v4 依次执行 u3、u2 算出来。\n\n明白了多版本和 row trx_id 的概念后，我们再来想一下，innodb 是怎么定义那个“100g”的快照的❓。\n\n按照可重复读的定义，一个事务启动的时候，能够看到所有已经提交的事务结果。但是之后，这个事务执行期间，其他事务的更新对它不可见。因此，一个事务只需要在启动后只承认那些位于自己启动之前的数据版本和自己更新的数据就好了。\n\n在实现上，innodb 为每个事务构造了一个视图数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务 id。“活跃”指的就是，启动了但还没提交。数组里面事务 id 的最小值记为低水位，当前系统里面已经创建过的事务 id 的最大值加 1 记为高水位。这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）。而数据版本的可见性规则，就是基于数据的 row trx_id 和这个一致性视图的对比结果得到的。\n\nmysql 中有两个“视图”的概念：\n * 一个是 view。它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是 create view …，而它的查询方法与表一样。\n * 另一个是 innodb 在实现 mvcc 时用到的一致性读视图(read-view)，即 consistent read view，用于支持 rc（read committed，读提交）和 rr（repeatable read，可重复读）隔离级别的实现。\n\n这个视图数组把所有的 row trx_id 分成了几种不同的情况：\n\n这样，对于当前事务的启动瞬间来说，一个数据版本的 row trx_id，有以下几种可能：\n\n 1. 如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；\n 2. 如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的；\n 3. 如果落在黄色部分，那就包括两种情况：\n    * 若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见\n    * 若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见\n\n> 易混：落在黄色区域意味着是事务 id 在低水位和高水位这个范围里面，而真正是是否可见，看黄色区域是否有这个值。如果黄色区域没有这个事务 id，则可见，如果有，则不可见。在这个范围里面并不意味这这个范围里有这个值，比如 [1,2,3,5]，4 在这个数组 1-5 的范围里，却没在这个数组里面。\n\n比如，对于图 2 中的数据来说，如果有一个事务，它的低水位是 18，那么当它访问这一行数据时，就会从 v4 通过 u3 计算出 v3，所以在它看来，这一行的值是 11。\n\n有了这个可见性规则，系统里面随后发生的更新就与这个事务看到的内容无关了，所以这个事务的 snapshot 就是“静态”的了。所以你现在知道了，innodb 利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。\n\n现在借助于这个知识，我们对之前的例子进行分析，看看为什么事务 a 返回的结果是 k=1。我们不妨假设：\n\n 1. 事务 a 开始前，系统里面只有一个活跃事务 id 是 99；\n 2. 事务 a、b、c 的版本号分别是 100、101、102，且当前系统里只有这四个事务；\n 3. 三个事务开始前，(1,1）这一行数据的 row trx_id 是 90。\n\n这样，事务 a 的视图数组就是[99,100], 事务 b 的视图数组是[99,100,101], 事务 c 的视图数组是[99,100,101,102]。为了简化分析，我先把其他干扰语句去掉，只画出跟事务 a 查询逻辑有关的操作：\n\n从图中可以看到，第一个有效更新是事务 c，把数据从 (1,1) 改成了 (1,2)。这时候，这个数据的最新版本的 row trx_id 是 102，而 90 这个版本已经成为了历史版本。第二个有效更新是事务 b，把数据从 (1,2) 改成了 (1,3)。这时候，这个数据的最新版本（即 row trx_id）是 101，而 102 又成为了历史版本。你可能注意到了，在事务 a 查询的时候，其实事务 b 还没有提交，但是它生成的 (1,3) 这个版本已经变成当前版本了。但这个版本对事务 a 必须是不可见的，否则就变成脏读了。好，现在事务 a 要来读数据了，它的视图数组是[99,100]。当然了，读数据都是从当前版本读起的。\n\n所以，事务 a 查询语句的读数据流程是这样的：\n\n * 找到 (1,3) 的时候，判断出 row trx_id=101，比高水位大，处于红色区域，不可见；\n * 接着，找到上一个历史版本，一看 row trx_id=102，比高水位大，处于红色区域，不可见；\n * 再往前找，终于找到了（1,1)，它的 row trx_id=90，比低水位小，处于绿色区域，可见。\n\n这样执行下来，虽然期间这一行数据被修改过，但是事务 a 不论在什么时候查询，看到这行数据的结果都是一致的，所以我们称之为一致性读。\n\n这个判断规则是从代码逻辑直接转译过来的，但是正如你所见，用于人肉分析可见性很麻烦。所以，用更直观的话说：一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：\n\n * 版本未提交，不可见；\n * 版本已提交，但是是在视图创建后提交的，不可见；\n * 版本已提交，而且是在视图创建前提交的，可见。\n\n现在，我们用这个规则来判断示例中的查询结果，事务 a 的查询语句的视图数组是在事务 a 启动的时候生成的，这时候：\n\n * (1,3) 还没提交，属于情况 1，不可见；\n * (1,2) 虽然提交了，但是是在视图数组创建之后提交的，属于情况 2，不可见；\n * (1,1) 是在视图数组创建之前提交的，可见。\n\n你看，去掉数字对比后，只用时间先后顺序来判断，分析起来是不是轻松多了。所以，后面我们就都用这个规则来分析。\n\n\n# 4.2 更新逻辑\n\n更细心的话，可以提出这样一个疑问：事务 b 的 update 语句，如果按照一致性读，好像结果不对哦？你看图 5 中，事务 b 的视图数组是先生成的，之后事务 c 才提交，不是应该看不见 (1,2) 吗，怎么能算出 (1,3) 来？\n\n是的，如果事务 b 在更新之前查询一次数据，这个查询返回的 k 的值确实是 1。但是，当它要去更新数据的时候，就不能再在历史版本上更新了，否则事务 c 的更新就丢失了。因此，事务 b 此时的 set k=k+1 是在（1,2）的基础上进行的操作。\n\n所以，这里就用到了这样一条规则：更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。\n\n因此，在更新的时候，当前读拿到的数据是 (1,2)，更新后生成了新版本的数据 (1,3)，这个新版本的 row trx_id 是 101。所以，在执行事务 b 查询语句的时候，一看自己的版本号是 101，最新数据的版本号也是 101，是自己的更新，可以直接使用，所以查询得到的 k 的值是 3。\n\n这里我们提到了一个概念，叫作当前读。其实，除了 update 语句外，select 语句如果加锁，也是当前读。所以，如果把事务 a 的查询语句 select * from t where id=1 修改一下，加上 lock in share mode 或 for update，也都可以读到版本号是 101 的数据，返回的 k 的值是 3。下面这两个 select 语句，就是分别加了读锁（s 锁，共享锁）和写锁（x 锁，排他锁）：\n\nmysql> select k from t where id=1 lock in share mode;\nmysql> select k from t where id=1 for update;\n\n\n1\n2\n\n\n再往前一步，假设事务 c 不是马上提交的，而是变成了下面的事务 c’，会怎么样呢？\n\n事务 c’的不同是，更新后并没有马上提交，在它提交前，事务 b 的更新语句先发起了。前面说过了，虽然事务 c’还没提交，但是 (1,2) 这个版本也已经生成了，并且是当前的最新版本。那么，事务 b 的更新语句会怎么处理呢？\n\n这时候，我们在上一篇文章中提到的“两阶段锁协议”就要上场了。事务 c’ 没提交，也就是说 (1,2) 这个版本上的写锁还没释放。而事务 b 是当前读，必须要读最新版本，而且必须加锁，因此就被锁住了，必须等到事务 c’ 释放这个锁，才能继续它的当前读。\n\n到这里，我们把一致性读、当前读和行锁就串起来了。\n\n现在，我们再回到文章开头的问题：事务的可重复读的能力是怎么实现的？❓可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。\n\n而读提交的逻辑和可重复读的逻辑类似，它们最主要的区别是：\n\n * 在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图；\n * 在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。\n\n那么，我们再看一下，在读提交隔离级别下，事务 a 和事务 b 的查询语句查到的 k，分别应该是多少呢？\n\n> 这里需要说明一下，“start transaction with consistent snapshot; ”的意思是从这个语句开始，创建一个持续整个事务的一致性快照。所以，在读提交隔离级别下，这个用法就没意义了，等效于普通的 start transaction。\n\n下面是读提交时的状态图，可以看到这两个查询语句的创建视图数组的时机发生了变化，就是图中的 read view 框。（注意：这里，我们用的还是事务 c 的逻辑直接提交，而不是事务 c’）\n\n这时，事务 a 的查询语句的视图数组是在执行这个语句的时候创建的，时序上 (1,2)、(1,3) 的生成时间都在创建这个视图数组的时刻之前。但是，在这个时刻：\n\n * (1,3) 还没提交，属于情况 1，不可见；\n * (1,2) 提交了，属于情况 3，可见。\n\n所以，这时候事务 a 查询语句返回的是 k=2。显然地，事务 b 查询结果 k=3。\n\n\n# 4.3 summary\n\ninnodb 的行数据有多个版本，每个数据版本有自己的 row trx_id，每个事务或者语句有自己的一致性视图。普通查询语句是一致性读，一致性读会根据 row trx_id 和一致性视图确定数据版本的可见性。\n\n * 对于可重复读，查询只承认在事务启动前就已经提交完成的数据；\n * 对于读提交，查询只承认在语句启动前就已经提交完成的数据；\n\n而当前读，总是读取已经提交完成的最新版本。\n\n你也可以想一下，为什么表结构不支持“可重复读”？这是因为表结构没有对应的行数据，也没有 row trx_id，因此只能遵循当前读的逻辑。\n\n当然，mysql 8.0 已经可以把表结构放在 innodb 字典里了，也许以后会支持表结构的可重复读。\n\n\n# qa\n\nq：你现在知道了系统里面应该避免长事务，如果你是业务开发负责人同时也是数据库负责人，你会有什么方案来避免出现或者处理这种情况呢？\n\na：这个问题，我们可以从应用开发端和数据库端来看：\n\n * 从应用开发端来看：\n   1. 确认是否使用了 set autocommit=0。这个确认工作可以在测试环境中开展，把 mysql 的 general_log 开起来，然后随便跑一个业务逻辑，通过 general_log 的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成 1。\n   2. 确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用 begin/commit 框起来。我见过有些是业务并没有这个需要，但是也把好几个 select 语句放到了事务中。这种只读事务可以去掉。\n   3. 业务连接数据库的时候，根据业务本身的预估，通过 set max_execution_time 命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。\n * 从数据库端来看：\n   1. 监控 information_schema.innodb_trx 表，设置长事务阈值，超过就报警 / 或者 kill；\n   2. percona 的 pt-kill 这个工具不错，推荐使用；\n   3. 在业务功能测试阶段要求输出所有的 general_log，分析日志行为提前发现问题；\n   4. 如果使用的是 mysql 5.6 或者更新版本，把 innodb_undo_tablespaces 设置成 2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。",charsets:{cjk:!0},lastUpdated:"2023/05/23, 03:09:13",lastUpdatedTimestamp:1684811353e3},{title:"深入浅出索引",frontmatter:{title:"深入浅出索引",date:"2023-05-18T16:38:41.000Z",permalink:"/pages/1ea58b/",categories:["中间件","MySQL","专栏：MySQL 实战 45 讲"],tags:[null]},regularPath:"/%E4%B8%AD%E9%97%B4%E4%BB%B6/06.MySQL/05.%E4%B8%93%E6%A0%8F%EF%BC%9AMySQL%20%E5%AE%9E%E6%88%98%2045%20%E8%AE%B2/04.%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%B4%A2%E5%BC%95.html",relativePath:"中间件/06.MySQL/05.专栏：MySQL 实战 45 讲/04.深入浅出索引.md",key:"v-7482ba20",path:"/pages/1ea58b/",headers:[{level:2,title:"1. 索引的常见模型",slug:"_1-索引的常见模型",normalizedTitle:"1. 索引的常见模型",charIndex:139},{level:3,title:"1.1 哈希表的索引模型",slug:"_1-1-哈希表的索引模型",normalizedTitle:"1.1 哈希表的索引模型",charIndex:261},{level:3,title:"1.2 有序数组的索引模型",slug:"_1-2-有序数组的索引模型",normalizedTitle:"1.2 有序数组的索引模型",charIndex:470},{level:3,title:"1.3 搜索树的索引模型",slug:"_1-3-搜索树的索引模型",normalizedTitle:"1.3 搜索树的索引模型",charIndex:732},{level:2,title:"2. InnoDB 的索引模型",slug:"_2-innodb-的索引模型",normalizedTitle:"2. innodb 的索引模型",charIndex:1628},{level:2,title:"3.索引维护",slug:"_3-索引维护",normalizedTitle:"3.索引维护",charIndex:2530},{level:2,title:"4. 带索引的查询优化",slug:"_4-带索引的查询优化",normalizedTitle:"4. 带索引的查询优化",charIndex:3748},{level:3,title:"4.1 覆盖索引",slug:"_4-1-覆盖索引",normalizedTitle:"4.1 覆盖索引",charIndex:4514},{level:3,title:"4.2 最左前缀原则",slug:"_4-2-最左前缀原则",normalizedTitle:"4.2 最左前缀原则",charIndex:5503},{level:3,title:"4.3 索引下推",slug:"_4-3-索引下推",normalizedTitle:"4.3 索引下推",charIndex:6531},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:7346},{level:2,title:"QA",slug:"qa",normalizedTitle:"qa",charIndex:7432}],headersStr:"1. 索引的常见模型 1.1 哈希表的索引模型 1.2 有序数组的索引模型 1.3 搜索树的索引模型 2. InnoDB 的索引模型 3.索引维护 4. 带索引的查询优化 4.1 覆盖索引 4.2 最左前缀原则 4.3 索引下推 Summary QA",content:"> 参考：\n> \n>  * 04 | 深入浅出索引（上）| 极客时间\n>  * 05 | 深入浅出索引（下）| 极客时间\n\n索引是数据库系统里面最重要的概念之一。一句话简单来说，索引的出现其实就是为了提高数据查询的效率，就像书的目录一样，能够快速定位其中的某个知识点。\n\n\n# 1. 索引的常见模型\n\n索引的出现是为了提高查询效率，但是实现索引的方式却有很多种，所以这里也就引入了索引模型的概念。可以用于提高读写效率的数据结构很多，这里我先介绍三种常见、也比较简单的数据结构，它们分别是哈希表、有序数组和搜索树。\n\n\n# 1.1 哈希表的索引模型\n\n哈希表是一种以键 - 值（key-value）存储数据的结构，我们只要输入待查找的键即 key，就可以找到其对应的值即 Value。哈希冲突时拉出一个链表就好了。\n\n假设，你现在维护着一个身份证信息和姓名的表，需要根据身份证号查找对应的名字，这时对应的哈希索引的示意图如下所示：\n\n但哈希表的缺点是它不是有序的，所以哈希索引做区间查询的速度很慢，这种结构适用于只有等值查询的场景。\n\n\n# 1.2 有序数组的索引模型\n\n有序数组在等值查询和范围查询场景中的性能就都非常优秀，比如上面那个根据身份证号查名字的例子，如果用有序数组来实现的话，如下图：\n\n若要查询某 ID 对应的名字，用二分法就可快速得到，时间复杂度是 O(log(N))。\n\n如果仅仅看查询效率，有序数组就是最好的数据结构了。但是，在需要更新数据的时候就麻烦了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高。\n\n所以，有序数组索引只适用于静态存储引擎，比如你要保存的是 2017 年某个城市的所有人口信息，这类不会再修改的数据。\n\n\n# 1.3 搜索树的索引模型\n\n二叉搜索树也是经典数据结构了，但为了维持 $O(\\log(N))$ 的查询复杂度，你需要一个平衡二叉树。为了保持平衡，更新的时间复杂度也是 O(log(N))。\n\n> 二叉搜索树的特点：每个节点的左儿子小于父节点，父节点又小于右儿子。\n\n树可以有二叉，也可以有多叉。二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上。\n\n> 你可以想象一下一棵 100 万节点的平衡二叉树，树高 20。一次查询可能需要访问 20 个数据块。在机械硬盘时代，从磁盘随机读一个数据块需要 10 ms 左右的寻址时间。也就是说，对于一个 100 万行的表，如果使用二叉树来存储，单独访问一个行可能需要 20 个 10 ms 的时间，这个查询可真够慢的。 为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N 叉”树。这里，“N 叉”树中的“N”取决于数据块的大小。\n\n以 InnoDB 的一个整数字段索引为例，这个 N 差不多是 1200。这棵树高是 4 的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。N 叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中了。\n\n数据库技术发展到今天，跳表、LSM 树等数据结构也被用于引擎设计中，这里我就不再一一展开了。你心里要有个概念，数据库底层存储的核心就是基于这些数据模型的。每碰到一个新数据库，我们需要先关注它的数据模型，这样才能从理论上分析出这个数据库的适用场景。\n\n在 MySQL 中，索引是在存储引擎层实现的，所以并没有统一的索引标准，即不同存储引擎的索引的工作方式并不一样。而即使多个存储引擎支持同一种类型的索引，其底层的实现也可能不同。下面以 InnoDB 的为例。\n\n\n# 2. InnoDB 的索引模型\n\n在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。又因为前面我们提到的，InnoDB 使用了 B+ 树索引模型，所以数据都是存储在 B+ 树中的。每一个索引在 InnoDB 里面对应一棵 B+ 树。\n\n> B+ 树能够很好地配合磁盘的读写特性，减少单次查询的磁盘访问次数。\n\n假设，我们有一个主键列为 ID 的表，表中有字段 k，并且在 k 上有索引。这样的建表语句为：\n\nmysql> create table T(\n    id int primary key,\n    k int not null,\n    name varchar(16),\n    index (k)) engine=InnoDB;\n\n\n1\n2\n3\n4\n5\n\n\n表中 R1~R5 的 (ID,k) 值分别为 (100,1)、(200,2)、(300,3)、(500,5) 和 (600,6)，两棵树的示例示意图如下：\n\n从图中不难看出，根据叶子节点的内容，索引类型分为主键索引和非主键索引。\n\n * 主键索引：叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。\n * 非主键索引：叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）。\n\n> 实际上主页索引中存的是对一个磁盘页的 ref。这一部分可结合 DDIA 来学习。\n\n根据上面的索引结构说明，我们来讨论一个问题：基于主键索引和普通索引的查询有什么区别？\n\n * 如果语句是 select * from T where ID=500，即主键查询方式，则只需要搜索 ID 这棵 B+ 树；\n * 如果语句是 select * from T where k=5，即普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为回表。\n\n也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。\n\n\n# 3.索引维护\n\nB+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。\n\n * 以上面这个图为例，如果插入新的行 ID 值为 700，则只需要在 R5 的记录后面插入一个新记录。如果新插入的 ID 值为 400，就相对麻烦了，需要逻辑上挪动后面的数据，空出位置。\n * 而更糟的情况是，如果 R5 所在的数据页已经满了，根据 B+ 树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页分裂。在这种情况下，性能自然会受影响。\n\n除了性能外，页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约 50%。\n\n当然有分裂就有合并。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做页合并。合并的过程，可以认为是分裂过程的逆过程。\n\n基于上面的索引维护过程说明，我们来讨论一个案例：你可能在一些建表规范里面见到过类似的描述，要求建表语句里一定要有自增主键。当然事无绝对，我们来分析一下哪些场景下应该使用自增主键，而哪些场景下不应该。\n\n自增主键是指自增列上定义的主键，在建表语句中一般是这么定义的： NOT NULL PRIMARY KEY AUTO_INCREMENT。\n\n插入新记录的时候可以不指定 ID 的值，系统会获取当前 ID 最大值加 1 作为下一条记录的 ID 值。也就是说，自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。\n\n而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。\n\n除了考虑性能外，我们还可以从存储空间的角度来看。❓ 假设你的表中确实有一个唯一字段，比如字符串类型的身份证号，那应该用身份证号做主键，还是用自增字段做主键呢？\n\n由于每个非主键索引的叶子节点上都是主键的值。如果用身份证号做主键，那么每个二级索引的叶子节点占用约 20 个字节，而如果用整型做主键，则只要 4 个字节，如果是长整型（bigint）则是 8 个字节。显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。\n\n❓ 有没有什么场景适合用业务字段直接做主键的呢？还是有的。比如，有些业务的场景需求是这样的：\n\n 1. 只有一个索引；\n 2. 该索引必须是唯一索引。\n\n这就是典型的 KV 场景。由于没有其他索引，所以也就不用考虑其他索引的叶子节点大小的问题。这时候我们就要优先考虑上一段提到的“尽量使用主键查询”原则，直接将这个索引设置为主键，可以避免每次查询需要搜索两棵树。\n\n所以，由于 InnoDB 是索引组织表，一般情况下我会建议你创建一个自增主键，这样非主键索引占用的空间最小。但事无绝对，我也跟你讨论了使用业务逻辑字段做主键的应用场景。\n\n\n# 4. 带索引的查询优化\n\n我们先看一个问题：在下面这个表 T 中，如果我执行 select * from T where k between 3 and 5，需要执行几次树的搜索操作，会扫描多少行？\n\nmysql> create table T (\n    ID int primary key,\n    k int NOT NULL DEFAULT 0,\n    s varchar(16) NOT NULL DEFAULT '',\n    index k(k)) engine=InnoDB;\n\ninsert into T values \n  (100,1, 'aa'),\n  (200,2,'bb'),\n  (300,3,'cc'),\n  (500,5,'ee'),\n  (600,6,'ff'),\n  (700,7,'gg');\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n下面是 InnoDB 的索引组织结构：\n\n现在，我们一起来看看这条 SQL 查询语句的执行流程：\n\n 1. 在 k 索引树上找到 k=3 的记录，取得 ID = 300；\n 2. 再到 ID 索引树查到 ID=300 对应的 R3；\n 3. 在 k 索引树取下一个值 k=5，取得 ID=500；\n 4. 再回到 ID 索引树查到 ID=500 对应的 R4；\n 5. 在 k 索引树取下一个值 k=6，不满足条件，循环结束。\n\n在这个过程中，回到主键索引树搜索的过程，我们称为回表。可以看到，这个查询过程读了 k 索引树的 3 条记录（步骤 1、3 和 5），回表了两次（步骤 2 和 4）。\n\n在这个例子中，由于查询结果所需要的数据只在主键索引上有，所以不得不回表。那么，有没有可能经过索引优化，避免回表过程呢？\n\n\n# 4.1 覆盖索引\n\n如果执行的语句是 select ID from T where k between 3 and 5，这时只需要查 ID 的值，而 ID 的值已经在 k 索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引 k 已经“覆盖了”我们的查询需求，我们称为覆盖索引。\n\n由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。\n\n> 需要注意的是，在引擎内部使用覆盖索引在索引 k 上其实读了三个记录，R3~R5（对应的索引 k 上的记录项），但是对于 MySQL 的 Server 层来说，它就是找引擎拿到了两条记录，因此 MySQL 认为扫描行数是 2。\n\n基于上面覆盖索引的说明，我们来讨论一个问题：在一个市民信息表上，是否有必要将身份证号和名字建立联合索引？假设这个市民表的定义是这样的：\n\n\nCREATE TABLE `tuser` (\n  `id` int(11) NOT NULL,\n  `id_card` varchar(32) DEFAULT NULL,\n  `name` varchar(32) DEFAULT NULL,\n  `age` int(11) DEFAULT NULL,\n  `ismale` tinyint(1) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `id_card` (`id_card`),\n  KEY `name_age` (`name`,`age`)\n) ENGINE=InnoDB\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n我们知道，身份证号是市民的唯一标识。也就是说，如果有根据身份证号查询市民信息的需求，我们只要在身份证号字段上建立索引就够了。而再建立一个（身份证号、姓名）的联合索引，是不是浪费空间？\n\n如果现在有一个高频请求，要根据市民的身份证号查询他的姓名，这个联合索引就有意义了。它可以在这个高频请求上用到覆盖索引，不再需要回表查整行记录，减少语句的执行时间。所以，借助联合索引所实现的索引冗余可以支持覆盖索引，从而优化查询性能。\n\n当然，索引字段的维护总是有代价的。因此，在建立冗余索引来支持覆盖索引时就需要权衡考虑了。这正是业务 DBA，或者称为业务数据架构师的工作。\n\n\n# 4.2 最左前缀原则\n\n看到这里你一定有一个疑问，如果为每一种查询都设计一个索引，索引是不是太多了。如果我现在要按照市民的身份证号去查他的家庭地址呢？虽然这个查询需求在业务中出现的概率不高，但总不能让它走全表扫描吧？反过来说，单独为一个不频繁的请求创建一个（身份证号，地址）的索引又感觉有点浪费。应该怎么做呢？\n\n这里直接说结论吧：B+ 树这种索引结构，可以利用索引的“最左前缀”，来定位记录。\n\n为了直观地说明这个概念，我们用（name，age）这个联合索引来分析：\n\n可以看到，索引项是按照索引定义里面出现的字段顺序排序的，即优先按“姓名”来排序。\n\n * 当你的逻辑需求是查到所有名字是“张三”的人时，可以快速定位到 ID4，然后向后遍历得到所有需要的结果。\n * 如果你要查的是所有名字第一个字是“张”的人，你的 SQL 语句的条件是\"where name like ‘张 %’\"。这时，你也能够用上这个索引，查找到第一个符合条件的记录是 ID3，然后向后遍历，直到不满足条件为止。\n\n可以看到，不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。\n\n基于上面对最左前缀索引的说明，我们来讨论一个问题：在建立联合索引的时候，如何安排索引内的字段顺序❓\n\n这里我们的评估标准是，索引的复用能力。因为可以支持最左前缀，所以当已经有了 (a,b) 这个联合索引后，一般就不需要单独在 a 上建立索引了。因此，第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。\n\n所以现在你知道了，这段开头的问题里，我们要为高频请求创建 (身份证号，姓名）这个联合索引，并用这个索引来同时支持“根据身份证号查询地址”的需求。\n\n那么，如果既有联合查询，又有基于 a、b 各自的查询呢？查询条件里面只有 b 的语句，是无法使用 (a,b) 这个联合索引的，这时候你不得不维护另外一个索引，也就是说你需要同时维护 (a,b)、(b) 这两个索引。这时候，我们要考虑的原则就是空间了。比如上面这个市民表的情况，name 字段是比 age 字段大的 ，那我就建议你创建一个（name,age) 的联合索引和一个 (age) 的单字段索引。\n\n所以可以看到，要不要建立联合索引，以怎样的顺序来建立联合索引，都是要根据业务场景来决定的。\n\n\n# 4.3 索引下推\n\n上一段我们说到满足最左前缀原则的时候，最左前缀可以用于在索引中定位记录。这时，你可能要问，那些不符合最左前缀的部分，会怎么样呢？\n\n我们还是以市民表的联合索引（name, age）为例。如果现在有一个需求：检索出表中“名字第一个字是张，而且年龄是 10 岁的所有男孩”。那么，SQL 语句是这么写的：\n\nmysql> select * from tuser where name like '张%' and age=10 and ismale=1;\n\n\n1\n\n\n你已经知道了前缀索引规则，所以这个语句在搜索索引树的时候，只能用 “张”，找到第一个满足条件的记录 ID3。当然，这还不错，总比全表扫描要好。\n\n然后呢？当然是判断其他条件是否满足：\n\n * 在 MySQL 5.6 之前，只能从 ID3 开始一个个回表。到主键索引上找出数据行，再对比字段值。\n * 而 MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。\n\n可能上面的说法比较抽象，下面举一个实际例子。下面是两个执行过程的流程图：\n\n * 无索引下推执行流程：\n\n * 索引下推执行流程：\n\n上图中，每一个虚线箭头表示回表一次。\n\n在无索引下推执行流程图中，在 (name,age) 索引里面我特意去掉了 age 的值，这个过程 InnoDB 并不会去看 age 的值，只是按顺序把“name 第一个字是’张’”的记录一条条取出来回表。因此，需要回表 4 次。\n\n在索引下推执行流程中，nnoDB 在 (name,age) 索引内部就判断了 age 是否等于 10，对于不等于 10 的记录，直接判断并跳过。在我们的这个例子中，只需要对 ID4、ID5 这两条记录回表取数据判断，就只需要回表 2 次。\n\n\n# Summary\n\n在满足语句需求的情况下， 尽量少地访问资源是数据库设计的重要原则之一。我们在使用数据库的时候，尤其是在设计表结构时，也要以减少资源消耗作为目标。\n\n\n# QA\n\n一个问题。对于第 2 大节中的例子中的 InnoDB 表 T，如果你要重建索引 k，你的两个 SQL 语句可以这么写：\n\nalter table T drop index k;\nalter table T add index(k);\n\n\n1\n2\n\n\n如果你要重建主键索引，也可以这么写：\n\nalter table T drop primary key;\nalter table T add primary key(id);\n\n\n1\n2\n\n\n问题是，对于上面这两个重建索引的作法，说出你的理解。如果有不合适的，为什么，更好的方法是什么？\n\n参考答案：重建索引 k 的做法是合理的，可以达到省空间的目的。因为 InnoDB 引擎在删除了表的部分记录后，但是它的索引还在，并未释放。但是，重建主键的过程不合理。不论是删除主键还是创建主键，都会将整个表重建。所以连着执行这两个语句的话，第一个语句就白做了。这两个语句，你可以用这个语句代替 ： alter table T engine=InnoDB",normalizedContent:"> 参考：\n> \n>  * 04 | 深入浅出索引（上）| 极客时间\n>  * 05 | 深入浅出索引（下）| 极客时间\n\n索引是数据库系统里面最重要的概念之一。一句话简单来说，索引的出现其实就是为了提高数据查询的效率，就像书的目录一样，能够快速定位其中的某个知识点。\n\n\n# 1. 索引的常见模型\n\n索引的出现是为了提高查询效率，但是实现索引的方式却有很多种，所以这里也就引入了索引模型的概念。可以用于提高读写效率的数据结构很多，这里我先介绍三种常见、也比较简单的数据结构，它们分别是哈希表、有序数组和搜索树。\n\n\n# 1.1 哈希表的索引模型\n\n哈希表是一种以键 - 值（key-value）存储数据的结构，我们只要输入待查找的键即 key，就可以找到其对应的值即 value。哈希冲突时拉出一个链表就好了。\n\n假设，你现在维护着一个身份证信息和姓名的表，需要根据身份证号查找对应的名字，这时对应的哈希索引的示意图如下所示：\n\n但哈希表的缺点是它不是有序的，所以哈希索引做区间查询的速度很慢，这种结构适用于只有等值查询的场景。\n\n\n# 1.2 有序数组的索引模型\n\n有序数组在等值查询和范围查询场景中的性能就都非常优秀，比如上面那个根据身份证号查名字的例子，如果用有序数组来实现的话，如下图：\n\n若要查询某 id 对应的名字，用二分法就可快速得到，时间复杂度是 o(log(n))。\n\n如果仅仅看查询效率，有序数组就是最好的数据结构了。但是，在需要更新数据的时候就麻烦了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高。\n\n所以，有序数组索引只适用于静态存储引擎，比如你要保存的是 2017 年某个城市的所有人口信息，这类不会再修改的数据。\n\n\n# 1.3 搜索树的索引模型\n\n二叉搜索树也是经典数据结构了，但为了维持 $o(\\log(n))$ 的查询复杂度，你需要一个平衡二叉树。为了保持平衡，更新的时间复杂度也是 o(log(n))。\n\n> 二叉搜索树的特点：每个节点的左儿子小于父节点，父节点又小于右儿子。\n\n树可以有二叉，也可以有多叉。二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上。\n\n> 你可以想象一下一棵 100 万节点的平衡二叉树，树高 20。一次查询可能需要访问 20 个数据块。在机械硬盘时代，从磁盘随机读一个数据块需要 10 ms 左右的寻址时间。也就是说，对于一个 100 万行的表，如果使用二叉树来存储，单独访问一个行可能需要 20 个 10 ms 的时间，这个查询可真够慢的。 为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“n 叉”树。这里，“n 叉”树中的“n”取决于数据块的大小。\n\n以 innodb 的一个整数字段索引为例，这个 n 差不多是 1200。这棵树高是 4 的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。n 叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中了。\n\n数据库技术发展到今天，跳表、lsm 树等数据结构也被用于引擎设计中，这里我就不再一一展开了。你心里要有个概念，数据库底层存储的核心就是基于这些数据模型的。每碰到一个新数据库，我们需要先关注它的数据模型，这样才能从理论上分析出这个数据库的适用场景。\n\n在 mysql 中，索引是在存储引擎层实现的，所以并没有统一的索引标准，即不同存储引擎的索引的工作方式并不一样。而即使多个存储引擎支持同一种类型的索引，其底层的实现也可能不同。下面以 innodb 的为例。\n\n\n# 2. innodb 的索引模型\n\n在 innodb 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。又因为前面我们提到的，innodb 使用了 b+ 树索引模型，所以数据都是存储在 b+ 树中的。每一个索引在 innodb 里面对应一棵 b+ 树。\n\n> b+ 树能够很好地配合磁盘的读写特性，减少单次查询的磁盘访问次数。\n\n假设，我们有一个主键列为 id 的表，表中有字段 k，并且在 k 上有索引。这样的建表语句为：\n\nmysql> create table t(\n    id int primary key,\n    k int not null,\n    name varchar(16),\n    index (k)) engine=innodb;\n\n\n1\n2\n3\n4\n5\n\n\n表中 r1~r5 的 (id,k) 值分别为 (100,1)、(200,2)、(300,3)、(500,5) 和 (600,6)，两棵树的示例示意图如下：\n\n从图中不难看出，根据叶子节点的内容，索引类型分为主键索引和非主键索引。\n\n * 主键索引：叶子节点存的是整行数据。在 innodb 里，主键索引也被称为聚簇索引（clustered index）。\n * 非主键索引：叶子节点内容是主键的值。在 innodb 里，非主键索引也被称为二级索引（secondary index）。\n\n> 实际上主页索引中存的是对一个磁盘页的 ref。这一部分可结合 ddia 来学习。\n\n根据上面的索引结构说明，我们来讨论一个问题：基于主键索引和普通索引的查询有什么区别？\n\n * 如果语句是 select * from t where id=500，即主键查询方式，则只需要搜索 id 这棵 b+ 树；\n * 如果语句是 select * from t where k=5，即普通索引查询方式，则需要先搜索 k 索引树，得到 id 的值为 500，再到 id 索引树搜索一次。这个过程称为回表。\n\n也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。\n\n\n# 3.索引维护\n\nb+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。\n\n * 以上面这个图为例，如果插入新的行 id 值为 700，则只需要在 r5 的记录后面插入一个新记录。如果新插入的 id 值为 400，就相对麻烦了，需要逻辑上挪动后面的数据，空出位置。\n * 而更糟的情况是，如果 r5 所在的数据页已经满了，根据 b+ 树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页分裂。在这种情况下，性能自然会受影响。\n\n除了性能外，页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约 50%。\n\n当然有分裂就有合并。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做页合并。合并的过程，可以认为是分裂过程的逆过程。\n\n基于上面的索引维护过程说明，我们来讨论一个案例：你可能在一些建表规范里面见到过类似的描述，要求建表语句里一定要有自增主键。当然事无绝对，我们来分析一下哪些场景下应该使用自增主键，而哪些场景下不应该。\n\n自增主键是指自增列上定义的主键，在建表语句中一般是这么定义的： not null primary key auto_increment。\n\n插入新记录的时候可以不指定 id 的值，系统会获取当前 id 最大值加 1 作为下一条记录的 id 值。也就是说，自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。\n\n而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。\n\n除了考虑性能外，我们还可以从存储空间的角度来看。❓ 假设你的表中确实有一个唯一字段，比如字符串类型的身份证号，那应该用身份证号做主键，还是用自增字段做主键呢？\n\n由于每个非主键索引的叶子节点上都是主键的值。如果用身份证号做主键，那么每个二级索引的叶子节点占用约 20 个字节，而如果用整型做主键，则只要 4 个字节，如果是长整型（bigint）则是 8 个字节。显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。\n\n❓ 有没有什么场景适合用业务字段直接做主键的呢？还是有的。比如，有些业务的场景需求是这样的：\n\n 1. 只有一个索引；\n 2. 该索引必须是唯一索引。\n\n这就是典型的 kv 场景。由于没有其他索引，所以也就不用考虑其他索引的叶子节点大小的问题。这时候我们就要优先考虑上一段提到的“尽量使用主键查询”原则，直接将这个索引设置为主键，可以避免每次查询需要搜索两棵树。\n\n所以，由于 innodb 是索引组织表，一般情况下我会建议你创建一个自增主键，这样非主键索引占用的空间最小。但事无绝对，我也跟你讨论了使用业务逻辑字段做主键的应用场景。\n\n\n# 4. 带索引的查询优化\n\n我们先看一个问题：在下面这个表 t 中，如果我执行 select * from t where k between 3 and 5，需要执行几次树的搜索操作，会扫描多少行？\n\nmysql> create table t (\n    id int primary key,\n    k int not null default 0,\n    s varchar(16) not null default '',\n    index k(k)) engine=innodb;\n\ninsert into t values \n  (100,1, 'aa'),\n  (200,2,'bb'),\n  (300,3,'cc'),\n  (500,5,'ee'),\n  (600,6,'ff'),\n  (700,7,'gg');\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n下面是 innodb 的索引组织结构：\n\n现在，我们一起来看看这条 sql 查询语句的执行流程：\n\n 1. 在 k 索引树上找到 k=3 的记录，取得 id = 300；\n 2. 再到 id 索引树查到 id=300 对应的 r3；\n 3. 在 k 索引树取下一个值 k=5，取得 id=500；\n 4. 再回到 id 索引树查到 id=500 对应的 r4；\n 5. 在 k 索引树取下一个值 k=6，不满足条件，循环结束。\n\n在这个过程中，回到主键索引树搜索的过程，我们称为回表。可以看到，这个查询过程读了 k 索引树的 3 条记录（步骤 1、3 和 5），回表了两次（步骤 2 和 4）。\n\n在这个例子中，由于查询结果所需要的数据只在主键索引上有，所以不得不回表。那么，有没有可能经过索引优化，避免回表过程呢？\n\n\n# 4.1 覆盖索引\n\n如果执行的语句是 select id from t where k between 3 and 5，这时只需要查 id 的值，而 id 的值已经在 k 索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引 k 已经“覆盖了”我们的查询需求，我们称为覆盖索引。\n\n由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。\n\n> 需要注意的是，在引擎内部使用覆盖索引在索引 k 上其实读了三个记录，r3~r5（对应的索引 k 上的记录项），但是对于 mysql 的 server 层来说，它就是找引擎拿到了两条记录，因此 mysql 认为扫描行数是 2。\n\n基于上面覆盖索引的说明，我们来讨论一个问题：在一个市民信息表上，是否有必要将身份证号和名字建立联合索引？假设这个市民表的定义是这样的：\n\n\ncreate table `tuser` (\n  `id` int(11) not null,\n  `id_card` varchar(32) default null,\n  `name` varchar(32) default null,\n  `age` int(11) default null,\n  `ismale` tinyint(1) default null,\n  primary key (`id`),\n  key `id_card` (`id_card`),\n  key `name_age` (`name`,`age`)\n) engine=innodb\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n我们知道，身份证号是市民的唯一标识。也就是说，如果有根据身份证号查询市民信息的需求，我们只要在身份证号字段上建立索引就够了。而再建立一个（身份证号、姓名）的联合索引，是不是浪费空间？\n\n如果现在有一个高频请求，要根据市民的身份证号查询他的姓名，这个联合索引就有意义了。它可以在这个高频请求上用到覆盖索引，不再需要回表查整行记录，减少语句的执行时间。所以，借助联合索引所实现的索引冗余可以支持覆盖索引，从而优化查询性能。\n\n当然，索引字段的维护总是有代价的。因此，在建立冗余索引来支持覆盖索引时就需要权衡考虑了。这正是业务 dba，或者称为业务数据架构师的工作。\n\n\n# 4.2 最左前缀原则\n\n看到这里你一定有一个疑问，如果为每一种查询都设计一个索引，索引是不是太多了。如果我现在要按照市民的身份证号去查他的家庭地址呢？虽然这个查询需求在业务中出现的概率不高，但总不能让它走全表扫描吧？反过来说，单独为一个不频繁的请求创建一个（身份证号，地址）的索引又感觉有点浪费。应该怎么做呢？\n\n这里直接说结论吧：b+ 树这种索引结构，可以利用索引的“最左前缀”，来定位记录。\n\n为了直观地说明这个概念，我们用（name，age）这个联合索引来分析：\n\n可以看到，索引项是按照索引定义里面出现的字段顺序排序的，即优先按“姓名”来排序。\n\n * 当你的逻辑需求是查到所有名字是“张三”的人时，可以快速定位到 id4，然后向后遍历得到所有需要的结果。\n * 如果你要查的是所有名字第一个字是“张”的人，你的 sql 语句的条件是\"where name like ‘张 %’\"。这时，你也能够用上这个索引，查找到第一个符合条件的记录是 id3，然后向后遍历，直到不满足条件为止。\n\n可以看到，不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左 n 个字段，也可以是字符串索引的最左 m 个字符。\n\n基于上面对最左前缀索引的说明，我们来讨论一个问题：在建立联合索引的时候，如何安排索引内的字段顺序❓\n\n这里我们的评估标准是，索引的复用能力。因为可以支持最左前缀，所以当已经有了 (a,b) 这个联合索引后，一般就不需要单独在 a 上建立索引了。因此，第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。\n\n所以现在你知道了，这段开头的问题里，我们要为高频请求创建 (身份证号，姓名）这个联合索引，并用这个索引来同时支持“根据身份证号查询地址”的需求。\n\n那么，如果既有联合查询，又有基于 a、b 各自的查询呢？查询条件里面只有 b 的语句，是无法使用 (a,b) 这个联合索引的，这时候你不得不维护另外一个索引，也就是说你需要同时维护 (a,b)、(b) 这两个索引。这时候，我们要考虑的原则就是空间了。比如上面这个市民表的情况，name 字段是比 age 字段大的 ，那我就建议你创建一个（name,age) 的联合索引和一个 (age) 的单字段索引。\n\n所以可以看到，要不要建立联合索引，以怎样的顺序来建立联合索引，都是要根据业务场景来决定的。\n\n\n# 4.3 索引下推\n\n上一段我们说到满足最左前缀原则的时候，最左前缀可以用于在索引中定位记录。这时，你可能要问，那些不符合最左前缀的部分，会怎么样呢？\n\n我们还是以市民表的联合索引（name, age）为例。如果现在有一个需求：检索出表中“名字第一个字是张，而且年龄是 10 岁的所有男孩”。那么，sql 语句是这么写的：\n\nmysql> select * from tuser where name like '张%' and age=10 and ismale=1;\n\n\n1\n\n\n你已经知道了前缀索引规则，所以这个语句在搜索索引树的时候，只能用 “张”，找到第一个满足条件的记录 id3。当然，这还不错，总比全表扫描要好。\n\n然后呢？当然是判断其他条件是否满足：\n\n * 在 mysql 5.6 之前，只能从 id3 开始一个个回表。到主键索引上找出数据行，再对比字段值。\n * 而 mysql 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。\n\n可能上面的说法比较抽象，下面举一个实际例子。下面是两个执行过程的流程图：\n\n * 无索引下推执行流程：\n\n * 索引下推执行流程：\n\n上图中，每一个虚线箭头表示回表一次。\n\n在无索引下推执行流程图中，在 (name,age) 索引里面我特意去掉了 age 的值，这个过程 innodb 并不会去看 age 的值，只是按顺序把“name 第一个字是’张’”的记录一条条取出来回表。因此，需要回表 4 次。\n\n在索引下推执行流程中，nnodb 在 (name,age) 索引内部就判断了 age 是否等于 10，对于不等于 10 的记录，直接判断并跳过。在我们的这个例子中，只需要对 id4、id5 这两条记录回表取数据判断，就只需要回表 2 次。\n\n\n# summary\n\n在满足语句需求的情况下， 尽量少地访问资源是数据库设计的重要原则之一。我们在使用数据库的时候，尤其是在设计表结构时，也要以减少资源消耗作为目标。\n\n\n# qa\n\n一个问题。对于第 2 大节中的例子中的 innodb 表 t，如果你要重建索引 k，你的两个 sql 语句可以这么写：\n\nalter table t drop index k;\nalter table t add index(k);\n\n\n1\n2\n\n\n如果你要重建主键索引，也可以这么写：\n\nalter table t drop primary key;\nalter table t add primary key(id);\n\n\n1\n2\n\n\n问题是，对于上面这两个重建索引的作法，说出你的理解。如果有不合适的，为什么，更好的方法是什么？\n\n参考答案：重建索引 k 的做法是合理的，可以达到省空间的目的。因为 innodb 引擎在删除了表的部分记录后，但是它的索引还在，并未释放。但是，重建主键的过程不合理。不论是删除主键还是创建主键，都会将整个表重建。所以连着执行这两个语句的话，第一个语句就白做了。这两个语句，你可以用这个语句代替 ： alter table t engine=innodb",charsets:{cjk:!0},lastUpdated:"2023/05/19, 13:07:07",lastUpdatedTimestamp:1684501627e3},{title:"全局锁、表级锁和行锁",frontmatter:{title:"全局锁、表级锁和行锁",date:"2023-05-19T15:06:00.000Z",permalink:"/pages/376254/",categories:["中间件","MySQL","专栏：MySQL 实战 45 讲"],tags:[null]},regularPath:"/%E4%B8%AD%E9%97%B4%E4%BB%B6/06.MySQL/05.%E4%B8%93%E6%A0%8F%EF%BC%9AMySQL%20%E5%AE%9E%E6%88%98%2045%20%E8%AE%B2/05.%E5%85%A8%E5%B1%80%E9%94%81%E3%80%81%E8%A1%A8%E7%BA%A7%E9%94%81%E5%92%8C%E8%A1%8C%E9%94%81.html",relativePath:"中间件/06.MySQL/05.专栏：MySQL 实战 45 讲/05.全局锁、表级锁和行锁.md",key:"v-2c529f3a",path:"/pages/376254/",headers:[{level:2,title:"1. 全局锁",slug:"_1-全局锁",normalizedTitle:"1. 全局锁",charIndex:255},{level:3,title:"1.1 什么是全局锁",slug:"_1-1-什么是全局锁",normalizedTitle:"1.1 什么是全局锁",charIndex:266},{level:2,title:"1.2 备份为什么要加锁？",slug:"_1-2-备份为什么要加锁",normalizedTitle:"1.2 备份为什么要加锁？",charIndex:669},{level:3,title:"1.3 全局加锁的方法",slug:"_1-3-全局加锁的方法",normalizedTitle:"1.3 全局加锁的方法",charIndex:1035},{level:4,title:"1.3.1 开启事务（single-transaction 方法）",slug:"_1-3-1-开启事务-single-transaction-方法",normalizedTitle:"1.3.1 开启事务（single-transaction 方法）",charIndex:1050},{level:4,title:"1.3.2 set global readonly=true 方式 vs FTWRL 方式",slug:"_1-3-2-set-global-readonly-true-方式-vs-ftwrl-方式",normalizedTitle:"1.3.2 set global readonly=true 方式 vs ftwrl 方式",charIndex:1536},{level:3,title:"1.4 小结",slug:"_1-4-小结",normalizedTitle:"1.4 小结",charIndex:2074},{level:2,title:"2. 表级锁",slug:"_2-表级锁",normalizedTitle:"2. 表级锁",charIndex:2159},{level:3,title:"2.1 lock tables",slug:"_2-1-lock-tables",normalizedTitle:"2.1 lock tables",charIndex:2223},{level:3,title:"2.2 MDL",slug:"_2-2-mdl",normalizedTitle:"2.2 mdl",charIndex:2630},{level:3,title:"2.3 小结",slug:"_2-3-小结",normalizedTitle:"2.3 小结",charIndex:4288},{level:2,title:"3. 行锁",slug:"_3-行锁",normalizedTitle:"3. 行锁",charIndex:4518},{level:3,title:"3.1 从两阶段锁说起",slug:"_3-1-从两阶段锁说起",normalizedTitle:"3.1 从两阶段锁说起",charIndex:4869},{level:3,title:"3.2 死锁和死锁检测",slug:"_3-2-死锁和死锁检测",normalizedTitle:"3.2 死锁和死锁检测",charIndex:5883},{level:3,title:"3.3 小结",slug:"_3-3-小结",normalizedTitle:"3.3 小结",charIndex:7702},{level:2,title:"QA",slug:"qa",normalizedTitle:"qa",charIndex:7952}],headersStr:"1. 全局锁 1.1 什么是全局锁 1.2 备份为什么要加锁？ 1.3 全局加锁的方法 1.3.1 开启事务（single-transaction 方法） 1.3.2 set global readonly=true 方式 vs FTWRL 方式 1.4 小结 2. 表级锁 2.1 lock tables 2.2 MDL 2.3 小结 3. 行锁 3.1 从两阶段锁说起 3.2 死锁和死锁检测 3.3 小结 QA",content:"> 参考：\n> \n>  * 06 | 全局锁和表锁 ：给表加个字段怎么有这么多阻碍？| 极客时间\n>  * 07 | 行锁功过：怎么减少行锁对性能的影响？| 极客时间\n\n数据库锁设计的初衷是处理并发问题。作为多用户共享的资源，当出现并发访问的时候，数据库需要合理地控制资源的访问规则。而锁就是用来实现这些访问规则的重要数据结构。\n\n根据加锁的范围，MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类。由于锁的设计比较复杂，这里不会涉及锁的具体实现细节，主要介绍的是碰到锁时的现象和其背后的原理。\n\n\n# 1. 全局锁\n\n\n# 1.1 什么是全局锁\n\n全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。\n\n全局锁的典型使用场景是，做全库逻辑备份。也就是把整库每个表都 select 出来存成文本。\n\n以前有一种做法，是通过 FTWRL 确保不会有其他线程对数据库做更新，然后对整个库做备份。注意，在备份过程中整个库完全处于只读状态。但是让整库都只读，听上去就很危险：\n\n * 如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；\n * 如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟。\n\n\n# 1.2 备份为什么要加锁？\n\n看来加全局锁不太好。但是细想一下，备份为什么要加锁呢❓ 我们来看一下不加锁会有什么问题。\n\n现在发起一个逻辑备份。假设备份期间，有一个用户，他购买了一门课程，业务逻辑里就要扣掉他的余额，然后往已购课程里面加上一门课。如果时间顺序上是先备份账户余额表 (u_account)，然后用户购买，然后备份用户课程表 (u_course)，会怎么样呢？你可以看一下这个图：\n\n可以看到，这个备份结果里，用户 A 的数据状态是“账户余额没扣，但是用户课程表里面已经多了一门课”。如果后面用这个备份来恢复数据的话，用户 A 就发现，自己赚了。如果备份表的顺序反过来，先备份用户课程表再备份账户余额表，那用户就亏了。\n\n也就是说，不加锁的话，备份系统备份的得到的库不是一个逻辑时间点，这个视图是逻辑不一致的。\n\n\n# 1.3 全局加锁的方法\n\n# 1.3.1 开启事务（single-transaction 方法）\n\n说到视图你肯定想起来了，我们在前面讲事务隔离的时候，其实是有一个方法能够拿到一致性视图的，对吧？是的，就是在可重复读隔离级别下开启一个事务。\n\n官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数 -single-transaction 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。\n\n你一定在疑惑，有了这个功能，为什么还需要 FTWRL 呢？一致性读是好，但前提是引擎要支持这个隔离级别。比如，对于 MyISAM 这种不支持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时，我们就需要使用 FTWRL 命令了。\n\n所以，single-transaction 方法只适用于所有的表使用事务引擎的库。如果有的表使用了不支持事务的引擎，那么备份就只能通过 FTWRL 方法。这往往是 DBA 要求业务开发人员使用 InnoDB 替代 MyISAM 的原因之一。\n\n# 1.3.2 set global readonly=true 方式 vs FTWRL 方式\n\n你也许会问，既然要全库只读，为什么不使用 set global readonly=true 的方式呢？确实 readonly 方式也可以让全库进入只读状态，但我还是会建议你用 FTWRL 方式，主要有两个原因：\n\n * 一是，在有些系统中，readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改 global 变量的方式影响面更大，我不建议你使用。\n * 二是，在异常处理机制上有差异。如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高。\n\n业务的更新不只是增删改数据(DML)，还有可能是加字段等修改表结构的操作（DDL）。不论是哪种方法，一个库被全局锁上以后，你要对里面任何一个表做加字段操作，都是会被锁住的。\n\n但是，即使没有被全局锁住，加字段也不是就能一帆风顺的，因为你还会碰到接下来我们要介绍的表级锁。\n\n\n# 1.4 小结\n\n全局锁主要用在逻辑备份过程中。对于全部是 InnoDB 引擎的库，我建议你选择使用–single-transaction 参数，对应用会更友好。\n\n\n# 2. 表级锁\n\nMySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL）。\n\n\n# 2.1 lock tables\n\n表锁的语法是 lock tables … read/write。与 FTWRL 类似，可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。\n\n> 举个例子, 如果在某个线程 A 中执行 lock tables t1 read, t2 write; 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 unlock tables 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表。\n\n在还没有出现更细粒度的锁的时候，表锁是最常用的处理并发的方式。而对于 InnoDB 这种支持行锁的引擎，一般不使用 lock tables 命令来控制并发，毕竟锁住整个表的影响面还是太大。\n\n\n# 2.2 MDL\n\n另一类表级的锁是 MDL（metadata lock）。MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。\n\n因此，在 MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。\n\n * 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。\n * 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。\n\n因此说，MDL 的作用是防止 DDL 和 DML 并发的冲突。\n\n虽然 MDL 锁是系统默认会加的，但却是你不能忽略的一个机制。比如下面这个例子，我经常看到有人掉到这个坑里：给一个小表加个字段，导致整个库挂了。\n\n你肯定知道，给一个表加字段，或者修改字段，或者加索引，需要扫描全表的数据。在对大表操作的时候，你肯定会特别小心，以免对线上服务造成影响。而实际上，即使是小表，操作不慎也会出问题。我们来看一下下面的操作序列，假设表 t 是一个小表：\n\n 1. 我们可以看到 session A 先启动，这时候会对表 t 加一个 MDL 读锁。由于 session B 需要的也是 MDL 读锁，因此可以正常执行。\n 2. 之后 session C 会被 blocked，是因为 session A 的 MDL 读锁还没有释放，而 session C 需要 MDL 写锁，因此只能被阻塞。\n 3. 如果只有 session C 自己被阻塞还没什么关系，但是之后所有要在表 t 上新申请 MDL 读锁的请求也会被 session C 阻塞。前面我们说了，所有对表的增删改查操作都需要先申请 MDL 读锁，就都被锁住，等于这个表现在完全不可读写了（因为 session A 和 session B 可能是长事务）。如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新 session 再请求的话，这个库的线程很快就会爆满。\n\n> session C 拿不到 MDL 写锁而被 block，之后 session D 也会被 block 而不是先执行，这样的设计初衷也许是防止 session C 饿死。\n\n你现在应该知道了，事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。基于上面的分析，我们来讨论一个问题，如何安全地给小表加字段❓\n\n首先我们要解决长事务，事务不提交，就会一直占着 MDL 锁。在 MySQL 的 information_schema 库的 innodb_trx 表中，你可以查到当前执行中的事务。如果你要做 DDL 变更的表刚好有长事务在执行，要考虑先暂停 DDL，或者 kill 掉这个长事务。\n\n但考虑一下这个场景。如果你要变更的表是一个热点表，虽然数据量不大，但是上面的请求很频繁，而你不得不加个字段，你该怎么做呢？\n\n这时候 kill 可能未必管用，因为新的请求马上就来了。比较理想的机制是，在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者 DBA 再通过重试命令重复这个过程。\n\nMariaDB 已经合并了 AliSQL 的这个功能，所以这两个开源分支目前都支持 DDL NOWAIT/WAIT n 这个语法。\n\nALTER TABLE tbl_name NOWAIT add column ...\nALTER TABLE tbl_name WAIT N add column ...\n\n\n1\n2\n\n\n\n# 2.3 小结\n\n表锁一般是在数据库引擎不支持行锁的时候才会被用到的。如果你发现你的应用程序里有 lock tables 这样的语句，你需要追查一下，比较可能的情况是：\n\n * 要么是你的系统现在还在用 MyISAM 这类不支持事务的引擎，那要安排升级换引擎；\n * 要么是你的引擎升级了，但是代码还没升级。我见过这样的情况，最后业务开发就是把 lock tables 和 unlock tables 改成 begin 和 commit，问题就解决了。\n\n\n# 3. 行锁\n\nMySQL 的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如 MyISAM 引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。InnoDB 是支持行锁的，这也是 MyISAM 被 InnoDB 替代的重要原因之一。这里主要聊聊 InnoDB 的行锁，以及如何通过减少锁冲突来提升业务并发度。\n\n行锁就是针对数据表中行记录的锁。这很好理解，比如事务 A 更新了一行，而这时候事务 B 也要更新同一行，则必须等事务 A 的操作完成后才能进行更新。\n\n当然，数据库中还有一些没那么一目了然的概念和设计，这些概念如果理解和使用不当，容易导致程序出现非预期行为，比如两阶段锁。\n\n\n# 3.1 从两阶段锁说起\n\n我先给你举个例子。在下面的操作序列中，事务 B 的 update 语句执行时会是什么现象呢？假设字段 id 是表 t 的主键。\n\n这个问题的结论取决于事务 A 在执行完两条 update 语句后，持有哪些锁，以及在什么时候释放。你可以验证一下：实际上事务 B 的 update 语句会被阻塞，直到事务 A 执行 commit 之后，事务 B 才能继续执行。\n\n知道了这个答案，你一定知道了事务 A 持有的两个记录的行锁，都是在 commit 的时候才释放的。也就是说，在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。\n\n知道了这个设定，对我们使用事务有什么帮助呢？那就是，如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。我给你举个例子。\n\n假设你负责实现一个电影票在线交易业务，顾客 A 要在影院 B 购买电影票。我们简化一点，这个业务需要涉及到以下操作：\n\n 1. 从顾客 A 账户余额中扣除电影票价；\n 2. 给影院 B 的账户余额增加这张电影票价；\n 3. 记录一条交易日志。\n\n也就是说，要完成这个交易，我们需要 update 两条记录，并 insert 一条记录。当然，为了保证交易的原子性，我们要把这三个操作放在一个事务中。那么，你会怎样安排这三个语句在事务中的顺序呢？\n\n试想如果同时有另外一个顾客 C 要在影院 B 买票，那么这两个事务冲突的部分就是语句 2 了。因为它们要更新同一个影院账户的余额，需要修改同一行数据。\n\n根据两阶段锁协议，不论你怎样安排语句顺序，所有的操作需要的行锁都是在事务提交的时候才释放的。所以，如果你把语句 2 安排在最后，比如按照 3、1、2 这样的顺序，那么影院账户余额这一行的锁时间就最少。这就最大程度地减少了事务之间的锁等待，提升了并发度。\n\n好了，现在由于你的正确设计，影院余额这一行的行锁在一个事务中不会停留很长时间。但是，这并没有完全解决你的困扰。如果这个影院做活动，可以低价预售一年内所有的电影票，而且这个活动只做一天。于是在活动时间开始的时候，你的 MySQL 就挂了。你登上服务器一看，CPU 消耗接近 100%，但整个数据库每秒就执行不到 100 个事务。这是什么原因呢？\n\n这里，就要说到死锁和死锁检测了。\n\n\n# 3.2 死锁和死锁检测\n\n当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。这里我用数据库中的行锁举个例子：\n\n这时候，事务 A 在等待事务 B 释放 id=2 的行锁，而事务 B 在等待事务 A 释放 id=1 的行锁。 事务 A 和事务 B 在互相等待对方的资源释放，就是进入了死锁状态。当出现死锁以后，有两种策略：\n\n * 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。\n * 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。\n\n在 InnoDB 中，innodb_lock_wait_timeout 的默认值是 50s，意味着如果采用第一个策略，当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出，然后其他线程才有可能继续执行。对于在线服务来说，这个等待时间往往是无法接受的。\n\n但是，我们又不可能直接把这个时间设置成一个很小的值，比如 1s。这样当出现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待呢？所以，超时时间设置太短的话，会出现很多误伤。\n\n所以，正常情况下我们还是要采用第二种策略，即：主动死锁检测，而且 innodb_deadlock_detect 的默认值本身就是 on。主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。\n\n你可以想象一下这个过程：每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。那如果是我们上面说到的所有事务都要更新同一行的场景呢？每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是 $O(n^2)$ 的操作。假设有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的 CPU 资源。因此，你就会看到 CPU 利用率很高，但是每秒却执行不了几个事务。\n\n根据上面的分析，我们来讨论一下，怎么解决由这种热点行更新导致的性能问题呢❓ 问题的症结在于，死锁检测要耗费大量的 CPU 资源：\n\n * 一种头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。但是这种操作本身带有一定的风险，因为业务设计的时候一般不会把死锁当做一个严重错误，毕竟出现死锁了，就回滚，然后通过业务重试一般就没问题了，这是业务无损的。而关掉死锁检测意味着可能会出现大量的超时，这是业务有损的。\n\n * 另一个思路是控制并发度。根据上面的分析，你会发现如果并发能够控制住，比如同一行同时最多只有 10 个线程在更新，那么死锁检测的成本很低，就不会出现这个问题。一个直接的想法就是，在客户端做并发控制。但是，你会很快发现这个方法不太可行，因为客户端很多。我见过一个应用，有 600 个客户端，这样即使每个客户端控制到只有 5 个并发线程，汇总到数据库服务端以后，峰值并发数也可能要达到 3000。\n\n因此，这个并发控制要做在数据库服务端。如果你有中间件，可以考虑在中间件实现；如果你的团队有能修改 MySQL 源码的人，也可以做在 MySQL 里面。基本思路就是，对于相同行的更新，在进入引擎之前排队。这样在 InnoDB 内部就不会有大量的死锁检测工作了。\n\n可能你会问，如果团队里暂时没有数据库方面的专家，不能实现这样的方案，能不能从设计上优化这个问题呢 ❓\n\n * 你可以考虑通过将一行改成逻辑上的多行来减少锁冲突。还是以影院账户为例，可以考虑放在多条记录上，比如 10 个记录，影院的账户总额等于这 10 个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的 1/10，可以减少锁等待个数，也就减少了死锁检测的 CPU 消耗。\n\n这个方案看上去是无损的，但其实这类方案需要根据业务逻辑做详细设计。如果账户余额可能会减少，比如退票逻辑，那么这时候就需要考虑当一部分行记录变成 0 的时候，代码要有特殊处理。\n\n\n# 3.3 小结\n\n这一大节介绍了 MySQL 的行锁，并主要涉及了两阶段锁协议、死锁和死锁检测这两大部分内容。\n\n * 以两阶段协议为起点，一起讨论了在开发的时候如何安排正确的事务语句。这里的原则 / 我给你的建议是：如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁的申请时机尽量往后放。\n * 但是，调整语句顺序并不能完全避免死锁。所以我们引入了死锁和死锁检测的概念，以及提供了三个方案，来减少死锁对数据库的影响。减少死锁的主要方向，就是控制访问相同资源的并发事务量。\n\n\n# QA\n\nQ：如果你要删除一个表里面的前 10000 行数据，有以下三种方法可以做到：\n\n * 第一种，直接执行 delete from T limit 10000;\n * 第二种，在一个连接中循环执行 20 次 delete from T limit 500;\n * 第三种，在 20 个连接中同时执行 delete from T limit 500。\n\n你会选择哪一种方法呢？为什么呢？\n\nA：第二种方式是相对较好的。\n\n * 第一种方式（即：直接执行 delete from T limit 10000）里面，单个语句占用时间长，锁的时间也比较长；而且大事务还会导致主从延迟。\n * 第三种方式（即：在 20 个连接中同时执行 delete from T limit 500），会人为造成锁冲突。",normalizedContent:"> 参考：\n> \n>  * 06 | 全局锁和表锁 ：给表加个字段怎么有这么多阻碍？| 极客时间\n>  * 07 | 行锁功过：怎么减少行锁对性能的影响？| 极客时间\n\n数据库锁设计的初衷是处理并发问题。作为多用户共享的资源，当出现并发访问的时候，数据库需要合理地控制资源的访问规则。而锁就是用来实现这些访问规则的重要数据结构。\n\n根据加锁的范围，mysql 里面的锁大致可以分成全局锁、表级锁和行锁三类。由于锁的设计比较复杂，这里不会涉及锁的具体实现细节，主要介绍的是碰到锁时的现象和其背后的原理。\n\n\n# 1. 全局锁\n\n\n# 1.1 什么是全局锁\n\n全局锁就是对整个数据库实例加锁。mysql 提供了一个加全局读锁的方法，命令是 flush tables with read lock (ftwrl)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。\n\n全局锁的典型使用场景是，做全库逻辑备份。也就是把整库每个表都 select 出来存成文本。\n\n以前有一种做法，是通过 ftwrl 确保不会有其他线程对数据库做更新，然后对整个库做备份。注意，在备份过程中整个库完全处于只读状态。但是让整库都只读，听上去就很危险：\n\n * 如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；\n * 如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟。\n\n\n# 1.2 备份为什么要加锁？\n\n看来加全局锁不太好。但是细想一下，备份为什么要加锁呢❓ 我们来看一下不加锁会有什么问题。\n\n现在发起一个逻辑备份。假设备份期间，有一个用户，他购买了一门课程，业务逻辑里就要扣掉他的余额，然后往已购课程里面加上一门课。如果时间顺序上是先备份账户余额表 (u_account)，然后用户购买，然后备份用户课程表 (u_course)，会怎么样呢？你可以看一下这个图：\n\n可以看到，这个备份结果里，用户 a 的数据状态是“账户余额没扣，但是用户课程表里面已经多了一门课”。如果后面用这个备份来恢复数据的话，用户 a 就发现，自己赚了。如果备份表的顺序反过来，先备份用户课程表再备份账户余额表，那用户就亏了。\n\n也就是说，不加锁的话，备份系统备份的得到的库不是一个逻辑时间点，这个视图是逻辑不一致的。\n\n\n# 1.3 全局加锁的方法\n\n# 1.3.1 开启事务（single-transaction 方法）\n\n说到视图你肯定想起来了，我们在前面讲事务隔离的时候，其实是有一个方法能够拿到一致性视图的，对吧？是的，就是在可重复读隔离级别下开启一个事务。\n\n官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数 -single-transaction 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 mvcc 的支持，这个过程中数据是可以正常更新的。\n\n你一定在疑惑，有了这个功能，为什么还需要 ftwrl 呢？一致性读是好，但前提是引擎要支持这个隔离级别。比如，对于 myisam 这种不支持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时，我们就需要使用 ftwrl 命令了。\n\n所以，single-transaction 方法只适用于所有的表使用事务引擎的库。如果有的表使用了不支持事务的引擎，那么备份就只能通过 ftwrl 方法。这往往是 dba 要求业务开发人员使用 innodb 替代 myisam 的原因之一。\n\n# 1.3.2 set global readonly=true 方式 vs ftwrl 方式\n\n你也许会问，既然要全库只读，为什么不使用 set global readonly=true 的方式呢？确实 readonly 方式也可以让全库进入只读状态，但我还是会建议你用 ftwrl 方式，主要有两个原因：\n\n * 一是，在有些系统中，readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改 global 变量的方式影响面更大，我不建议你使用。\n * 二是，在异常处理机制上有差异。如果执行 ftwrl 命令之后由于客户端发生异常断开，那么 mysql 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高。\n\n业务的更新不只是增删改数据(dml)，还有可能是加字段等修改表结构的操作（ddl）。不论是哪种方法，一个库被全局锁上以后，你要对里面任何一个表做加字段操作，都是会被锁住的。\n\n但是，即使没有被全局锁住，加字段也不是就能一帆风顺的，因为你还会碰到接下来我们要介绍的表级锁。\n\n\n# 1.4 小结\n\n全局锁主要用在逻辑备份过程中。对于全部是 innodb 引擎的库，我建议你选择使用–single-transaction 参数，对应用会更友好。\n\n\n# 2. 表级锁\n\nmysql 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，mdl）。\n\n\n# 2.1 lock tables\n\n表锁的语法是 lock tables … read/write。与 ftwrl 类似，可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。\n\n> 举个例子, 如果在某个线程 a 中执行 lock tables t1 read, t2 write; 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 a 在执行 unlock tables 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表。\n\n在还没有出现更细粒度的锁的时候，表锁是最常用的处理并发的方式。而对于 innodb 这种支持行锁的引擎，一般不使用 lock tables 命令来控制并发，毕竟锁住整个表的影响面还是太大。\n\n\n# 2.2 mdl\n\n另一类表级的锁是 mdl（metadata lock）。mdl 不需要显式使用，在访问一个表的时候会被自动加上。mdl 的作用是，保证读写的正确性。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。\n\n因此，在 mysql 5.5 版本中引入了 mdl，当对一个表做增删改查操作的时候，加 mdl 读锁；当要对表做结构变更操作的时候，加 mdl 写锁。\n\n * 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。\n * 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。\n\n因此说，mdl 的作用是防止 ddl 和 dml 并发的冲突。\n\n虽然 mdl 锁是系统默认会加的，但却是你不能忽略的一个机制。比如下面这个例子，我经常看到有人掉到这个坑里：给一个小表加个字段，导致整个库挂了。\n\n你肯定知道，给一个表加字段，或者修改字段，或者加索引，需要扫描全表的数据。在对大表操作的时候，你肯定会特别小心，以免对线上服务造成影响。而实际上，即使是小表，操作不慎也会出问题。我们来看一下下面的操作序列，假设表 t 是一个小表：\n\n 1. 我们可以看到 session a 先启动，这时候会对表 t 加一个 mdl 读锁。由于 session b 需要的也是 mdl 读锁，因此可以正常执行。\n 2. 之后 session c 会被 blocked，是因为 session a 的 mdl 读锁还没有释放，而 session c 需要 mdl 写锁，因此只能被阻塞。\n 3. 如果只有 session c 自己被阻塞还没什么关系，但是之后所有要在表 t 上新申请 mdl 读锁的请求也会被 session c 阻塞。前面我们说了，所有对表的增删改查操作都需要先申请 mdl 读锁，就都被锁住，等于这个表现在完全不可读写了（因为 session a 和 session b 可能是长事务）。如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新 session 再请求的话，这个库的线程很快就会爆满。\n\n> session c 拿不到 mdl 写锁而被 block，之后 session d 也会被 block 而不是先执行，这样的设计初衷也许是防止 session c 饿死。\n\n你现在应该知道了，事务中的 mdl 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。基于上面的分析，我们来讨论一个问题，如何安全地给小表加字段❓\n\n首先我们要解决长事务，事务不提交，就会一直占着 mdl 锁。在 mysql 的 information_schema 库的 innodb_trx 表中，你可以查到当前执行中的事务。如果你要做 ddl 变更的表刚好有长事务在执行，要考虑先暂停 ddl，或者 kill 掉这个长事务。\n\n但考虑一下这个场景。如果你要变更的表是一个热点表，虽然数据量不大，但是上面的请求很频繁，而你不得不加个字段，你该怎么做呢？\n\n这时候 kill 可能未必管用，因为新的请求马上就来了。比较理想的机制是，在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 mdl 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者 dba 再通过重试命令重复这个过程。\n\nmariadb 已经合并了 alisql 的这个功能，所以这两个开源分支目前都支持 ddl nowait/wait n 这个语法。\n\nalter table tbl_name nowait add column ...\nalter table tbl_name wait n add column ...\n\n\n1\n2\n\n\n\n# 2.3 小结\n\n表锁一般是在数据库引擎不支持行锁的时候才会被用到的。如果你发现你的应用程序里有 lock tables 这样的语句，你需要追查一下，比较可能的情况是：\n\n * 要么是你的系统现在还在用 myisam 这类不支持事务的引擎，那要安排升级换引擎；\n * 要么是你的引擎升级了，但是代码还没升级。我见过这样的情况，最后业务开发就是把 lock tables 和 unlock tables 改成 begin 和 commit，问题就解决了。\n\n\n# 3. 行锁\n\nmysql 的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如 myisam 引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。innodb 是支持行锁的，这也是 myisam 被 innodb 替代的重要原因之一。这里主要聊聊 innodb 的行锁，以及如何通过减少锁冲突来提升业务并发度。\n\n行锁就是针对数据表中行记录的锁。这很好理解，比如事务 a 更新了一行，而这时候事务 b 也要更新同一行，则必须等事务 a 的操作完成后才能进行更新。\n\n当然，数据库中还有一些没那么一目了然的概念和设计，这些概念如果理解和使用不当，容易导致程序出现非预期行为，比如两阶段锁。\n\n\n# 3.1 从两阶段锁说起\n\n我先给你举个例子。在下面的操作序列中，事务 b 的 update 语句执行时会是什么现象呢？假设字段 id 是表 t 的主键。\n\n这个问题的结论取决于事务 a 在执行完两条 update 语句后，持有哪些锁，以及在什么时候释放。你可以验证一下：实际上事务 b 的 update 语句会被阻塞，直到事务 a 执行 commit 之后，事务 b 才能继续执行。\n\n知道了这个答案，你一定知道了事务 a 持有的两个记录的行锁，都是在 commit 的时候才释放的。也就是说，在 innodb 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。\n\n知道了这个设定，对我们使用事务有什么帮助呢？那就是，如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。我给你举个例子。\n\n假设你负责实现一个电影票在线交易业务，顾客 a 要在影院 b 购买电影票。我们简化一点，这个业务需要涉及到以下操作：\n\n 1. 从顾客 a 账户余额中扣除电影票价；\n 2. 给影院 b 的账户余额增加这张电影票价；\n 3. 记录一条交易日志。\n\n也就是说，要完成这个交易，我们需要 update 两条记录，并 insert 一条记录。当然，为了保证交易的原子性，我们要把这三个操作放在一个事务中。那么，你会怎样安排这三个语句在事务中的顺序呢？\n\n试想如果同时有另外一个顾客 c 要在影院 b 买票，那么这两个事务冲突的部分就是语句 2 了。因为它们要更新同一个影院账户的余额，需要修改同一行数据。\n\n根据两阶段锁协议，不论你怎样安排语句顺序，所有的操作需要的行锁都是在事务提交的时候才释放的。所以，如果你把语句 2 安排在最后，比如按照 3、1、2 这样的顺序，那么影院账户余额这一行的锁时间就最少。这就最大程度地减少了事务之间的锁等待，提升了并发度。\n\n好了，现在由于你的正确设计，影院余额这一行的行锁在一个事务中不会停留很长时间。但是，这并没有完全解决你的困扰。如果这个影院做活动，可以低价预售一年内所有的电影票，而且这个活动只做一天。于是在活动时间开始的时候，你的 mysql 就挂了。你登上服务器一看，cpu 消耗接近 100%，但整个数据库每秒就执行不到 100 个事务。这是什么原因呢？\n\n这里，就要说到死锁和死锁检测了。\n\n\n# 3.2 死锁和死锁检测\n\n当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。这里我用数据库中的行锁举个例子：\n\n这时候，事务 a 在等待事务 b 释放 id=2 的行锁，而事务 b 在等待事务 a 释放 id=1 的行锁。 事务 a 和事务 b 在互相等待对方的资源释放，就是进入了死锁状态。当出现死锁以后，有两种策略：\n\n * 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。\n * 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。\n\n在 innodb 中，innodb_lock_wait_timeout 的默认值是 50s，意味着如果采用第一个策略，当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出，然后其他线程才有可能继续执行。对于在线服务来说，这个等待时间往往是无法接受的。\n\n但是，我们又不可能直接把这个时间设置成一个很小的值，比如 1s。这样当出现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待呢？所以，超时时间设置太短的话，会出现很多误伤。\n\n所以，正常情况下我们还是要采用第二种策略，即：主动死锁检测，而且 innodb_deadlock_detect 的默认值本身就是 on。主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。\n\n你可以想象一下这个过程：每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。那如果是我们上面说到的所有事务都要更新同一行的场景呢？每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是 $o(n^2)$ 的操作。假设有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的 cpu 资源。因此，你就会看到 cpu 利用率很高，但是每秒却执行不了几个事务。\n\n根据上面的分析，我们来讨论一下，怎么解决由这种热点行更新导致的性能问题呢❓ 问题的症结在于，死锁检测要耗费大量的 cpu 资源：\n\n * 一种头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。但是这种操作本身带有一定的风险，因为业务设计的时候一般不会把死锁当做一个严重错误，毕竟出现死锁了，就回滚，然后通过业务重试一般就没问题了，这是业务无损的。而关掉死锁检测意味着可能会出现大量的超时，这是业务有损的。\n\n * 另一个思路是控制并发度。根据上面的分析，你会发现如果并发能够控制住，比如同一行同时最多只有 10 个线程在更新，那么死锁检测的成本很低，就不会出现这个问题。一个直接的想法就是，在客户端做并发控制。但是，你会很快发现这个方法不太可行，因为客户端很多。我见过一个应用，有 600 个客户端，这样即使每个客户端控制到只有 5 个并发线程，汇总到数据库服务端以后，峰值并发数也可能要达到 3000。\n\n因此，这个并发控制要做在数据库服务端。如果你有中间件，可以考虑在中间件实现；如果你的团队有能修改 mysql 源码的人，也可以做在 mysql 里面。基本思路就是，对于相同行的更新，在进入引擎之前排队。这样在 innodb 内部就不会有大量的死锁检测工作了。\n\n可能你会问，如果团队里暂时没有数据库方面的专家，不能实现这样的方案，能不能从设计上优化这个问题呢 ❓\n\n * 你可以考虑通过将一行改成逻辑上的多行来减少锁冲突。还是以影院账户为例，可以考虑放在多条记录上，比如 10 个记录，影院的账户总额等于这 10 个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的 1/10，可以减少锁等待个数，也就减少了死锁检测的 cpu 消耗。\n\n这个方案看上去是无损的，但其实这类方案需要根据业务逻辑做详细设计。如果账户余额可能会减少，比如退票逻辑，那么这时候就需要考虑当一部分行记录变成 0 的时候，代码要有特殊处理。\n\n\n# 3.3 小结\n\n这一大节介绍了 mysql 的行锁，并主要涉及了两阶段锁协议、死锁和死锁检测这两大部分内容。\n\n * 以两阶段协议为起点，一起讨论了在开发的时候如何安排正确的事务语句。这里的原则 / 我给你的建议是：如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁的申请时机尽量往后放。\n * 但是，调整语句顺序并不能完全避免死锁。所以我们引入了死锁和死锁检测的概念，以及提供了三个方案，来减少死锁对数据库的影响。减少死锁的主要方向，就是控制访问相同资源的并发事务量。\n\n\n# qa\n\nq：如果你要删除一个表里面的前 10000 行数据，有以下三种方法可以做到：\n\n * 第一种，直接执行 delete from t limit 10000;\n * 第二种，在一个连接中循环执行 20 次 delete from t limit 500;\n * 第三种，在 20 个连接中同时执行 delete from t limit 500。\n\n你会选择哪一种方法呢？为什么呢？\n\na：第二种方式是相对较好的。\n\n * 第一种方式（即：直接执行 delete from t limit 10000）里面，单个语句占用时间长，锁的时间也比较长；而且大事务还会导致主从延迟。\n * 第三种方式（即：在 20 个连接中同时执行 delete from t limit 500），会人为造成锁冲突。",charsets:{cjk:!0},lastUpdated:"2023/05/22, 03:07:46",lastUpdatedTimestamp:1684724866e3},{title:"change buffer",frontmatter:{title:"change buffer",date:"2023-05-23T15:10:15.000Z",permalink:"/pages/02bb58/",categories:["中间件","MySQL","专栏：MySQL 实战 45 讲"],tags:[null]},regularPath:"/%E4%B8%AD%E9%97%B4%E4%BB%B6/06.MySQL/05.%E4%B8%93%E6%A0%8F%EF%BC%9AMySQL%20%E5%AE%9E%E6%88%98%2045%20%E8%AE%B2/06.change%20buffer.html",relativePath:"中间件/06.MySQL/05.专栏：MySQL 实战 45 讲/06.change buffer.md",key:"v-76fe5474",path:"/pages/02bb58/",headers:[{level:2,title:"1. 从问题切入",slug:"_1-从问题切入",normalizedTitle:"1. 从问题切入",charIndex:72},{level:3,title:"1.1 查询过程",slug:"_1-1-查询过程",normalizedTitle:"1.1 查询过程",charIndex:533},{level:3,title:"1.2 更新过程",slug:"_1-2-更新过程",normalizedTitle:"1.2 更新过程",charIndex:922},{level:2,title:"2. change buffer 的使用场景",slug:"_2-change-buffer-的使用场景",normalizedTitle:"2. change buffer 的使用场景",charIndex:2686},{level:2,title:"3. 普通索引和唯一索引应该怎么选？",slug:"_3-普通索引和唯一索引应该怎么选",normalizedTitle:"3. 普通索引和唯一索引应该怎么选？",charIndex:3238},{level:2,title:"4. change buffer 和 redo log",slug:"_4-change-buffer-和-redo-log",normalizedTitle:"4. change buffer 和 redo log",charIndex:3969},{level:2,title:"5. 小结",slug:"_5-小结",normalizedTitle:"5. 小结",charIndex:5311},{level:2,title:"QA",slug:"qa",normalizedTitle:"qa",charIndex:5462}],headersStr:"1. 从问题切入 1.1 查询过程 1.2 更新过程 2. change buffer 的使用场景 3. 普通索引和唯一索引应该怎么选？ 4. change buffer 和 redo log 5. 小结 QA",content:"> 参考：09 普通索引和唯一索引，应该怎么选择？| 极客时间\n\n这一章主要谈谈，在不同的业务场景下，应该选择普通索引，还是唯一索引？\n\n\n# 1. 从问题切入\n\n假设你在维护一个市民系统，每个人都有一个唯一的身份证号，而且业务代码已经保证了不会写入两个重复的身份证号。如果市民系统需要按照身份证号查姓名，就会执行类似这样的 SQL 语句：\n\nselect name from CUser where id_card = 'xxxxxxxyyyyyyzzzzz';\n\n\n1\n\n\n所以，你一定会考虑在 id_card 字段上建索引。由于身份证号字段比较大，我不建议你把身份证号当做主键，那么现在你有两个选择，要么给 id_card 字段创建唯一索引，要么创建一个普通索引。如果业务代码已经保证了不会写入重复的身份证号，那么这两个选择逻辑上都是正确的。\n\n现在我要问你的是，从性能的角度考虑，你选择唯一索引还是普通索引呢 ❓ 选择的依据是什么呢？\n\n为了方便描述，我们假设有一个主键列为 ID 的表，表中有字段 k，并且在 k 上有索引，而且 k 值不重复。那么这张表的索引组织结构如下：\n\n接下来，我们就从这两种索引对查询语句和更新语句的性能影响来进行分析。\n\n\n# 1.1 查询过程\n\n假设，执行查询的语句是 select id from T where k=5。这个查询语句在索引树上查找的过程，先是通过 B+ 树从树根开始，按层搜索到叶子节点，也就是图中右下角的这个数据页，然后可以认为数据页内部通过二分法来定位记录。\n\n * 对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录。\n * 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。\n\n那么，这个不同带来的性能差距会有多少呢？答案是，微乎其微。因为 InnoDB 的数据是按页为单位读写的，因此它以页为单位将整体读入内存，那么相邻记录的查找与判断的开销极小。而且恰好处于边缘情况导致换页的概率很低很低，可以忽略不计。所以，两种索引的查询过程的性能差距微乎其微。\n\n\n# 1.2 更新过程\n\n为了说明普通索引和唯一索引对更新语句性能的影响这个问题，我需要先跟你介绍一下 change buffer：\n\n当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InnoDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。\n\n> 需要说明的是，虽然名字叫作 change buffer，实际上它是可以持久化的数据。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上。\n\n将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作。\n\nchange buffer 可以提高性能的原因是：\n\n * 将更新操作先记录在 change buffer，从而减少读磁盘，语句的执行速度会得到明显的提升。\n * 数据读入内存是需要占用 buffer pool 的，所以使用这种方式让很多本需要加载数据到内存的操作不再需要占用内存，提高了内存利用率。\n\n那么，什么条件下可以使用 change buffer 呢❓？\n\n对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入 (4,400) 这个记录，就要先判断现在表中是否已经存在 k=4 的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 change buffer 了。\n\n因此，唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用。\n\n注意\n\nchange buffer 只能应用到非唯一的二级索引上，不适用于主键索引、空间索引、全文索引以及唯一索引。\n\nchange buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。\n\n现在，你已经理解了 change buffer 的机制，那么我们再一起来看看如果要在这张表中插入一个新记录 (4,400) 的话，InnoDB 的处理流程是怎样的：\n\n * 第一种情况是，这个记录要更新的目标页在内存中。这时，InnoDB 的处理流程如下：\n   * 对于唯一索引来说，找到 3 和 5 之间的位置，判断到没有冲突，插入这个值，语句执行结束；\n   * 对于普通索引来说，找到 3 和 5 之间的位置，插入这个值，语句执行结束。\n   * 这样看来，普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的 CPU 时间。\n * 第二种情况是，这个记录要更新的目标页不在内存中。这时，InnoDB 的处理流程如下：\n   * 对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束；\n   * 对于普通索引来说，则是将更新记录在 change buffer，语句执行就结束了。\n\n将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。change buffer 因为减少了随机磁盘访问，对更新性能的提升是会很明显的。可以看出，当所要插入的记录所在数据页不在内存中时，使用了 change buffer 的普通索引的情况将具有更好的性能。\n\n> 之前我就碰到过一件事儿，有个 DBA 的同学跟我反馈说，他负责的某个业务的库内存命中率突然从 99% 降低到了 75%，整个系统处于阻塞状态，更新语句全部堵住。而探究其原因后，我发现这个业务有大量插入数据的操作，而他在前一天把其中的某个普通索引改成了唯一索引。\n\n\n# 2. change buffer 的使用场景\n\n通过上面的分析，你已经清楚了使用 change buffer 对更新过程的加速作用，也清楚了 change buffer 只限于用在普通索引的场景下，而不适用于唯一索引。\n\n那么，现在有一个问题就是：普通索引的所有场景，使用 change buffer 都可以起到加速作用吗？\n\n因为 merge 的时候是真正进行数据更新的时刻，而 change buffer 的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做 merge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。\n\n因此，对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。\n\n反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。所以，对于这种业务模式来说，change buffer 反而起到了副作用。\n\n\n# 3. 普通索引和唯一索引应该怎么选？\n\n回到我们文章开头的问题，普通索引和唯一索引应该怎么选择。其实，这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。所以，我建议你尽量选择普通索引。\n\n如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭 change buffer。而在其他情况下，change buffer 都能提升更新性能。\n\n在实际使用中，你会发现，普通索引和 change buffer 的配合使用，对于数据量大的表的更新优化还是很明显的。\n\n特别地，在使用机械硬盘时，change buffer 这个机制的收效是非常显著的。所以，当你有一个类似“历史数据”的库，并且出于成本考虑用的是机械硬盘时，那你应该特别关注这些表里的索引，尽量使用普通索引，然后把 change buffer 尽量开大，以确保这个“历史数据”表的数据写入速度。\n\n关于实际中业务可能无法保证唯一性的情况\n * 首先，业务正确性优先。咱们这篇文章的前提是“业务代码已经保证不会写入重复数据”的情况下，讨论性能问题。如果业务不能保证，或者业务就是要求数据库来做约束，那么没得选，必须创建唯一索引。这种情况下，本篇文章的意义在于，如果碰上了大量插入数据慢、内存命中率低的时候，可以给你多提供一个排查思路。\n * 然后，在一些“归档库”的场景，你是可以考虑使用普通索引的。比如，线上数据只需要保留半年，然后历史数据保存在归档库。这时候，归档数据已经是确保没有唯一键冲突了。要提高归档效率，可以考虑把表里面的唯一索引改成普通索引。\n * 极客时间版权所有: https://time.geekbang.org/column/article/70848\n\n\n# 4. change buffer 和 redo log\n\n理解了 change buffer 的原理，你可能会联想到我在前面文章中和你介绍过的 redo log 和 WAL。\n\nWAL 提升性能的核心机制，也的确是尽量减少随机读写，这两个概念确实容易混淆。所以，这里我把它们放到了同一个流程里来说明，便于你区分这两个概念。\n\n现在，我们要在表上执行这个插入语句：\n\ninsert into t(id,k) values (id1,k1), (id2,k2);\n\n\n1\n\n\n这里，我们假设当前 k 索引树的状态，查找到位置后，k1 所在的数据页在内存 (InnoDB buffer pool) 中，k2 所在的数据页不在内存中。如下图是带 change buffer 的更新状态图：\n\n分析这条更新语句，你会发现它涉及了四个部分：内存、redo log（ib_log_fileX）、 数据表空间（t.ibd）、系统表空间（ibdata1）。\n\n> 系统表空间就是用来放系统信息的，比如数据字典什么的，对应的磁盘文件是 ibdata1, 数据表空间就是一个个的表数据文件，对应的磁盘文件就是 表名.ibd。\n\n这条更新语句做了如下的操作（按照图中的数字顺序）：\n\n 1. Page 1 在内存中，直接更新内存；\n 2. Page 2 没有在内存中，就在内存的 change buffer 区域，记录下“我要往 Page 2 插入一行”这个信息\n 3. 将上述两个动作记入 redo log 中（图中 3 和 4）。\n\n做完上面这些，事务就可以完成了。所以，你会看到，执行这条更新语句的成本很低，就是写了两处内存，然后写了一处磁盘（两次操作合在一起写了一次磁盘），而且还是顺序写的。同时，图中的两个虚线箭头，是后台操作，不影响更新的响应时间。\n\n那在这之后的读请求，要怎么处理呢？\n\n比如，我们现在要执行 select * from t where k in (k1, k2)。这里，我画了这两个读请求的流程图。\n\n如果读语句发生在更新语句后不久，内存中的数据都还在，那么此时的这两个读操作就与系统表空间（ibdata1）和 redo log（ib_log_fileX）无关了。所以，我在图中就没画出这两部分：\n\n从图中可以看到：\n\n 1. 读 Page 1 的时候，直接从内存返回。有几位同学在前面文章的评论中问到，WAL 之后如果读数据，是不是一定要读盘，是不是一定要从 redo log 里面把数据更新以后才可以返回？其实是不用的。你可以看一下图 3 的这个状态，虽然磁盘上还是之前的数据，但是这里直接从内存返回结果，结果是正确的。\n 2. 要读 Page 2 的时候，需要把 Page 2 从磁盘读入内存中，然后应用 change buffer 里面的操作日志，生成一个正确的版本并返回结果。\n\n可以看到，直到需要读 Page 2 的时候，这个数据页才会被读入内存。\n\n所以，如果要简单地对比这两个机制在提升更新性能上的收益的话，redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。\n\n\n# 5. 小结\n\n今天从普通索引和唯一索引的选择开始，分享了数据的查询和更新过程，然后说明了 change buffer 的机制以及应用场景，最后讲到了索引选择的实践。\n\n由于唯一索引用不上 change buffer 的优化机制，因此如果业务可以接受，从性能角度出发我建议你优先考虑非唯一索引。\n\n\n# QA\n\nQ：change buffer 一开始是写内存的，那么如果这个时候机器掉电重启，会不会导致 change buffer 丢失呢？change buffer 丢失可不是小事儿，再从磁盘读入数据可就没有了 merge 过程，就等于是数据丢失了。会不会出现这种情况呢？",normalizedContent:"> 参考：09 普通索引和唯一索引，应该怎么选择？| 极客时间\n\n这一章主要谈谈，在不同的业务场景下，应该选择普通索引，还是唯一索引？\n\n\n# 1. 从问题切入\n\n假设你在维护一个市民系统，每个人都有一个唯一的身份证号，而且业务代码已经保证了不会写入两个重复的身份证号。如果市民系统需要按照身份证号查姓名，就会执行类似这样的 sql 语句：\n\nselect name from cuser where id_card = 'xxxxxxxyyyyyyzzzzz';\n\n\n1\n\n\n所以，你一定会考虑在 id_card 字段上建索引。由于身份证号字段比较大，我不建议你把身份证号当做主键，那么现在你有两个选择，要么给 id_card 字段创建唯一索引，要么创建一个普通索引。如果业务代码已经保证了不会写入重复的身份证号，那么这两个选择逻辑上都是正确的。\n\n现在我要问你的是，从性能的角度考虑，你选择唯一索引还是普通索引呢 ❓ 选择的依据是什么呢？\n\n为了方便描述，我们假设有一个主键列为 id 的表，表中有字段 k，并且在 k 上有索引，而且 k 值不重复。那么这张表的索引组织结构如下：\n\n接下来，我们就从这两种索引对查询语句和更新语句的性能影响来进行分析。\n\n\n# 1.1 查询过程\n\n假设，执行查询的语句是 select id from t where k=5。这个查询语句在索引树上查找的过程，先是通过 b+ 树从树根开始，按层搜索到叶子节点，也就是图中右下角的这个数据页，然后可以认为数据页内部通过二分法来定位记录。\n\n * 对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录。\n * 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。\n\n那么，这个不同带来的性能差距会有多少呢？答案是，微乎其微。因为 innodb 的数据是按页为单位读写的，因此它以页为单位将整体读入内存，那么相邻记录的查找与判断的开销极小。而且恰好处于边缘情况导致换页的概率很低很低，可以忽略不计。所以，两种索引的查询过程的性能差距微乎其微。\n\n\n# 1.2 更新过程\n\n为了说明普通索引和唯一索引对更新语句性能的影响这个问题，我需要先跟你介绍一下 change buffer：\n\n当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，innodb 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。\n\n> 需要说明的是，虽然名字叫作 change buffer，实际上它是可以持久化的数据。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上。\n\n将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作。\n\nchange buffer 可以提高性能的原因是：\n\n * 将更新操作先记录在 change buffer，从而减少读磁盘，语句的执行速度会得到明显的提升。\n * 数据读入内存是需要占用 buffer pool 的，所以使用这种方式让很多本需要加载数据到内存的操作不再需要占用内存，提高了内存利用率。\n\n那么，什么条件下可以使用 change buffer 呢❓？\n\n对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入 (4,400) 这个记录，就要先判断现在表中是否已经存在 k=4 的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 change buffer 了。\n\n因此，唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用。\n\n注意\n\nchange buffer 只能应用到非唯一的二级索引上，不适用于主键索引、空间索引、全文索引以及唯一索引。\n\nchange buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。\n\n现在，你已经理解了 change buffer 的机制，那么我们再一起来看看如果要在这张表中插入一个新记录 (4,400) 的话，innodb 的处理流程是怎样的：\n\n * 第一种情况是，这个记录要更新的目标页在内存中。这时，innodb 的处理流程如下：\n   * 对于唯一索引来说，找到 3 和 5 之间的位置，判断到没有冲突，插入这个值，语句执行结束；\n   * 对于普通索引来说，找到 3 和 5 之间的位置，插入这个值，语句执行结束。\n   * 这样看来，普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的 cpu 时间。\n * 第二种情况是，这个记录要更新的目标页不在内存中。这时，innodb 的处理流程如下：\n   * 对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束；\n   * 对于普通索引来说，则是将更新记录在 change buffer，语句执行就结束了。\n\n将数据从磁盘读入内存涉及随机 io 的访问，是数据库里面成本最高的操作之一。change buffer 因为减少了随机磁盘访问，对更新性能的提升是会很明显的。可以看出，当所要插入的记录所在数据页不在内存中时，使用了 change buffer 的普通索引的情况将具有更好的性能。\n\n> 之前我就碰到过一件事儿，有个 dba 的同学跟我反馈说，他负责的某个业务的库内存命中率突然从 99% 降低到了 75%，整个系统处于阻塞状态，更新语句全部堵住。而探究其原因后，我发现这个业务有大量插入数据的操作，而他在前一天把其中的某个普通索引改成了唯一索引。\n\n\n# 2. change buffer 的使用场景\n\n通过上面的分析，你已经清楚了使用 change buffer 对更新过程的加速作用，也清楚了 change buffer 只限于用在普通索引的场景下，而不适用于唯一索引。\n\n那么，现在有一个问题就是：普通索引的所有场景，使用 change buffer 都可以起到加速作用吗？\n\n因为 merge 的时候是真正进行数据更新的时刻，而 change buffer 的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做 merge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。\n\n因此，对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。\n\n反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。这样随机访问 io 的次数不会减少，反而增加了 change buffer 的维护代价。所以，对于这种业务模式来说，change buffer 反而起到了副作用。\n\n\n# 3. 普通索引和唯一索引应该怎么选？\n\n回到我们文章开头的问题，普通索引和唯一索引应该怎么选择。其实，这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。所以，我建议你尽量选择普通索引。\n\n如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭 change buffer。而在其他情况下，change buffer 都能提升更新性能。\n\n在实际使用中，你会发现，普通索引和 change buffer 的配合使用，对于数据量大的表的更新优化还是很明显的。\n\n特别地，在使用机械硬盘时，change buffer 这个机制的收效是非常显著的。所以，当你有一个类似“历史数据”的库，并且出于成本考虑用的是机械硬盘时，那你应该特别关注这些表里的索引，尽量使用普通索引，然后把 change buffer 尽量开大，以确保这个“历史数据”表的数据写入速度。\n\n关于实际中业务可能无法保证唯一性的情况\n * 首先，业务正确性优先。咱们这篇文章的前提是“业务代码已经保证不会写入重复数据”的情况下，讨论性能问题。如果业务不能保证，或者业务就是要求数据库来做约束，那么没得选，必须创建唯一索引。这种情况下，本篇文章的意义在于，如果碰上了大量插入数据慢、内存命中率低的时候，可以给你多提供一个排查思路。\n * 然后，在一些“归档库”的场景，你是可以考虑使用普通索引的。比如，线上数据只需要保留半年，然后历史数据保存在归档库。这时候，归档数据已经是确保没有唯一键冲突了。要提高归档效率，可以考虑把表里面的唯一索引改成普通索引。\n * 极客时间版权所有: https://time.geekbang.org/column/article/70848\n\n\n# 4. change buffer 和 redo log\n\n理解了 change buffer 的原理，你可能会联想到我在前面文章中和你介绍过的 redo log 和 wal。\n\nwal 提升性能的核心机制，也的确是尽量减少随机读写，这两个概念确实容易混淆。所以，这里我把它们放到了同一个流程里来说明，便于你区分这两个概念。\n\n现在，我们要在表上执行这个插入语句：\n\ninsert into t(id,k) values (id1,k1), (id2,k2);\n\n\n1\n\n\n这里，我们假设当前 k 索引树的状态，查找到位置后，k1 所在的数据页在内存 (innodb buffer pool) 中，k2 所在的数据页不在内存中。如下图是带 change buffer 的更新状态图：\n\n分析这条更新语句，你会发现它涉及了四个部分：内存、redo log（ib_log_filex）、 数据表空间（t.ibd）、系统表空间（ibdata1）。\n\n> 系统表空间就是用来放系统信息的，比如数据字典什么的，对应的磁盘文件是 ibdata1, 数据表空间就是一个个的表数据文件，对应的磁盘文件就是 表名.ibd。\n\n这条更新语句做了如下的操作（按照图中的数字顺序）：\n\n 1. page 1 在内存中，直接更新内存；\n 2. page 2 没有在内存中，就在内存的 change buffer 区域，记录下“我要往 page 2 插入一行”这个信息\n 3. 将上述两个动作记入 redo log 中（图中 3 和 4）。\n\n做完上面这些，事务就可以完成了。所以，你会看到，执行这条更新语句的成本很低，就是写了两处内存，然后写了一处磁盘（两次操作合在一起写了一次磁盘），而且还是顺序写的。同时，图中的两个虚线箭头，是后台操作，不影响更新的响应时间。\n\n那在这之后的读请求，要怎么处理呢？\n\n比如，我们现在要执行 select * from t where k in (k1, k2)。这里，我画了这两个读请求的流程图。\n\n如果读语句发生在更新语句后不久，内存中的数据都还在，那么此时的这两个读操作就与系统表空间（ibdata1）和 redo log（ib_log_filex）无关了。所以，我在图中就没画出这两部分：\n\n从图中可以看到：\n\n 1. 读 page 1 的时候，直接从内存返回。有几位同学在前面文章的评论中问到，wal 之后如果读数据，是不是一定要读盘，是不是一定要从 redo log 里面把数据更新以后才可以返回？其实是不用的。你可以看一下图 3 的这个状态，虽然磁盘上还是之前的数据，但是这里直接从内存返回结果，结果是正确的。\n 2. 要读 page 2 的时候，需要把 page 2 从磁盘读入内存中，然后应用 change buffer 里面的操作日志，生成一个正确的版本并返回结果。\n\n可以看到，直到需要读 page 2 的时候，这个数据页才会被读入内存。\n\n所以，如果要简单地对比这两个机制在提升更新性能上的收益的话，redo log 主要节省的是随机写磁盘的 io 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 io 消耗。\n\n\n# 5. 小结\n\n今天从普通索引和唯一索引的选择开始，分享了数据的查询和更新过程，然后说明了 change buffer 的机制以及应用场景，最后讲到了索引选择的实践。\n\n由于唯一索引用不上 change buffer 的优化机制，因此如果业务可以接受，从性能角度出发我建议你优先考虑非唯一索引。\n\n\n# qa\n\nq：change buffer 一开始是写内存的，那么如果这个时候机器掉电重启，会不会导致 change buffer 丢失呢？change buffer 丢失可不是小事儿，再从磁盘读入数据可就没有了 merge 过程，就等于是数据丢失了。会不会出现这种情况呢？",charsets:{cjk:!0},lastUpdated:"2023/05/23, 08:32:03",lastUpdatedTimestamp:1684830723e3},{title:"MySQL为什么有时候会加错索引",frontmatter:{title:"MySQL为什么有时候会加错索引",date:"2023-05-25T16:56:52.000Z",permalink:"/pages/c4cff3/",categories:["中间件","MySQL","专栏：MySQL 实战 45 讲"],tags:[null]},regularPath:"/%E4%B8%AD%E9%97%B4%E4%BB%B6/06.MySQL/05.%E4%B8%93%E6%A0%8F%EF%BC%9AMySQL%20%E5%AE%9E%E6%88%98%2045%20%E8%AE%B2/07.MySQL%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89%E6%97%B6%E5%80%99%E4%BC%9A%E5%8A%A0%E9%94%99%E7%B4%A2%E5%BC%95.html",relativePath:"中间件/06.MySQL/05.专栏：MySQL 实战 45 讲/07.MySQL为什么有时候会加错索引.md",key:"v-24aa3866",path:"/pages/c4cff3/",headersStr:null,content:"> 参考：10 MySQL为什么有时候会选错索引？| 极客时间 其实本文没有解释很多原理，本文的初衷只是分享了几个解决方法，或许可以在碰到类似情况的时候，有一些思路。\n\n我们知道在 MySQL 中，一张表是可以支持多个索引的，但我们的 SQL 语句并不会主动指定使用哪个索引，也就是说，使用哪个索引时由 MySQL 来确定的。\n\n不过有时候我们可能碰到这样的情况：一条本来可以执行得很快的语句，却由于 MySQL 选错了索引，而导致执行速度变得很慢。\n\n下面看一个例子。我们建一个简单的表，有 a、b 两个字段，并分别建立索引：\n\nCREATE TABLE `t` (\n  `id` int(11) NOT NULL AUTO_INCREMENT,\n  `a` int(11) DEFAULT NULL,\n  `b` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `a` (`a`),\n  KEY `b` (`b`)\n) ENGINE=InnoDB;\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n然后，我们往表 t 中插入 10 万行记录，取值按整数递增，即：(1,1,1)，(2,2,2)，(3,3,3) 直到 (100000,100000,100000)。如下是使用存储过程来实现这个插入数据的逻辑的：\n\ndelimiter ;;\ncreate procedure idata()\nbegin\n  declare i int;\n  set i=1;\n  while(i<=100000)do\n    insert into t values(i, i, i);\n    set i=i+1;\n  end while;\nend;;\ndelimiter ;\ncall idata();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n接下来，我们分析一条 SQL 语句：\n\nmysql> select * from t where a between 10000 and 20000;\n\n\n1\n\n\n你一定会说，这个语句还用分析吗，很简单呀，a 上有索引，肯定是要使用索引 a 的。没错，图 1 显示的就是使用 explain 命令看到的这条语句的执行情况。\n\n图 1 使用 explain 命令查看语句执行情况\n\n从图 1 看上去，这条查询语句的执行也确实符合预期，key 这个字段值是’a’，表示优化器选择了索引 a。",normalizedContent:"> 参考：10 mysql为什么有时候会选错索引？| 极客时间 其实本文没有解释很多原理，本文的初衷只是分享了几个解决方法，或许可以在碰到类似情况的时候，有一些思路。\n\n我们知道在 mysql 中，一张表是可以支持多个索引的，但我们的 sql 语句并不会主动指定使用哪个索引，也就是说，使用哪个索引时由 mysql 来确定的。\n\n不过有时候我们可能碰到这样的情况：一条本来可以执行得很快的语句，却由于 mysql 选错了索引，而导致执行速度变得很慢。\n\n下面看一个例子。我们建一个简单的表，有 a、b 两个字段，并分别建立索引：\n\ncreate table `t` (\n  `id` int(11) not null auto_increment,\n  `a` int(11) default null,\n  `b` int(11) default null,\n  primary key (`id`),\n  key `a` (`a`),\n  key `b` (`b`)\n) engine=innodb;\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n然后，我们往表 t 中插入 10 万行记录，取值按整数递增，即：(1,1,1)，(2,2,2)，(3,3,3) 直到 (100000,100000,100000)。如下是使用存储过程来实现这个插入数据的逻辑的：\n\ndelimiter ;;\ncreate procedure idata()\nbegin\n  declare i int;\n  set i=1;\n  while(i<=100000)do\n    insert into t values(i, i, i);\n    set i=i+1;\n  end while;\nend;;\ndelimiter ;\ncall idata();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n接下来，我们分析一条 sql 语句：\n\nmysql> select * from t where a between 10000 and 20000;\n\n\n1\n\n\n你一定会说，这个语句还用分析吗，很简单呀，a 上有索引，肯定是要使用索引 a 的。没错，图 1 显示的就是使用 explain 命令看到的这条语句的执行情况。\n\n图 1 使用 explain 命令查看语句执行情况\n\n从图 1 看上去，这条查询语句的执行也确实符合预期，key 这个字段值是’a’，表示优化器选择了索引 a。",charsets:{cjk:!0},lastUpdated:"2023/05/25, 09:07:23",lastUpdatedTimestamp:1685005643e3},{title:"怎么给字符串字段加索引",frontmatter:{title:"怎么给字符串字段加索引",date:"2023-05-29T14:35:09.000Z",permalink:"/pages/fa9ec1/",categories:["中间件","MySQL","专栏：MySQL 实战 45 讲"],tags:[null]},regularPath:"/%E4%B8%AD%E9%97%B4%E4%BB%B6/06.MySQL/05.%E4%B8%93%E6%A0%8F%EF%BC%9AMySQL%20%E5%AE%9E%E6%88%98%2045%20%E8%AE%B2/08.%E6%80%8E%E4%B9%88%E7%BB%99%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%AD%97%E6%AE%B5%E5%8A%A0%E7%B4%A2%E5%BC%95.html",relativePath:"中间件/06.MySQL/05.专栏：MySQL 实战 45 讲/08.怎么给字符串字段加索引.md",key:"v-18bc1557",path:"/pages/fa9ec1/",headers:[{level:2,title:"1. 怎么给字符串字段加索引？",slug:"_1-怎么给字符串字段加索引",normalizedTitle:"1. 怎么给字符串字段加索引？",charIndex:31},{level:3,title:"1.1 前缀索引的使用",slug:"_1-1-前缀索引的使用",normalizedTitle:"1.1 前缀索引的使用",charIndex:102},{level:3,title:"1.2 前缀索引对覆盖索引的影响",slug:"_1-2-前缀索引对覆盖索引的影响",normalizedTitle:"1.2 前缀索引对覆盖索引的影响",charIndex:2394},{level:3,title:"1.3 其他方式",slug:"_1-3-其他方式",normalizedTitle:"1.3 其他方式",charIndex:2992},{level:3,title:"1.4 小结",slug:"_1-4-小结",normalizedTitle:"1.4 小结",charIndex:4537}],headersStr:"1. 怎么给字符串字段加索引？ 1.1 前缀索引的使用 1.2 前缀索引对覆盖索引的影响 1.3 其他方式 1.4 小结",content:"> 参考：11 怎么给字符串字段加索引？| 极客时间\n\n\n# 1. 怎么给字符串字段加索引？\n\n现在，几乎所有的系统都支持邮箱登录，如何在邮箱这样的字段上建立合理的索引，是我们今天要讨论的问题。\n\n\n# 1.1 前缀索引的使用\n\n假设，你现在维护一个支持邮箱登录的系统，用户表是这么定义的：\n\ncreate table SUser(\n    ID bigint unsigned primary key,\n    email varchar(64), \n    ... \n) engine=innodb;\n\n\n1\n2\n3\n4\n5\n\n\n由于要使用邮箱登录，所以业务代码中一定会出现类似于这样的语句：\n\nselect f1, f2 from SUser where email='xxx';\n\n\n1\n\n\n我们可以知道，如果 email 这个字段上没有索引，那么这个语句就只能做全表扫描。\n\n同时，MySQL 是支持前缀索引的，也就是说，你可以定义字符串的一部分作为索引。默认地，如果你创建索引的语句不指定前缀长度，那么索引就会包含整个字符串。\n\n比如，这两个在 email 字段上创建索引的语句：\n\nmysql> alter table SUser add index index1(email);\n或\nmysql> alter table SUser add index index2(email(6));\n\n\n1\n2\n3\n\n * 第一个语句创建的 index1 索引里面，包含了每个记录的整个字符串；\n * 第二个语句创建的 index2 索引里面，对于每个记录都是只取前 6 个字节。\n\n那么，这两种不同的定义在数据结构和存储上有什么区别呢？如下图 1 和 2 就是这两个索引的示意图：\n\n图 1 email 索引结构 图 2 email(6) 索引结构\n\n从图中你可以看到，由于 email(6) 这个索引结构中每个邮箱字段都只取前 6 个字节（即：zhangs），所以索引占用的空间会更小，这就是使用前缀索引的优势。但，这同时带来的损失是，可能会增加额外的记录扫描次数。\n\n接下来，我们再看看下面这个语句，在这两个索引定义下分别是怎么执行下面这条 SQL 的：\n\nselect id,name,email from SUser where email='zhangssxyz@xxx.com';\n\n\n1\n\n * 如果使用的是 index1（即 email 整个字符串的索引结构），执行顺序是这样的：\n   1. 从 index1 索引树找到满足索引值是 zhangssxyz@xxx.com 的这条记录，取得 ID2 的值；\n   2. 到主键上查到主键值是 ID2 的行，判断 email 的值是正确的，将这行记录加入结果集；\n   3. 取 index1 索引树上刚刚查到的位置的下一条记录，发现已经不满足 email='zhangssxyz@xxx.com' 的条件了，循环结束。\n\n这个过程中，只需要回主键索引取一次数据，所以系统认为只扫描了一行。\n\n * 如果使用的是 index2（即 email(6) 索引结构），执行顺序是这样的：\n   1. 从 index2 索引树找到满足索引值是’zhangs’的记录，找到的第一个是 ID1；\n   2. 到主键上查到主键值是 ID1 的行，判断出 email 的值不是 zhangssxyz@xxx.com，这行记录丢弃；\n   3. 取 index2 上刚刚查到的位置的下一条记录，发现仍然是’zhangs’，取出 ID2，再到 ID 索引上取整行然后判断，这次值对了，将这行记录加入结果集；\n   4. 重复上一步，直到在 idxe2 上取到的值不是’zhangs’时，循环结束。\n\n在这个过程中，要回主键索引取 4 次数据，也就是扫描了 4 行。通过这个对比，你很容易就可以发现，使用前缀索引后，可能会导致查询语句读数据的次数变多。\n\n但是，对于这个查询语句来说，如果你定义的 index2 不是 email(6) 而是 email(7)，也就是说取 email 字段的前 7 个字节来构建索引的话，即满足前缀’zhangss’的记录只有一个，也能够直接查到 ID2，只扫描一行就结束了。\n\n也就是说使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。\n\n于是，你就有个问题：当要给字符串创建前缀索引时，有什么方法能够确定我应该使用多长的前缀呢？❓\n\n实际上，我们在建立索引时关注的是区分度，区分度越高越好。因为区分度越高，意味着重复的键值越少。因此，我们可以通过统计索引上有多少个不同的值来判断要使用多长的前缀。\n\n首先，你可以使用下面这个语句，算出这个列上有多少个不同的值：\n\nselect count(distinct email) as L from SUser;\n\n\n1\n\n\n然后，依次选取不同长度的前缀来看这个值，比如我们要看一下 4~7 个字节的前缀索引，可以用这个语句：\n\nselect \n  count(distinct left(email,4)）as L4,\n  count(distinct left(email,5)）as L5,\n  count(distinct left(email,6)）as L6,\n  count(distinct left(email,7)）as L7,\nfrom SUser;\n\n\n1\n2\n3\n4\n5\n6\n\n\n当然，使用前缀索引很可能会损失区分度，所以你需要预先设定一个可以接受的损失比例，比如 5%。然后，在返回的 L4~L7 中，找出不小于 L * 95% 的值，假设这里 L6、L7 都满足，你就可以选择前缀长度为 6。\n\n\n# 1.2 前缀索引对覆盖索引的影响\n\n前面我们说了使用前缀索引可能会增加扫描行数，这会影响到性能。其实，前缀索引的影响不止如此，我们再看一下另外一个场景。\n\n你先来看看这个 SQL 语句：\n\nselect id,email from SUser where email='zhangssxyz@xxx.com';\n\n\n1\n\n\n与前面例子中的 SQL 语句\n\nselect id,name,email from SUser where email='zhangssxyz@xxx.com';\n\n\n1\n\n\n相比，这个语句只要求返回 id 和 email 字段。\n\n所以，如果使用 index1（即 email 整个字符串的索引结构）的话，可以利用覆盖索引，从 index1 查到结果后直接就返回了，不需要回到 ID 索引再去查一次。而如果使用 index2（即 email(6) 索引结构）的话，就不得不回到 ID 索引再去判断 email 字段的值。\n\n> 即使你将 index2 的定义修改为 email(18) 的前缀索引，这时候虽然 index2 已经包含了所有的信息，但 InnoDB 还是要回到 id 索引再查一下，因为系统并不确定前缀索引的定义是否截断了完整信息。\n\n也就是说，使用前缀索引就用不上覆盖索引对查询性能的优化了，这也是你在选择是否使用前缀索引时需要考虑的一个因素。\n\n\n# 1.3 其他方式\n\n对于类似于邮箱这样的字段来说，使用前缀索引的效果可能还不错。但是，遇到前缀的区分度不够好的情况时，我们要怎么办呢？\n\n比如，我们国家的身份证号，一共 18 位，其中前 6 位是地址码，所以同一个县的人的身份证号前 6 位一般会是相同的。\n\n假设你维护的数据库是一个市的公民信息系统，这时候如果对身份证号做长度为 6 的前缀索引的话，这个索引的区分度就非常低了。按照我们前面说的方法，可能你需要创建长度为 12 以上的前缀索引，才能够满足区分度要求。但是，索引选取的越长，占用的磁盘空间就越大，相同的数据页能放下的索引值就越少，搜索的效率也就会越低。\n\n那么，如果我们能够确定业务需求里面只有按照身份证进行等值查询的需求，还有没有别的处理方法呢？这种方法，既可以占用更小的空间，也能达到相同的查询效率。答案是，有的。\n\n第一种方式是使用倒序存储。如果你存储身份证号的时候把它倒过来存，每次查询的时候，你可以这么写：\n\nselect field_list from t where id_card = reverse('input_id_card_string');\n\n\n1\n\n\n由于身份证号的最后 6 位没有地址码这样的重复逻辑，所以最后这 6 位很可能就提供了足够的区分度。当然了，实践中你不要忘记使用 count(distinct) 方法去做个验证。\n\n第二种方式是使用 hash 字段。你可以在表上再创建一个整数字段，来保存身份证的校验码，同时在这个字段上创建索引。\n\nalter table t add id_card_crc int unsigned, add index(id_card_crc);\n\n\n1\n\n\n然后每次插入新记录的时候，都同时用 crc32() 这个函数得到校验码填到这个新字段。由于校验码可能存在冲突，也就是说两个不同的身份证号通过 crc32() 函数得到的结果可能是相同的，所以你的查询语句 where 部分要判断 id_card 的值是否精确相同。\n\nselect field_list from t where id_card_crc=crc32('input_id_card_string') and id_card='input_id_card_string'\n\n\n1\n\n\n这样，索引的长度变成了 4 个字节，比原来小了很多。\n\n接下来，我们再一起看看使用倒序存储和使用 hash 字段这两种方法的异同点。\n\n * 相同点是，都不支持范围查询。倒序存储的字段上创建的索引是按照倒序字符串的方式排序的，已经没有办法利用索引方式查出身份证号码在[ID_X, ID_Y]的所有市民了。同样地，hash 字段的方式也只能支持等值查询。\n * 区别主要体现在以下三个方面：\n   * 从占用的额外空间来看，倒序存储方式在主键索引上，不会消耗额外的存储空间，而 hash 字段方法需要增加一个字段。当然，倒序存储方式使用 4 个字节的前缀长度应该是不够的，如果再长一点，这个消耗跟额外这个 hash 字段也差不多抵消了。\n   * 在 CPU 消耗方面，倒序方式每次写和读的时候，都需要额外调用一次 reverse 函数，而 hash 字段的方式需要额外调用一次 crc32() 函数。如果只从这两个函数的计算复杂度来看的话，reverse 函数额外消耗的 CPU 资源会更小些。\n   * 从查询效率上看，使用 hash 字段方式的查询性能相对更稳定一些。因为 crc32 算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近 1。而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。\n\n\n# 1.4 小结\n\n总结一下给字符串的字段创建索引的方式：\n\n * 直接创建完整索引，这样可能比较占用空间；\n * 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；\n * 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；\n * 创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。\n\n在实际应用中，你要根据业务字段的特点选择使用哪种方式。",normalizedContent:"> 参考：11 怎么给字符串字段加索引？| 极客时间\n\n\n# 1. 怎么给字符串字段加索引？\n\n现在，几乎所有的系统都支持邮箱登录，如何在邮箱这样的字段上建立合理的索引，是我们今天要讨论的问题。\n\n\n# 1.1 前缀索引的使用\n\n假设，你现在维护一个支持邮箱登录的系统，用户表是这么定义的：\n\ncreate table suser(\n    id bigint unsigned primary key,\n    email varchar(64), \n    ... \n) engine=innodb;\n\n\n1\n2\n3\n4\n5\n\n\n由于要使用邮箱登录，所以业务代码中一定会出现类似于这样的语句：\n\nselect f1, f2 from suser where email='xxx';\n\n\n1\n\n\n我们可以知道，如果 email 这个字段上没有索引，那么这个语句就只能做全表扫描。\n\n同时，mysql 是支持前缀索引的，也就是说，你可以定义字符串的一部分作为索引。默认地，如果你创建索引的语句不指定前缀长度，那么索引就会包含整个字符串。\n\n比如，这两个在 email 字段上创建索引的语句：\n\nmysql> alter table suser add index index1(email);\n或\nmysql> alter table suser add index index2(email(6));\n\n\n1\n2\n3\n\n * 第一个语句创建的 index1 索引里面，包含了每个记录的整个字符串；\n * 第二个语句创建的 index2 索引里面，对于每个记录都是只取前 6 个字节。\n\n那么，这两种不同的定义在数据结构和存储上有什么区别呢？如下图 1 和 2 就是这两个索引的示意图：\n\n图 1 email 索引结构 图 2 email(6) 索引结构\n\n从图中你可以看到，由于 email(6) 这个索引结构中每个邮箱字段都只取前 6 个字节（即：zhangs），所以索引占用的空间会更小，这就是使用前缀索引的优势。但，这同时带来的损失是，可能会增加额外的记录扫描次数。\n\n接下来，我们再看看下面这个语句，在这两个索引定义下分别是怎么执行下面这条 sql 的：\n\nselect id,name,email from suser where email='zhangssxyz@xxx.com';\n\n\n1\n\n * 如果使用的是 index1（即 email 整个字符串的索引结构），执行顺序是这样的：\n   1. 从 index1 索引树找到满足索引值是 zhangssxyz@xxx.com 的这条记录，取得 id2 的值；\n   2. 到主键上查到主键值是 id2 的行，判断 email 的值是正确的，将这行记录加入结果集；\n   3. 取 index1 索引树上刚刚查到的位置的下一条记录，发现已经不满足 email='zhangssxyz@xxx.com' 的条件了，循环结束。\n\n这个过程中，只需要回主键索引取一次数据，所以系统认为只扫描了一行。\n\n * 如果使用的是 index2（即 email(6) 索引结构），执行顺序是这样的：\n   1. 从 index2 索引树找到满足索引值是’zhangs’的记录，找到的第一个是 id1；\n   2. 到主键上查到主键值是 id1 的行，判断出 email 的值不是 zhangssxyz@xxx.com，这行记录丢弃；\n   3. 取 index2 上刚刚查到的位置的下一条记录，发现仍然是’zhangs’，取出 id2，再到 id 索引上取整行然后判断，这次值对了，将这行记录加入结果集；\n   4. 重复上一步，直到在 idxe2 上取到的值不是’zhangs’时，循环结束。\n\n在这个过程中，要回主键索引取 4 次数据，也就是扫描了 4 行。通过这个对比，你很容易就可以发现，使用前缀索引后，可能会导致查询语句读数据的次数变多。\n\n但是，对于这个查询语句来说，如果你定义的 index2 不是 email(6) 而是 email(7)，也就是说取 email 字段的前 7 个字节来构建索引的话，即满足前缀’zhangss’的记录只有一个，也能够直接查到 id2，只扫描一行就结束了。\n\n也就是说使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。\n\n于是，你就有个问题：当要给字符串创建前缀索引时，有什么方法能够确定我应该使用多长的前缀呢？❓\n\n实际上，我们在建立索引时关注的是区分度，区分度越高越好。因为区分度越高，意味着重复的键值越少。因此，我们可以通过统计索引上有多少个不同的值来判断要使用多长的前缀。\n\n首先，你可以使用下面这个语句，算出这个列上有多少个不同的值：\n\nselect count(distinct email) as l from suser;\n\n\n1\n\n\n然后，依次选取不同长度的前缀来看这个值，比如我们要看一下 4~7 个字节的前缀索引，可以用这个语句：\n\nselect \n  count(distinct left(email,4)）as l4,\n  count(distinct left(email,5)）as l5,\n  count(distinct left(email,6)）as l6,\n  count(distinct left(email,7)）as l7,\nfrom suser;\n\n\n1\n2\n3\n4\n5\n6\n\n\n当然，使用前缀索引很可能会损失区分度，所以你需要预先设定一个可以接受的损失比例，比如 5%。然后，在返回的 l4~l7 中，找出不小于 l * 95% 的值，假设这里 l6、l7 都满足，你就可以选择前缀长度为 6。\n\n\n# 1.2 前缀索引对覆盖索引的影响\n\n前面我们说了使用前缀索引可能会增加扫描行数，这会影响到性能。其实，前缀索引的影响不止如此，我们再看一下另外一个场景。\n\n你先来看看这个 sql 语句：\n\nselect id,email from suser where email='zhangssxyz@xxx.com';\n\n\n1\n\n\n与前面例子中的 sql 语句\n\nselect id,name,email from suser where email='zhangssxyz@xxx.com';\n\n\n1\n\n\n相比，这个语句只要求返回 id 和 email 字段。\n\n所以，如果使用 index1（即 email 整个字符串的索引结构）的话，可以利用覆盖索引，从 index1 查到结果后直接就返回了，不需要回到 id 索引再去查一次。而如果使用 index2（即 email(6) 索引结构）的话，就不得不回到 id 索引再去判断 email 字段的值。\n\n> 即使你将 index2 的定义修改为 email(18) 的前缀索引，这时候虽然 index2 已经包含了所有的信息，但 innodb 还是要回到 id 索引再查一下，因为系统并不确定前缀索引的定义是否截断了完整信息。\n\n也就是说，使用前缀索引就用不上覆盖索引对查询性能的优化了，这也是你在选择是否使用前缀索引时需要考虑的一个因素。\n\n\n# 1.3 其他方式\n\n对于类似于邮箱这样的字段来说，使用前缀索引的效果可能还不错。但是，遇到前缀的区分度不够好的情况时，我们要怎么办呢？\n\n比如，我们国家的身份证号，一共 18 位，其中前 6 位是地址码，所以同一个县的人的身份证号前 6 位一般会是相同的。\n\n假设你维护的数据库是一个市的公民信息系统，这时候如果对身份证号做长度为 6 的前缀索引的话，这个索引的区分度就非常低了。按照我们前面说的方法，可能你需要创建长度为 12 以上的前缀索引，才能够满足区分度要求。但是，索引选取的越长，占用的磁盘空间就越大，相同的数据页能放下的索引值就越少，搜索的效率也就会越低。\n\n那么，如果我们能够确定业务需求里面只有按照身份证进行等值查询的需求，还有没有别的处理方法呢？这种方法，既可以占用更小的空间，也能达到相同的查询效率。答案是，有的。\n\n第一种方式是使用倒序存储。如果你存储身份证号的时候把它倒过来存，每次查询的时候，你可以这么写：\n\nselect field_list from t where id_card = reverse('input_id_card_string');\n\n\n1\n\n\n由于身份证号的最后 6 位没有地址码这样的重复逻辑，所以最后这 6 位很可能就提供了足够的区分度。当然了，实践中你不要忘记使用 count(distinct) 方法去做个验证。\n\n第二种方式是使用 hash 字段。你可以在表上再创建一个整数字段，来保存身份证的校验码，同时在这个字段上创建索引。\n\nalter table t add id_card_crc int unsigned, add index(id_card_crc);\n\n\n1\n\n\n然后每次插入新记录的时候，都同时用 crc32() 这个函数得到校验码填到这个新字段。由于校验码可能存在冲突，也就是说两个不同的身份证号通过 crc32() 函数得到的结果可能是相同的，所以你的查询语句 where 部分要判断 id_card 的值是否精确相同。\n\nselect field_list from t where id_card_crc=crc32('input_id_card_string') and id_card='input_id_card_string'\n\n\n1\n\n\n这样，索引的长度变成了 4 个字节，比原来小了很多。\n\n接下来，我们再一起看看使用倒序存储和使用 hash 字段这两种方法的异同点。\n\n * 相同点是，都不支持范围查询。倒序存储的字段上创建的索引是按照倒序字符串的方式排序的，已经没有办法利用索引方式查出身份证号码在[id_x, id_y]的所有市民了。同样地，hash 字段的方式也只能支持等值查询。\n * 区别主要体现在以下三个方面：\n   * 从占用的额外空间来看，倒序存储方式在主键索引上，不会消耗额外的存储空间，而 hash 字段方法需要增加一个字段。当然，倒序存储方式使用 4 个字节的前缀长度应该是不够的，如果再长一点，这个消耗跟额外这个 hash 字段也差不多抵消了。\n   * 在 cpu 消耗方面，倒序方式每次写和读的时候，都需要额外调用一次 reverse 函数，而 hash 字段的方式需要额外调用一次 crc32() 函数。如果只从这两个函数的计算复杂度来看的话，reverse 函数额外消耗的 cpu 资源会更小些。\n   * 从查询效率上看，使用 hash 字段方式的查询性能相对更稳定一些。因为 crc32 算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近 1。而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。\n\n\n# 1.4 小结\n\n总结一下给字符串的字段创建索引的方式：\n\n * 直接创建完整索引，这样可能比较占用空间；\n * 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；\n * 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；\n * 创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。\n\n在实际应用中，你要根据业务字段的特点选择使用哪种方式。",charsets:{cjk:!0},lastUpdated:"2023/05/29, 07:11:57",lastUpdatedTimestamp:1685344317e3},{title:"Linux 基础篇",frontmatter:{title:"Linux 基础篇",date:"2022-04-09T10:17:39.000Z",permalink:"/pages/c774f5/",categories:["基础","Linux","韩顺平2021课程笔记"],tags:[null]},regularPath:"/%E5%9F%BA%E7%A1%80/10.Linux/05.%E9%9F%A9%E9%A1%BA%E5%B9%B32021%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/05.Linux%E5%9F%BA%E7%A1%80%E7%AF%87.html",relativePath:"基础/10.Linux/05.韩顺平2021课程笔记/05.Linux基础篇.md",key:"v-4fda8213",path:"/pages/c774f5/",headers:[{level:2,title:"1. Linux入门",slug:"_1-linux入门",normalizedTitle:"1. linux入门",charIndex:2},{level:2,title:"2. VM 和 Linux 的安装",slug:"_2-vm-和-linux-的安装",normalizedTitle:"2. vm 和 linux 的安装",charIndex:81},{level:3,title:"2.1 虚拟机的使用",slug:"_2-1-虚拟机的使用",normalizedTitle:"2.1 虚拟机的使用",charIndex:103},{level:4,title:"2.1.1 克隆",slug:"_2-1-1-克隆",normalizedTitle:"2.1.1 克隆",charIndex:117},{level:4,title:"2.1.2 快照",slug:"_2-1-2-快照",normalizedTitle:"2.1.2 快照",charIndex:254},{level:4,title:"2.1.3 迁移和删除",slug:"_2-1-3-迁移和删除",normalizedTitle:"2.1.3 迁移和删除",charIndex:282},{level:3,title:"2.2 网络连接的三种方式",slug:"_2-2-网络连接的三种方式",normalizedTitle:"2.2 网络连接的三种方式",charIndex:349},{level:4,title:"1）桥接模式（张三）",slug:"_1-桥接模式-张三",normalizedTitle:"1）桥接模式（张三）",charIndex:416},{level:4,title:"2）NAT 模式（王五）",slug:"_2-nat-模式-王五",normalizedTitle:"2）nat 模式（王五）",charIndex:505},{level:4,title:"3）仅主机模式（李四）",slug:"_3-仅主机模式-李四",normalizedTitle:"3）仅主机模式（李四）",charIndex:642},{level:3,title:"2.3 vmtools",slug:"_2-3-vmtools",normalizedTitle:"2.3 vmtools",charIndex:677},{level:4,title:"2.3.1 vmtools 的安装",slug:"_2-3-1-vmtools-的安装",normalizedTitle:"2.3.1 vmtools 的安装",charIndex:756},{level:4,title:"2.3.2 主机与 VM 共享文件夹",slug:"_2-3-2-主机与-vm-共享文件夹",normalizedTitle:"2.3.2 主机与 vm 共享文件夹",charIndex:1069},{level:2,title:"3. Linux 的目录结构",slug:"_3-linux-的目录结构",normalizedTitle:"3. linux 的目录结构",charIndex:1222},{level:3,title:"3.1 基本介绍",slug:"_3-1-基本介绍",normalizedTitle:"3.1 基本介绍",charIndex:1241},{level:3,title:"3.2 具体的目录结构",slug:"_3-2-具体的目录结构",normalizedTitle:"3.2 具体的目录结构",charIndex:1301},{level:3,title:"3.3 文件目录的相关指令",slug:"_3-3-文件目录的相关指令",normalizedTitle:"3.3 文件目录的相关指令",charIndex:2330},{level:4,title:"3.3.1 *pwd",slug:"_3-3-1-pwd",normalizedTitle:"3.3.1 *pwd",charIndex:2347},{level:4,title:"3.3.2 *ls",slug:"_3-3-2-ls",normalizedTitle:"3.3.2 *ls",charIndex:2377},{level:4,title:"3.3.3 *cd 切换到指定目录",slug:"_3-3-3-cd-切换到指定目录",normalizedTitle:"3.3.3 *cd 切换到指定目录",charIndex:2589},{level:4,title:"3.3.4 mkdir 创建目录",slug:"_3-3-4-mkdir-创建目录",normalizedTitle:"3.3.4 mkdir 创建目录",charIndex:2766},{level:4,title:"3.3.5 rmdir 删除目录",slug:"_3-3-5-rmdir-删除目录",normalizedTitle:"3.3.5 rmdir 删除目录",charIndex:2897},{level:4,title:"3.3.6 touch 创建空文件",slug:"_3-3-6-touch-创建空文件",normalizedTitle:"3.3.6 touch 创建空文件",charIndex:3022},{level:4,title:"3.3.7 *cp 拷贝",slug:"_3-3-7-cp-拷贝",normalizedTitle:"3.3.7 *cp 拷贝",charIndex:3054},{level:4,title:"3.3.8 *rm 移除文件或目录",slug:"_3-3-8-rm-移除文件或目录",normalizedTitle:"3.3.8 *rm 移除文件或目录",charIndex:3147},{level:4,title:"3.3.9 mv 移动（文件/目录）或重命名",slug:"_3-3-9-mv-移动-文件-目录-或重命名",normalizedTitle:"3.3.9 mv 移动（文件/目录）或重命名",charIndex:3288},{level:4,title:"3.3.10 cat",slug:"_3-3-10-cat",normalizedTitle:"3.3.10 cat",charIndex:3446},{level:4,title:"3.3.11 more",slug:"_3-3-11-more",normalizedTitle:"3.3.11 more",charIndex:3663},{level:4,title:"3.3.12 less",slug:"_3-3-12-less",normalizedTitle:"3.3.12 less",charIndex:3833},{level:4,title:"3.3.13 echo 输出内容到控制台",slug:"_3-3-13-echo-输出内容到控制台",normalizedTitle:"3.3.13 echo 输出内容到控制台",charIndex:4106},{level:4,title:"3.3.14 head 显示文件开头部分",slug:"_3-3-14-head-显示文件开头部分",normalizedTitle:"3.3.14 head 显示文件开头部分",charIndex:4230},{level:4,title:"3.3.15 tail 显示文件结尾部分",slug:"_3-3-15-tail-显示文件结尾部分",normalizedTitle:"3.3.15 tail 显示文件结尾部分",charIndex:4315},{level:4,title:"3.3.16 > 和 >> 重定向",slug:"_3-3-16-和-重定向",normalizedTitle:"3.3.16 &gt; 和 &gt;&gt; 重定向",charIndex:null},{level:4,title:"3.3.17 ln 创建软链接",slug:"_3-3-17-ln-创建软链接",normalizedTitle:"3.3.17 ln 创建软链接",charIndex:4678},{level:4,title:"3.3.18 history",slug:"_3-3-18-history",normalizedTitle:"3.3.18 history",charIndex:4958},{level:2,title:"4. 远程登录到 Linux 服务器",slug:"_4-远程登录到-linux-服务器",normalizedTitle:"4. 远程登录到 linux 服务器",charIndex:5081}],headersStr:"1. Linux入门 2. VM 和 Linux 的安装 2.1 虚拟机的使用 2.1.1 克隆 2.1.2 快照 2.1.3 迁移和删除 2.2 网络连接的三种方式 1）桥接模式（张三） 2）NAT 模式（王五） 3）仅主机模式（李四） 2.3 vmtools 2.3.1 vmtools 的安装 2.3.2 主机与 VM 共享文件夹 3. Linux 的目录结构 3.1 基本介绍 3.2 具体的目录结构 3.3 文件目录的相关指令 3.3.1 *pwd 3.3.2 *ls 3.3.3 *cd 切换到指定目录 3.3.4 mkdir 创建目录 3.3.5 rmdir 删除目录 3.3.6 touch 创建空文件 3.3.7 *cp 拷贝 3.3.8 *rm 移除文件或目录 3.3.9 mv 移动（文件/目录）或重命名 3.3.10 cat 3.3.11 more 3.3.12 less 3.3.13 echo 输出内容到控制台 3.3.14 head 显示文件开头部分 3.3.15 tail 显示文件结尾部分 3.3.16 > 和 >> 重定向 3.3.17 ln 创建软链接 3.3.18 history 4. 远程登录到 Linux 服务器",content:"# 1. Linux入门\n\n> 最新 Linux 源码下载：The Linux Kernel Archives\n\nLinux 和 Unix 关系图：\n\n\n\n\n# 2. VM 和 Linux 的安装\n\n\n# 2.1 虚拟机的使用\n\n# 2.1.1 克隆\n\n如果已经安装了一台 Linux 操作系统，并还想要更多的，这时没必要重新安装，只需要克隆就可以了：\n\n * 方式1：直接拷贝一份安装好的虚拟机文件\n * 方式2：使用 VMware 的克隆操作。注意，克隆时要先关闭要克隆的这台 Linux 系统。\n\n# 2.1.2 快照\n\n快速恢复到快照时的运行状态。\n\n# 2.1.3 迁移和删除\n\n虚拟系统本质就是文件。迁移只需要文件夹的整体拷贝或剪切到另外位置。删除可以直接删除对应文件夹即可。\n\n\n# 2.2 网络连接的三种方式\n\n\n\n张三、李四、王五三人此时在同一个网段下（都是192.168.0.X），他们可以进行相互通信。\n\n# 1）桥接模式（张三）\n\n在桥接模式下，虚拟机 IP 地址需要与主机在同一个网段，给虚拟系统再分配一个本网段的 IP。虚拟系统可以和外部系统通讯，但这容易造成 IP 冲突。\n\n# 2）NAT 模式（王五）\n\nNAT 模式，就是网络地址转换模式。虚拟系统可以和外部系统通讯，不造成 IP 冲突。此时192.168.0.50 是个代理，虚拟系统只是通过代理来和外部进行通信，但是外部无法直接访问到192.168.100.88 ，所有右侧只有一个箭头。\n\n# 3）仅主机模式（李四）\n\n一个独立的系统，不和外部产生联系。\n\n\n# 2.3 vmtools\n\nvmtools 可以让我们在 Windows 下更好的管理虚拟机，比如可以设置 Windows 和 Centos 共享文件。\n\n# 2.3.1 vmtools 的安装\n\n 1. VMware 上方 虚拟机 -> （重新）安装 VM tools\n 2. 桌面上出现一个 VMware tools，打开里面有个 xxx.tar.gz，将其拷贝到 /opt\n 3. 使用解压命令 tar -zxvf xx.tar.gz 得到一个安装文件\n 4. 进入该安装文件夹里面，执行命令 ./vmware-install.pl 进行安装，安装过程全部回车默认即可，直到安装完成。\n\n> 注意点：\n> \n>  * 安装过程需要有 gcc， gcc -v查看版本。\n>  * 第一步的点击 （重新）安装 VM tools 后可能没有反应，只需要取消一下再重新点一下即可。\n\n# 2.3.2 主机与 VM 共享文件夹\n\n 1. 安装 VMtools 后，在 VMware 的 设置 -> 选项 -> 共享文件夹\n 2. 在这个界面中，先点击 总是启用 ，然后在下面文件夹中添加需要共享的文件夹\n 3. 在虚拟系统中，/mnt 里可以找到共享的文件夹，对其的修改也会同步到主机中\n\n\n# 3. Linux 的目录结构\n\n\n# 3.1 基本介绍\n\nLinux 采用层级目录结构，最上层是根目录 /。\n\n在 Linux 世界里，一切皆文件。\n\n\n# 3.2 具体的目录结构\n\n目录            说明\n/bin          或 /usr/bin、/usr/local/bin。Binary 的缩写，存放着最经常使用的命令。\n/sbin         或 /usr/sbin、/usr/local/sbin。s —— Super User，存放着系统管理员使用的程序。\n/home         存放普通用户的主目录，每个用户有一个自己的目录。\n/root         系统管理员的主目录\n/lib          系统开机所需要的最基本的动态链接共享库。几乎所有应用程序都需要这些库。\n/lost+found   一般为空，当系统非法关机时这里就存放了一些文件、\n/etc          所有的系统管理所需要的配置文件和子目录。比如安装 mysql 时的 my.conf\n/usr          用户安装的很多应用程序都放在这个目录下。类似于 Windows 的 program files。\n/boot         存放着启动 Linux 时使用的核心文件\n/proc         【不能动】。是一个虚拟目录，它是系统内存的映射，访问这个目录来获取系统信息。\n/srv          【不能动】。service 的缩写，存放一些服务启动后需要提取的数据\n/sys          【不能动】。安装了 2.6 内核中新出现的一个文件系统 sysfs\n/tmp          存放临时文件\n/dev          把所有设备硬件用文件的形式存储\n/media        Linux 自动识别的一些设备（如 U 盘、光驱）挂载到这个目录下。\n/mnt          让用户临时挂载别的文件系统。我们可以将外部存储挂载到 /mnt 下，然后进入里面查看内容\n/opt          主机额外安装软件所存放的目录。如安装 Oracle 就可以放到这里面\n/usr/local    这是另一个给主机额外安装软件所存放的目录。这里一般是通过编译源码方式安装的程序。（软件的使用目录，软件安装的目标目录）\n/var          存放着不断扩充着的东西，习惯将经常修改的目录放在这里面，如日志文件。\n/selinux      Security-Enhanced Linux。SELinux 是一种安全子系统，它能控制程序只能访问特定文件。\n\n\n# 3.3 文件目录的相关指令\n\n# 3.3.1 *pwd\n\n显示当前工作目录的绝对路径。\n\n# 3.3.2 *ls\n\nls [选项] [目录或文件]\n\n * -a：显示包括隐藏文件在内的所有文件\n * -l：以单列的方式显示详细信息\n * -h：给人看的\n\n> 补充知识点：\n> \n>  * Linux 下，隐藏文件是以 . 开头\n>  * 命令的选项可以组合使用，无顺序差别，比如 ls 的选项可以组合成 ls -al 或者 ls -la。\n>  * ls 命令还可以指定一个目录，比如 ls -l /root\n\n# 3.3.3 *cd 切换到指定目录\n\n * cd ~：回到家目录，若你是 root ，则到 /root；若是 tom，则到 /home/tom\n * cd ..：回到上一级目录\n * cd /usr：切换到 /usr 目录\n\n> cd .. 可以连续使用，比如：当前在 /home/tom 下，使用 cd ../../root 即可到 /root\n\n# 3.3.4 mkdir 创建目录\n\nmkdir [选项] 要创建的目录\n\n * -p：创建多级目录\n\n> 案例：\n> \n>  * 创建一个目录：mkdir /home/dog\n>  * 创建多级目录：mkdir -p /home/animal/tiger\n\n# 3.3.5 rmdir 删除目录\n\nrmdir [选项] 要删除的空目录\n\n\n1\n\n * rmdir 删除的是空目录，如果目录下有内容时无法删除\n * 如果需要删除非空目录，应该使用 rm -rf 要删除的目录，-r 递归删除，-f 强制删除\n\n# 3.3.6 touch 创建空文件\n\ntouch 文件名\n\n# 3.3.7 *cp 拷贝\n\ncp [选项] src dst\n\n * -r：递归复制整个文件夹\n * 强制覆盖不提示的方法：\\cp，比如 \\cp -r /home/src /opt\n\n# 3.3.8 *rm 移除文件或目录\n\nrm [选项] 要移除的文件或目录\n\n\n1\n\n\n * -r：递归删除整个文件夹\n\n * -f：强制删除不提示，不加此选项时，每删除一个文件都要提示一次\n   \n   rm -rf [dir] 一定要灰常小心地操作！！直接删了整个目录了！\n\n# 3.3.9 mv 移动（文件/目录）或重命名\n\nmv old new\n\n * 可以移动并且重命名\n\n> 案例：\n> \n>  * mv cat.txt pig.txt：将 cat.text 重命名为 pig.txt\n>  * mv /home/src /opt/：将 /home/src 移动到 /opt 下面\n\n# 3.3.10 cat\n\n只能查看不能修改，比 vim 更安全，因此对于重要的文件，建议用 cat 命令。\n\ncat [选项] 文件名\n\n * -n：显示行号\n * 为了浏览方便，一般会带上管道命令 | more\n\n> 管道命令：将前一个指令的输出作为后一个指令的输入\n\n> 案例：\n> \n>  * cat -n /etc/profile | more ：查看 profile 文件内容，可以使用 more 命令的按键进行交互。\n\n# 3.3.11 more\n\nmore 指令以全屏的方式按页显示文本内容。常见操作：\n\n操作       功能\n空白键      向下翻页\nEnter    向下翻一行\nq        离开 more\nCtrl F   向下滚动一屏\nCtrl B   返回上一屏\n=        输出当前行号\n:f       输出文件名和当前行号\n\n# 3.3.12 less\n\n用来分屏查看文件内容，与 more 指令类似，但更加强大。支持各种终端；显示文本时按需加载文本内容，对大型文件效率较高。\n\n查看较大的文件时，更建议使用 less 命令。\n\n常见操作：\n\n操作           功能\n空白键          向下翻页\n[pagedown]   向下翻页\n[pageup]     向上翻页\n/str         向下搜索 “str”。n 下一个，N 上一个\n?str         向上搜索 “str”。n 上一个，N 下一个\nq            离开 less\n\n# 3.3.13 echo 输出内容到控制台\n\necho [选项] [输出内容]\n\n> 案例：\n> \n>  * ⭐️ echo 输出环境变量：echo $PATH，其中 $ 后面接环境变量名。\n>  * 输出主机名：echo $HOSTNAME\n\n# 3.3.14 head 显示文件开头部分\n\nhead 文件 默认显示文件前 10 行内容。\n\n * -n：指定显示前几行，比如 head -n 5 foo.txt\n\n# 3.3.15 tail 显示文件结尾部分\n\ntail 文件 显示文件最后默认 10 行内容。\n\n * -n：指定行数\n * -f：实时追踪该文档的所有更新，并打印出来\n\n> -f 的作用：\n> \n>  * 做服务器管理时，需要监控某个文件，比如监控发包、网络的实时变化，可以用这个选项。\n\n# 3.3.16 > 和 >> 重定向\n\n * > 输出重定向\n * >> 重定向并追加\n\n> 案例：\n> \n>  * ls -l > foo.txt：将 ls 的输出覆盖写入 foo.txt 中，该文件不存在时，会自动创建这个文件\n>  * cat foo.txt > bar.txt ：将 foo.txt 内容覆盖到 bar.txt\n>  * echo “hello” >> foo.txt ：将 hello 追加到文件后面\n\n# 3.3.17 ln 创建软链接\n\nln，是 link 的缩写，创建一个软链接（类似 Windows 的快捷方式），主要存放了链接其他文件的路径。\n\nln -s [原文件或目录] [软链接名]：给原文件创建一个软链接。\n\ne.g. 在 /home 目录下创建一个软连接 myroot，连接到 /root 目录：\n\nln -s /root /home/myroot\n\n * rm 删除的是软链接，不会删除到原文件\n * pwd 查看目录时仍然看到的是软链接所在目录\n\n> rm /home/myroot ：myroot 后面不要加 / ，否则会视为一个目录\n\n# 3.3.18 history\n\nhistory 查看已经执行过的历史命令，也可以执行历史命令\n\n * history：显示所有的历史命令\n * history 10：显示最近使用过的 10 个指令\n * !5：指令历史编号为 5 的指令\n\n\n# 4. 远程登录到 Linux 服务器\n\n我们这里使用 Xshell 6 和 Xftp 6 来作为远程登录客户端。\n\nXshell 是用来远程登录服务器并对其进行操作的，Xftp 是用来本地和服务器进行文件传输的。\n\n在虚拟机中使用 ifconfig 查看 IP 地址，ens33就是网卡，在第一部分的 inet 中可以看到 IP。\n\n然后尝试主机与虚拟机能否连通：在主机中用 ping <IP> 测试是否能够成功。\n\n在 Xshell 和 Xftp 中新建会话即可。\n\nWindows 还可以用 FinalShell 作为远程登录工具，免费且相当于Xshell + Xftp 的合体。",normalizedContent:"# 1. linux入门\n\n> 最新 linux 源码下载：the linux kernel archives\n\nlinux 和 unix 关系图：\n\n\n\n\n# 2. vm 和 linux 的安装\n\n\n# 2.1 虚拟机的使用\n\n# 2.1.1 克隆\n\n如果已经安装了一台 linux 操作系统，并还想要更多的，这时没必要重新安装，只需要克隆就可以了：\n\n * 方式1：直接拷贝一份安装好的虚拟机文件\n * 方式2：使用 vmware 的克隆操作。注意，克隆时要先关闭要克隆的这台 linux 系统。\n\n# 2.1.2 快照\n\n快速恢复到快照时的运行状态。\n\n# 2.1.3 迁移和删除\n\n虚拟系统本质就是文件。迁移只需要文件夹的整体拷贝或剪切到另外位置。删除可以直接删除对应文件夹即可。\n\n\n# 2.2 网络连接的三种方式\n\n\n\n张三、李四、王五三人此时在同一个网段下（都是192.168.0.x），他们可以进行相互通信。\n\n# 1）桥接模式（张三）\n\n在桥接模式下，虚拟机 ip 地址需要与主机在同一个网段，给虚拟系统再分配一个本网段的 ip。虚拟系统可以和外部系统通讯，但这容易造成 ip 冲突。\n\n# 2）nat 模式（王五）\n\nnat 模式，就是网络地址转换模式。虚拟系统可以和外部系统通讯，不造成 ip 冲突。此时192.168.0.50 是个代理，虚拟系统只是通过代理来和外部进行通信，但是外部无法直接访问到192.168.100.88 ，所有右侧只有一个箭头。\n\n# 3）仅主机模式（李四）\n\n一个独立的系统，不和外部产生联系。\n\n\n# 2.3 vmtools\n\nvmtools 可以让我们在 windows 下更好的管理虚拟机，比如可以设置 windows 和 centos 共享文件。\n\n# 2.3.1 vmtools 的安装\n\n 1. vmware 上方 虚拟机 -> （重新）安装 vm tools\n 2. 桌面上出现一个 vmware tools，打开里面有个 xxx.tar.gz，将其拷贝到 /opt\n 3. 使用解压命令 tar -zxvf xx.tar.gz 得到一个安装文件\n 4. 进入该安装文件夹里面，执行命令 ./vmware-install.pl 进行安装，安装过程全部回车默认即可，直到安装完成。\n\n> 注意点：\n> \n>  * 安装过程需要有 gcc， gcc -v查看版本。\n>  * 第一步的点击 （重新）安装 vm tools 后可能没有反应，只需要取消一下再重新点一下即可。\n\n# 2.3.2 主机与 vm 共享文件夹\n\n 1. 安装 vmtools 后，在 vmware 的 设置 -> 选项 -> 共享文件夹\n 2. 在这个界面中，先点击 总是启用 ，然后在下面文件夹中添加需要共享的文件夹\n 3. 在虚拟系统中，/mnt 里可以找到共享的文件夹，对其的修改也会同步到主机中\n\n\n# 3. linux 的目录结构\n\n\n# 3.1 基本介绍\n\nlinux 采用层级目录结构，最上层是根目录 /。\n\n在 linux 世界里，一切皆文件。\n\n\n# 3.2 具体的目录结构\n\n目录            说明\n/bin          或 /usr/bin、/usr/local/bin。binary 的缩写，存放着最经常使用的命令。\n/sbin         或 /usr/sbin、/usr/local/sbin。s —— super user，存放着系统管理员使用的程序。\n/home         存放普通用户的主目录，每个用户有一个自己的目录。\n/root         系统管理员的主目录\n/lib          系统开机所需要的最基本的动态链接共享库。几乎所有应用程序都需要这些库。\n/lost+found   一般为空，当系统非法关机时这里就存放了一些文件、\n/etc          所有的系统管理所需要的配置文件和子目录。比如安装 mysql 时的 my.conf\n/usr          用户安装的很多应用程序都放在这个目录下。类似于 windows 的 program files。\n/boot         存放着启动 linux 时使用的核心文件\n/proc         【不能动】。是一个虚拟目录，它是系统内存的映射，访问这个目录来获取系统信息。\n/srv          【不能动】。service 的缩写，存放一些服务启动后需要提取的数据\n/sys          【不能动】。安装了 2.6 内核中新出现的一个文件系统 sysfs\n/tmp          存放临时文件\n/dev          把所有设备硬件用文件的形式存储\n/media        linux 自动识别的一些设备（如 u 盘、光驱）挂载到这个目录下。\n/mnt          让用户临时挂载别的文件系统。我们可以将外部存储挂载到 /mnt 下，然后进入里面查看内容\n/opt          主机额外安装软件所存放的目录。如安装 oracle 就可以放到这里面\n/usr/local    这是另一个给主机额外安装软件所存放的目录。这里一般是通过编译源码方式安装的程序。（软件的使用目录，软件安装的目标目录）\n/var          存放着不断扩充着的东西，习惯将经常修改的目录放在这里面，如日志文件。\n/selinux      security-enhanced linux。selinux 是一种安全子系统，它能控制程序只能访问特定文件。\n\n\n# 3.3 文件目录的相关指令\n\n# 3.3.1 *pwd\n\n显示当前工作目录的绝对路径。\n\n# 3.3.2 *ls\n\nls [选项] [目录或文件]\n\n * -a：显示包括隐藏文件在内的所有文件\n * -l：以单列的方式显示详细信息\n * -h：给人看的\n\n> 补充知识点：\n> \n>  * linux 下，隐藏文件是以 . 开头\n>  * 命令的选项可以组合使用，无顺序差别，比如 ls 的选项可以组合成 ls -al 或者 ls -la。\n>  * ls 命令还可以指定一个目录，比如 ls -l /root\n\n# 3.3.3 *cd 切换到指定目录\n\n * cd ~：回到家目录，若你是 root ，则到 /root；若是 tom，则到 /home/tom\n * cd ..：回到上一级目录\n * cd /usr：切换到 /usr 目录\n\n> cd .. 可以连续使用，比如：当前在 /home/tom 下，使用 cd ../../root 即可到 /root\n\n# 3.3.4 mkdir 创建目录\n\nmkdir [选项] 要创建的目录\n\n * -p：创建多级目录\n\n> 案例：\n> \n>  * 创建一个目录：mkdir /home/dog\n>  * 创建多级目录：mkdir -p /home/animal/tiger\n\n# 3.3.5 rmdir 删除目录\n\nrmdir [选项] 要删除的空目录\n\n\n1\n\n * rmdir 删除的是空目录，如果目录下有内容时无法删除\n * 如果需要删除非空目录，应该使用 rm -rf 要删除的目录，-r 递归删除，-f 强制删除\n\n# 3.3.6 touch 创建空文件\n\ntouch 文件名\n\n# 3.3.7 *cp 拷贝\n\ncp [选项] src dst\n\n * -r：递归复制整个文件夹\n * 强制覆盖不提示的方法：\\cp，比如 \\cp -r /home/src /opt\n\n# 3.3.8 *rm 移除文件或目录\n\nrm [选项] 要移除的文件或目录\n\n\n1\n\n\n * -r：递归删除整个文件夹\n\n * -f：强制删除不提示，不加此选项时，每删除一个文件都要提示一次\n   \n   rm -rf [dir] 一定要灰常小心地操作！！直接删了整个目录了！\n\n# 3.3.9 mv 移动（文件/目录）或重命名\n\nmv old new\n\n * 可以移动并且重命名\n\n> 案例：\n> \n>  * mv cat.txt pig.txt：将 cat.text 重命名为 pig.txt\n>  * mv /home/src /opt/：将 /home/src 移动到 /opt 下面\n\n# 3.3.10 cat\n\n只能查看不能修改，比 vim 更安全，因此对于重要的文件，建议用 cat 命令。\n\ncat [选项] 文件名\n\n * -n：显示行号\n * 为了浏览方便，一般会带上管道命令 | more\n\n> 管道命令：将前一个指令的输出作为后一个指令的输入\n\n> 案例：\n> \n>  * cat -n /etc/profile | more ：查看 profile 文件内容，可以使用 more 命令的按键进行交互。\n\n# 3.3.11 more\n\nmore 指令以全屏的方式按页显示文本内容。常见操作：\n\n操作       功能\n空白键      向下翻页\nenter    向下翻一行\nq        离开 more\nctrl f   向下滚动一屏\nctrl b   返回上一屏\n=        输出当前行号\n:f       输出文件名和当前行号\n\n# 3.3.12 less\n\n用来分屏查看文件内容，与 more 指令类似，但更加强大。支持各种终端；显示文本时按需加载文本内容，对大型文件效率较高。\n\n查看较大的文件时，更建议使用 less 命令。\n\n常见操作：\n\n操作           功能\n空白键          向下翻页\n[pagedown]   向下翻页\n[pageup]     向上翻页\n/str         向下搜索 “str”。n 下一个，n 上一个\n?str         向上搜索 “str”。n 上一个，n 下一个\nq            离开 less\n\n# 3.3.13 echo 输出内容到控制台\n\necho [选项] [输出内容]\n\n> 案例：\n> \n>  * ⭐️ echo 输出环境变量：echo $path，其中 $ 后面接环境变量名。\n>  * 输出主机名：echo $hostname\n\n# 3.3.14 head 显示文件开头部分\n\nhead 文件 默认显示文件前 10 行内容。\n\n * -n：指定显示前几行，比如 head -n 5 foo.txt\n\n# 3.3.15 tail 显示文件结尾部分\n\ntail 文件 显示文件最后默认 10 行内容。\n\n * -n：指定行数\n * -f：实时追踪该文档的所有更新，并打印出来\n\n> -f 的作用：\n> \n>  * 做服务器管理时，需要监控某个文件，比如监控发包、网络的实时变化，可以用这个选项。\n\n# 3.3.16 > 和 >> 重定向\n\n * > 输出重定向\n * >> 重定向并追加\n\n> 案例：\n> \n>  * ls -l > foo.txt：将 ls 的输出覆盖写入 foo.txt 中，该文件不存在时，会自动创建这个文件\n>  * cat foo.txt > bar.txt ：将 foo.txt 内容覆盖到 bar.txt\n>  * echo “hello” >> foo.txt ：将 hello 追加到文件后面\n\n# 3.3.17 ln 创建软链接\n\nln，是 link 的缩写，创建一个软链接（类似 windows 的快捷方式），主要存放了链接其他文件的路径。\n\nln -s [原文件或目录] [软链接名]：给原文件创建一个软链接。\n\ne.g. 在 /home 目录下创建一个软连接 myroot，连接到 /root 目录：\n\nln -s /root /home/myroot\n\n * rm 删除的是软链接，不会删除到原文件\n * pwd 查看目录时仍然看到的是软链接所在目录\n\n> rm /home/myroot ：myroot 后面不要加 / ，否则会视为一个目录\n\n# 3.3.18 history\n\nhistory 查看已经执行过的历史命令，也可以执行历史命令\n\n * history：显示所有的历史命令\n * history 10：显示最近使用过的 10 个指令\n * !5：指令历史编号为 5 的指令\n\n\n# 4. 远程登录到 linux 服务器\n\n我们这里使用 xshell 6 和 xftp 6 来作为远程登录客户端。\n\nxshell 是用来远程登录服务器并对其进行操作的，xftp 是用来本地和服务器进行文件传输的。\n\n在虚拟机中使用 ifconfig 查看 ip 地址，ens33就是网卡，在第一部分的 inet 中可以看到 ip。\n\n然后尝试主机与虚拟机能否连通：在主机中用 ping <ip> 测试是否能够成功。\n\n在 xshell 和 xftp 中新建会话即可。\n\nwindows 还可以用 finalshell 作为远程登录工具，免费且相当于xshell + xftp 的合体。",charsets:{cjk:!0},lastUpdated:"2022/07/27, 11:28:29",lastUpdatedTimestamp:1658921309e3},{title:"Linux实操篇（上）",frontmatter:{title:"Linux实操篇（上）",date:"2022-04-11T13:38:58.000Z",permalink:"/pages/4a5b75/",categories:["基础","Linux","韩顺平2021课程笔记"],tags:[null]},regularPath:"/%E5%9F%BA%E7%A1%80/10.Linux/05.%E9%9F%A9%E9%A1%BA%E5%B9%B32021%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/10.Linux%E5%AE%9E%E6%93%8D%E7%AF%87%EF%BC%88%E4%B8%8A%EF%BC%89.html",relativePath:"基础/10.Linux/05.韩顺平2021课程笔记/10.Linux实操篇（上）.md",key:"v-c45fcee4",path:"/pages/4a5b75/",headers:[{level:2,title:"1. Vi 和 Vim 编辑器",slug:"_1-vi-和-vim-编辑器",normalizedTitle:"1. vi 和 vim 编辑器",charIndex:2},{level:2,title:"2. 开机、重启与用户登录注销",slug:"_2-开机、重启与用户登录注销",normalizedTitle:"2. 开机、重启与用户登录注销",charIndex:149},{level:3,title:"2.1 关机 & 重启命令",slug:"_2-1-关机-重启命令",normalizedTitle:"2.1 关机 &amp; 重启命令",charIndex:null},{level:3,title:"2.2 用户登录与注销",slug:"_2-2-用户登录与注销",normalizedTitle:"2.2 用户登录与注销",charIndex:512},{level:2,title:"3. 用户管理",slug:"_3-用户管理",normalizedTitle:"3. 用户管理",charIndex:604},{level:3,title:"3.1 添加用户",slug:"_3-1-添加用户",normalizedTitle:"3.1 添加用户",charIndex:639},{level:3,title:"3.2 指定/修改密码",slug:"_3-2-指定-修改密码",normalizedTitle:"3.2 指定/修改密码",charIndex:749},{level:3,title:"3.3 删除用户",slug:"_3-3-删除用户",normalizedTitle:"3.3 删除用户",charIndex:817},{level:3,title:"3.4 查询用户信息",slug:"_3-4-查询用户信息",normalizedTitle:"3.4 查询用户信息",charIndex:926},{level:3,title:"3.5 切换用户",slug:"_3-5-切换用户",normalizedTitle:"3.5 切换用户",charIndex:973},{level:3,title:"3.6 查看当前登录用户",slug:"_3-6-查看当前登录用户",normalizedTitle:"3.6 查看当前登录用户",charIndex:1077},{level:3,title:"3.7 用户组",slug:"_3-7-用户组",normalizedTitle:"3.7 用户组",charIndex:1185},{level:3,title:"3.8 用户和组相关的文件",slug:"_3-8-用户和组相关的文件",normalizedTitle:"3.8 用户和组相关的文件",charIndex:1395},{level:2,title:"4. 实用指令",slug:"_4-实用指令",normalizedTitle:"4. 实用指令",charIndex:1766},{level:3,title:"4.1 运行级别",slug:"_4-1-运行级别",normalizedTitle:"4.1 运行级别",charIndex:1778},{level:4,title:"CentOS 7 后运行级别说明",slug:"centos-7-后运行级别说明",normalizedTitle:"centos 7 后运行级别说明",charIndex:2016},{level:3,title:"4.2 找回 root 密码",slug:"_4-2-找回-root-密码",normalizedTitle:"4.2 找回 root 密码",charIndex:2260},{level:3,title:"4.3 帮助指令",slug:"_4-3-帮助指令",normalizedTitle:"4.3 帮助指令",charIndex:2310},{level:3,title:"4.4 时间日期类",slug:"_4-4-时间日期类",normalizedTitle:"4.4 时间日期类",charIndex:2536},{level:4,title:"4.4.1 date 显示当前日期",slug:"_4-4-1-date-显示当前日期",normalizedTitle:"4.4.1 date 显示当前日期",charIndex:2549},{level:4,title:"4.4.2 cal 显示日历",slug:"_4-4-2-cal-显示日历",normalizedTitle:"4.4.2 cal 显示日历",charIndex:2761},{level:3,title:"4.5 搜索查找类",slug:"_4-5-搜索查找类",normalizedTitle:"4.5 搜索查找类",charIndex:2848},{level:4,title:"4.5.1 find",slug:"_4-5-1-find",normalizedTitle:"4.5.1 find",charIndex:2861},{level:4,title:"4.5.2 locate",slug:"_4-5-2-locate",normalizedTitle:"4.5.2 locate",charIndex:3243},{level:4,title:"4.5.3 which",slug:"_4-5-3-which",normalizedTitle:"4.5.3 which",charIndex:3421},{level:4,title:"4.5.4 grep 指令和管道符号 |",slug:"_4-5-4-grep-指令和管道符号",normalizedTitle:"4.5.4 grep 指令和管道符号 |",charIndex:3485},{level:3,title:"4.6 压缩和解压类",slug:"_4-6-压缩和解压类",normalizedTitle:"4.6 压缩和解压类",charIndex:3736},{level:4,title:"4.6.1 gzip 压缩 & gunzip 解压",slug:"_4-6-1-gzip-压缩-gunzip-解压",normalizedTitle:"4.6.1 gzip 压缩 &amp; gunzip 解压",charIndex:null},{level:4,title:"4.6.2 zip 压缩 & unzip 解压",slug:"_4-6-2-zip-压缩-unzip-解压",normalizedTitle:"4.6.2 zip 压缩 &amp; unzip 解压",charIndex:null},{level:4,title:"4.6.3 tar 打包 ⭐️",slug:"_4-6-3-tar-打包-⭐️",normalizedTitle:"4.6.3 tar 打包 ⭐️",charIndex:4125},{level:2,title:"5. 组管理和权限管理",slug:"_5-组管理和权限管理",normalizedTitle:"5. 组管理和权限管理",charIndex:4720},{level:3,title:"5.1 所有者",slug:"_5-1-所有者",normalizedTitle:"5.1 所有者",charIndex:4817},{level:4,title:"5.1.1 查看文件的所有者",slug:"_5-1-1-查看文件的所有者",normalizedTitle:"5.1.1 查看文件的所有者",charIndex:4849},{level:4,title:"5.1.2 修改文件所有者",slug:"_5-1-2-修改文件所有者",normalizedTitle:"5.1.2 修改文件所有者",charIndex:4907},{level:3,title:"5.2 组的创建",slug:"_5-2-组的创建",normalizedTitle:"5.2 组的创建",charIndex:5045},{level:3,title:"5.3 所在组",slug:"_5-3-所在组",normalizedTitle:"5.3 所在组",charIndex:5236},{level:4,title:"53.1 查看文件的所在组",slug:"_53-1-查看文件的所在组",normalizedTitle:"53.1 查看文件的所在组",charIndex:5285},{level:4,title:"5.3.2 修改文件的所在组",slug:"_5-3-2-修改文件的所在组",normalizedTitle:"5.3.2 修改文件的所在组",charIndex:5316},{level:3,title:"5.4 其他组",slug:"_5-4-其他组",normalizedTitle:"5.4 其他组",charIndex:5364},{level:3,title:"5.5 改变用户的所在组",slug:"_5-5-改变用户的所在组",normalizedTitle:"5.5 改变用户的所在组",charIndex:5411},{level:3,title:"5.6 文件的权限",slug:"_5-6-文件的权限",normalizedTitle:"5.6 文件的权限",charIndex:5553},{level:4,title:"5.6.1 权限的基本介绍",slug:"_5-6-1-权限的基本介绍",normalizedTitle:"5.6.1 权限的基本介绍",charIndex:5566},{level:4,title:"5.6.2 rwx 权限 ⭐️",slug:"_5-6-2-rwx-权限-⭐️",normalizedTitle:"5.6.2 rwx 权限 ⭐️",charIndex:5730},{level:5,title:"1）rwx 作用到文件**",slug:"_1-rwx-作用到文件",normalizedTitle:"1）rwx 作用到文件**",charIndex:5749},{level:5,title:"2）rwx 作用到目录**",slug:"_2-rwx-作用到目录",normalizedTitle:"2）rwx 作用到目录**",charIndex:5847},{level:4,title:"5.6.3 权限的数字表示",slug:"_5-6-3-权限的数字表示",normalizedTitle:"5.6.3 权限的数字表示",charIndex:5961},{level:4,title:"5.6.4 chmod 修改权限",slug:"_5-6-4-chmod-修改权限",normalizedTitle:"5.6.4 chmod 修改权限",charIndex:6033},{level:5,title:"1）第一种方式：+ - = 变更权限",slug:"_1-第一种方式-变更权限",normalizedTitle:"1）第一种方式：+ - = 变更权限",charIndex:6090},{level:5,title:"2）第二种方式：通过数字变更权限",slug:"_2-第二种方式-通过数字变更权限",normalizedTitle:"2）第二种方式：通过数字变更权限",charIndex:6297},{level:4,title:"5.6.5 其他说明",slug:"_5-6-5-其他说明",normalizedTitle:"5.6.5 其他说明",charIndex:6394},{level:2,title:"6. 定时任务调度",slug:"_6-定时任务调度",normalizedTitle:"6. 定时任务调度",charIndex:6482},{level:3,title:"6.1 crond 任务调度",slug:"_6-1-crond-任务调度",normalizedTitle:"6.1 crond 任务调度",charIndex:6496},{level:4,title:"6.1.1 概述",slug:"_6-1-1-概述",normalizedTitle:"6.1.1 概述",charIndex:6604},{level:4,title:"6.1.2 基本语法",slug:"_6-1-2-基本语法",normalizedTitle:"6.1.2 基本语法",charIndex:6719},{level:4,title:"6.1.3 快速入门",slug:"_6-1-3-快速入门",normalizedTitle:"6.1.3 快速入门",charIndex:6861},{level:5,title:"任务书写格式：",slug:"任务书写格式",normalizedTitle:"任务书写格式：",charIndex:7022},{level:5,title:"5 个占位符的说明：",slug:"_5-个占位符的说明",normalizedTitle:"5 个占位符的说明：",charIndex:7111},{level:5,title:"特殊符号的说明",slug:"特殊符号的说明",normalizedTitle:"特殊符号的说明",charIndex:7425},{level:3,title:"6.2 at 定时任务",slug:"_6-2-at-定时任务",normalizedTitle:"6.2 at 定时任务",charIndex:7878},{level:4,title:"6.2.1 at 时间定义的方法",slug:"_6-2-1-at-时间定义的方法",normalizedTitle:"6.2.1 at 时间定义的方法",charIndex:8569},{level:2,title:"7. 磁盘分区、挂载",slug:"_7-磁盘分区、挂载",normalizedTitle:"7. 磁盘分区、挂载",charIndex:9131},{level:3,title:"7.1 Linux 分区",slug:"_7-1-linux-分区",normalizedTitle:"7.1 linux 分区",charIndex:9146},{level:4,title:"7.1.1 原理介绍",slug:"_7-1-1-原理介绍",normalizedTitle:"7.1.1 原理介绍",charIndex:9197},{level:4,title:"7.1.2 硬盘说明",slug:"_7-1-2-硬盘说明",normalizedTitle:"7.1.2 硬盘说明",charIndex:9389},{level:4,title:"7.1.3 查看所有设备挂载情况",slug:"_7-1-3-查看所有设备挂载情况",normalizedTitle:"7.1.3 查看所有设备挂载情况",charIndex:9728},{level:3,title:"7.2 挂载的经典案例 —— 增加一块硬盘",slug:"_7-2-挂载的经典案例-增加一块硬盘",normalizedTitle:"7.2 挂载的经典案例 —— 增加一块硬盘",charIndex:9830},{level:4,title:"1）虚拟机添加硬盘",slug:"_1-虚拟机添加硬盘",normalizedTitle:"1）虚拟机添加硬盘",charIndex:9932},{level:4,title:"2）磁盘分区",slug:"_2-磁盘分区",normalizedTitle:"2）磁盘分区",charIndex:10022},{level:4,title:"3）格式化磁盘",slug:"_3-格式化磁盘",normalizedTitle:"3）格式化磁盘",charIndex:10249},{level:4,title:"4）挂载",slug:"_4-挂载",normalizedTitle:"4）挂载",charIndex:10347},{level:4,title:"5）设置自动挂载",slug:"_5-设置自动挂载",normalizedTitle:"5）设置自动挂载",charIndex:10499},{level:3,title:"7.3 磁盘情况查询",slug:"_7-3-磁盘情况查询",normalizedTitle:"7.3 磁盘情况查询",charIndex:10681},{level:4,title:"7.3.1 查询系统整体磁盘使用情况",slug:"_7-3-1-查询系统整体磁盘使用情况",normalizedTitle:"7.3.1 查询系统整体磁盘使用情况",charIndex:10695},{level:4,title:"7.3.2 查询指定目录的磁盘占用情况",slug:"_7-3-2-查询指定目录的磁盘占用情况",normalizedTitle:"7.3.2 查询指定目录的磁盘占用情况",charIndex:11388},{level:3,title:"7.4 磁盘情况 - 工作实用指令",slug:"_7-4-磁盘情况-工作实用指令",normalizedTitle:"7.4 磁盘情况 - 工作实用指令",charIndex:11768},{level:4,title:"1）统计 /opt 文件夹下文件的个数",slug:"_1-统计-opt-文件夹下文件的个数",normalizedTitle:"1）统计 /opt 文件夹下文件的个数",charIndex:11789},{level:4,title:"2）统计 /opt 文件夹下目录的个数",slug:"_2-统计-opt-文件夹下目录的个数",normalizedTitle:"2）统计 /opt 文件夹下目录的个数",charIndex:11844},{level:4,title:"3）统计 /opt 文件夹下文件的个数，包括子文件夹下的",slug:"_3-统计-opt-文件夹下文件的个数-包括子文件夹下的",normalizedTitle:"3）统计 /opt 文件夹下文件的个数，包括子文件夹下的",charIndex:11899},{level:4,title:"4）统计 /opt 文件夹下目录的个数，包括子文件夹下的",slug:"_4-统计-opt-文件夹下目录的个数-包括子文件夹下的",normalizedTitle:"4）统计 /opt 文件夹下目录的个数，包括子文件夹下的",charIndex:11964},{level:4,title:"5）以树状显示目录结构",slug:"_5-以树状显示目录结构",normalizedTitle:"5）以树状显示目录结构",charIndex:12029}],headersStr:"1. Vi 和 Vim 编辑器 2. 开机、重启与用户登录注销 2.1 关机 & 重启命令 2.2 用户登录与注销 3. 用户管理 3.1 添加用户 3.2 指定/修改密码 3.3 删除用户 3.4 查询用户信息 3.5 切换用户 3.6 查看当前登录用户 3.7 用户组 3.8 用户和组相关的文件 4. 实用指令 4.1 运行级别 CentOS 7 后运行级别说明 4.2 找回 root 密码 4.3 帮助指令 4.4 时间日期类 4.4.1 date 显示当前日期 4.4.2 cal 显示日历 4.5 搜索查找类 4.5.1 find 4.5.2 locate 4.5.3 which 4.5.4 grep 指令和管道符号 | 4.6 压缩和解压类 4.6.1 gzip 压缩 & gunzip 解压 4.6.2 zip 压缩 & unzip 解压 4.6.3 tar 打包 ⭐️ 5. 组管理和权限管理 5.1 所有者 5.1.1 查看文件的所有者 5.1.2 修改文件所有者 5.2 组的创建 5.3 所在组 53.1 查看文件的所在组 5.3.2 修改文件的所在组 5.4 其他组 5.5 改变用户的所在组 5.6 文件的权限 5.6.1 权限的基本介绍 5.6.2 rwx 权限 ⭐️ 1）rwx 作用到文件** 2）rwx 作用到目录** 5.6.3 权限的数字表示 5.6.4 chmod 修改权限 1）第一种方式：+ - = 变更权限 2）第二种方式：通过数字变更权限 5.6.5 其他说明 6. 定时任务调度 6.1 crond 任务调度 6.1.1 概述 6.1.2 基本语法 6.1.3 快速入门 任务书写格式： 5 个占位符的说明： 特殊符号的说明 6.2 at 定时任务 6.2.1 at 时间定义的方法 7. 磁盘分区、挂载 7.1 Linux 分区 7.1.1 原理介绍 7.1.2 硬盘说明 7.1.3 查看所有设备挂载情况 7.2 挂载的经典案例 —— 增加一块硬盘 1）虚拟机添加硬盘 2）磁盘分区 3）格式化磁盘 4）挂载 5）设置自动挂载 7.3 磁盘情况查询 7.3.1 查询系统整体磁盘使用情况 7.3.2 查询指定目录的磁盘占用情况 7.4 磁盘情况 - 工作实用指令 1）统计 /opt 文件夹下文件的个数 2）统计 /opt 文件夹下目录的个数 3）统计 /opt 文件夹下文件的个数，包括子文件夹下的 4）统计 /opt 文件夹下目录的个数，包括子文件夹下的 5）以树状显示目录结构",content:'# 1. Vi 和 Vim 编辑器\n\n要会一些基本的快捷键，一般在 Linux 下不需要特别复杂的操作。\n\n三种模式之间的相互切换\n\n * 一般模式\n\n * 编辑模式\n\n * 命令模式\n   \n   :wq（保存退出）\n   \n   :q（退出）\n   \n   :q!（强制退出，不保存）\n\n\n# 2. 开机、重启与用户登录注销\n\n\n# 2.1 关机 & 重启命令\n\n命令                         说明\nshutdown -h now            立刻进行关机\nshutdown -h 2              “hello，2 分钟后会关机了”\nshutdown -r now = reboot   现在重启\nhalt                       关机，与上面一样\nsync                       把内存的数据同步到磁盘\n\n * 不管是重启还是关机，首先要运行 sync 命令，把内存中的数据写到磁盘中。目前的 shutdown/reboot/halt 等命令均在关机前进行了 sync，但小心驶得万年船。\n * root 才可以关机。\n\n\n# 2.2 用户登录与注销\n\n登录时尽量少用 root 账号，避免操作失误。使用 su <用户名> 可以切换身份。\n\nlogout 命令即可注销用户。这个指令在图形运行级别无效。\n\n\n# 3. 用户管理\n\nLinux 是一个多用户多任务的操作系统。\n\n\n# 3.1 添加用户\n\n语法：useradd 用户名\n\n * 当用户创建成功后，会自动创建与用户同名的家目录（/home/用户名）。\n * 也可以通过 useradd -d 指定目录 用户名 来给新用户指定家目录。\n\n\n# 3.2 指定/修改密码\n\npasswd tom：给 tom 指定密码\n\n**注：**若不指定用户名，则是修改当前用户的用户名。\n\n\n# 3.3 删除用户\n\n * userdel nrich：删除用户 nrich，但要保留家目录\n * userdel -r nrich：删除用户及其家目录\n\n一般情况下，我们建议保留，毕竟他所做的工作放在了里面。\n\n\n# 3.4 查询用户信息\n\nid 用户名：查询该用户的信息，当用户不存在时返回无此用户。\n\n\n# 3.5 切换用户\n\n当操作权限不够时，可以通过 su 命令切换到高权限用户。\n\n * 从高权限到低权限的切换不需要密码，反之需要。\n * 当需要返回到原来用户时，使用 exit/logout 指令。\n\n\n# 3.6 查看当前登录用户\n\nwhoami = who am I：显示第一次登录时的用户。\n\n> 此处自行尝试时，发现 whoami 显示的是当前切换过来的用户，who am i 显示的是第一次登陆时的用户。\n\n\n# 3.7 用户组\n\n类似于角色，用户组可以让系统对有共性/权限的多个用户进行统一管理。\n\n * groupadd 组名：新增组\n * groupdel 组名：删除组\n\n如何将让一个用户加入一个组呢？有以下几种方法：\n\n 1. 增加用户时直接加上组：useradd -g 用户组 用户名\n 2. 修改用户的组：usermod -g 用户组 用户名\n 3. 若一个用户没有指定加入哪个组，会默认在一个与自己同名的组中\n\n\n# 3.8 用户和组相关的文件\n\n * /etc/passwd 文件：用户的配置文件，记录用户的各种信息\n   \n   * 每行的含义：用户名:口令:用户标识号(uid):组标识号(gid):注释性描述:主目录(home中相应的目录):登录shell\n   \n   * shell 的简单解释：可以把传给 Linux 内核的命令解析（直接把命令传给 Linux 内核是无法被解析的），如下图。我们常用的是 bash。\n\n * /etc/shadow 文件：口令的配置文件\n   \n   * 每行的含义：登录名:加密口令:最后一次修改时间:最小时间间隔:最大时间间隔:警告时间:不活动时间:失效时间:标志\n\n * /etc/group 文件：组的配置文件，记录各组的信息\n   \n   * 每行的含义：组名:口令:组标识号:组内的用户列表\n\n\n# 4. 实用指令\n\n\n# 4.1 运行级别\n\n运行级别   说明\n0      关机\n1      单用户模式（可以帮助我们找回丢失密码）\n2      多用户状态没有网络服务\n3      多用户状态有网络服务【工作中常用】\n4      系统未使用，保留给用户\n5      图形界面\n6      系统重启\n\n * 常见运行级别是 3 和 5，也可以指定默认运行级别。\n\ninit <num>：切换到 num 运行级别，如 init 3 将切换到多用户状态有网络服务模式（没有图形界面）。\n\n# CentOS 7 后运行级别说明\n\n * multi-user.target：相当于 runlevel 3\n * graphical.target：相当于 runlevel 5\n\n查看当前默认运行级别：systemctl get-default\n\n设置默认运行级别：systemctl set-default TARGET.target\n\n> 当我们在图形化下将默认运行级别设为 multi-user.target 后，重启系统后会默认进入黑框框界面，即 runlevel 3。\n\n\n# 4.2 找回 root 密码\n\n// TODO\n\n不同版本的系统找回密码具体操作有所区别。\n\n\n# 4.3 帮助指令\n\n * man [命令或配置文件]：获得帮助信息，比如 man ls\n   \n   * 😄显示不全乎的按空格键继续往下走\n   * 在 Linux 下， 隐藏文件是以 . 开头的\n   * 选项可以组合使用，无顺序区别，比如 ls -al 或者 ls -la\n   * ls 命令还可以指定一个目录，比如 ls -l /root\n\n * help 命令：获得 shell 内置命令的帮助信息\n\n如果英语不太好，百度更直接。\n\n\n# 4.4 时间日期类\n\n# 4.4.1 date 显示当前日期\n\n * date 显示时间：\n   \n   * date：显示当前日期\n   * date "+format"：format 中可以用 %Y（年）、%m（月）、%d111（日）、%H（时）、%M（月）、%S（秒），比如 date "+%Y-%m-%d %H:%M:%S"\n\n * date 设置时间： date -s "2020-11-03 20:02:10" ，时间为字符串格式\n\n# 4.4.2 cal 显示日历\n\ncalendar 的缩写。\n\ncal [选项]\n\n\n1\n\n * 默认显示本月日历\n * cal 2020：显示 2020 全年的日历\n\n\n# 4.5 搜索查找类\n\n# 4.5.1 find\n\nfind 指令将从指定目录向下递归地遍历其各个子目录，将满足条件的文件或目录显示出来。\n\nfind [搜索范围] [选项]\n\n\n1\n\n * -name <查询方式>：按指定的文件名查找模式查找文件，也可以加匹配符 * 等。\n * -user <用户名>：查找属于指定用户名的所有文件\n * -size <文件大小>：按照指定的文件大小查找文件\n\n> 案例：\n> \n>  * 根据名称查找 /home 目录下的 hello.txt：find /home -name hello.txt\n>  * 查找 /opt 下用户 nrich 的文件：find /opt -user nrich\n>  * 查找整个 linux 系统下大于 200M 的文件(+n 大于， -n 小于，单位有 k, M, G)：find / -size +200M\n\n# 4.5.2 locate\n\nlocate 可以快速定位文件路径。locate 指令利用事先建立的数据库实现快速定位，它无需遍历整个文件系统因而较快。为了保证查询结果准确性，管理员必须定期更新 locate 时刻：updatedb。\n\nlocate [搜索文件]：\n\n * 第一次使用前，必须使用 updatedb 指令来创建 locate 数据库。\n\n# 4.5.3 which\n\nwhich 可以查看某个指令在哪个目录下。比如 which ls 查看 ls 指令在哪个目录。\n\n# 4.5.4 grep 指令和管道符号 |\n\ngrep 过滤查找。\n\n管道夫 | 表示将前一个命令的处理结果输出传递给后面的命令处理。\n\ngrep [选项] 查找内容 源文件\n\n\n1\n\n * -n：显示匹配行及行号\n * -i：忽略字母大小写\n\n> 案例：在 hello.text 文件中查找“yes”所在行，并显示行号\n> \n>  * 写法1：cat /home/hello.txt | grep -n "yes"\n>  * 写法2：grep -n "yes" /home/hello.txt\n\n\n# 4.6 压缩和解压类\n\n# 4.6.1 gzip 压缩 & gunzip 解压\n\n * gzip 文件：压缩文件为 *.gz 文件\n   \n   📝 压缩的同时会把原文件删除！\n\n * gunzip 文件.gz：解压\n\n📝 解压的同时也会把压缩文件删除\n\n# 4.6.2 zip 压缩 & unzip 解压\n\n * zip [选项] xxx.zip：压缩文件和目录。-r 递归压缩，即压缩目录。\n * unzip [选项] xxx.zip：解压缩文件。-d <目录> 指定解压后文件的存放目录。\n\n> 案例：\n> \n>  * 将 home 本身及 /home 下的所有文件压缩：zip -r myhome.zip /home/\n>  * 将 myhome.zip 解压到 /opt/tmp 目录下：unzip -d /opt/tmp /home/myhome.zip\n\n# 4.6.3 tar 打包 ⭐️\n\ntar 是打包指令（仅仅打包但不压缩），最后打包后的文件是 xxx.tar.gz 文件。\n\ntar [选项] xxx.tar.gz 打包的内容：打包目录，压缩后的文件格式为 xxx.tar.gz\n\n * -c：【create】创建一个新的打包文件\n * -v：【verbose】显示详细信息\n * -f：【filename】指定压缩后的文件名\n * -z：【gzip】打包同时用 gzip 算法压缩\n * -x：【extract】解包 .tar 文件\n\n常用的选项组合：\n\n * 打包并压缩：tar -zcvf xxx.tar.gz [原文件名/目录名]\n * 解压并解包：tar -zxvf xxx.tar.gz [目的地]\n\n> 案例：\n> \n>  * 将 pig.txt 和 cat.txt 压缩成 pc.tar.gz：tar -zcvf pc.tar.gz pig.txt cat.txt\n>  * 将 /home 文件夹压缩成 myhome.tar.gz：tar -zcvf myhome.tar.gz /home/\n>  * 将 pc.tar.gz 解压到当前目录：tar -zxvf pc.tar.gz\n>  * 将 pc.tar.gz 解压到 /opt/tmp 目录：tar -zxvf pc.tar.gz -C /opt/tmp\n\n\n# 5. 组管理和权限管理\n\nLinux 中每个用户必须属于一个组，不能独立于组外。每个文件有所有者、所在组、其他组的概念。\n\n> 目录也是一种特殊的文件，所以这里的“文件”也包括了目录。\n\n\n# 5.1 所有者\n\n创建文件的人是所有者，所有者可以更改。\n\n# 5.1.1 查看文件的所有者\n\nls -ahl\n\n\n1\n\n * 最后一列的蓝色表示这是个目录，白色表示是文件\n\n# 5.1.2 修改文件所有者\n\n * chown 用户名 文件名：【change owner】将文件的所有者改成指定的用户\n * chown newOwner:newGroup 文件名：同时改变所有者和所在组\n * -R：如果是目录，则使其下所有子文件或者目录递归生效\n\n\n# 5.2 组的创建\n\ngroupadd 组名：创建一个组\n\n> 案例：\n> \n>  * 创建一个组 monster：groupadd monster\n> \n>  * 创建一个用户 fox，并放到 monster 组中：\n>    \n>    useradd -g monster fox\n>    \n>    \n>    1\n>    \n>    * -g 表示 group\n\n\n# 5.3 所在组\n\n当某个用户创建了一个文件后，这个文件的所在组就是该用户所在的组（默认）。\n\n# 53.1 查看文件的所在组\n\nls -ahl\n\n\n1\n\n\n# 5.3.2 修改文件的所在组\n\nchgrp 组名 文件名：【change group】\n\n\n# 5.4 其他组\n\n除了文件的所有者和所在组的用户外，系统的其他用户都是文件的其他组。\n\n\n# 5.5 改变用户的所在组\n\nroot 的管理权限可以改变某个用户的所在组。\n\n * usermod -g 新组名 用户名：修改用户的所在组。\n\n> usermod 可以用来修改用户账号的各项设定，具体可查 usermod命令 | 菜鸟教程(opens new window)\n\n\n# 5.6 文件的权限\n\n# 5.6.1 权限的基本介绍\n\n下图的第一列便是权限：\n\n * 第 0 位表示文件类型：l 链接，d 目录，c 字符设备文件（如鼠标、光盘），b 块设备（如硬盘），- 普通文件\n * 第 1~3 位表示所有者拥有该文件的权限\n * 第 4~6 位表示所属组拥有该文件的权限\n * 第 7~9 位表示其他用户拥有该文件的权限\n\n# 5.6.2 rwx 权限 ⭐️\n\n# 1）rwx 作用到文件**\n\n * 【r】可读\n * 【w】可写。可以修改但不代表可以删除该文件，删除一个文件的前提条件是对该文件所在的目录有写权限。\n * 【x】可执行（execute）\n\n# 2）rwx 作用到目录**\n\n * 【r】可读。ls 可以查看目录内容。\n * 【w】可写。可以对目录内创建 + 删除 + 重命名目录。\n * 【x】可执行。可以进入该目录。此时根据目录中文件的权限，对其该读读，该写写。\n\n# 5.6.3 权限的数字表示\n\n$r=4, w=2, x =1$\n\n因此 rwx = 4+2+1 = 7，rw- = 4+2 = 6 等。\n\n# 5.6.4 chmod 修改权限\n\nchmod 可以修改文件/目录的权限：chmod [变更方式] 文件名\n\n# 1）第一种方式：+ - = 变更权限\n\n * u —— 所有者，user 的简写\n * g —— 所有组，group 的简写\n * o —— 其他人，other 的简写\n * a —— 所有人（即 u、g、o 的总和），all 的简写\n\n> 案例：给 foo.txt 的所有者赋予读写执行的权限，增加所在组写的权限，除去其他人读的权限\n> \n>  * chmod u=rwx,g+w,o-r foo.txt\n\n# 2）第二种方式：通过数字变更权限\n\n$r=4, w=2, x =1$\n\n> 案例：将 bar.txt 的权限修改为 rwxr-xr-x\n> \n>  * chmod 755 bar.txt\n\n# 5.6.5 其他说明\n\n * 权限列后的数字列：文件的硬连接数 | 目录的子目录数（不包含普通文件）。\n * 若要对目录内的文件进行操作，需要先有对该目录的相应权限。\n\n\n# 6. 定时任务调度\n\n\n# 6.1 crond 任务调度\n\ncrontab 进行定时任务的设置。该命令每分钟会定期检查是否有要执行的工作，如果有要执行的工作便会自动执行该工作。\n\n> 英语：crond 定时任务，crontab 定时任务\n\n# 6.1.1 概述\n\n任务调度：是指系统在某个时间执行特定的命令或程序。\n\n任务调度分类：\n\n * 系统工作：系统周期性所要执行的工作，如病毒扫描\n * 个别用户工作：某个用户定期要做的工作，比如对 MySQL 数据库的备份\n\n# 6.1.2 基本语法\n\ncrontab [选项]\n\n\n1\n\n * -e：使用编辑器来编辑 crontab 定时任务\n * -l：列出目前的时程表\n * -r：删除当前用户的时程表（即删除所有 crontab 任务）\n\n重启任务调度： service crond restart\n\n# 6.1.3 快速入门\n\n设置任务调度文件：/etc/crontab\n\n设置个人任务调度：执行 crontab -e 命令，接着输入任务到调度文件。如输入 */1 * * * * ls -l /etc/ > /tmp/to.txt 表示每个小时的每分钟执行 ls -l /etc/ > /tmp/to.txt 命令。\n\n# 任务书写格式：\n\nf1 f2 f3 f4 f5 program\n\n\n1\n\n * program 处为定时执行的命令\n * f1 ~ f5 为指示时间的占位符，具体可见下面\n\n# 5 个占位符的说明：\n\n*    *    *    *    *\n-    -    -    -    -\n|    |    |    |    |\n|    |    |    |    +----- 星期中星期几 (0 - 6) (星期天 为0)\n|    |    |    +---------- 月份 (1 - 12) \n|    |    +--------------- 一个月中的第几天 (1 - 31)\n|    +-------------------- 小时 (0 - 23)\n+------------------------- 分钟 (0 - 59)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n# 特殊符号的说明\n\n特殊符号   含义\n*      代表任何时间，比如第一个 * 就代表一个小时中每分钟执行一次的意思。\n,      代表不连续的时间，如 0 8,12,16 * * * 命令就代表每天的8点0分、12点0分、16点0分都执行一次命令。\n-      代表连续的时间范围，如 0 5 * * 1-6 命令就代表周一到周六的凌晨5点0分执行命令\n*/n    代表每隔多久执行一次，如 */10 * * * * 就代表每隔 10 分钟就执行一次命令\n\n> 案例可见 crontab 命令 | 菜鸟教程\n\n> 案例：每隔一分钟，将当前日期和日历都追加到 /home/mycal 文件中：（1） vim /home/my.sh ，写入内容： date >> /home/mycal 和 cal >> /home/mycal （2）给 my.sh 增加执行权限：chmod u+x /home/my.sh （3）crontab -e 增加 */1 * * * * /home/my.sh\n\n\n# 6.2 at 定时任务\n\ncrond 是反复执行的任务，而 at 命令是一次性定时计划任务，其守护进程 atd 会以后台模式运行，检查任务队列来运行。\n\n默认情况下，atd 守护进程每分钟检查一次作业队列，有作业时会检查其运行时间，若匹配则运行此作业。在使用 at 命令时，一定要保证 atd 进程的启动，可以使用 ps -ef | grep atd 来检测 atd 是否在运行。\n\n * ps -ef | grep atd：查看所有进程并过滤出 atd\n\n如图所示，上面一条表示 atd 进程已经启动，下面一条表示当前查看 atd 是否运行的指令。\n\n> 启动 atd 进程：sudo service atd start 或 sudo systemctl start atd\n\n命令格式：at [选项] [时间] ，两次 Ctrl + D 结束 at 命令的输入，Ctrl + Backspace 删除\n\n * -m 当指定的任务被完成之后，将给用户发送邮件，即使没有标准输出\n * -I atq的别名\n * -d atrm的别名（删除已经设置的任务，e.g. atrm 4 表示删除 job 队列中编号为4的 job）\n * -v 显示任务将被执行的时间\n * -c 打印任务的内容到标准输出\n * -V 显示版本信息\n * -q<列队> 使用指定的列队\n * -f<文件> 从指定文件读入任务而不是从标准输入读入\n * -t<时间参数> 以时间参数的形式提交要运行的任务\n\n> 注： atd 一次只会执行一个任务，从 job 队列中一次检查一个 job 是否该执行了。\n\n# 6.2.1 at 时间定义的方法\n\n * 接受在当天的 hh:mm（小时:分钟）式的时间指定。假如该时间已过去，那么就放在第二天执行。\n * 使用 midnight（深夜），noon（中午），teatime（饮茶时间，一般是下午4点）等比较模糊的 词语来指定时间。\n * 采用 12 小时计时制，即在时间后面加上 AM（上午）或 PM（下午）来说明是上午还是下午。\n * 指定命令执行的具体日期，指定格式为 month day（月 日）或 mm/dd/yy（月/日/年）或 dd.mm.yy（日.月.年）。指定的日期必须跟在指定时间的后面。\n * 使用相对计时法，指定格式为：now + count time-units ，now 就是当前时间，time-units 是时间单位，这里能够是minutes（分钟）、hours（小时）、days（天）、weeks（星期）。count 是时间的数量，究竟是几天，还是几小时，等等。比如 now + 5 minutes。\n * 直接使用today（今天）、tomorrow（明天）来指定完成命令的时间。\n\n> 案例：2 天后的下午 5 点执行 /bin/ls /home\n\n先输入 at [选项] [时间] 后回车，再接着输入命令，输入完后按两次 Ctrl D 结束输入\n\n\n# 7. 磁盘分区、挂载\n\n\n# 7.1 Linux 分区\n\n🖊 目录只是个目录，目录中的内容在物理上是存放在硬盘的分区中的。\n\n# 7.1.1 原理介绍\n\nLinux 来说无论有几个分区，分给哪一目录使用，它归根结底就只有一个根目录，一个独立且唯一的文件结构，Linux 中每个分区都是用来组成整个文件系统的一部分。\n\nLinux 采用了一种叫“载入”的处理方法，它的整个文件系统中包含了一整套的文件和目录， 且将一个分区和一个目录联系起来。这时要载入的一个分区将使它的存储空间在一个目录下获得。\n\n示意图：\n\n# 7.1.2 硬盘说明\n\nLinux 硬盘分 IDE 硬盘和 SCSI 硬盘，目前基本上是 SCSI 硬盘。\n\n * 对于 IDE 硬盘，驱动器标识符为“hdx~”，“hd”表明分区所在设备的类型，这里是指IDE硬盘。“x”为盘号（a 为基本盘，b 为基本从属盘，c 为辅助主盘，d 为辅助从属盘），“~”代表分区，前四个分区用数字1到4表示，它们是主分区或扩展分区，从5开始就是逻辑分区。比如 hda3 表示为第一个 IDE 硬盘上的第三个主分区或扩展分区，hdb2 表示为第二个 IDE 硬盘上的第二个主分区或扩展分区。\n * 对于 SCSI 硬盘，驱动器标识符为“sdx~”，SCSI 硬盘是用“sd”来表示分区所在设备的类型，其余则和 IDE 硬盘的表示方法一样。\n\n# 7.1.3 查看所有设备挂载情况\n\n命令：lsblk 或者 lsblk -f\n\n * lsblk：英文是“list block”，即用于列出所有可用块设备的信息\n\n> 图中的 sr0 是指光驱。\n\n\n# 7.2 挂载的经典案例 —— 增加一块硬盘\n\n目标：给 Linux 系统增加一块新的硬盘，并且挂载到 /newdisk\n\n主要有以下5个步骤：虚拟机添加硬盘、分区、格式化、挂载、设置可以自动挂载。\n\n# 1）虚拟机添加硬盘\n\n在【虚拟机】菜单中，选择【设置】，然后设备列表里添加硬盘，然后一路【下一步】，中间只有选择磁盘大小的地方需要修改，直到完成。然后重启系统（才能识别）！\n\n# 2）磁盘分区\n\n分区命令：fdisk /dev/sdb\n\n开始对 /sdb 分区：\n\n命令   含义\nm    显示命令列表\nn    新增分区\nd    删除分区\nw    写入并退出\n\n做法：开始分区后输入 n，新增分区，然后选择 p，分区类型为主分区，分区号1-4可选，默认为1，1代表为只为磁盘划分一块分区，2代表为磁盘划分两块分区，依次类推。此次案例选择1。两次回车默认剩余全部空间。最后输入 w 写入分区并退出，若不保存退出输入 q。\n\n# 3）格式化磁盘\n\n命令：mkfs -t ext4 /dev/sdb1\n\n * 其中 ext4 是分区类型\n\n格式化之后才会有上图中的 UUID （唯一标识符）给这个分区，此分区才可以使用。\n\n# 4）挂载\n\n挂载: 将一个分区与一个目录联系起来。\n\n命令：mount 设备名称 挂载目录\n\n * 此次案例为 mount /dev/sdb1 /newdisk\n * 去除挂载命令为 umount 设备名称或者挂载目录，比如 umount /dev/sdb1 或者 umount /newdisk\n\n# 5）设置自动挂载\n\n用命令行挂载只能实现临时挂载，重启系统后，挂载就会失效。设置自动挂载，即永久挂载，当重启系统，仍然可以挂载到指定目录。\n\n通过修改 /etc/fstab 文件实现永久挂载。\n\n * 此次案例在文件中增加 /dev/sdb1 /newdisk ext4 defaults 0 0\n * 保存并退出文件后，执行 mount –a 即刻生效\n\n\n# 7.3 磁盘情况查询\n\n# 7.3.1 查询系统整体磁盘使用情况\n\n命令：df -h\n\n * df：disk free，显示目前在 Linux 系统上的文件系统磁盘使用情况统计\n * -h：human readable，使用人类可读的格式(预设值是不加这个选项的\n\n可用于查询系统整体磁盘使用情况：\n\n$ df -h\n文件系统                 容量  已用  可用 已用% 挂载点\ndevtmpfs                 974M     0  974M    0% /dev\ntmpfs                    991M     0  991M    0% /dev/shm\ntmpfs                    991M   11M  980M    2% /run\ntmpfs                    991M     0  991M    0% /sys/fs/cgroup\n/dev/mapper/centos-root   17G  5.4G   11G   34% /\n/dev/sda1                976M  177M  733M   20% /boot\nvmhgfs-fuse              400G  317G   84G   80% /mnt/hgfs\ntmpfs                    199M   52K  198M    1% /run/user/1000\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n * 当“已用”超过 80% 后就不正常了，应该想到扩容。\n\n# 7.3.2 查询指定目录的磁盘占用情况\n\n命令：du -h\n\n * du：disk usage，显示指定的目录或文件所占用的磁盘空间，默认是当前目录。\n * -s：指定目录占用大小汇总\n * -h：带计量单位\n * -a：含文件\n * --max-depth=1：子目录深度为1\n * -c：列出明细的同时，增加汇总值\n\n> 案例：查看 /opt 目录的磁盘占用情况，深度为 1\n> \n> $ du -hac --max-depth=1 /opt\n> 163M\t/opt/vmware-tools-distrib\n> 4.0K\t/opt/rh\n> 54M\t    /opt/VMwareTools-10.3.10-13959562.tar.gz\n> 216M\t/opt\n> 216M\t总用量\n> \n> \n> 1\n> 2\n> 3\n> 4\n> 5\n> 6\n\n\n# 7.4 磁盘情况 - 工作实用指令\n\n# 1）统计 /opt 文件夹下文件的个数\n\nls -l /opt | grep "^-" | wc -l\n\n# 2）统计 /opt 文件夹下目录的个数\n\nls -l /opt | grep "^d" | wc -l\n\n# 3）统计 /opt 文件夹下文件的个数，包括子文件夹下的\n\nls -lR /opt | grep "^-" | wc -l\n\n# 4）统计 /opt 文件夹下目录的个数，包括子文件夹下的\n\nls -lR /opt | grep "^d" | wc -l\n\n# 5）以树状显示目录结构\n\nyum install tree 后 tree 指定目录\n\n$ tree .\n.\n├── aaa\n│   └── abc.txt\n├── bar.txt\n├── foo.txt\n\n\n1\n2\n3\n4\n5\n6\n\n\n> 补充：wc 命令\n> \n> wc（Word Count）命令的功能为统计指定文件中的字节数、字数、行数，并将统计结果显示输出。\n> \n> 命令：wc [选项] [文件]\n> \n>  * -c：统计字节数\n>  * -l：统计行数\n>  * -m：统计字符数，这个选项不能与 -c 一起使用\n>  * -w：统计字数，一个字被定义为由空白、跳格或换行字符分隔的字符串\n>  * -L：统计最长行的长度',normalizedContent:'# 1. vi 和 vim 编辑器\n\n要会一些基本的快捷键，一般在 linux 下不需要特别复杂的操作。\n\n三种模式之间的相互切换\n\n * 一般模式\n\n * 编辑模式\n\n * 命令模式\n   \n   :wq（保存退出）\n   \n   :q（退出）\n   \n   :q!（强制退出，不保存）\n\n\n# 2. 开机、重启与用户登录注销\n\n\n# 2.1 关机 & 重启命令\n\n命令                         说明\nshutdown -h now            立刻进行关机\nshutdown -h 2              “hello，2 分钟后会关机了”\nshutdown -r now = reboot   现在重启\nhalt                       关机，与上面一样\nsync                       把内存的数据同步到磁盘\n\n * 不管是重启还是关机，首先要运行 sync 命令，把内存中的数据写到磁盘中。目前的 shutdown/reboot/halt 等命令均在关机前进行了 sync，但小心驶得万年船。\n * root 才可以关机。\n\n\n# 2.2 用户登录与注销\n\n登录时尽量少用 root 账号，避免操作失误。使用 su <用户名> 可以切换身份。\n\nlogout 命令即可注销用户。这个指令在图形运行级别无效。\n\n\n# 3. 用户管理\n\nlinux 是一个多用户多任务的操作系统。\n\n\n# 3.1 添加用户\n\n语法：useradd 用户名\n\n * 当用户创建成功后，会自动创建与用户同名的家目录（/home/用户名）。\n * 也可以通过 useradd -d 指定目录 用户名 来给新用户指定家目录。\n\n\n# 3.2 指定/修改密码\n\npasswd tom：给 tom 指定密码\n\n**注：**若不指定用户名，则是修改当前用户的用户名。\n\n\n# 3.3 删除用户\n\n * userdel nrich：删除用户 nrich，但要保留家目录\n * userdel -r nrich：删除用户及其家目录\n\n一般情况下，我们建议保留，毕竟他所做的工作放在了里面。\n\n\n# 3.4 查询用户信息\n\nid 用户名：查询该用户的信息，当用户不存在时返回无此用户。\n\n\n# 3.5 切换用户\n\n当操作权限不够时，可以通过 su 命令切换到高权限用户。\n\n * 从高权限到低权限的切换不需要密码，反之需要。\n * 当需要返回到原来用户时，使用 exit/logout 指令。\n\n\n# 3.6 查看当前登录用户\n\nwhoami = who am i：显示第一次登录时的用户。\n\n> 此处自行尝试时，发现 whoami 显示的是当前切换过来的用户，who am i 显示的是第一次登陆时的用户。\n\n\n# 3.7 用户组\n\n类似于角色，用户组可以让系统对有共性/权限的多个用户进行统一管理。\n\n * groupadd 组名：新增组\n * groupdel 组名：删除组\n\n如何将让一个用户加入一个组呢？有以下几种方法：\n\n 1. 增加用户时直接加上组：useradd -g 用户组 用户名\n 2. 修改用户的组：usermod -g 用户组 用户名\n 3. 若一个用户没有指定加入哪个组，会默认在一个与自己同名的组中\n\n\n# 3.8 用户和组相关的文件\n\n * /etc/passwd 文件：用户的配置文件，记录用户的各种信息\n   \n   * 每行的含义：用户名:口令:用户标识号(uid):组标识号(gid):注释性描述:主目录(home中相应的目录):登录shell\n   \n   * shell 的简单解释：可以把传给 linux 内核的命令解析（直接把命令传给 linux 内核是无法被解析的），如下图。我们常用的是 bash。\n\n * /etc/shadow 文件：口令的配置文件\n   \n   * 每行的含义：登录名:加密口令:最后一次修改时间:最小时间间隔:最大时间间隔:警告时间:不活动时间:失效时间:标志\n\n * /etc/group 文件：组的配置文件，记录各组的信息\n   \n   * 每行的含义：组名:口令:组标识号:组内的用户列表\n\n\n# 4. 实用指令\n\n\n# 4.1 运行级别\n\n运行级别   说明\n0      关机\n1      单用户模式（可以帮助我们找回丢失密码）\n2      多用户状态没有网络服务\n3      多用户状态有网络服务【工作中常用】\n4      系统未使用，保留给用户\n5      图形界面\n6      系统重启\n\n * 常见运行级别是 3 和 5，也可以指定默认运行级别。\n\ninit <num>：切换到 num 运行级别，如 init 3 将切换到多用户状态有网络服务模式（没有图形界面）。\n\n# centos 7 后运行级别说明\n\n * multi-user.target：相当于 runlevel 3\n * graphical.target：相当于 runlevel 5\n\n查看当前默认运行级别：systemctl get-default\n\n设置默认运行级别：systemctl set-default target.target\n\n> 当我们在图形化下将默认运行级别设为 multi-user.target 后，重启系统后会默认进入黑框框界面，即 runlevel 3。\n\n\n# 4.2 找回 root 密码\n\n// todo\n\n不同版本的系统找回密码具体操作有所区别。\n\n\n# 4.3 帮助指令\n\n * man [命令或配置文件]：获得帮助信息，比如 man ls\n   \n   * 😄显示不全乎的按空格键继续往下走\n   * 在 linux 下， 隐藏文件是以 . 开头的\n   * 选项可以组合使用，无顺序区别，比如 ls -al 或者 ls -la\n   * ls 命令还可以指定一个目录，比如 ls -l /root\n\n * help 命令：获得 shell 内置命令的帮助信息\n\n如果英语不太好，百度更直接。\n\n\n# 4.4 时间日期类\n\n# 4.4.1 date 显示当前日期\n\n * date 显示时间：\n   \n   * date：显示当前日期\n   * date "+format"：format 中可以用 %y（年）、%m（月）、%d111（日）、%h（时）、%m（月）、%s（秒），比如 date "+%y-%m-%d %h:%m:%s"\n\n * date 设置时间： date -s "2020-11-03 20:02:10" ，时间为字符串格式\n\n# 4.4.2 cal 显示日历\n\ncalendar 的缩写。\n\ncal [选项]\n\n\n1\n\n * 默认显示本月日历\n * cal 2020：显示 2020 全年的日历\n\n\n# 4.5 搜索查找类\n\n# 4.5.1 find\n\nfind 指令将从指定目录向下递归地遍历其各个子目录，将满足条件的文件或目录显示出来。\n\nfind [搜索范围] [选项]\n\n\n1\n\n * -name <查询方式>：按指定的文件名查找模式查找文件，也可以加匹配符 * 等。\n * -user <用户名>：查找属于指定用户名的所有文件\n * -size <文件大小>：按照指定的文件大小查找文件\n\n> 案例：\n> \n>  * 根据名称查找 /home 目录下的 hello.txt：find /home -name hello.txt\n>  * 查找 /opt 下用户 nrich 的文件：find /opt -user nrich\n>  * 查找整个 linux 系统下大于 200m 的文件(+n 大于， -n 小于，单位有 k, m, g)：find / -size +200m\n\n# 4.5.2 locate\n\nlocate 可以快速定位文件路径。locate 指令利用事先建立的数据库实现快速定位，它无需遍历整个文件系统因而较快。为了保证查询结果准确性，管理员必须定期更新 locate 时刻：updatedb。\n\nlocate [搜索文件]：\n\n * 第一次使用前，必须使用 updatedb 指令来创建 locate 数据库。\n\n# 4.5.3 which\n\nwhich 可以查看某个指令在哪个目录下。比如 which ls 查看 ls 指令在哪个目录。\n\n# 4.5.4 grep 指令和管道符号 |\n\ngrep 过滤查找。\n\n管道夫 | 表示将前一个命令的处理结果输出传递给后面的命令处理。\n\ngrep [选项] 查找内容 源文件\n\n\n1\n\n * -n：显示匹配行及行号\n * -i：忽略字母大小写\n\n> 案例：在 hello.text 文件中查找“yes”所在行，并显示行号\n> \n>  * 写法1：cat /home/hello.txt | grep -n "yes"\n>  * 写法2：grep -n "yes" /home/hello.txt\n\n\n# 4.6 压缩和解压类\n\n# 4.6.1 gzip 压缩 & gunzip 解压\n\n * gzip 文件：压缩文件为 *.gz 文件\n   \n   📝 压缩的同时会把原文件删除！\n\n * gunzip 文件.gz：解压\n\n📝 解压的同时也会把压缩文件删除\n\n# 4.6.2 zip 压缩 & unzip 解压\n\n * zip [选项] xxx.zip：压缩文件和目录。-r 递归压缩，即压缩目录。\n * unzip [选项] xxx.zip：解压缩文件。-d <目录> 指定解压后文件的存放目录。\n\n> 案例：\n> \n>  * 将 home 本身及 /home 下的所有文件压缩：zip -r myhome.zip /home/\n>  * 将 myhome.zip 解压到 /opt/tmp 目录下：unzip -d /opt/tmp /home/myhome.zip\n\n# 4.6.3 tar 打包 ⭐️\n\ntar 是打包指令（仅仅打包但不压缩），最后打包后的文件是 xxx.tar.gz 文件。\n\ntar [选项] xxx.tar.gz 打包的内容：打包目录，压缩后的文件格式为 xxx.tar.gz\n\n * -c：【create】创建一个新的打包文件\n * -v：【verbose】显示详细信息\n * -f：【filename】指定压缩后的文件名\n * -z：【gzip】打包同时用 gzip 算法压缩\n * -x：【extract】解包 .tar 文件\n\n常用的选项组合：\n\n * 打包并压缩：tar -zcvf xxx.tar.gz [原文件名/目录名]\n * 解压并解包：tar -zxvf xxx.tar.gz [目的地]\n\n> 案例：\n> \n>  * 将 pig.txt 和 cat.txt 压缩成 pc.tar.gz：tar -zcvf pc.tar.gz pig.txt cat.txt\n>  * 将 /home 文件夹压缩成 myhome.tar.gz：tar -zcvf myhome.tar.gz /home/\n>  * 将 pc.tar.gz 解压到当前目录：tar -zxvf pc.tar.gz\n>  * 将 pc.tar.gz 解压到 /opt/tmp 目录：tar -zxvf pc.tar.gz -c /opt/tmp\n\n\n# 5. 组管理和权限管理\n\nlinux 中每个用户必须属于一个组，不能独立于组外。每个文件有所有者、所在组、其他组的概念。\n\n> 目录也是一种特殊的文件，所以这里的“文件”也包括了目录。\n\n\n# 5.1 所有者\n\n创建文件的人是所有者，所有者可以更改。\n\n# 5.1.1 查看文件的所有者\n\nls -ahl\n\n\n1\n\n * 最后一列的蓝色表示这是个目录，白色表示是文件\n\n# 5.1.2 修改文件所有者\n\n * chown 用户名 文件名：【change owner】将文件的所有者改成指定的用户\n * chown newowner:newgroup 文件名：同时改变所有者和所在组\n * -r：如果是目录，则使其下所有子文件或者目录递归生效\n\n\n# 5.2 组的创建\n\ngroupadd 组名：创建一个组\n\n> 案例：\n> \n>  * 创建一个组 monster：groupadd monster\n> \n>  * 创建一个用户 fox，并放到 monster 组中：\n>    \n>    useradd -g monster fox\n>    \n>    \n>    1\n>    \n>    * -g 表示 group\n\n\n# 5.3 所在组\n\n当某个用户创建了一个文件后，这个文件的所在组就是该用户所在的组（默认）。\n\n# 53.1 查看文件的所在组\n\nls -ahl\n\n\n1\n\n\n# 5.3.2 修改文件的所在组\n\nchgrp 组名 文件名：【change group】\n\n\n# 5.4 其他组\n\n除了文件的所有者和所在组的用户外，系统的其他用户都是文件的其他组。\n\n\n# 5.5 改变用户的所在组\n\nroot 的管理权限可以改变某个用户的所在组。\n\n * usermod -g 新组名 用户名：修改用户的所在组。\n\n> usermod 可以用来修改用户账号的各项设定，具体可查 usermod命令 | 菜鸟教程(opens new window)\n\n\n# 5.6 文件的权限\n\n# 5.6.1 权限的基本介绍\n\n下图的第一列便是权限：\n\n * 第 0 位表示文件类型：l 链接，d 目录，c 字符设备文件（如鼠标、光盘），b 块设备（如硬盘），- 普通文件\n * 第 1~3 位表示所有者拥有该文件的权限\n * 第 4~6 位表示所属组拥有该文件的权限\n * 第 7~9 位表示其他用户拥有该文件的权限\n\n# 5.6.2 rwx 权限 ⭐️\n\n# 1）rwx 作用到文件**\n\n * 【r】可读\n * 【w】可写。可以修改但不代表可以删除该文件，删除一个文件的前提条件是对该文件所在的目录有写权限。\n * 【x】可执行（execute）\n\n# 2）rwx 作用到目录**\n\n * 【r】可读。ls 可以查看目录内容。\n * 【w】可写。可以对目录内创建 + 删除 + 重命名目录。\n * 【x】可执行。可以进入该目录。此时根据目录中文件的权限，对其该读读，该写写。\n\n# 5.6.3 权限的数字表示\n\n$r=4, w=2, x =1$\n\n因此 rwx = 4+2+1 = 7，rw- = 4+2 = 6 等。\n\n# 5.6.4 chmod 修改权限\n\nchmod 可以修改文件/目录的权限：chmod [变更方式] 文件名\n\n# 1）第一种方式：+ - = 变更权限\n\n * u —— 所有者，user 的简写\n * g —— 所有组，group 的简写\n * o —— 其他人，other 的简写\n * a —— 所有人（即 u、g、o 的总和），all 的简写\n\n> 案例：给 foo.txt 的所有者赋予读写执行的权限，增加所在组写的权限，除去其他人读的权限\n> \n>  * chmod u=rwx,g+w,o-r foo.txt\n\n# 2）第二种方式：通过数字变更权限\n\n$r=4, w=2, x =1$\n\n> 案例：将 bar.txt 的权限修改为 rwxr-xr-x\n> \n>  * chmod 755 bar.txt\n\n# 5.6.5 其他说明\n\n * 权限列后的数字列：文件的硬连接数 | 目录的子目录数（不包含普通文件）。\n * 若要对目录内的文件进行操作，需要先有对该目录的相应权限。\n\n\n# 6. 定时任务调度\n\n\n# 6.1 crond 任务调度\n\ncrontab 进行定时任务的设置。该命令每分钟会定期检查是否有要执行的工作，如果有要执行的工作便会自动执行该工作。\n\n> 英语：crond 定时任务，crontab 定时任务\n\n# 6.1.1 概述\n\n任务调度：是指系统在某个时间执行特定的命令或程序。\n\n任务调度分类：\n\n * 系统工作：系统周期性所要执行的工作，如病毒扫描\n * 个别用户工作：某个用户定期要做的工作，比如对 mysql 数据库的备份\n\n# 6.1.2 基本语法\n\ncrontab [选项]\n\n\n1\n\n * -e：使用编辑器来编辑 crontab 定时任务\n * -l：列出目前的时程表\n * -r：删除当前用户的时程表（即删除所有 crontab 任务）\n\n重启任务调度： service crond restart\n\n# 6.1.3 快速入门\n\n设置任务调度文件：/etc/crontab\n\n设置个人任务调度：执行 crontab -e 命令，接着输入任务到调度文件。如输入 */1 * * * * ls -l /etc/ > /tmp/to.txt 表示每个小时的每分钟执行 ls -l /etc/ > /tmp/to.txt 命令。\n\n# 任务书写格式：\n\nf1 f2 f3 f4 f5 program\n\n\n1\n\n * program 处为定时执行的命令\n * f1 ~ f5 为指示时间的占位符，具体可见下面\n\n# 5 个占位符的说明：\n\n*    *    *    *    *\n-    -    -    -    -\n|    |    |    |    |\n|    |    |    |    +----- 星期中星期几 (0 - 6) (星期天 为0)\n|    |    |    +---------- 月份 (1 - 12) \n|    |    +--------------- 一个月中的第几天 (1 - 31)\n|    +-------------------- 小时 (0 - 23)\n+------------------------- 分钟 (0 - 59)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n# 特殊符号的说明\n\n特殊符号   含义\n*      代表任何时间，比如第一个 * 就代表一个小时中每分钟执行一次的意思。\n,      代表不连续的时间，如 0 8,12,16 * * * 命令就代表每天的8点0分、12点0分、16点0分都执行一次命令。\n-      代表连续的时间范围，如 0 5 * * 1-6 命令就代表周一到周六的凌晨5点0分执行命令\n*/n    代表每隔多久执行一次，如 */10 * * * * 就代表每隔 10 分钟就执行一次命令\n\n> 案例可见 crontab 命令 | 菜鸟教程\n\n> 案例：每隔一分钟，将当前日期和日历都追加到 /home/mycal 文件中：（1） vim /home/my.sh ，写入内容： date >> /home/mycal 和 cal >> /home/mycal （2）给 my.sh 增加执行权限：chmod u+x /home/my.sh （3）crontab -e 增加 */1 * * * * /home/my.sh\n\n\n# 6.2 at 定时任务\n\ncrond 是反复执行的任务，而 at 命令是一次性定时计划任务，其守护进程 atd 会以后台模式运行，检查任务队列来运行。\n\n默认情况下，atd 守护进程每分钟检查一次作业队列，有作业时会检查其运行时间，若匹配则运行此作业。在使用 at 命令时，一定要保证 atd 进程的启动，可以使用 ps -ef | grep atd 来检测 atd 是否在运行。\n\n * ps -ef | grep atd：查看所有进程并过滤出 atd\n\n如图所示，上面一条表示 atd 进程已经启动，下面一条表示当前查看 atd 是否运行的指令。\n\n> 启动 atd 进程：sudo service atd start 或 sudo systemctl start atd\n\n命令格式：at [选项] [时间] ，两次 ctrl + d 结束 at 命令的输入，ctrl + backspace 删除\n\n * -m 当指定的任务被完成之后，将给用户发送邮件，即使没有标准输出\n * -i atq的别名\n * -d atrm的别名（删除已经设置的任务，e.g. atrm 4 表示删除 job 队列中编号为4的 job）\n * -v 显示任务将被执行的时间\n * -c 打印任务的内容到标准输出\n * -v 显示版本信息\n * -q<列队> 使用指定的列队\n * -f<文件> 从指定文件读入任务而不是从标准输入读入\n * -t<时间参数> 以时间参数的形式提交要运行的任务\n\n> 注： atd 一次只会执行一个任务，从 job 队列中一次检查一个 job 是否该执行了。\n\n# 6.2.1 at 时间定义的方法\n\n * 接受在当天的 hh:mm（小时:分钟）式的时间指定。假如该时间已过去，那么就放在第二天执行。\n * 使用 midnight（深夜），noon（中午），teatime（饮茶时间，一般是下午4点）等比较模糊的 词语来指定时间。\n * 采用 12 小时计时制，即在时间后面加上 am（上午）或 pm（下午）来说明是上午还是下午。\n * 指定命令执行的具体日期，指定格式为 month day（月 日）或 mm/dd/yy（月/日/年）或 dd.mm.yy（日.月.年）。指定的日期必须跟在指定时间的后面。\n * 使用相对计时法，指定格式为：now + count time-units ，now 就是当前时间，time-units 是时间单位，这里能够是minutes（分钟）、hours（小时）、days（天）、weeks（星期）。count 是时间的数量，究竟是几天，还是几小时，等等。比如 now + 5 minutes。\n * 直接使用today（今天）、tomorrow（明天）来指定完成命令的时间。\n\n> 案例：2 天后的下午 5 点执行 /bin/ls /home\n\n先输入 at [选项] [时间] 后回车，再接着输入命令，输入完后按两次 ctrl d 结束输入\n\n\n# 7. 磁盘分区、挂载\n\n\n# 7.1 linux 分区\n\n🖊 目录只是个目录，目录中的内容在物理上是存放在硬盘的分区中的。\n\n# 7.1.1 原理介绍\n\nlinux 来说无论有几个分区，分给哪一目录使用，它归根结底就只有一个根目录，一个独立且唯一的文件结构，linux 中每个分区都是用来组成整个文件系统的一部分。\n\nlinux 采用了一种叫“载入”的处理方法，它的整个文件系统中包含了一整套的文件和目录， 且将一个分区和一个目录联系起来。这时要载入的一个分区将使它的存储空间在一个目录下获得。\n\n示意图：\n\n# 7.1.2 硬盘说明\n\nlinux 硬盘分 ide 硬盘和 scsi 硬盘，目前基本上是 scsi 硬盘。\n\n * 对于 ide 硬盘，驱动器标识符为“hdx~”，“hd”表明分区所在设备的类型，这里是指ide硬盘。“x”为盘号（a 为基本盘，b 为基本从属盘，c 为辅助主盘，d 为辅助从属盘），“~”代表分区，前四个分区用数字1到4表示，它们是主分区或扩展分区，从5开始就是逻辑分区。比如 hda3 表示为第一个 ide 硬盘上的第三个主分区或扩展分区，hdb2 表示为第二个 ide 硬盘上的第二个主分区或扩展分区。\n * 对于 scsi 硬盘，驱动器标识符为“sdx~”，scsi 硬盘是用“sd”来表示分区所在设备的类型，其余则和 ide 硬盘的表示方法一样。\n\n# 7.1.3 查看所有设备挂载情况\n\n命令：lsblk 或者 lsblk -f\n\n * lsblk：英文是“list block”，即用于列出所有可用块设备的信息\n\n> 图中的 sr0 是指光驱。\n\n\n# 7.2 挂载的经典案例 —— 增加一块硬盘\n\n目标：给 linux 系统增加一块新的硬盘，并且挂载到 /newdisk\n\n主要有以下5个步骤：虚拟机添加硬盘、分区、格式化、挂载、设置可以自动挂载。\n\n# 1）虚拟机添加硬盘\n\n在【虚拟机】菜单中，选择【设置】，然后设备列表里添加硬盘，然后一路【下一步】，中间只有选择磁盘大小的地方需要修改，直到完成。然后重启系统（才能识别）！\n\n# 2）磁盘分区\n\n分区命令：fdisk /dev/sdb\n\n开始对 /sdb 分区：\n\n命令   含义\nm    显示命令列表\nn    新增分区\nd    删除分区\nw    写入并退出\n\n做法：开始分区后输入 n，新增分区，然后选择 p，分区类型为主分区，分区号1-4可选，默认为1，1代表为只为磁盘划分一块分区，2代表为磁盘划分两块分区，依次类推。此次案例选择1。两次回车默认剩余全部空间。最后输入 w 写入分区并退出，若不保存退出输入 q。\n\n# 3）格式化磁盘\n\n命令：mkfs -t ext4 /dev/sdb1\n\n * 其中 ext4 是分区类型\n\n格式化之后才会有上图中的 uuid （唯一标识符）给这个分区，此分区才可以使用。\n\n# 4）挂载\n\n挂载: 将一个分区与一个目录联系起来。\n\n命令：mount 设备名称 挂载目录\n\n * 此次案例为 mount /dev/sdb1 /newdisk\n * 去除挂载命令为 umount 设备名称或者挂载目录，比如 umount /dev/sdb1 或者 umount /newdisk\n\n# 5）设置自动挂载\n\n用命令行挂载只能实现临时挂载，重启系统后，挂载就会失效。设置自动挂载，即永久挂载，当重启系统，仍然可以挂载到指定目录。\n\n通过修改 /etc/fstab 文件实现永久挂载。\n\n * 此次案例在文件中增加 /dev/sdb1 /newdisk ext4 defaults 0 0\n * 保存并退出文件后，执行 mount –a 即刻生效\n\n\n# 7.3 磁盘情况查询\n\n# 7.3.1 查询系统整体磁盘使用情况\n\n命令：df -h\n\n * df：disk free，显示目前在 linux 系统上的文件系统磁盘使用情况统计\n * -h：human readable，使用人类可读的格式(预设值是不加这个选项的\n\n可用于查询系统整体磁盘使用情况：\n\n$ df -h\n文件系统                 容量  已用  可用 已用% 挂载点\ndevtmpfs                 974m     0  974m    0% /dev\ntmpfs                    991m     0  991m    0% /dev/shm\ntmpfs                    991m   11m  980m    2% /run\ntmpfs                    991m     0  991m    0% /sys/fs/cgroup\n/dev/mapper/centos-root   17g  5.4g   11g   34% /\n/dev/sda1                976m  177m  733m   20% /boot\nvmhgfs-fuse              400g  317g   84g   80% /mnt/hgfs\ntmpfs                    199m   52k  198m    1% /run/user/1000\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n * 当“已用”超过 80% 后就不正常了，应该想到扩容。\n\n# 7.3.2 查询指定目录的磁盘占用情况\n\n命令：du -h\n\n * du：disk usage，显示指定的目录或文件所占用的磁盘空间，默认是当前目录。\n * -s：指定目录占用大小汇总\n * -h：带计量单位\n * -a：含文件\n * --max-depth=1：子目录深度为1\n * -c：列出明细的同时，增加汇总值\n\n> 案例：查看 /opt 目录的磁盘占用情况，深度为 1\n> \n> $ du -hac --max-depth=1 /opt\n> 163m\t/opt/vmware-tools-distrib\n> 4.0k\t/opt/rh\n> 54m\t    /opt/vmwaretools-10.3.10-13959562.tar.gz\n> 216m\t/opt\n> 216m\t总用量\n> \n> \n> 1\n> 2\n> 3\n> 4\n> 5\n> 6\n\n\n# 7.4 磁盘情况 - 工作实用指令\n\n# 1）统计 /opt 文件夹下文件的个数\n\nls -l /opt | grep "^-" | wc -l\n\n# 2）统计 /opt 文件夹下目录的个数\n\nls -l /opt | grep "^d" | wc -l\n\n# 3）统计 /opt 文件夹下文件的个数，包括子文件夹下的\n\nls -lr /opt | grep "^-" | wc -l\n\n# 4）统计 /opt 文件夹下目录的个数，包括子文件夹下的\n\nls -lr /opt | grep "^d" | wc -l\n\n# 5）以树状显示目录结构\n\nyum install tree 后 tree 指定目录\n\n$ tree .\n.\n├── aaa\n│   └── abc.txt\n├── bar.txt\n├── foo.txt\n\n\n1\n2\n3\n4\n5\n6\n\n\n> 补充：wc 命令\n> \n> wc（word count）命令的功能为统计指定文件中的字节数、字数、行数，并将统计结果显示输出。\n> \n> 命令：wc [选项] [文件]\n> \n>  * -c：统计字节数\n>  * -l：统计行数\n>  * -m：统计字符数，这个选项不能与 -c 一起使用\n>  * -w：统计字数，一个字被定义为由空白、跳格或换行字符分隔的字符串\n>  * -l：统计最长行的长度',charsets:{cjk:!0},lastUpdated:"2022/08/01, 12:48:16",lastUpdatedTimestamp:1659358096e3},{title:"Linux实操篇（下）",frontmatter:{title:"Linux实操篇（下）",date:"2022-08-02T22:00:10.000Z",permalink:"/pages/16468e/",categories:["基础","Linux","韩顺平2021课程笔记"],tags:[null]},regularPath:"/%E5%9F%BA%E7%A1%80/10.Linux/05.%E9%9F%A9%E9%A1%BA%E5%B9%B32021%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/15.Linux%E5%AE%9E%E6%93%8D%E7%AF%87%EF%BC%88%E4%B8%8B%EF%BC%89.html",relativePath:"基础/10.Linux/05.韩顺平2021课程笔记/15.Linux实操篇（下）.md",key:"v-e36601e4",path:"/pages/16468e/",headers:[{level:2,title:"1. 网络配置",slug:"_1-网络配置",normalizedTitle:"1. 网络配置",charIndex:2},{level:3,title:"1.1 Linux 网络配置原理",slug:"_1-1-linux-网络配置原理",normalizedTitle:"1.1 linux 网络配置原理",charIndex:14},{level:3,title:"1.2 查看网络 IP 和网关",slug:"_1-2-查看网络-ip-和网关",normalizedTitle:"1.2 查看网络 ip 和网关",charIndex:210},{level:4,title:"1.2.1 查看虚拟机 IP",slug:"_1-2-1-查看虚拟机-ip",normalizedTitle:"1.2.1 查看虚拟机 ip",charIndex:229},{level:4,title:"1.2.2 查看网络编辑器和网关",slug:"_1-2-2-查看网络编辑器和网关",normalizedTitle:"1.2.2 查看网络编辑器和网关",charIndex:839},{level:4,title:"1.2.3 查看 Windows 环境中的 VMnet8 网络配置",slug:"_1-2-3-查看-windows-环境中的-vmnet8-网络配置",normalizedTitle:"1.2.3 查看 windows 环境中的 vmnet8 网络配置",charIndex:929},{level:3,title:"1.3 ping 测试连通性",slug:"_1-3-ping-测试连通性",normalizedTitle:"1.3 ping 测试连通性",charIndex:1296},{level:3,title:"1.4 Linux 网络环境配置",slug:"_1-4-linux-网络环境配置",normalizedTitle:"1.4 linux 网络环境配置",charIndex:1377},{level:4,title:"1.4.1 第一种方法：自动获取",slug:"_1-4-1-第一种方法-自动获取",normalizedTitle:"1.4.1 第一种方法：自动获取",charIndex:1397},{level:4,title:"1.4.2 第二种方法：指定 IP ⭐️",slug:"_1-4-2-第二种方法-指定-ip-⭐️",normalizedTitle:"1.4.2 第二种方法：指定 ip ⭐️",charIndex:1481},{level:3,title:"1.5 设置主机名和 hosts 映射",slug:"_1-5-设置主机名和-hosts-映射",normalizedTitle:"1.5 设置主机名和 hosts 映射",charIndex:3079},{level:4,title:"1.5.1 设置主机名",slug:"_1-5-1-设置主机名",normalizedTitle:"1.5.1 设置主机名",charIndex:3102},{level:4,title:"1.5.2 设置 hosts 映射",slug:"_1-5-2-设置-hosts-映射",normalizedTitle:"1.5.2 设置 hosts 映射",charIndex:3209},{level:3,title:"1.6 应用实例：浏览器解析 www.baidu.com 的过程",slug:"_1-6-应用实例-浏览器解析-www-baidu-com-的过程",normalizedTitle:"1.6 应用实例：浏览器解析 www.baidu.com 的过程",charIndex:3538},{level:2,title:"2. 进程管理⭐️",slug:"_2-进程管理",normalizedTitle:"2. 进程管理⭐️",charIndex:3940},{level:3,title:"2.1 基本介绍",slug:"_2-1-基本介绍",normalizedTitle:"2.1 基本介绍",charIndex:3954},{level:3,title:"2.2 ps 显示系统执行的进程",slug:"_2-2-ps-显示系统执行的进程",normalizedTitle:"2.2 ps 显示系统执行的进程",charIndex:4189},{level:4,title:"2.2.1 ps 命令",slug:"_2-2-1-ps-命令",normalizedTitle:"2.2.1 ps 命令",charIndex:4209},{level:4,title:"2.2.2 ps 详解",slug:"_2-2-2-ps-详解",normalizedTitle:"2.2.2 ps 详解",charIndex:4650},{level:4,title:"2.2.3 应用实例",slug:"_2-2-3-应用实例",normalizedTitle:"2.2.3 应用实例",charIndex:5029},{level:3,title:"2.3 kill 和 killall",slug:"_2-3-kill-和-killall",normalizedTitle:"2.3 kill 和 killall",charIndex:5248},{level:4,title:"🖊 案例 1：踢掉某个非法用户",slug:"🖊-案例-1-踢掉某个非法用户",normalizedTitle:"🖊 案例 1：踢掉某个非法用户",charIndex:5536},{level:4,title:"🖊 案例 2：终止远程登录服务 sshd，并在适当时候再次重启 sshd 服务",slug:"🖊-案例-2-终止远程登录服务-sshd-并在适当时候再次重启-sshd-服务",normalizedTitle:"🖊 案例 2：终止远程登录服务 sshd，并在适当时候再次重启 sshd 服务",charIndex:6219},{level:4,title:"🖊 案例 3：终止多个 gedit",slug:"🖊-案例-3-终止多个-gedit",normalizedTitle:"🖊 案例 3：终止多个 gedit",charIndex:6431},{level:4,title:"🖊 案例 4：强制杀掉一个终端",slug:"🖊-案例-4-强制杀掉一个终端",normalizedTitle:"🖊 案例 4：强制杀掉一个终端",charIndex:6509},{level:3,title:"2.4 pstree 查看进程树",slug:"_2-4-pstree-查看进程树",normalizedTitle:"2.4 pstree 查看进程树",charIndex:6722},{level:3,title:"2.5 服务（service）管理",slug:"_2-5-服务-service-管理",normalizedTitle:"2.5 服务（service）管理",charIndex:6873},{level:4,title:"2.5.1 service 管理指令",slug:"_2-5-1-service-管理指令",normalizedTitle:"2.5.1 service 管理指令",charIndex:7035},{level:4,title:"2.5.2 查看服务名",slug:"_2-5-2-查看服务名",normalizedTitle:"2.5.2 查看服务名",charIndex:7336},{level:4,title:"2.5.3 服务的运行级别",slug:"_2-5-3-服务的运行级别",normalizedTitle:"2.5.3 服务的运行级别",charIndex:7489},{level:4,title:"2.5.4 CentOS 7 后运行级别说明",slug:"_2-5-4-centos-7-后运行级别说明",normalizedTitle:"2.5.4 centos 7 后运行级别说明",charIndex:7887},{level:4,title:"2.5.5 chkconfig 指令",slug:"_2-5-5-chkconfig-指令",normalizedTitle:"2.5.5 chkconfig 指令",charIndex:8097},{level:3,title:"2.6 systemctl 命令🎶",slug:"_2-6-systemctl-命令",normalizedTitle:"2.6 systemctl 命令🎶",charIndex:8433},{level:4,title:"2.6.1 systemctl 管理指令",slug:"_2-6-1-systemctl-管理指令",normalizedTitle:"2.6.1 systemctl 管理指令",charIndex:8479},{level:4,title:"2.6.2 systemctl 设置服务自启动状态",slug:"_2-6-2-systemctl-设置服务自启动状态",normalizedTitle:"2.6.2 systemctl 设置服务自启动状态",charIndex:8607},{level:3,title:"2.7 防火墙打开和关闭指定端口🎶",slug:"_2-7-防火墙打开和关闭指定端口",normalizedTitle:"2.7 防火墙打开和关闭指定端口🎶",charIndex:9160},{level:3,title:"2.8 top 动态监控进程",slug:"_2-8-top-动态监控进程",normalizedTitle:"2.8 top 动态监控进程",charIndex:9998},{level:4,title:"🖊 案例 1：监视特定用户",slug:"🖊-案例-1-监视特定用户",normalizedTitle:"🖊 案例 1：监视特定用户",charIndex:10308},{level:4,title:"🖊 案例 2：终止指定的进程",slug:"🖊-案例-2-终止指定的进程",normalizedTitle:"🖊 案例 2：终止指定的进程",charIndex:10363},{level:3,title:"2.9 netstat 监控网络状态⭐️",slug:"_2-9-netstat-监控网络状态",normalizedTitle:"2.9 netstat 监控网络状态⭐️",charIndex:10429},{level:3,title:"2.10 ping 检测主机连接",slug:"_2-10-ping-检测主机连接",normalizedTitle:"2.10 ping 检测主机连接",charIndex:10653},{level:2,title:"3. RPM 与 YUM",slug:"_3-rpm-与-yum",normalizedTitle:"3. rpm 与 yum",charIndex:10738},{level:3,title:"3.1 RPM 包的管理",slug:"_3-1-rpm-包的管理",normalizedTitle:"3.1 rpm 包的管理",charIndex:10755},{level:4,title:"3.1.1 rpm 包的简单查询指令",slug:"_3-1-1-rpm-包的简单查询指令",normalizedTitle:"3.1.1 rpm 包的简单查询指令",charIndex:10980},{level:4,title:"3.1.2 rpm 包名基本格式",slug:"_3-1-2-rpm-包名基本格式",normalizedTitle:"3.1.2 rpm 包名基本格式",charIndex:11191},{level:4,title:"3.1.3 RPM 包的其它查询指令",slug:"_3-1-3-rpm-包的其它查询指令",normalizedTitle:"3.1.3 rpm 包的其它查询指令",charIndex:11380},{level:4,title:"3.1.4 卸载 rpm 包",slug:"_3-1-4-卸载-rpm-包",normalizedTitle:"3.1.4 卸载 rpm 包",charIndex:11539},{level:4,title:"3.1.5 安装 rpm 包",slug:"_3-1-5-安装-rpm-包",normalizedTitle:"3.1.5 安装 rpm 包",charIndex:11778},{level:3,title:"3.2 yum",slug:"_3-2-yum",normalizedTitle:"3.2 yum",charIndex:12009}],headersStr:"1. 网络配置 1.1 Linux 网络配置原理 1.2 查看网络 IP 和网关 1.2.1 查看虚拟机 IP 1.2.2 查看网络编辑器和网关 1.2.3 查看 Windows 环境中的 VMnet8 网络配置 1.3 ping 测试连通性 1.4 Linux 网络环境配置 1.4.1 第一种方法：自动获取 1.4.2 第二种方法：指定 IP ⭐️ 1.5 设置主机名和 hosts 映射 1.5.1 设置主机名 1.5.2 设置 hosts 映射 1.6 应用实例：浏览器解析 www.baidu.com 的过程 2. 进程管理⭐️ 2.1 基本介绍 2.2 ps 显示系统执行的进程 2.2.1 ps 命令 2.2.2 ps 详解 2.2.3 应用实例 2.3 kill 和 killall 🖊 案例 1：踢掉某个非法用户 🖊 案例 2：终止远程登录服务 sshd，并在适当时候再次重启 sshd 服务 🖊 案例 3：终止多个 gedit 🖊 案例 4：强制杀掉一个终端 2.4 pstree 查看进程树 2.5 服务（service）管理 2.5.1 service 管理指令 2.5.2 查看服务名 2.5.3 服务的运行级别 2.5.4 CentOS 7 后运行级别说明 2.5.5 chkconfig 指令 2.6 systemctl 命令🎶 2.6.1 systemctl 管理指令 2.6.2 systemctl 设置服务自启动状态 2.7 防火墙打开和关闭指定端口🎶 2.8 top 动态监控进程 🖊 案例 1：监视特定用户 🖊 案例 2：终止指定的进程 2.9 netstat 监控网络状态⭐️ 2.10 ping 检测主机连接 3. RPM 与 YUM 3.1 RPM 包的管理 3.1.1 rpm 包的简单查询指令 3.1.2 rpm 包名基本格式 3.1.3 RPM 包的其它查询指令 3.1.4 卸载 rpm 包 3.1.5 安装 rpm 包 3.2 yum",content:'# 1. 网络配置\n\n\n# 1.1 Linux 网络配置原理\n\n假设我们的物理主机在一个教室的局域网内：\n\n * Linux 虚拟机和 vmnet8 在一个子网内形成一个网络，可以互通（ping 通）\n * 本机电脑的无线网卡与教室局域网的网关互通，vmnet8 又和无线网卡互通\n * 老韩讲错了？vmnet8 不是虚拟机的网关，只是用来虚拟机和实体机通讯的，把 vmnet8 禁用了虚拟机也可以连接互联网。\n\n\n# 1.2 查看网络 IP 和网关\n\n# 1.2.1 查看虚拟机 IP\n\n在 Linux 中的 ifconfig 可以看到本机的 IP：\n\n$ ifconfig\nens33: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 192.168.220.134  netmask 255.255.255.0  broadcast 192.168.220.255\n        inet6 fe80::c84d:947f:c9c3:2aa3  prefixlen 64  scopeid 0x20<link>\n        ether 00:0c:29:f9:c5:14  txqueuelen 1000  (Ethernet)\n        RX packets 142  bytes 14858 (14.5 KiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 130  bytes 17101 (16.7 KiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n可以看到 Linux 虚拟机的 IP 为 192.168.220.134。\n\n# 1.2.2 查看网络编辑器和网关\n\n在 VMware 的虚拟网络编辑器中，可以看到 NAT 连接方式下本机的子网 IP：\n\n\n\n然后在点击 NAT 设置 可以看到网关：\n\n\n\n# 1.2.3 查看 Windows 环境中的 VMnet8 网络配置\n\n使用 ipconfig 命令：\n\n> ipconfig\n...\n以太网适配器 VMware Network Adapter VMnet8:\n\n   连接特定的 DNS 后缀 . . . . . . . :\n   本地链接 IPv6 地址. . . . . . . . : fe80::c823:6a37:c475:ed49%24\n   IPv4 地址 . . . . . . . . . . . . : 192.168.220.1\n   子网掩码  . . . . . . . . . . . . : 255.255.255.0\n   默认网关. . . . . . . . . . . . . :\n...\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# 1.3 ping 测试连通性\n\nping 目的主机：测试当前服务器是否可以连接目的主机\n\n> 测试是否可以连接百度：ping www.baidu.com\n\n\n# 1.4 Linux 网络环境配置\n\n# 1.4.1 第一种方法：自动获取\n\n登录后，通过界面来设置自动获取 IP。特点：Linux 启动后会自动获取 IP，但每次自动获取的 IP 地址可能不一样。\n\n\n\n# 1.4.2 第二种方法：指定 IP ⭐️\n\n直接修改配置文件来指定 IP，并可以连接到外网（程序员推荐）。\n\n配置文件根据网卡不同名字有所区别，但文件路径一致：/etc/sysconfig/network-scripts/，常见的配置文件名有 ifcfg-eth0 或者 ifcfg-ens33，可以通过 ifconfig 查看后缀。\n\n以 ifcfg-ens33 为例，使用 vim 修改此文件 vim /etc/sysconfig/network-scripts/ifcfg-ens33：\n\nYPE="Ethernet"\nPROXY_METHOD="none"\nBROWSER_ONLY="no"\n- BOOTPROTO="dhcp"\n+ BOOTPROTO="static"\nDEFROUTE="yes"\nIPV4_FAILURE_FATAL="no"\nIPV6INIT="yes"\nIPV6_AUTOCONF="yes"\nIPV6_DEFROUTE="yes"\nIPV6_FAILURE_FATAL="no"\nIPV6_ADDR_GEN_MODE="stable-privacy"\nNAME="ens33"\nUUID="1af88ac9-573c-49da-993c-9ab4e6c73159"\nDEVICE="ens33"\nONBOOT="yes"\n+ IPADDR=192.168.200.130 # 本机 IP 地址\n+ NETMASK=255.255.255.0 # 子网掩码\n+ GATEWAY=192.168.200.2 # 默认网关\n+ DNS1=192.168.200.2 # 域名解析器\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n修改好后并保存。然后进入 VMware 的虚拟网络编辑器，将 NAT 配置中的子网 IP 改为 192.168.200.0，将网关 IP 改为 192.168.200.2。修改位置可见本文的 1.2.2 节所示。\n\n完成以上操作后，重启网络服务或重启系统生效：\n\nservice network restart、reboot\n\n\n1\n\n\n以上这些操作就是将本文 1.1 节图中的 Linux 虚拟机和 vmnet8 的地址分别改成了 192.168.200.130 和 192.168.200.1。这时在虚拟机中使用 ifconfig 命令可以看到：\n\n$ ifconfig\nens33: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n        inet 192.168.200.130  netmask 255.255.255.0  broadcast 192.168.200.255\n        inet6 fe80::c84d:947f:c9c3:2aa3  prefixlen 64  scopeid 0x20<link>\n        ether 00:0c:29:f9:c5:14  txqueuelen 1000  (Ethernet)\n        RX packets 792  bytes 825124 (805.7 KiB)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 456  bytes 33428 (32.6 KiB)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n * 本机 IP 已经成功改为了 192.168.200.130。\n\n\n# 1.5 设置主机名和 hosts 映射\n\n# 1.5.1 设置主机名\n\n为了方便记忆，可以给 Linux 系统设置主机名，也可以根据需要修改主机名。\n\n指令 hostname：查看主机名\n\n修改文件在 /etc/hostname 指定。修改后重启生效。\n\n# 1.5.2 设置 hosts 映射\n\n思考：如何通过主机名能够找到（比如 ping）某个 Linux 系统？\n\nHosts：一个记录 IP 和 hostname 之间映射关系的文本文件。\n\n✏️ Windows 中，在 C:\\Windows\\System32\\drivers\\etc\\hosts 文件指定即可。\n\n> 案例：192.168.200.130 hspEdu100\n> \n>  * 前半部分是 IP 地址，后半部分是其对应的主机名\n> \n> PS：还有一个常见的案例是 127.0.0.1 localhost\n\n✏️ Linux 中，在 /etc/hosts 文件指定即可。\n\n> 案例：192.168.200.1 ThinkPad-PC\n\n\n# 1.6 应用实例：浏览器解析 www.baidu.com 的过程\n\n 1. 浏览器先检查浏览器中有没有该域名解析 IP，有就先调用这个 IP 完成解析。如果没有，就再检查 DNS 解析器缓存，如果有就直接返回 IP 完成解析。这两个缓存可以理解为本地解析器缓存。\n 2. 一般来说，当电脑第一次成功访问某一个网站后，在一定时间内浏览器或 OS 会缓存它的 DNS 解析记录。\n\nipconfig /displaydns  // 查看 DNS 域名解析缓存\nipconfig /flushdns    // 手动清理 DNS 缓存\n\n\n1\n2\n\n 1. 如果本地解析器缓存没有找到对应的映射，就检查系统中 hosts 文件中有没有对应的域名 IP 映射，有则完成解析并返回。\n 2. 如果本地 DNS 解析器缓存和 hosts 文件都没能解析出对应的 IP，则到域名服务 DNS 进行解析域。\n\n\n\n\n# 2. 进程管理⭐️\n\n\n# 2.1 基本介绍\n\n在 Linux 中，每个执行的程序（代码）都称为一个进程。每一个进程都分配一个 ID 号，即进程号，PID。\n\n> 程序和进程：程序==代码，是静态概念；进程是运行起来的占用内存的程序。\n\n每个进程都可能以两种方式存在的：前台与后台。所谓前台进程就是用户目前的屏幕上可以进行操作的。后台进程则是实际在操作，但由于屏幕上无法看到的进程，通常使用后台方式执行。\n\n一般系统的服务都是以后台进程的方式存在，而且都会常驻在系统中，直到关机才才结束。\n\n\n# 2.2 ps 显示系统执行的进程\n\n# 2.2.1 ps 命令\n\nps 命令是 Process Status 的缩写，用来列出系统中当前正在运行的那些进程，就是执行 ps 命令的那个时刻的那些进程的快照。\n\n> ps 查看的结果不是动态连续的，如果想要动态的显示进程信息，就可以使用 top、htop 命令。\n\n$ ps\n   PID TTY          TIME CMD\n  2149 pts/0    00:00:00 zsh\n  2228 pts/0    00:00:00 ps\n\n\n1\n2\n3\n4\n\n * ps 显示的信息字段：\n   * PID：进程识别号\n   * TTY：终端机号\n   * TIME：进程使用 CPU 的总时间\n   * CMD：正在执行的命令或进程名\n * 常用选项：\n   * -a：显示当前终端的所有进程信息\n   * -u：以用户的格式显示进程信息\n   * -x：显示后台进程运行的参数\n\n> 常见情况下是 ps -aux | more 三个选项一块用，并分页查看\n\n# 2.2.2 ps 详解\n\n输入 ps -aux|more 后可以看到：\n\n\n\n * USER：用户名称\n * %CPU：进程占用 CPU 百分比\n * %MEM：进程占用物理内存的百分比\n * VSZ：进程占用的虚拟内存大小（单位 KB）\n * RSS：进程占用的物理内存大小（单位 KB）\n * TTY：终端名称，缩写\n * STAT：进程状态。S 睡眠，s 表示该进程是会话的先导进程，N 表示该进程拥有比普通优先级更低的优先级，R 正在运行，D 短期等待，Z 僵死进程，T 被跟踪或被停止等\n * START：进程的启动时间\n * TIME：进程使用 CPU 的总时间\n * COMMAND：启动进程所用的命令和参数，如果过长会被截断显示\n\n但是直接 ps 会显示太多的进程了，如果想看有没有某个进程，可以用 ps -aux|grep xxx。\n\n# 2.2.3 应用实例\n\n要求：以全格式显示当前所有的进程，查看进程的父进程\n\nps -ef：以全格式查看系统上的运行的所有进程 【常用】\n\n * -e：显示运行在系统上的所有进程\n * -f：全格式，即扩展显示输出\n\n\n\n * C 字段是 CPU 用于计算执行优先级的因子。数值越大，表明进程是 CPU 密集型运算，执行的优先级会降低；数值越小，表明进程是 IO 密集型运算，执行优先级会提高。\n * PPID：父进程的 PID\n\n\n# 2.3 kill 和 killall\n\n> 这部分在 CSAPP 中有讲解\n\nkill 命令会向操作系统内核发送一个信号（多是终止信号）和目标进程的 PID，然后系统内核根据收到的信号类型，对指定进程进行相应的操作。预设的信息为 SIGTERM(15)，可将指定程序终止。\n\n这里只讲用 kill 命令终止进程：\n\n * kill [选项] 进程号：终止进程\n * killall 进程名称：通过进程名称杀死进程（及其子进程），也支持通配符，这在系统因负载过大而变得很慢时很有用。此命令会把对应进程的所有子进程都杀掉。\n\n常用选项：\n\n * -9：表示强迫进程立即终止\n\n# 🖊 案例 1：踢掉某个非法用户\n\n我们先让用户 fox 登录，然后 root 下输入 ps -aux | grep sshd，可以看到：\n\n$ ps -aux | grep sshd\nroot       1462  0.0  0.2 112984  4324 ?        Ss   12:24   0:00 /usr/sbin/sshd -D\nroot       2140  0.0  0.2 161072  5584 ?        Ss   12:24   0:00 sshd: yubin [priv]\nyubin      2148  0.0  0.1 161072  2556 ?        S    12:24   0:00 sshd: yubin@pts/0\nroot       2900  0.3  0.2 161080  5584 ?        Ss   13:22   0:00 sshd: fox [priv]\nfox        2907  0.0  0.1 161080  2560 ?        S    13:22   0:00 sshd: fox@pts/1\nroot       3006  0.0  0.0 112828   984 pts/0    S+   13:23   0:00 grep --color=auto sshd\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n可以看到 fox 登录的时候，是通过进程 2900 登录的，于是我们 kill 2900 后可以看到 fox 用户被踢掉。\n\n# 🖊 案例 2：终止远程登录服务 sshd，并在适当时候再次重启 sshd 服务\n\n类似于案例1，在案例 1 的输出中可以看到，sshd 服务（/usr/sbin/sshd -D 启动的进程）的进程号是 1462，所以 kill 1462 即可终止 sshd 服务。终止后会发现别的用户无法再远程登录。\n\n终止 sshd 后，通过 /bin/systemctl start sshd.service 即可重启该服务。\n\n# 🖊 案例 3：终止多个 gedit\n\n先在图形化界面下用 gedit 打开多个文本编辑页面，然后 killall gedit 即可一次性关闭全部。\n\n# 🖊 案例 4：强制杀掉一个终端\n\n先开一个 bash 终端，然后 ps -aux|grep bash 即可看到所有的 bash 进程，找到要杀死的 bash 进程号 xxxx，然后使用 kill -9 bash对应的进程号 即可杀死。\n\n * 加上 -9 选项是因为如果不加的话，系统会认为由于要被 kill 的 bash 正在工作，而认为你的 kill 是一个误操作，从而置之不理，只有加了 -9 才会强制杀掉。\n\n\n# 2.4 pstree 查看进程树\n\npstree [选项]：可以更加直观的来看进程信息。\n\n * -p：显示进程的 PID\n * -u：显示进程的所属用户\n\n> 案例：\n> \n>  * pstree -p：树状的形式显示进程的 PID。\n>  * pstree -u：树状的形式显示进程的用户\n\n\n# 2.5 服务（service）管理\n\n服务本质就是进程，但是是运行在后台的，通常都会监听某个端口，等待其它程序的请求，比如(mysql、sshd、防火墙等)，因此我们又称为守护进程。\n\n请求某个端口时，本质是请求监听该端口的守护进程。比如，mysqld 服务常监听 3306 端口，SSHD 服务常监听 22 端口。\n\n# 2.5.1 service 管理指令\n\nservice 服务名 [start | stop | restart | reload | status]\n\n\n1\n\n * 在 CentOS 7.0 后 不再使用 service ,而是 systemctl（后面专门介绍）\n * service 指令管理的服务在 /etc/init.d 查看，即 ls -l /etc/init.d 命令。\n\n> 案例：\n> \n>  * 查看网络：service network status\n>  * 关闭网络：service network stop\n>  * 启动网络：service network start\n\n# 2.5.2 查看服务名\n\n✏️ 方式一：执行命令 setup -> 系统服务 就可以看到全部：\n\n\n\n * 带星号的是开机自启动的服务\n * 可以通过命令 sevice 或 systemctl 启动。\n\n✏️ 方式二：运行 ls -l /etc/init.d 查看 service 指令管理的服务。\n\n# 2.5.3 服务的运行级别\n\nLinux 系统有7种运行级别（runlevel）：常用的是级别 3 和 5。\n\n * 运行级别 0：系统停机状态，系统默认运行级别不能设为0，否则不能正常启动。\n * 运行级别 1：单用户工作状态，root 权限，用于系统维护，禁止远程登陆。\n * 运行级别 2：多用户状态(没有 NFS)，不支持网络。\n * 🔺运行级别 3：完全的多用户状态(有 NFS)，无界面，登陆后进入控制台命令行模式。【工作常用】\n * 运行级别 4：系统未使用，保留。\n * 运行级别 5：X11 控制台，登陆后进入图形 GUI 模式\n * 运行级别 6：系统正常关闭并重启，默认运行级别不能设为6，否则不能正常启动。\n\n开机的流程说明：开机 -> BIOS -> /boot -> systemd 进程 1（所有进程的老祖宗）-> 确定运行级别 -> 启动运行级对应的服务\n\n# 2.5.4 CentOS 7 后运行级别说明\n\n在 /etc/initab 进行了简化，multi-user.target 等同于运行级别 3，graphical.target 等同于运行级别 5。\n\n * 命令 systemctl get-default：获取当前的运行级别\n * 命令 systemctl set-default multi-user.target：将默认运行级别设置为 mulit-user\n\n# 2.5.5 chkconfig 指令\n\nchkconfig 命令用于检查，设置系统的各种服务。通过 chkconfig 命令可以给每个服务的各个运行级别设置“自启动”/“关闭”，此处的服务是指 service 指令管理的服务，在 /etc/init.d 查看，即 ls -l /etc/init.d 命令。\n\n在 CentOS 7.0之后，很多服务使用 systemctl 管理。\n\n基本语法：\n\n * 查看服务：chkconfig --list | grep 服务名\n * chkconfig --level 5 服务名 on/off：将某一个服务在特定级别下设置为“自启动”/“关闭”\n\nchkconfig 重新设置服务自启动或关闭后，需要重启机器才能生效。\n\n\n# 2.6 systemctl 命令🎶\n\n> systemctl：system ctl\n\n# 2.6.1 systemctl 管理指令\n\n命令：systemctl [start | stop | restart | status] 服务名\n\n * systemctl 指令管理的服务在 /usr/lib/systemd/system 目录查看\n\n# 2.6.2 systemctl 设置服务自启动状态\n\n * systemctl list-unit-files| grep 服务名：查看服务开机启动状态，使用 grep 进行过滤。\n * systemctl enable 服务名：设置服务开机自启动。\n * systemctl disenable 服务名：关闭服务开机自启动。【这两条指令是设置/关闭在 3 和 5 运行级别下的自启动】\n * systemctl is-enable 服务名：查询某个服务是否开机自启动。\n\n> 案例：查看当前防火墙的状况，关闭并重启它 => firewalld.service\n> \n>  * 查看状况：\n>    \n>    systemctl status firewalld\n>    \n>    \n>    1\n>    \n>    * 这里写 firewalld 或者全名 firewalld.service 均可\n> \n>  * 关闭防火墙：systemctl stop firewalld\n> \n> 细节讨论：这种关闭防火墙是立即生效，但只是临时生效，重启系统后还是回归以前对服务的设置。如果希望某个服务自启动或者关闭永久生效，要使用 systemctl [enable|disable] 服务名。\n\n\n# 2.7 防火墙打开和关闭指定端口🎶\n\n在真正的生产环境，往往需要将防火墙打开。但如果把防火墙打开，那么外部请求数据包就不能跟服务器监听端口通讯。这时，需要打开指定的端口。\n\n> 防火墙的一个功能就是将请求允许的端口放行，不允许的端口过滤掉\n\nfirewall 指令：\n\n * 打开端口：firewall-cmd --permanent --add-port=端口号/协议\n * 关闭端口：firewall-cmd --permanent --remove-port=端口号/协议\n * 重新载入，才能生效：firewall-cmd --reload\n * 查询端口是否开放：firewall-cmd --query-port=端口号/协议\n * 端口号和协议可以通过 netstat 进行监听\n\n> 案例：\n> \n>  1. 先启用防火墙，然后在 Windows 中测试请求 Linux 的 111 端口能否 telnet => 不能\n> \n> > telnet 192.168.200.130 111\n> 正在连接192.168.200.130...无法打开到主机的连接。 在端口 111: 连接失败\n> \n> \n> 1\n> 2\n> \n>  2. 开放 111 端口：\n> \n> $ firewall-cmd --permanent --add-port=111/tcp;\n> success\n> $ firewall-cmd --reload\n> success\n> \n> \n> 1\n> 2\n> 3\n> 4\n> \n>  3. 在 Windows 中测试 telnet 就可以成功了\n>  4. 关闭 111 端口：\n> \n> $ firewall-cmd --permanent --remove-port=111/tcp;\n> success\n> $ firewall-cmd --reload\n> success\n> \n> \n> 1\n> 2\n> 3\n> 4\n\n\n# 2.8 top 动态监控进程\n\ntop 与 ps 命令很相似，它们都用来显示正在执行的进程。top 与 ps 最大的不同之处，在于 top 在执行一段时间可以更新正在运行的的进程。\n\n命令：top [选项]\n\n * -d：指定 top 命令每隔几秒更新，默认 3 秒\n * -i：使 top 不显示任何闲置或者僵死进程\n * -p：通过指定监控进程 ID 来仅仅监控某个进程的状态\n\n\n\n * 各字段含义可以百度\n\n执行 top 后进入监控页面，还可以通过键盘输入一下按键来交互：\n\n * P：以 CPU 使用率排序，默认就是此项\n * M：以内存的使用率排序\n * N：以 PID 排序\n * q：退出 top\n\n# 🖊 案例 1：监视特定用户\n\n输入 top 命令，查看执行的进程，然后输入 u 回车，再输入用户名。\n\n# 🖊 案例 2：终止指定的进程\n\n输入 top 命令，查看执行的进程，然后输入 k 回车，再输入要结束的进程 PID 号。\n\n\n# 2.9 netstat 监控网络状态⭐️\n\nnetstat [选项]：查看系统网络情况\n\n * -an：按一定顺序排列输出\n * -p：显示哪个进程在调用\n\n> 案例：\n> \n>  * 查看服务名为 sshd 服务的信息：netstat -anp|grep sshd\n> \n> > netstat 命令可以查看当前的网络哪些服务处于监控状态，当前已有哪些连接（比如 TCP 连接的 ESTABLISHED 和 TIMEWAIT 等状态）。\n\n\n# 2.10 ping 检测主机连接\n\nping 是一种网络检测工具，它主要是用来检测远程主机是否正常，或是两部主机间的网线或网卡故障。如 ping 对方IP地址。\n\n\n# 3. RPM 与 YUM\n\n\n# 3.1 RPM 包的管理\n\nrpm 是用于互联网下载包的打包及安装工具，它包含在某些 Linux 发行版中。它生成具有.RPM 扩展名的文件。RPM 是 RedHat Package Manager（RedHat 软件包管理工具）的缩写，类似 Windows 的 setup.exe，这一文件格式名称虽然打上了 RedHat 的标志，但理念是通用的。Linux 的发行版本都有采用（RedHat，CentOS等等），可以算是公认的行业标准了。\n\n# 3.1.1 rpm 包的简单查询指令\n\n> 查询指令的选项是 -q（query），然后再和其他选项组合来使用。\n\nrpm -qa：查询已安装的全部 rpm 软件包\n\n> 案例：看看当前系统是否安装了 Firefox：rpm -qa|grep firefox\n> \n> $ rpm -qa|grep firefox\n> firefox-91.5.0-1.el7.centos.x86_64\n> \n> \n> 1\n> 2\n\n# 3.1.2 rpm 包名基本格式\n\n一个 rpm 包名：firefox-91.5.0-1.el7.centos.x86_64\n\n * 名称：firefox\n * 版本号：91.5.0-1\n * 适用 OS：el7.centos.x86_64\n   * 表示 centos7.x 的 64 位系统\n   * 如果是 i686、i386表示32位系统，noarch 表示通用\n\n# 3.1.3 RPM 包的其它查询指令\n\n * rpm -qa | grep 软件包名：查询所安装的是否有该软件包\n * rpm -qi 软件包名：查询软件包信息\n * rpm -ql 软件包名：查询软件包中的文件\n * rpm -qf 文件全路径：查询文件所属的软件包，如rpm -qf /etc/passwd\n\n# 3.1.4 卸载 rpm 包\n\nrpm -e RPM包的名称\n\n\n1\n\n * 包名不需要写全称，比如卸载火狐只需要写 firefox 即可。\n * e —— erase\n\n> 案例：删除 firefox 软件包：rpm -e firefox\n\n细节问题\n\n * 如果其它软件包依赖于要卸载的软件包，卸载时则会产生错误信息。\n * 如果就是要删除这个 rpm 包，可以增加参数 --nodeps，就可以强制删除，但是一般不推荐这样做，因为依赖于该软件包的程序可能无法运行。\n\n# 3.1.5 安装 rpm 包\n\nrpm -ivh RPM包全路径名称\n\n\n1\n\n * -i：install，安装\n * -v：verbose，提示\n * -h：hash，进度条\n\n> 案例：卸载和安装 Firefox 浏览器\n> \n>  * 卸载：rpm -e firefox\n>  * 安装：rpm -ivh firefox的rpm安装包\n>  * rpm安装包的位置：光盘的 Package 文件夹中找到对应的包，copy 到本地目录中，进行安装。\n\n\n# 3.2 yum\n\nYUM 是一个 Shell 前端软件包管理器。基于 RPM 包管理，能够从指定的服务器自动下载 RPM 包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软件包。使用 YUM 的前提是可以联网。\n\n> 很像 maven。相当于 Ubuntu 的 apt。\n\n * 查询 YUM 服务器是否有需要安装的软件：yum list | grep 软件名\n * 安装指定的 yum 包：yum install 软件名\n\n> 案例：使用 yum 的方式来安装 firefox\n> \n>  * 删除 Firefox：rpm -e firefox\n>  * 查询 Firefox：yum install | grep firefox\n>  * 安装：yum install firefox',normalizedContent:'# 1. 网络配置\n\n\n# 1.1 linux 网络配置原理\n\n假设我们的物理主机在一个教室的局域网内：\n\n * linux 虚拟机和 vmnet8 在一个子网内形成一个网络，可以互通（ping 通）\n * 本机电脑的无线网卡与教室局域网的网关互通，vmnet8 又和无线网卡互通\n * 老韩讲错了？vmnet8 不是虚拟机的网关，只是用来虚拟机和实体机通讯的，把 vmnet8 禁用了虚拟机也可以连接互联网。\n\n\n# 1.2 查看网络 ip 和网关\n\n# 1.2.1 查看虚拟机 ip\n\n在 linux 中的 ifconfig 可以看到本机的 ip：\n\n$ ifconfig\nens33: flags=4163<up,broadcast,running,multicast>  mtu 1500\n        inet 192.168.220.134  netmask 255.255.255.0  broadcast 192.168.220.255\n        inet6 fe80::c84d:947f:c9c3:2aa3  prefixlen 64  scopeid 0x20<link>\n        ether 00:0c:29:f9:c5:14  txqueuelen 1000  (ethernet)\n        rx packets 142  bytes 14858 (14.5 kib)\n        rx errors 0  dropped 0  overruns 0  frame 0\n        tx packets 130  bytes 17101 (16.7 kib)\n        tx errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n可以看到 linux 虚拟机的 ip 为 192.168.220.134。\n\n# 1.2.2 查看网络编辑器和网关\n\n在 vmware 的虚拟网络编辑器中，可以看到 nat 连接方式下本机的子网 ip：\n\n\n\n然后在点击 nat 设置 可以看到网关：\n\n\n\n# 1.2.3 查看 windows 环境中的 vmnet8 网络配置\n\n使用 ipconfig 命令：\n\n> ipconfig\n...\n以太网适配器 vmware network adapter vmnet8:\n\n   连接特定的 dns 后缀 . . . . . . . :\n   本地链接 ipv6 地址. . . . . . . . : fe80::c823:6a37:c475:ed49%24\n   ipv4 地址 . . . . . . . . . . . . : 192.168.220.1\n   子网掩码  . . . . . . . . . . . . : 255.255.255.0\n   默认网关. . . . . . . . . . . . . :\n...\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# 1.3 ping 测试连通性\n\nping 目的主机：测试当前服务器是否可以连接目的主机\n\n> 测试是否可以连接百度：ping www.baidu.com\n\n\n# 1.4 linux 网络环境配置\n\n# 1.4.1 第一种方法：自动获取\n\n登录后，通过界面来设置自动获取 ip。特点：linux 启动后会自动获取 ip，但每次自动获取的 ip 地址可能不一样。\n\n\n\n# 1.4.2 第二种方法：指定 ip ⭐️\n\n直接修改配置文件来指定 ip，并可以连接到外网（程序员推荐）。\n\n配置文件根据网卡不同名字有所区别，但文件路径一致：/etc/sysconfig/network-scripts/，常见的配置文件名有 ifcfg-eth0 或者 ifcfg-ens33，可以通过 ifconfig 查看后缀。\n\n以 ifcfg-ens33 为例，使用 vim 修改此文件 vim /etc/sysconfig/network-scripts/ifcfg-ens33：\n\nype="ethernet"\nproxy_method="none"\nbrowser_only="no"\n- bootproto="dhcp"\n+ bootproto="static"\ndefroute="yes"\nipv4_failure_fatal="no"\nipv6init="yes"\nipv6_autoconf="yes"\nipv6_defroute="yes"\nipv6_failure_fatal="no"\nipv6_addr_gen_mode="stable-privacy"\nname="ens33"\nuuid="1af88ac9-573c-49da-993c-9ab4e6c73159"\ndevice="ens33"\nonboot="yes"\n+ ipaddr=192.168.200.130 # 本机 ip 地址\n+ netmask=255.255.255.0 # 子网掩码\n+ gateway=192.168.200.2 # 默认网关\n+ dns1=192.168.200.2 # 域名解析器\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n修改好后并保存。然后进入 vmware 的虚拟网络编辑器，将 nat 配置中的子网 ip 改为 192.168.200.0，将网关 ip 改为 192.168.200.2。修改位置可见本文的 1.2.2 节所示。\n\n完成以上操作后，重启网络服务或重启系统生效：\n\nservice network restart、reboot\n\n\n1\n\n\n以上这些操作就是将本文 1.1 节图中的 linux 虚拟机和 vmnet8 的地址分别改成了 192.168.200.130 和 192.168.200.1。这时在虚拟机中使用 ifconfig 命令可以看到：\n\n$ ifconfig\nens33: flags=4163<up,broadcast,running,multicast>  mtu 1500\n        inet 192.168.200.130  netmask 255.255.255.0  broadcast 192.168.200.255\n        inet6 fe80::c84d:947f:c9c3:2aa3  prefixlen 64  scopeid 0x20<link>\n        ether 00:0c:29:f9:c5:14  txqueuelen 1000  (ethernet)\n        rx packets 792  bytes 825124 (805.7 kib)\n        rx errors 0  dropped 0  overruns 0  frame 0\n        tx packets 456  bytes 33428 (32.6 kib)\n        tx errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n * 本机 ip 已经成功改为了 192.168.200.130。\n\n\n# 1.5 设置主机名和 hosts 映射\n\n# 1.5.1 设置主机名\n\n为了方便记忆，可以给 linux 系统设置主机名，也可以根据需要修改主机名。\n\n指令 hostname：查看主机名\n\n修改文件在 /etc/hostname 指定。修改后重启生效。\n\n# 1.5.2 设置 hosts 映射\n\n思考：如何通过主机名能够找到（比如 ping）某个 linux 系统？\n\nhosts：一个记录 ip 和 hostname 之间映射关系的文本文件。\n\n✏️ windows 中，在 c:\\windows\\system32\\drivers\\etc\\hosts 文件指定即可。\n\n> 案例：192.168.200.130 hspedu100\n> \n>  * 前半部分是 ip 地址，后半部分是其对应的主机名\n> \n> ps：还有一个常见的案例是 127.0.0.1 localhost\n\n✏️ linux 中，在 /etc/hosts 文件指定即可。\n\n> 案例：192.168.200.1 thinkpad-pc\n\n\n# 1.6 应用实例：浏览器解析 www.baidu.com 的过程\n\n 1. 浏览器先检查浏览器中有没有该域名解析 ip，有就先调用这个 ip 完成解析。如果没有，就再检查 dns 解析器缓存，如果有就直接返回 ip 完成解析。这两个缓存可以理解为本地解析器缓存。\n 2. 一般来说，当电脑第一次成功访问某一个网站后，在一定时间内浏览器或 os 会缓存它的 dns 解析记录。\n\nipconfig /displaydns  // 查看 dns 域名解析缓存\nipconfig /flushdns    // 手动清理 dns 缓存\n\n\n1\n2\n\n 1. 如果本地解析器缓存没有找到对应的映射，就检查系统中 hosts 文件中有没有对应的域名 ip 映射，有则完成解析并返回。\n 2. 如果本地 dns 解析器缓存和 hosts 文件都没能解析出对应的 ip，则到域名服务 dns 进行解析域。\n\n\n\n\n# 2. 进程管理⭐️\n\n\n# 2.1 基本介绍\n\n在 linux 中，每个执行的程序（代码）都称为一个进程。每一个进程都分配一个 id 号，即进程号，pid。\n\n> 程序和进程：程序==代码，是静态概念；进程是运行起来的占用内存的程序。\n\n每个进程都可能以两种方式存在的：前台与后台。所谓前台进程就是用户目前的屏幕上可以进行操作的。后台进程则是实际在操作，但由于屏幕上无法看到的进程，通常使用后台方式执行。\n\n一般系统的服务都是以后台进程的方式存在，而且都会常驻在系统中，直到关机才才结束。\n\n\n# 2.2 ps 显示系统执行的进程\n\n# 2.2.1 ps 命令\n\nps 命令是 process status 的缩写，用来列出系统中当前正在运行的那些进程，就是执行 ps 命令的那个时刻的那些进程的快照。\n\n> ps 查看的结果不是动态连续的，如果想要动态的显示进程信息，就可以使用 top、htop 命令。\n\n$ ps\n   pid tty          time cmd\n  2149 pts/0    00:00:00 zsh\n  2228 pts/0    00:00:00 ps\n\n\n1\n2\n3\n4\n\n * ps 显示的信息字段：\n   * pid：进程识别号\n   * tty：终端机号\n   * time：进程使用 cpu 的总时间\n   * cmd：正在执行的命令或进程名\n * 常用选项：\n   * -a：显示当前终端的所有进程信息\n   * -u：以用户的格式显示进程信息\n   * -x：显示后台进程运行的参数\n\n> 常见情况下是 ps -aux | more 三个选项一块用，并分页查看\n\n# 2.2.2 ps 详解\n\n输入 ps -aux|more 后可以看到：\n\n\n\n * user：用户名称\n * %cpu：进程占用 cpu 百分比\n * %mem：进程占用物理内存的百分比\n * vsz：进程占用的虚拟内存大小（单位 kb）\n * rss：进程占用的物理内存大小（单位 kb）\n * tty：终端名称，缩写\n * stat：进程状态。s 睡眠，s 表示该进程是会话的先导进程，n 表示该进程拥有比普通优先级更低的优先级，r 正在运行，d 短期等待，z 僵死进程，t 被跟踪或被停止等\n * start：进程的启动时间\n * time：进程使用 cpu 的总时间\n * command：启动进程所用的命令和参数，如果过长会被截断显示\n\n但是直接 ps 会显示太多的进程了，如果想看有没有某个进程，可以用 ps -aux|grep xxx。\n\n# 2.2.3 应用实例\n\n要求：以全格式显示当前所有的进程，查看进程的父进程\n\nps -ef：以全格式查看系统上的运行的所有进程 【常用】\n\n * -e：显示运行在系统上的所有进程\n * -f：全格式，即扩展显示输出\n\n\n\n * c 字段是 cpu 用于计算执行优先级的因子。数值越大，表明进程是 cpu 密集型运算，执行的优先级会降低；数值越小，表明进程是 io 密集型运算，执行优先级会提高。\n * ppid：父进程的 pid\n\n\n# 2.3 kill 和 killall\n\n> 这部分在 csapp 中有讲解\n\nkill 命令会向操作系统内核发送一个信号（多是终止信号）和目标进程的 pid，然后系统内核根据收到的信号类型，对指定进程进行相应的操作。预设的信息为 sigterm(15)，可将指定程序终止。\n\n这里只讲用 kill 命令终止进程：\n\n * kill [选项] 进程号：终止进程\n * killall 进程名称：通过进程名称杀死进程（及其子进程），也支持通配符，这在系统因负载过大而变得很慢时很有用。此命令会把对应进程的所有子进程都杀掉。\n\n常用选项：\n\n * -9：表示强迫进程立即终止\n\n# 🖊 案例 1：踢掉某个非法用户\n\n我们先让用户 fox 登录，然后 root 下输入 ps -aux | grep sshd，可以看到：\n\n$ ps -aux | grep sshd\nroot       1462  0.0  0.2 112984  4324 ?        ss   12:24   0:00 /usr/sbin/sshd -d\nroot       2140  0.0  0.2 161072  5584 ?        ss   12:24   0:00 sshd: yubin [priv]\nyubin      2148  0.0  0.1 161072  2556 ?        s    12:24   0:00 sshd: yubin@pts/0\nroot       2900  0.3  0.2 161080  5584 ?        ss   13:22   0:00 sshd: fox [priv]\nfox        2907  0.0  0.1 161080  2560 ?        s    13:22   0:00 sshd: fox@pts/1\nroot       3006  0.0  0.0 112828   984 pts/0    s+   13:23   0:00 grep --color=auto sshd\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n可以看到 fox 登录的时候，是通过进程 2900 登录的，于是我们 kill 2900 后可以看到 fox 用户被踢掉。\n\n# 🖊 案例 2：终止远程登录服务 sshd，并在适当时候再次重启 sshd 服务\n\n类似于案例1，在案例 1 的输出中可以看到，sshd 服务（/usr/sbin/sshd -d 启动的进程）的进程号是 1462，所以 kill 1462 即可终止 sshd 服务。终止后会发现别的用户无法再远程登录。\n\n终止 sshd 后，通过 /bin/systemctl start sshd.service 即可重启该服务。\n\n# 🖊 案例 3：终止多个 gedit\n\n先在图形化界面下用 gedit 打开多个文本编辑页面，然后 killall gedit 即可一次性关闭全部。\n\n# 🖊 案例 4：强制杀掉一个终端\n\n先开一个 bash 终端，然后 ps -aux|grep bash 即可看到所有的 bash 进程，找到要杀死的 bash 进程号 xxxx，然后使用 kill -9 bash对应的进程号 即可杀死。\n\n * 加上 -9 选项是因为如果不加的话，系统会认为由于要被 kill 的 bash 正在工作，而认为你的 kill 是一个误操作，从而置之不理，只有加了 -9 才会强制杀掉。\n\n\n# 2.4 pstree 查看进程树\n\npstree [选项]：可以更加直观的来看进程信息。\n\n * -p：显示进程的 pid\n * -u：显示进程的所属用户\n\n> 案例：\n> \n>  * pstree -p：树状的形式显示进程的 pid。\n>  * pstree -u：树状的形式显示进程的用户\n\n\n# 2.5 服务（service）管理\n\n服务本质就是进程，但是是运行在后台的，通常都会监听某个端口，等待其它程序的请求，比如(mysql、sshd、防火墙等)，因此我们又称为守护进程。\n\n请求某个端口时，本质是请求监听该端口的守护进程。比如，mysqld 服务常监听 3306 端口，sshd 服务常监听 22 端口。\n\n# 2.5.1 service 管理指令\n\nservice 服务名 [start | stop | restart | reload | status]\n\n\n1\n\n * 在 centos 7.0 后 不再使用 service ,而是 systemctl（后面专门介绍）\n * service 指令管理的服务在 /etc/init.d 查看，即 ls -l /etc/init.d 命令。\n\n> 案例：\n> \n>  * 查看网络：service network status\n>  * 关闭网络：service network stop\n>  * 启动网络：service network start\n\n# 2.5.2 查看服务名\n\n✏️ 方式一：执行命令 setup -> 系统服务 就可以看到全部：\n\n\n\n * 带星号的是开机自启动的服务\n * 可以通过命令 sevice 或 systemctl 启动。\n\n✏️ 方式二：运行 ls -l /etc/init.d 查看 service 指令管理的服务。\n\n# 2.5.3 服务的运行级别\n\nlinux 系统有7种运行级别（runlevel）：常用的是级别 3 和 5。\n\n * 运行级别 0：系统停机状态，系统默认运行级别不能设为0，否则不能正常启动。\n * 运行级别 1：单用户工作状态，root 权限，用于系统维护，禁止远程登陆。\n * 运行级别 2：多用户状态(没有 nfs)，不支持网络。\n * 🔺运行级别 3：完全的多用户状态(有 nfs)，无界面，登陆后进入控制台命令行模式。【工作常用】\n * 运行级别 4：系统未使用，保留。\n * 运行级别 5：x11 控制台，登陆后进入图形 gui 模式\n * 运行级别 6：系统正常关闭并重启，默认运行级别不能设为6，否则不能正常启动。\n\n开机的流程说明：开机 -> bios -> /boot -> systemd 进程 1（所有进程的老祖宗）-> 确定运行级别 -> 启动运行级对应的服务\n\n# 2.5.4 centos 7 后运行级别说明\n\n在 /etc/initab 进行了简化，multi-user.target 等同于运行级别 3，graphical.target 等同于运行级别 5。\n\n * 命令 systemctl get-default：获取当前的运行级别\n * 命令 systemctl set-default multi-user.target：将默认运行级别设置为 mulit-user\n\n# 2.5.5 chkconfig 指令\n\nchkconfig 命令用于检查，设置系统的各种服务。通过 chkconfig 命令可以给每个服务的各个运行级别设置“自启动”/“关闭”，此处的服务是指 service 指令管理的服务，在 /etc/init.d 查看，即 ls -l /etc/init.d 命令。\n\n在 centos 7.0之后，很多服务使用 systemctl 管理。\n\n基本语法：\n\n * 查看服务：chkconfig --list | grep 服务名\n * chkconfig --level 5 服务名 on/off：将某一个服务在特定级别下设置为“自启动”/“关闭”\n\nchkconfig 重新设置服务自启动或关闭后，需要重启机器才能生效。\n\n\n# 2.6 systemctl 命令🎶\n\n> systemctl：system ctl\n\n# 2.6.1 systemctl 管理指令\n\n命令：systemctl [start | stop | restart | status] 服务名\n\n * systemctl 指令管理的服务在 /usr/lib/systemd/system 目录查看\n\n# 2.6.2 systemctl 设置服务自启动状态\n\n * systemctl list-unit-files| grep 服务名：查看服务开机启动状态，使用 grep 进行过滤。\n * systemctl enable 服务名：设置服务开机自启动。\n * systemctl disenable 服务名：关闭服务开机自启动。【这两条指令是设置/关闭在 3 和 5 运行级别下的自启动】\n * systemctl is-enable 服务名：查询某个服务是否开机自启动。\n\n> 案例：查看当前防火墙的状况，关闭并重启它 => firewalld.service\n> \n>  * 查看状况：\n>    \n>    systemctl status firewalld\n>    \n>    \n>    1\n>    \n>    * 这里写 firewalld 或者全名 firewalld.service 均可\n> \n>  * 关闭防火墙：systemctl stop firewalld\n> \n> 细节讨论：这种关闭防火墙是立即生效，但只是临时生效，重启系统后还是回归以前对服务的设置。如果希望某个服务自启动或者关闭永久生效，要使用 systemctl [enable|disable] 服务名。\n\n\n# 2.7 防火墙打开和关闭指定端口🎶\n\n在真正的生产环境，往往需要将防火墙打开。但如果把防火墙打开，那么外部请求数据包就不能跟服务器监听端口通讯。这时，需要打开指定的端口。\n\n> 防火墙的一个功能就是将请求允许的端口放行，不允许的端口过滤掉\n\nfirewall 指令：\n\n * 打开端口：firewall-cmd --permanent --add-port=端口号/协议\n * 关闭端口：firewall-cmd --permanent --remove-port=端口号/协议\n * 重新载入，才能生效：firewall-cmd --reload\n * 查询端口是否开放：firewall-cmd --query-port=端口号/协议\n * 端口号和协议可以通过 netstat 进行监听\n\n> 案例：\n> \n>  1. 先启用防火墙，然后在 windows 中测试请求 linux 的 111 端口能否 telnet => 不能\n> \n> > telnet 192.168.200.130 111\n> 正在连接192.168.200.130...无法打开到主机的连接。 在端口 111: 连接失败\n> \n> \n> 1\n> 2\n> \n>  2. 开放 111 端口：\n> \n> $ firewall-cmd --permanent --add-port=111/tcp;\n> success\n> $ firewall-cmd --reload\n> success\n> \n> \n> 1\n> 2\n> 3\n> 4\n> \n>  3. 在 windows 中测试 telnet 就可以成功了\n>  4. 关闭 111 端口：\n> \n> $ firewall-cmd --permanent --remove-port=111/tcp;\n> success\n> $ firewall-cmd --reload\n> success\n> \n> \n> 1\n> 2\n> 3\n> 4\n\n\n# 2.8 top 动态监控进程\n\ntop 与 ps 命令很相似，它们都用来显示正在执行的进程。top 与 ps 最大的不同之处，在于 top 在执行一段时间可以更新正在运行的的进程。\n\n命令：top [选项]\n\n * -d：指定 top 命令每隔几秒更新，默认 3 秒\n * -i：使 top 不显示任何闲置或者僵死进程\n * -p：通过指定监控进程 id 来仅仅监控某个进程的状态\n\n\n\n * 各字段含义可以百度\n\n执行 top 后进入监控页面，还可以通过键盘输入一下按键来交互：\n\n * p：以 cpu 使用率排序，默认就是此项\n * m：以内存的使用率排序\n * n：以 pid 排序\n * q：退出 top\n\n# 🖊 案例 1：监视特定用户\n\n输入 top 命令，查看执行的进程，然后输入 u 回车，再输入用户名。\n\n# 🖊 案例 2：终止指定的进程\n\n输入 top 命令，查看执行的进程，然后输入 k 回车，再输入要结束的进程 pid 号。\n\n\n# 2.9 netstat 监控网络状态⭐️\n\nnetstat [选项]：查看系统网络情况\n\n * -an：按一定顺序排列输出\n * -p：显示哪个进程在调用\n\n> 案例：\n> \n>  * 查看服务名为 sshd 服务的信息：netstat -anp|grep sshd\n> \n> > netstat 命令可以查看当前的网络哪些服务处于监控状态，当前已有哪些连接（比如 tcp 连接的 established 和 timewait 等状态）。\n\n\n# 2.10 ping 检测主机连接\n\nping 是一种网络检测工具，它主要是用来检测远程主机是否正常，或是两部主机间的网线或网卡故障。如 ping 对方ip地址。\n\n\n# 3. rpm 与 yum\n\n\n# 3.1 rpm 包的管理\n\nrpm 是用于互联网下载包的打包及安装工具，它包含在某些 linux 发行版中。它生成具有.rpm 扩展名的文件。rpm 是 redhat package manager（redhat 软件包管理工具）的缩写，类似 windows 的 setup.exe，这一文件格式名称虽然打上了 redhat 的标志，但理念是通用的。linux 的发行版本都有采用（redhat，centos等等），可以算是公认的行业标准了。\n\n# 3.1.1 rpm 包的简单查询指令\n\n> 查询指令的选项是 -q（query），然后再和其他选项组合来使用。\n\nrpm -qa：查询已安装的全部 rpm 软件包\n\n> 案例：看看当前系统是否安装了 firefox：rpm -qa|grep firefox\n> \n> $ rpm -qa|grep firefox\n> firefox-91.5.0-1.el7.centos.x86_64\n> \n> \n> 1\n> 2\n\n# 3.1.2 rpm 包名基本格式\n\n一个 rpm 包名：firefox-91.5.0-1.el7.centos.x86_64\n\n * 名称：firefox\n * 版本号：91.5.0-1\n * 适用 os：el7.centos.x86_64\n   * 表示 centos7.x 的 64 位系统\n   * 如果是 i686、i386表示32位系统，noarch 表示通用\n\n# 3.1.3 rpm 包的其它查询指令\n\n * rpm -qa | grep 软件包名：查询所安装的是否有该软件包\n * rpm -qi 软件包名：查询软件包信息\n * rpm -ql 软件包名：查询软件包中的文件\n * rpm -qf 文件全路径：查询文件所属的软件包，如rpm -qf /etc/passwd\n\n# 3.1.4 卸载 rpm 包\n\nrpm -e rpm包的名称\n\n\n1\n\n * 包名不需要写全称，比如卸载火狐只需要写 firefox 即可。\n * e —— erase\n\n> 案例：删除 firefox 软件包：rpm -e firefox\n\n细节问题\n\n * 如果其它软件包依赖于要卸载的软件包，卸载时则会产生错误信息。\n * 如果就是要删除这个 rpm 包，可以增加参数 --nodeps，就可以强制删除，但是一般不推荐这样做，因为依赖于该软件包的程序可能无法运行。\n\n# 3.1.5 安装 rpm 包\n\nrpm -ivh rpm包全路径名称\n\n\n1\n\n * -i：install，安装\n * -v：verbose，提示\n * -h：hash，进度条\n\n> 案例：卸载和安装 firefox 浏览器\n> \n>  * 卸载：rpm -e firefox\n>  * 安装：rpm -ivh firefox的rpm安装包\n>  * rpm安装包的位置：光盘的 package 文件夹中找到对应的包，copy 到本地目录中，进行安装。\n\n\n# 3.2 yum\n\nyum 是一个 shell 前端软件包管理器。基于 rpm 包管理，能够从指定的服务器自动下载 rpm 包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软件包。使用 yum 的前提是可以联网。\n\n> 很像 maven。相当于 ubuntu 的 apt。\n\n * 查询 yum 服务器是否有需要安装的软件：yum list | grep 软件名\n * 安装指定的 yum 包：yum install 软件名\n\n> 案例：使用 yum 的方式来安装 firefox\n> \n>  * 删除 firefox：rpm -e firefox\n>  * 查询 firefox：yum install | grep firefox\n>  * 安装：yum install firefox',charsets:{cjk:!0},lastUpdated:"2022/08/15, 13:42:34",lastUpdatedTimestamp:1660570954e3},{title:"JavaEE与Python定制篇",frontmatter:{title:"JavaEE与Python定制篇",date:"2022-08-15T21:48:03.000Z",permalink:"/pages/1e98d9/",categories:["基础","Linux","韩顺平2021课程笔记"],tags:[null]},regularPath:"/%E5%9F%BA%E7%A1%80/10.Linux/05.%E9%9F%A9%E9%A1%BA%E5%B9%B32021%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/20.JavaEE%E4%B8%8EPython%E5%AE%9A%E5%88%B6%E7%AF%87.html",relativePath:"基础/10.Linux/05.韩顺平2021课程笔记/20.JavaEE与Python定制篇.md",key:"v-1ae0a658",path:"/pages/1e98d9/",headers:[{level:2,title:"一、Java EE 定制篇——搭建 Java EE 环境",slug:"一、java-ee-定制篇-搭建-java-ee-环境",normalizedTitle:"一、java ee 定制篇——搭建 java ee 环境",charIndex:2},{level:3,title:"1.1 安装 JDK 8",slug:"_1-1-安装-jdk-8",normalizedTitle:"1.1 安装 jdk 8",charIndex:102},{level:3,title:"1.2 安装 Tomcat",slug:"_1-2-安装-tomcat",normalizedTitle:"1.2 安装 tomcat",charIndex:779},{level:3,title:"1.3 安装 MySQL 5.7",slug:"_1-3-安装-mysql-5-7",normalizedTitle:"1.3 安装 mysql 5.7",charIndex:1083},{level:2,title:"二、Python 定制篇 —— Ubuntu",slug:"二、python-定制篇-ubuntu",normalizedTitle:"二、python 定制篇 —— ubuntu",charIndex:2270},{level:3,title:"2.1 Ubuntu 的安装",slug:"_2-1-ubuntu-的安装",normalizedTitle:"2.1 ubuntu 的安装",charIndex:2507},{level:3,title:"2.2 设置 Ubuntu 环境",slug:"_2-2-设置-ubuntu-环境",normalizedTitle:"2.2 设置 ubuntu 环境",charIndex:2531},{level:2,title:"三、APT 软件管理和远程登录",slug:"三、apt-软件管理和远程登录",normalizedTitle:"三、apt 软件管理和远程登录",charIndex:2557},{level:3,title:"3.1 Ubuntu 软件相关操作的相关命令",slug:"_3-1-ubuntu-软件相关操作的相关命令",normalizedTitle:"3.1 ubuntu 软件相关操作的相关命令",charIndex:2667}],headersStr:"一、Java EE 定制篇——搭建 Java EE 环境 1.1 安装 JDK 8 1.2 安装 Tomcat 1.3 安装 MySQL 5.7 二、Python 定制篇 —— Ubuntu 2.1 Ubuntu 的安装 2.2 设置 Ubuntu 环境 三、APT 软件管理和远程登录 3.1 Ubuntu 软件相关操作的相关命令",content:"# 一、Java EE 定制篇——搭建 Java EE 环境\n\n如果需要在 Linux 下进行Java EE 的开发，我们需要安装如下软件：\n\n * JDK\n * Tomcat\n * MySQL\n\n\n# 1.1 安装 JDK 8\n\n * mkdir /opt/jdk\n\n * 通过 Xftp 6上传 JDK 安装包（jdk-8u261-linux-x64.tar.gz）到 /opt/jdk\n\n * cd /opt/jdk\n\n * 使用 tar -zxvf jdk-8u261-linux-x64.tar.gz 命令解压 JDK 安装包\n\n * mkdir /usr/local/java\n\n * mv jdk1.8.0_261/ /usr/local/java/\n\n * 使用 echo $PATH 命令查看当前的环境变量，没有 JDK\n\n * 通过编辑 /etc/profile 文件配置 JDK 环境变量\n   \n   * 增加命令 export JAVA_HOME=/usr/local/java/jdk1.8.0_261\n   \n   * 增加命令\n     \n     export PATH=$JAVA_HOME/bin:$PATH\n     \n     \n     1\n     \n     * 注意：这里带上 :$PATH 是把之前的 PATH 环境变量也带上，否则会破坏之前的环境变量，导致出大问题\n   \n   * 其中，第二条命令的 $PATH 是之前的环境变量，一定要写上。否则，一些常用指令将无法使用。\n\n * 通过 source /etc/profile 命令让新的环境变量生效\n\n * 再次使用 echo $PATH 命令查看当前的环境变量，JDK 环境变量添加成功\n\n * 通过运行 Java 程序测试是否安装成功\n\n\n# 1.2 安装 Tomcat\n\n * mkdir /opt/tomcat\n * 上传安装文件，并解压到 /opt/tomcat\n * 进入解压目录 /bin，启动 Tomcat：./startup.sh\n * 开放端口 8080\n   * 使用 firewall-cmd --permanent --add-port=8080/tcp 命令打开8080端口\n   * 使用 firewall-cmd --reload 命令更新端口状态\n   * 使用 firewall-cmd --query-port=8080/tcp 命令查看端口是否打开\n\n通过浏览器访问 IP地址:8080 来查看是否安装成功\n\n\n# 1.3 安装 MySQL 5.7\n\n * mkdir /opt/mysql\n * 上传安装文件，并解压到 /opt/mysql（用 tar -xvf ... 解压）\n * CentOS 7.6自带的 MySQL 类数据库是 mariadb，会和 MySQL 冲突，要先删除\n   * 使用 rpm -qa | grep mari 命令查看 mariadb 相关安装包\n   * 分别运行 rpm -e --nodeps mariadb-libs 以及 rpm -e --nodeps marisa 命令删除\n   * 再次使用 rpm -qa | grep mari 命令查询 mariadb 相关安装包，已删除干净\n * 开始真正安装 MySQL，依次按顺序运行以下命令\n   * rpm -ivh mysql-community-common-5.7.26-1.el7.x86_64.rpm\n   * rpm -ivh mysql-community-libs-5.7.26-1.el7.x86_64.rpm\n   * rpm -ivh mysql-community-client-5.7.26-1.el7.x86_64.rpm\n   * rpm -ivh mysql-community-server-5.7.26-1.el7.x86_64.rpm\n * 运行 systemctl start mysqld.service 命令，启动 MySQL\n * 设置 root 用户密码\n   * MySQL 自动给 root 用户设置随机密码，通过 grep password /var/log/mysqld.log 来查看当前密码\n   * 运行 mysql -u root -p 命令登录 root 用户，输入上面 root 用户当前密码，登录进入 MySQL 命令行\n   * 对于个人开发环境，如果设置较简单的 root 用户密码，在 MySQL 命令行运行 set global validate_password_policy=0; 将密码策略修改为0，即弱口令（默认情况为1）。对于生产环境，要设置复杂的 root 用户密码。\n   * 修改 root 用户密码命令格式：set password for 用户名@localhost = password('新密码'); 比如在 MySQL 命令行里运行 set password for root@localhost = password('12345678');\n   * 继续在 MySQL 命令行里输入 flush privileges; 使密码设置生效\n   * 输入 quit 退出\n * 重新登陆即可\n\n📝 更简单的安装方式：MySQL 安装 | 菜鸟教程 (runoob.com)\n\n\n# 二、Python 定制篇 —— Ubuntu\n\nUbuntu（乌班图）是一个以桌面应用为主的开源 GNU/Linux 操作系统。\n\n专业的 Python 开发者一般会选择 Ubuntu 这款 Linux 系统作为生产平台，Ubuntu 和 Centos 都是基于 GNU/Linux 内核的，因此基本使用和 Centos 是几乎一样的，它们的各种指令可以通用。只是界面和预安装的软件有所差别。\n\n下载地址：Ubuntu 下载地址(opens new window)\n\n\n# 2.1 Ubuntu 的安装\n\n...\n\n\n# 2.2 设置 Ubuntu 环境\n\n...\n\n\n# 三、APT 软件管理和远程登录\n\nAPT 是 Advanced Packaging Tool 的简称，是一款安装包管理工具。在 Ubuntu 下，我们可以使用 apt 命令可用于软件包的安装、删除、清理等。\n\n\n\n\n# 3.1 Ubuntu 软件相关操作的相关命令",normalizedContent:"# 一、java ee 定制篇——搭建 java ee 环境\n\n如果需要在 linux 下进行java ee 的开发，我们需要安装如下软件：\n\n * jdk\n * tomcat\n * mysql\n\n\n# 1.1 安装 jdk 8\n\n * mkdir /opt/jdk\n\n * 通过 xftp 6上传 jdk 安装包（jdk-8u261-linux-x64.tar.gz）到 /opt/jdk\n\n * cd /opt/jdk\n\n * 使用 tar -zxvf jdk-8u261-linux-x64.tar.gz 命令解压 jdk 安装包\n\n * mkdir /usr/local/java\n\n * mv jdk1.8.0_261/ /usr/local/java/\n\n * 使用 echo $path 命令查看当前的环境变量，没有 jdk\n\n * 通过编辑 /etc/profile 文件配置 jdk 环境变量\n   \n   * 增加命令 export java_home=/usr/local/java/jdk1.8.0_261\n   \n   * 增加命令\n     \n     export path=$java_home/bin:$path\n     \n     \n     1\n     \n     * 注意：这里带上 :$path 是把之前的 path 环境变量也带上，否则会破坏之前的环境变量，导致出大问题\n   \n   * 其中，第二条命令的 $path 是之前的环境变量，一定要写上。否则，一些常用指令将无法使用。\n\n * 通过 source /etc/profile 命令让新的环境变量生效\n\n * 再次使用 echo $path 命令查看当前的环境变量，jdk 环境变量添加成功\n\n * 通过运行 java 程序测试是否安装成功\n\n\n# 1.2 安装 tomcat\n\n * mkdir /opt/tomcat\n * 上传安装文件，并解压到 /opt/tomcat\n * 进入解压目录 /bin，启动 tomcat：./startup.sh\n * 开放端口 8080\n   * 使用 firewall-cmd --permanent --add-port=8080/tcp 命令打开8080端口\n   * 使用 firewall-cmd --reload 命令更新端口状态\n   * 使用 firewall-cmd --query-port=8080/tcp 命令查看端口是否打开\n\n通过浏览器访问 ip地址:8080 来查看是否安装成功\n\n\n# 1.3 安装 mysql 5.7\n\n * mkdir /opt/mysql\n * 上传安装文件，并解压到 /opt/mysql（用 tar -xvf ... 解压）\n * centos 7.6自带的 mysql 类数据库是 mariadb，会和 mysql 冲突，要先删除\n   * 使用 rpm -qa | grep mari 命令查看 mariadb 相关安装包\n   * 分别运行 rpm -e --nodeps mariadb-libs 以及 rpm -e --nodeps marisa 命令删除\n   * 再次使用 rpm -qa | grep mari 命令查询 mariadb 相关安装包，已删除干净\n * 开始真正安装 mysql，依次按顺序运行以下命令\n   * rpm -ivh mysql-community-common-5.7.26-1.el7.x86_64.rpm\n   * rpm -ivh mysql-community-libs-5.7.26-1.el7.x86_64.rpm\n   * rpm -ivh mysql-community-client-5.7.26-1.el7.x86_64.rpm\n   * rpm -ivh mysql-community-server-5.7.26-1.el7.x86_64.rpm\n * 运行 systemctl start mysqld.service 命令，启动 mysql\n * 设置 root 用户密码\n   * mysql 自动给 root 用户设置随机密码，通过 grep password /var/log/mysqld.log 来查看当前密码\n   * 运行 mysql -u root -p 命令登录 root 用户，输入上面 root 用户当前密码，登录进入 mysql 命令行\n   * 对于个人开发环境，如果设置较简单的 root 用户密码，在 mysql 命令行运行 set global validate_password_policy=0; 将密码策略修改为0，即弱口令（默认情况为1）。对于生产环境，要设置复杂的 root 用户密码。\n   * 修改 root 用户密码命令格式：set password for 用户名@localhost = password('新密码'); 比如在 mysql 命令行里运行 set password for root@localhost = password('12345678');\n   * 继续在 mysql 命令行里输入 flush privileges; 使密码设置生效\n   * 输入 quit 退出\n * 重新登陆即可\n\n📝 更简单的安装方式：mysql 安装 | 菜鸟教程 (runoob.com)\n\n\n# 二、python 定制篇 —— ubuntu\n\nubuntu（乌班图）是一个以桌面应用为主的开源 gnu/linux 操作系统。\n\n专业的 python 开发者一般会选择 ubuntu 这款 linux 系统作为生产平台，ubuntu 和 centos 都是基于 gnu/linux 内核的，因此基本使用和 centos 是几乎一样的，它们的各种指令可以通用。只是界面和预安装的软件有所差别。\n\n下载地址：ubuntu 下载地址(opens new window)\n\n\n# 2.1 ubuntu 的安装\n\n...\n\n\n# 2.2 设置 ubuntu 环境\n\n...\n\n\n# 三、apt 软件管理和远程登录\n\napt 是 advanced packaging tool 的简称，是一款安装包管理工具。在 ubuntu 下，我们可以使用 apt 命令可用于软件包的安装、删除、清理等。\n\n\n\n\n# 3.1 ubuntu 软件相关操作的相关命令",charsets:{cjk:!0},lastUpdated:"2022/08/22, 01:57:58",lastUpdatedTimestamp:1661133478e3},{title:"大数据定制篇-Shell编程",frontmatter:{title:"大数据定制篇-Shell编程",date:"2022-08-21T15:39:01.000Z",permalink:"/pages/338288/",categories:["基础","Linux","韩顺平2021课程笔记"],tags:[null]},regularPath:"/%E5%9F%BA%E7%A1%80/10.Linux/05.%E9%9F%A9%E9%A1%BA%E5%B9%B32021%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/25.%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AE%9A%E5%88%B6%E7%AF%87-Shell%E7%BC%96%E7%A8%8B.html",relativePath:"基础/10.Linux/05.韩顺平2021课程笔记/25.大数据定制篇-Shell编程.md",key:"v-97c51d34",path:"/pages/338288/",headers:[{level:2,title:"1. Shell 概述",slug:"_1-shell-概述",normalizedTitle:"1. shell 概述",charIndex:2},{level:3,title:"1.1 为什么要学习 Shell 编程",slug:"_1-1-为什么要学习-shell-编程",normalizedTitle:"1.1 为什么要学习 shell 编程",charIndex:18},{level:3,title:"1.2 shell 是什么",slug:"_1-2-shell-是什么",normalizedTitle:"1.2 shell 是什么",charIndex:209},{level:2,title:"2. Shell 脚本的执行方式",slug:"_2-shell-脚本的执行方式",normalizedTitle:"2. shell 脚本的执行方式",charIndex:314},{level:3,title:"2.1 脚本格式要求",slug:"_2-1-脚本格式要求",normalizedTitle:"2.1 脚本格式要求",charIndex:335},{level:3,title:"2.2 编写第一个 shell 脚本",slug:"_2-2-编写第一个-shell-脚本",normalizedTitle:"2.2 编写第一个 shell 脚本",charIndex:380},{level:3,title:"2.3 脚本的常用执行方式",slug:"_2-3-脚本的常用执行方式",normalizedTitle:"2.3 脚本的常用执行方式",charIndex:492},{level:4,title:"🖊 方式一：输入脚本的绝对路径或相对路径",slug:"🖊-方式一-输入脚本的绝对路径或相对路径",normalizedTitle:"🖊 方式一：输入脚本的绝对路径或相对路径",charIndex:509},{level:4,title:"🖊 方式二：sh + 脚本",slug:"🖊-方式二-sh-脚本",normalizedTitle:"🖊 方式二：sh + 脚本",charIndex:559},{level:2,title:"3. shell 的变量",slug:"_3-shell-的变量",normalizedTitle:"3. shell 的变量",charIndex:617},{level:3,title:"3.1 Shell 变量介绍",slug:"_3-1-shell-变量介绍",normalizedTitle:"3.1 shell 变量介绍",charIndex:634},{level:3,title:"3.2 Shell 变量定义",slug:"_3-2-shell-变量定义",normalizedTitle:"3.2 shell 变量定义",charIndex:760},{level:4,title:"基本语法：",slug:"基本语法",normalizedTitle:"基本语法：",charIndex:778},{level:4,title:"快速入门：",slug:"快速入门",normalizedTitle:"快速入门：",charIndex:885},{level:4,title:"补充：shell 脚本的注释：",slug:"补充-shell-脚本的注释",normalizedTitle:"补充：shell 脚本的注释：",charIndex:1139},{level:3,title:"3.3 shell 变量的定义",slug:"_3-3-shell-变量的定义",normalizedTitle:"3.3 shell 变量的定义",charIndex:1220},{level:4,title:"定义变量的规则：",slug:"定义变量的规则",normalizedTitle:"定义变量的规则：",charIndex:1239},{level:4,title:"将命令的返回值赋给变量：",slug:"将命令的返回值赋给变量",normalizedTitle:"将命令的返回值赋给变量：",charIndex:1325},{level:3,title:"3.4 设置环境变量",slug:"_3-4-设置环境变量",normalizedTitle:"3.4 设置环境变量",charIndex:1399},{level:4,title:"基本语法：",slug:"基本语法-2",normalizedTitle:"基本语法：",charIndex:778},{level:4,title:"快速入门：",slug:"快速入门-2",normalizedTitle:"快速入门：",charIndex:885},{level:3,title:"3.5 位置参数变量",slug:"_3-5-位置参数变量",normalizedTitle:"3.5 位置参数变量",charIndex:1832},{level:4,title:"3.5.1 基本语法",slug:"_3-5-1-基本语法",normalizedTitle:"3.5.1 基本语法",charIndex:1964},{level:4,title:"3.5.2 案例",slug:"_3-5-2-案例",normalizedTitle:"3.5.2 案例",charIndex:2127},{level:3,title:"3.6 预定义变量",slug:"_3-6-预定义变量",normalizedTitle:"3.6 预定义变量",charIndex:2257},{level:4,title:"3.6.1 基本语法",slug:"_3-6-1-基本语法",normalizedTitle:"3.6.1 基本语法",charIndex:2314},{level:4,title:"3.6.2 案例",slug:"_3-6-2-案例",normalizedTitle:"3.6.2 案例",charIndex:2455},{level:2,title:"4. 运算符",slug:"_4-运算符",normalizedTitle:"4. 运算符",charIndex:2580},{level:4,title:"4.1 基本语法",slug:"_4-1-基本语法",normalizedTitle:"4.1 基本语法",charIndex:2610},{level:4,title:"4.2 案例",slug:"_4-2-案例",normalizedTitle:"4.2 案例",charIndex:2785},{level:2,title:"5. 条件判断",slug:"_5-条件判断",normalizedTitle:"5. 条件判断",charIndex:3129},{level:4,title:"5.1 基本语法",slug:"_5-1-基本语法",normalizedTitle:"5.1 基本语法",charIndex:1966},{level:4,title:"5.2 常用判断条件",slug:"_5-2-常用判断条件",normalizedTitle:"5.2 常用判断条件",charIndex:3230},{level:4,title:"3.8.3 案例",slug:"_3-8-3-案例",normalizedTitle:"3.8.3 案例",charIndex:3483},{level:2,title:"6. 流程控制",slug:"_6-流程控制",normalizedTitle:"6. 流程控制",charIndex:3881},{level:3,title:"6.1 if 判断",slug:"_6-1-if-判断",normalizedTitle:"6.1 if 判断",charIndex:3893},{level:3,title:"6.2 case 语句",slug:"_6-2-case-语句",normalizedTitle:"6.2 case 语句",charIndex:4223},{level:3,title:"6.3 for 循环",slug:"_6-3-for-循环",normalizedTitle:"6.3 for 循环",charIndex:4659},{level:3,title:"🖊 基本语法 1",slug:"🖊-基本语法-1",normalizedTitle:"🖊 基本语法 1",charIndex:4674},{level:4,title:"🖊 基本语法 2",slug:"🖊-基本语法-2",normalizedTitle:"🖊 基本语法 2",charIndex:5012},{level:3,title:"6.4 while 循环",slug:"_6-4-while-循环",normalizedTitle:"6.4 while 循环",charIndex:5247},{level:2,title:"7. read 读取控制台输入",slug:"_7-read-读取控制台输入",normalizedTitle:"7. read 读取控制台输入",charIndex:5536},{level:2,title:"8. 函数",slug:"_8-函数",normalizedTitle:"8. 函数",charIndex:5858},{level:3,title:"8.1 系统函数",slug:"_8-1-系统函数",normalizedTitle:"8.1 系统函数",charIndex:5893},{level:4,title:"8.1.1 basename 函数",slug:"_8-1-1-basename-函数",normalizedTitle:"8.1.1 basename 函数",charIndex:5923},{level:4,title:"8.1.2 dirname 函数",slug:"_8-1-2-dirname-函数",normalizedTitle:"8.1.2 dirname 函数",charIndex:6291},{level:3,title:"8.2 自定义函数",slug:"_8-2-自定义函数",normalizedTitle:"8.2 自定义函数",charIndex:6490},{level:2,title:"9. 综合案例",slug:"_9-综合案例",normalizedTitle:"9. 综合案例",charIndex:6912}],headersStr:"1. Shell 概述 1.1 为什么要学习 Shell 编程 1.2 shell 是什么 2. Shell 脚本的执行方式 2.1 脚本格式要求 2.2 编写第一个 shell 脚本 2.3 脚本的常用执行方式 🖊 方式一：输入脚本的绝对路径或相对路径 🖊 方式二：sh + 脚本 3. shell 的变量 3.1 Shell 变量介绍 3.2 Shell 变量定义 基本语法： 快速入门： 补充：shell 脚本的注释： 3.3 shell 变量的定义 定义变量的规则： 将命令的返回值赋给变量： 3.4 设置环境变量 基本语法： 快速入门： 3.5 位置参数变量 3.5.1 基本语法 3.5.2 案例 3.6 预定义变量 3.6.1 基本语法 3.6.2 案例 4. 运算符 4.1 基本语法 4.2 案例 5. 条件判断 5.1 基本语法 5.2 常用判断条件 3.8.3 案例 6. 流程控制 6.1 if 判断 6.2 case 语句 6.3 for 循环 🖊 基本语法 1 🖊 基本语法 2 6.4 while 循环 7. read 读取控制台输入 8. 函数 8.1 系统函数 8.1.1 basename 函数 8.1.2 dirname 函数 8.2 自定义函数 9. 综合案例",content:'# 1. Shell 概述\n\n\n# 1.1 为什么要学习 Shell 编程\n\n * Linux 运维工程师在进行服务器集群管理时，需要编写 Shell 程序来进行服务器管理。\n * 对于 JavaEE 和 Python 程序员来说，工作的需要，会要求你编写一些 Shell 脚本进行程序或者是服务器的维护，比如编写一个定时备份数据库的脚本。\n * 对于大数据程序员来说，需要编写 Shell 程序来管理集群。\n\n\n# 1.2 shell 是什么\n\nShell 是一个命令行解释器，它为用户提供了一个向 Linux 内核发送请求以便运行程序的界面系统级程序，用户可以用 Shell 来启动、挂起、停止甚至是编写一些程序。\n\n\n# 2. Shell 脚本的执行方式\n\n\n# 2.1 脚本格式要求\n\n脚本以 #!/bin/bash 开头，需要有可执行权限。\n\n\n# 2.2 编写第一个 shell 脚本\n\n需求：创建一个 shell 脚本，输出 hello world！\n\nvim hello.sh\n#!/bin/bash\necho "hello,world~"\n\n\n1\n2\n3\n\n\n\n# 2.3 脚本的常用执行方式\n\n# 🖊 方式一：输入脚本的绝对路径或相对路径\n\n说明：首先要赋予脚本 +x 的权限，再执行脚本\n\n# 🖊 方式二：sh + 脚本\n\n说明：不用赋予脚本+x 权限，直接执行即可\n\n比如 sh hello.sh\n\n\n# 3. shell 的变量\n\n\n# 3.1 Shell 变量介绍\n\n * Shell 变量分为系统变量和用户自定义变量。\n * 系统变量：$HOME、$PWD、$SHELL、$USER 等等，比如：echo $HOME 等等。\n * 显示 shell 所有系统变量：set 指令\n\n\n# 3.2 Shell 变量定义\n\n# 基本语法：\n\n * 定义变量：变量名=值\n   * 注意在 shell 编程中，这种等号的两边不要打空格。\n * 撤销变量：unset 变量\n * 声明静态变量：readonly 变量，注意不能 unset\n\n# 快速入门：\n\n#!/bin/bash\n\n# 案例 1：定义变量 A\nA=100\n# 输出变量需要加上 $\necho A=$A\necho "A=$A"\n# 案例 2：撤销变量 A\nunset A\necho "A=$A"\n# 案例 3：声明静态的变量 B=2，不能撤销\nreadonly B=2\necho "B=$B"\n# 此时如果 unset B，执行时会报错\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\nvim 中临时显示行号：:nu vim 中显示行号：:set nu\n\n# 补充：shell 脚本的注释：\n\n * 单行注释：#\n * 多行注释：\n\n:<<!\n需要注释的第一行内容\n需要注释的第二行内容\n!\n\n\n1\n2\n3\n4\n\n\n\n# 3.3 shell 变量的定义\n\n# 定义变量的规则：\n\n * 变量名称可以由字母、数字和下划线组成，但是不能以数字开头。\n * 等号两侧不能有空格\n * 变量名称一般习惯为大写，这是一个规范，遵守即可\n\n# 将命令的返回值赋给变量：\n\n * A=date，通过反引号，运行里面的命令，并把结果返回给变量 A\n * A=$(date) 等价于反引号\n\n\n# 3.4 设置环境变量\n\n# 基本语法：\n\n * export 变量名=变量值：将 Shell 变量输出为环境变量\n * source 配置文件：让修改后的配置文件立即生效\n * echo $变量名：查询环境变量的值\n\n# 快速入门：\n\n# 通过编辑 /etc/profile 文件配置 JDK 环境变量，要增加以下命令\nexport JAVA_HOME=/usr/local/java/jdk1.8.0_261\nexport PATH=$JAVA_HOME/bin:$PATH\n# 保存退出 /etc/profile 文件后，执行 source /etc/profile 命令使修改后的配置文件生效\n\n\n1\n2\n3\n4\n\n\n> 在 /etc/profile 文件中设置的变量是全局变量。而 .bashrc文件（在用户的家目录下）则只对当前用户有用。~/.bashrc、~/.bash_file 是当前用户目录下的配置信息。修改后用 source 命令更新。\n\n\n# 3.5 位置参数变量\n\n当我们执行一个 Shell 脚本时，如果希望获取到命令行的参数信息，就可以使用到位置参数变量，比如 ./myshell.sh 100 200 , 这个就是一个执行 shell 的命令行，可以在 myshell 脚本中获取到参数信息。\n\n# 3.5.1 基本语法\n\n * $n：n 为数字，$0 代表命令本身，$1-$9 代表第一到第九个参数，十以上的参数需要用大括号，如 ${10}\n * $*：代表命令行中所有的参数，$* 把所有的参数看成一个整体\n * $@：代表命令行中所有的参数，不过该命令是把每个参数区分对待\n * $#：代表命令行中所有参数的个数\n\n# 3.5.2 案例\n\n案例：在脚本中获取到命令行的各个参数信息\n\n#!/bin/bash\necho "0=$0 1=$1 2=$2"\necho "命令行所有传入的参数=$*"\necho "$@"\necho "参数的个数=$#"\n\n\n1\n2\n3\n4\n5\n\n\n\n# 3.6 预定义变量\n\nShell 设计者事先已经定义好的变量，可以直接在 Shell 脚本中使用。不常用。\n\n# 3.6.1 基本语法\n\n * $$：当前进程的进程号\n * $!：后台运行的最后一个进程的进程号\n * $?：最后一次执行的命令的返回状态。如果这个变量的值为 0，证明上一个命令正确执行；如果这个变量的值为非 0（具体是哪个数，由命令自己来决定），则证明上一个命令执行不正确\n\n# 3.6.2 案例\n\n#!/bin/bash\necho "当前进程号=$$"\n# 后台方式运行 myShell.sh\n./myShell.sh &\necho "最后的的进程号=$!"\necho "执行的值=$?"\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n# 4. 运算符\n\n在 Shell 中进行各种运算操作。\n\n# 4.1 基本语法\n\n * $((运算式)) 或 $[运算式]\n * 或 expr m + n。注意 expr 运算符间要有空格 [推荐使用]\n   * 如果希望将 expr 的结果赋给某个变量，使用反引号 `` 将它们包围起来。\n * expr \\*，/， % 分别代表乘，除，取余\n   * 注意在使用 expr 时乘法前面有个转义符：\\*\n\n# 4.2 案例\n\n#!/bin/bash\n# 案例1：计算（2+3）X4 的值\n# 使用第一种方式\nRES1=$(((2+3)*4))\necho "res1=$RES1"\n# 使用第二种方式（推荐）\nRES2=$[(2+3)*4]\necho "res2=$RES2"\n# 使用第三种方式（较为复杂）\nTEMP=`expr 2 + 3`\nRES3=`expr $TEMP \\* 4` \necho "temp=$TEMP"\necho "res3=$RES3"\necho "执行的值=$?"\n# 案例2：请求出命令行的两个参数[整数]的和\nSUM=$[$1+$2]\necho "sum=$SUM"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n\n# 5. 条件判断\n\n# 5.1 基本语法\n\n[ condition ] （注意 condition 前后要有空格），非空返回 true，可使用 $? 验证（0 为 true，>1 为 false）\n\n# 5.2 常用判断条件\n\n1）=：字符串是否相等\n\n2）两个整数的比较\n\n选项    含义\n-lt   小于\n-le   小于等于\n-eq   等于\n-gt   大于\n-ge   大于等于\n-ne   不等于\n\n3）按照文件权限进行判断\n\n选项   含义\n-r   有读的权限\n-w   有写的权限\n-x   有执行的权限\n\n4）按照文件类型进行判断\n\n选项   含义\n-f   文件存在并且是一个常规的文件\n-e   文件存在\n-d   文件存在并是一个目录\n\n * 注意使用时，这些 - 不能丢。\n\n# 3.8.3 案例\n\n#!/bin/bash\n# 案例1：“ok”是否等于“ok”\n# 判断语句：是否 =\nif [ "ok" = "ok" ]\nthen\n      echo "equal"\nfi\n# 案例2：23是否大于等于22\n# 判断语句：使用 -ge\nif [ 23 -ge 22 ] \nthen\n      echo "大于"\nfi\n# 案例3：/root/shcode/aaa.txt 目录中的文件是否存在\n# 判断语句：使用 -f\nif [ -f /root/shcode/aaa.txt ]\nthen\n      echo "存在"\nfi\n# 其他案例\nif [ edu ]\nthen\n      echo "hello, edu"\nfi\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# 6. 流程控制\n\n\n# 6.1 if 判断\n\nif [ 条件判断式 ]\nthen\n      程序\nelif [ 条件判断式 ]\nthen\n      程序\nfi\n\n\n1\n2\n3\n4\n5\n6\n7\n\n * 注意：[ 条件判断式 ] 中括号和条件判断式之间必须有空格，if 与 [ 之间也有空格。\n\nFor example：\n\n#!/bin/bash\n# 案例：编写一个 Shell 程序，如果输入的参数，大于等于60，则输出“及格了”，如果小于60，则输出 “不及格”\nif [ $1 -ge 60 ]\nthen\n      echo "及格了"\nelif [ $1 -lt 60 ]\nthen\n      echo "不及格"\nfi\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 6.2 case 语句\n\ncase $变量名 in\n"值 1")\n      如果变量的值等于值 1，则执行程序 1\n;;\n"值 2")\n      如果变量的值等于值 2，则执行程序 2\n;;\n      ...省略其他分支...\n*)\n      如果变量的值都不是以上的值，则执行此程序 \n;;\nesac\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n> 也许 Shell 程序看起来比较诡异，但当初设计者就是这么设计的，我们也只需要承认即可。\n\nFor Example：\n\n#!/bin/bash\n# 案例：当命令行参数是1时，输出“周一”，是2时，就输出“周二”，其它情况输出“other”\ncase $1 in\n"1")\n      echo "周一"\n;;\n"2")\n      echo "周二"\n;;\n*)\n      echo "other" \n;;\nesac\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 6.3 for 循环\n\n\n# 🖊 基本语法 1\n\nfor 变量 in 值1 值2 值3 ...\ndo\n      程序\ndone\n\n\n1\n2\n3\n4\n\n\nFor Example：\n\n#!/bin/bash\n# 案例：打印命令行输入的参数【可以看出 $* 和 $@ 的区别】\n# 注意 $* 是把输入的参数，当作一个整体，所以只会输出一行\nfor i in "$*"\ndo\n      echo "num is $i"\ndone\n# 使用 $@ 是把输入的参数，分别对待，所以有几个参数，就会输出几行\nfor j in "$@"\ndo\n      echo "num is $j"\ndone\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n * 从此案例可以看出 $* 和 $@ 的区别\n\n# 🖊 基本语法 2\n\nfor (( 初始值;循环控制条件;变量变化 ))\ndo\n      程序\ndone\n\n\n1\n2\n3\n4\n\n\n1 2 3 4\n\nFor Example：\n\n#!/bin/bash\n# 案例：从1加到100的值输出显示\n# 定义一个变量 SUM\nSUM=0\nfor (( i=1;i<=100;i++ ))\ndo\n      SUM=$[$SUM+i]\ndone\necho "总和SUM=$SUM"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 6.4 while 循环\n\nwhile [ 条件判断式 ]\ndo\n      程序\ndone\n\n\n1\n2\n3\n4\n\n * 注意：[ 条件判断式 ] 中括号和条件判断式之间必须有空格，while 与 [ 之间也有空格\n\nFor Example：\n\n#!/bin/bash\n# 案例：从命令行输入一个数 n，统计从 1+...+ n 的值\nSUM=0\ni=0\nwhile [ $i -le $1 ]\ndo\n      SUM=$[$i+$SUM]\n      i=$[$i+1]\ndone\necho "总和SUM=$SUM"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# 7. read 读取控制台输入\n\nread [选项] [参数]\n\n\n1\n\n * -p：指定读取值时的提示符；\n * -t：指定读取值时等待的时间（秒），如果没有在指定的时间内输入，就不再等待了。\n * 参数：指定读取值的变量名\n\nFor Example：\n\n#!/bin/bash\n# 案例1：读取控制台输入一个 NUM1 值\nread -p "请输入一个数NUM1=" NUM1\necho "您输入数NUM1=$NUM1"\n# 案例2：读取控制台输入一个 NUM2 值，在 10 秒内输入\nread -t 10 -p "请输入一个数NUM2=" NUM2\necho "您输入数NUM2=$NUM2"\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# 8. 函数\n\nshell 编程有系统函数，也可以自定义函数。\n\n\n# 8.1 系统函数\n\n这里只抛砖引玉地介绍两个系统函数\n\n# 8.1.1 basename 函数\n\n功能：返回完整路径最后 / 的部分，常用于获取文件名\n\n * basename [pathname] [suffix]\n * basename [string] [suffix]：会删掉所有的前缀包括最后一个（‘/’）字符，然后将字符串显示出来。\n\n选项：suffix 为后缀，如果 suffix 被指定了，basename 会将 pathname 或 string 中的 suffix 去掉。\n\n> 案例：请返回 /home/aaa/test.txt 的 test.txt 部分\n> \n>  * basename /home/aaa/test.txt\n>  * 如果我们指定后缀 suffix，即 basename /home/aaa/test.txt .txt，那么显示的只有 test\n\n# 8.1.2 dirname 函数\n\n功能：返回完整路径最后 / 的前面的部分，常用于返回路径部分。\n\n * dirname 文件绝对路径：从给定的包含绝对路径的文件名中去除文件名（非目录的部分），然后返回剩下的路径（目录的部分）。\n\n> 案例：请返回 /home/aaa/test.txt 的 /home/aaa 部分\n> \n>  * dirname /home/aaa/test.txt\n\n\n# 8.2 自定义函数\n\n[ function ] funname[()]\n{\n      Action;\n      [return int;]\n}\n\n\n1\n2\n3\n4\n5\n\n\n调用直接写函数名：funname [值]\n\nFor Example：\n\n#!/bin/bash\n# 案例1：计算输入两个参数的和（动态获取），getSum\n# 定义函数 getSum\nfunction getSum()\n{\n      SUM=$[$NUM1+$NUM2] \n      echo "和是=$SUM"\n}\n# 输入两个值\nread -p "请输入一个数NUM1=" NUM1\nread -p "请输入一个数NUM2=" NUM2\n# 调用自定义函数\ngetSum $NUM1 $NUM2\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n> 可以看出，shell 编程与我们常用的编程语言还是不太一样的，既然学了就看开一点。\n\n\n# 9. 综合案例\n\n需求：\n\n * 每天凌晨2:10，备份数据库 hspedu 到 /data/backup/db\n * 备份开始和备份结束能够给出相应的提示信息\n * 备份后的文件要求以备份时间为文件名，并打包成 .tar.gz 的形式，比如：2018-03-12_230201.tar.gz\n * 在备份的同时，检查是否有 10 天前备份的数据库文件，如果有就将其删除。\n * 编写一个 Shell 脚本。\n\nshell 脚本：\n\n#!/bin/bash\n#完成数据库的定时备份\n#备份的路径\nBACKUP=/data/backup/db\n#当前的时间作为文件名\nDATETIME=$(date +%Y-%m-%d_%H%M%S)\n#可以输出变量调试\n#echo ${DATETIME}\necho "======================开始备份=========================="\necho "========备份的路径为 $BACKUP/$DATETIME.tar.gz =========="\n#数据库地址\nHOST=localhost\n#数据库用户名\nDB_USER=root\n#数据库密码\nDB_PW=root\n#备份数据库名\nDATABASE=hspedu\n#创建备份的文件夹\n#如果该备份的文件夹有则使用，没有就重新创建一个。\n#-p：表示递归创建目录，或者说创建多级目录。\n[ ! -d "${BACKUP}/${DATETIME}"] && mkdir -p "${BACKUP}/${DATETIME}"\n#执行 MySQL 备份数据库的指令\nmysqldump -u${DB_USER} -p${DB_PW} --host=${HOST} ${DATABASE} | gzip > ${BACKUP}/${DATETIME}/$DATETIME.sql.gz\n#将文件处理成 tar.gz\ncd ${BACKUP}\ntar -zcvf $DATETIME.tar.gz ${DATETIME}\n# 删除对应的备份目录\nrm -rf ${BACKUP}/${DATETIME}\n#删除10天前的备份文件\nfind ${BACKUP} -atime +10 -name "*.tar.gz" -exec rm -rf {} \\;\necho "=====================备份文件成功========================="\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n\n\n运行 crontab -e 指令，增加下面命令（结尾光标要停留在 h 上），用于定时调用上面的 Shell 脚本：\n\n10 2 * * * /usr/sbin/mysql_db_backup.sh\n\n\n1\n',normalizedContent:'# 1. shell 概述\n\n\n# 1.1 为什么要学习 shell 编程\n\n * linux 运维工程师在进行服务器集群管理时，需要编写 shell 程序来进行服务器管理。\n * 对于 javaee 和 python 程序员来说，工作的需要，会要求你编写一些 shell 脚本进行程序或者是服务器的维护，比如编写一个定时备份数据库的脚本。\n * 对于大数据程序员来说，需要编写 shell 程序来管理集群。\n\n\n# 1.2 shell 是什么\n\nshell 是一个命令行解释器，它为用户提供了一个向 linux 内核发送请求以便运行程序的界面系统级程序，用户可以用 shell 来启动、挂起、停止甚至是编写一些程序。\n\n\n# 2. shell 脚本的执行方式\n\n\n# 2.1 脚本格式要求\n\n脚本以 #!/bin/bash 开头，需要有可执行权限。\n\n\n# 2.2 编写第一个 shell 脚本\n\n需求：创建一个 shell 脚本，输出 hello world！\n\nvim hello.sh\n#!/bin/bash\necho "hello,world~"\n\n\n1\n2\n3\n\n\n\n# 2.3 脚本的常用执行方式\n\n# 🖊 方式一：输入脚本的绝对路径或相对路径\n\n说明：首先要赋予脚本 +x 的权限，再执行脚本\n\n# 🖊 方式二：sh + 脚本\n\n说明：不用赋予脚本+x 权限，直接执行即可\n\n比如 sh hello.sh\n\n\n# 3. shell 的变量\n\n\n# 3.1 shell 变量介绍\n\n * shell 变量分为系统变量和用户自定义变量。\n * 系统变量：$home、$pwd、$shell、$user 等等，比如：echo $home 等等。\n * 显示 shell 所有系统变量：set 指令\n\n\n# 3.2 shell 变量定义\n\n# 基本语法：\n\n * 定义变量：变量名=值\n   * 注意在 shell 编程中，这种等号的两边不要打空格。\n * 撤销变量：unset 变量\n * 声明静态变量：readonly 变量，注意不能 unset\n\n# 快速入门：\n\n#!/bin/bash\n\n# 案例 1：定义变量 a\na=100\n# 输出变量需要加上 $\necho a=$a\necho "a=$a"\n# 案例 2：撤销变量 a\nunset a\necho "a=$a"\n# 案例 3：声明静态的变量 b=2，不能撤销\nreadonly b=2\necho "b=$b"\n# 此时如果 unset b，执行时会报错\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\nvim 中临时显示行号：:nu vim 中显示行号：:set nu\n\n# 补充：shell 脚本的注释：\n\n * 单行注释：#\n * 多行注释：\n\n:<<!\n需要注释的第一行内容\n需要注释的第二行内容\n!\n\n\n1\n2\n3\n4\n\n\n\n# 3.3 shell 变量的定义\n\n# 定义变量的规则：\n\n * 变量名称可以由字母、数字和下划线组成，但是不能以数字开头。\n * 等号两侧不能有空格\n * 变量名称一般习惯为大写，这是一个规范，遵守即可\n\n# 将命令的返回值赋给变量：\n\n * a=date，通过反引号，运行里面的命令，并把结果返回给变量 a\n * a=$(date) 等价于反引号\n\n\n# 3.4 设置环境变量\n\n# 基本语法：\n\n * export 变量名=变量值：将 shell 变量输出为环境变量\n * source 配置文件：让修改后的配置文件立即生效\n * echo $变量名：查询环境变量的值\n\n# 快速入门：\n\n# 通过编辑 /etc/profile 文件配置 jdk 环境变量，要增加以下命令\nexport java_home=/usr/local/java/jdk1.8.0_261\nexport path=$java_home/bin:$path\n# 保存退出 /etc/profile 文件后，执行 source /etc/profile 命令使修改后的配置文件生效\n\n\n1\n2\n3\n4\n\n\n> 在 /etc/profile 文件中设置的变量是全局变量。而 .bashrc文件（在用户的家目录下）则只对当前用户有用。~/.bashrc、~/.bash_file 是当前用户目录下的配置信息。修改后用 source 命令更新。\n\n\n# 3.5 位置参数变量\n\n当我们执行一个 shell 脚本时，如果希望获取到命令行的参数信息，就可以使用到位置参数变量，比如 ./myshell.sh 100 200 , 这个就是一个执行 shell 的命令行，可以在 myshell 脚本中获取到参数信息。\n\n# 3.5.1 基本语法\n\n * $n：n 为数字，$0 代表命令本身，$1-$9 代表第一到第九个参数，十以上的参数需要用大括号，如 ${10}\n * $*：代表命令行中所有的参数，$* 把所有的参数看成一个整体\n * $@：代表命令行中所有的参数，不过该命令是把每个参数区分对待\n * $#：代表命令行中所有参数的个数\n\n# 3.5.2 案例\n\n案例：在脚本中获取到命令行的各个参数信息\n\n#!/bin/bash\necho "0=$0 1=$1 2=$2"\necho "命令行所有传入的参数=$*"\necho "$@"\necho "参数的个数=$#"\n\n\n1\n2\n3\n4\n5\n\n\n\n# 3.6 预定义变量\n\nshell 设计者事先已经定义好的变量，可以直接在 shell 脚本中使用。不常用。\n\n# 3.6.1 基本语法\n\n * $$：当前进程的进程号\n * $!：后台运行的最后一个进程的进程号\n * $?：最后一次执行的命令的返回状态。如果这个变量的值为 0，证明上一个命令正确执行；如果这个变量的值为非 0（具体是哪个数，由命令自己来决定），则证明上一个命令执行不正确\n\n# 3.6.2 案例\n\n#!/bin/bash\necho "当前进程号=$$"\n# 后台方式运行 myshell.sh\n./myshell.sh &\necho "最后的的进程号=$!"\necho "执行的值=$?"\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n# 4. 运算符\n\n在 shell 中进行各种运算操作。\n\n# 4.1 基本语法\n\n * $((运算式)) 或 $[运算式]\n * 或 expr m + n。注意 expr 运算符间要有空格 [推荐使用]\n   * 如果希望将 expr 的结果赋给某个变量，使用反引号 `` 将它们包围起来。\n * expr \\*，/， % 分别代表乘，除，取余\n   * 注意在使用 expr 时乘法前面有个转义符：\\*\n\n# 4.2 案例\n\n#!/bin/bash\n# 案例1：计算（2+3）x4 的值\n# 使用第一种方式\nres1=$(((2+3)*4))\necho "res1=$res1"\n# 使用第二种方式（推荐）\nres2=$[(2+3)*4]\necho "res2=$res2"\n# 使用第三种方式（较为复杂）\ntemp=`expr 2 + 3`\nres3=`expr $temp \\* 4` \necho "temp=$temp"\necho "res3=$res3"\necho "执行的值=$?"\n# 案例2：请求出命令行的两个参数[整数]的和\nsum=$[$1+$2]\necho "sum=$sum"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n\n# 5. 条件判断\n\n# 5.1 基本语法\n\n[ condition ] （注意 condition 前后要有空格），非空返回 true，可使用 $? 验证（0 为 true，>1 为 false）\n\n# 5.2 常用判断条件\n\n1）=：字符串是否相等\n\n2）两个整数的比较\n\n选项    含义\n-lt   小于\n-le   小于等于\n-eq   等于\n-gt   大于\n-ge   大于等于\n-ne   不等于\n\n3）按照文件权限进行判断\n\n选项   含义\n-r   有读的权限\n-w   有写的权限\n-x   有执行的权限\n\n4）按照文件类型进行判断\n\n选项   含义\n-f   文件存在并且是一个常规的文件\n-e   文件存在\n-d   文件存在并是一个目录\n\n * 注意使用时，这些 - 不能丢。\n\n# 3.8.3 案例\n\n#!/bin/bash\n# 案例1：“ok”是否等于“ok”\n# 判断语句：是否 =\nif [ "ok" = "ok" ]\nthen\n      echo "equal"\nfi\n# 案例2：23是否大于等于22\n# 判断语句：使用 -ge\nif [ 23 -ge 22 ] \nthen\n      echo "大于"\nfi\n# 案例3：/root/shcode/aaa.txt 目录中的文件是否存在\n# 判断语句：使用 -f\nif [ -f /root/shcode/aaa.txt ]\nthen\n      echo "存在"\nfi\n# 其他案例\nif [ edu ]\nthen\n      echo "hello, edu"\nfi\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# 6. 流程控制\n\n\n# 6.1 if 判断\n\nif [ 条件判断式 ]\nthen\n      程序\nelif [ 条件判断式 ]\nthen\n      程序\nfi\n\n\n1\n2\n3\n4\n5\n6\n7\n\n * 注意：[ 条件判断式 ] 中括号和条件判断式之间必须有空格，if 与 [ 之间也有空格。\n\nfor example：\n\n#!/bin/bash\n# 案例：编写一个 shell 程序，如果输入的参数，大于等于60，则输出“及格了”，如果小于60，则输出 “不及格”\nif [ $1 -ge 60 ]\nthen\n      echo "及格了"\nelif [ $1 -lt 60 ]\nthen\n      echo "不及格"\nfi\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 6.2 case 语句\n\ncase $变量名 in\n"值 1")\n      如果变量的值等于值 1，则执行程序 1\n;;\n"值 2")\n      如果变量的值等于值 2，则执行程序 2\n;;\n      ...省略其他分支...\n*)\n      如果变量的值都不是以上的值，则执行此程序 \n;;\nesac\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n> 也许 shell 程序看起来比较诡异，但当初设计者就是这么设计的，我们也只需要承认即可。\n\nfor example：\n\n#!/bin/bash\n# 案例：当命令行参数是1时，输出“周一”，是2时，就输出“周二”，其它情况输出“other”\ncase $1 in\n"1")\n      echo "周一"\n;;\n"2")\n      echo "周二"\n;;\n*)\n      echo "other" \n;;\nesac\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 6.3 for 循环\n\n\n# 🖊 基本语法 1\n\nfor 变量 in 值1 值2 值3 ...\ndo\n      程序\ndone\n\n\n1\n2\n3\n4\n\n\nfor example：\n\n#!/bin/bash\n# 案例：打印命令行输入的参数【可以看出 $* 和 $@ 的区别】\n# 注意 $* 是把输入的参数，当作一个整体，所以只会输出一行\nfor i in "$*"\ndo\n      echo "num is $i"\ndone\n# 使用 $@ 是把输入的参数，分别对待，所以有几个参数，就会输出几行\nfor j in "$@"\ndo\n      echo "num is $j"\ndone\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n * 从此案例可以看出 $* 和 $@ 的区别\n\n# 🖊 基本语法 2\n\nfor (( 初始值;循环控制条件;变量变化 ))\ndo\n      程序\ndone\n\n\n1\n2\n3\n4\n\n\n1 2 3 4\n\nfor example：\n\n#!/bin/bash\n# 案例：从1加到100的值输出显示\n# 定义一个变量 sum\nsum=0\nfor (( i=1;i<=100;i++ ))\ndo\n      sum=$[$sum+i]\ndone\necho "总和sum=$sum"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 6.4 while 循环\n\nwhile [ 条件判断式 ]\ndo\n      程序\ndone\n\n\n1\n2\n3\n4\n\n * 注意：[ 条件判断式 ] 中括号和条件判断式之间必须有空格，while 与 [ 之间也有空格\n\nfor example：\n\n#!/bin/bash\n# 案例：从命令行输入一个数 n，统计从 1+...+ n 的值\nsum=0\ni=0\nwhile [ $i -le $1 ]\ndo\n      sum=$[$i+$sum]\n      i=$[$i+1]\ndone\necho "总和sum=$sum"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# 7. read 读取控制台输入\n\nread [选项] [参数]\n\n\n1\n\n * -p：指定读取值时的提示符；\n * -t：指定读取值时等待的时间（秒），如果没有在指定的时间内输入，就不再等待了。\n * 参数：指定读取值的变量名\n\nfor example：\n\n#!/bin/bash\n# 案例1：读取控制台输入一个 num1 值\nread -p "请输入一个数num1=" num1\necho "您输入数num1=$num1"\n# 案例2：读取控制台输入一个 num2 值，在 10 秒内输入\nread -t 10 -p "请输入一个数num2=" num2\necho "您输入数num2=$num2"\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# 8. 函数\n\nshell 编程有系统函数，也可以自定义函数。\n\n\n# 8.1 系统函数\n\n这里只抛砖引玉地介绍两个系统函数\n\n# 8.1.1 basename 函数\n\n功能：返回完整路径最后 / 的部分，常用于获取文件名\n\n * basename [pathname] [suffix]\n * basename [string] [suffix]：会删掉所有的前缀包括最后一个（‘/’）字符，然后将字符串显示出来。\n\n选项：suffix 为后缀，如果 suffix 被指定了，basename 会将 pathname 或 string 中的 suffix 去掉。\n\n> 案例：请返回 /home/aaa/test.txt 的 test.txt 部分\n> \n>  * basename /home/aaa/test.txt\n>  * 如果我们指定后缀 suffix，即 basename /home/aaa/test.txt .txt，那么显示的只有 test\n\n# 8.1.2 dirname 函数\n\n功能：返回完整路径最后 / 的前面的部分，常用于返回路径部分。\n\n * dirname 文件绝对路径：从给定的包含绝对路径的文件名中去除文件名（非目录的部分），然后返回剩下的路径（目录的部分）。\n\n> 案例：请返回 /home/aaa/test.txt 的 /home/aaa 部分\n> \n>  * dirname /home/aaa/test.txt\n\n\n# 8.2 自定义函数\n\n[ function ] funname[()]\n{\n      action;\n      [return int;]\n}\n\n\n1\n2\n3\n4\n5\n\n\n调用直接写函数名：funname [值]\n\nfor example：\n\n#!/bin/bash\n# 案例1：计算输入两个参数的和（动态获取），getsum\n# 定义函数 getsum\nfunction getsum()\n{\n      sum=$[$num1+$num2] \n      echo "和是=$sum"\n}\n# 输入两个值\nread -p "请输入一个数num1=" num1\nread -p "请输入一个数num2=" num2\n# 调用自定义函数\ngetsum $num1 $num2\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n> 可以看出，shell 编程与我们常用的编程语言还是不太一样的，既然学了就看开一点。\n\n\n# 9. 综合案例\n\n需求：\n\n * 每天凌晨2:10，备份数据库 hspedu 到 /data/backup/db\n * 备份开始和备份结束能够给出相应的提示信息\n * 备份后的文件要求以备份时间为文件名，并打包成 .tar.gz 的形式，比如：2018-03-12_230201.tar.gz\n * 在备份的同时，检查是否有 10 天前备份的数据库文件，如果有就将其删除。\n * 编写一个 shell 脚本。\n\nshell 脚本：\n\n#!/bin/bash\n#完成数据库的定时备份\n#备份的路径\nbackup=/data/backup/db\n#当前的时间作为文件名\ndatetime=$(date +%y-%m-%d_%h%m%s)\n#可以输出变量调试\n#echo ${datetime}\necho "======================开始备份=========================="\necho "========备份的路径为 $backup/$datetime.tar.gz =========="\n#数据库地址\nhost=localhost\n#数据库用户名\ndb_user=root\n#数据库密码\ndb_pw=root\n#备份数据库名\ndatabase=hspedu\n#创建备份的文件夹\n#如果该备份的文件夹有则使用，没有就重新创建一个。\n#-p：表示递归创建目录，或者说创建多级目录。\n[ ! -d "${backup}/${datetime}"] && mkdir -p "${backup}/${datetime}"\n#执行 mysql 备份数据库的指令\nmysqldump -u${db_user} -p${db_pw} --host=${host} ${database} | gzip > ${backup}/${datetime}/$datetime.sql.gz\n#将文件处理成 tar.gz\ncd ${backup}\ntar -zcvf $datetime.tar.gz ${datetime}\n# 删除对应的备份目录\nrm -rf ${backup}/${datetime}\n#删除10天前的备份文件\nfind ${backup} -atime +10 -name "*.tar.gz" -exec rm -rf {} \\;\necho "=====================备份文件成功========================="\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n\n\n运行 crontab -e 指令，增加下面命令（结尾光标要停留在 h 上），用于定时调用上面的 shell 脚本：\n\n10 2 * * * /usr/sbin/mysql_db_backup.sh\n\n\n1\n',charsets:{cjk:!0},lastUpdated:"2022/08/22, 08:23:58",lastUpdatedTimestamp:1661156638e3},{title:"带你实现Linux命令自由",frontmatter:{title:"带你实现Linux命令自由",date:"2022-09-09T10:05:35.000Z",permalink:"/pages/dd2e0e/",categories:["基础","Linux","From公众号"],tags:[null]},regularPath:"/%E5%9F%BA%E7%A1%80/10.Linux/10.From%E5%85%AC%E4%BC%97%E5%8F%B7/5.%E5%B8%A6%E4%BD%A0%E5%AE%9E%E7%8E%B0Linux%E5%91%BD%E4%BB%A4%E8%87%AA%E7%94%B1.html",relativePath:"基础/10.Linux/10.From公众号/5.带你实现Linux命令自由.md",key:"v-02285212",path:"/pages/dd2e0e/",headers:[{level:2,title:"目录",slug:"目录",normalizedTitle:"目录",charIndex:2},{level:2,title:"什么是 Linux",slug:"什么是-linux",normalizedTitle:"什么是 linux",charIndex:9},{level:3,title:"Linux 系统内核与 Linux 发行套件的区别",slug:"linux-系统内核与-linux-发行套件的区别",normalizedTitle:"linux 系统内核与 linux 发行套件的区别",charIndex:28},{level:3,title:"Linux 系统种类",slug:"linux-系统种类",normalizedTitle:"linux 系统种类",charIndex:63},{level:2,title:"Shell",slug:"shell",normalizedTitle:"shell",charIndex:78},{level:2,title:"命令",slug:"命令",normalizedTitle:"命令",charIndex:88},{level:3,title:"命令行提示符",slug:"命令行提示符",normalizedTitle:"命令行提示符",charIndex:100},{level:2,title:"文件和目录",slug:"文件和目录",normalizedTitle:"文件和目录",charIndex:111},{level:3,title:"文件的组织",slug:"文件的组织",normalizedTitle:"文件的组织",charIndex:126},{level:3,title:"查看路径",slug:"查看路径",normalizedTitle:"查看路径",charIndex:141},{level:4,title:"pwd",slug:"pwd",normalizedTitle:"pwd",charIndex:159},{level:4,title:"which",slug:"which",normalizedTitle:"which",charIndex:176},{level:3,title:"浏览和切换目录",slug:"浏览和切换目录",normalizedTitle:"浏览和切换目录",charIndex:191},{level:4,title:"ls",slug:"ls",normalizedTitle:"ls",charIndex:212},{level:4,title:"cd",slug:"cd",normalizedTitle:"cd",charIndex:228},{level:4,title:"du",slug:"du",normalizedTitle:"du",charIndex:244},{level:3,title:"浏览和创建文件",slug:"浏览和创建文件",normalizedTitle:"浏览和创建文件",charIndex:256},{level:4,title:"cat",slug:"cat",normalizedTitle:"cat",charIndex:277},{level:4,title:"less",slug:"less",normalizedTitle:"less",charIndex:294},{level:4,title:"head",slug:"head",normalizedTitle:"head",charIndex:312},{level:4,title:"tail",slug:"tail",normalizedTitle:"tail",charIndex:330},{level:4,title:"touch",slug:"touch",normalizedTitle:"touch",charIndex:348},{level:4,title:"mkdir",slug:"mkdir",normalizedTitle:"mkdir",charIndex:367},{level:3,title:"文件的复制和移动",slug:"文件的复制和移动",normalizedTitle:"文件的复制和移动",charIndex:382},{level:4,title:"cp",slug:"cp",normalizedTitle:"cp",charIndex:404},{level:4,title:"mv",slug:"mv",normalizedTitle:"mv",charIndex:420},{level:3,title:"文件的删除和链接",slug:"文件的删除和链接",normalizedTitle:"文件的删除和链接",charIndex:432},{level:4,title:"rm",slug:"rm",normalizedTitle:"rm",charIndex:454},{level:4,title:"ln",slug:"ln",normalizedTitle:"ln",charIndex:470},{level:4,title:"硬链接",slug:"硬链接",normalizedTitle:"硬链接",charIndex:486},{level:4,title:"软链接",slug:"软链接",normalizedTitle:"软链接",charIndex:503},{level:2,title:"用户与权限",slug:"用户与权限",normalizedTitle:"用户与权限",charIndex:511},{level:3,title:"用户",slug:"用户",normalizedTitle:"用户",charIndex:511},{level:4,title:"sudo",slug:"sudo",normalizedTitle:"sudo",charIndex:542},{level:4,title:"useradd + passwd",slug:"useradd-passwd",normalizedTitle:"useradd + passwd",charIndex:560},{level:4,title:"userdel",slug:"userdel",normalizedTitle:"userdel",charIndex:590},{level:4,title:"su",slug:"su",normalizedTitle:"su",charIndex:542},{level:3,title:"群组的管理",slug:"群组的管理",normalizedTitle:"群组的管理",charIndex:623},{level:4,title:"groupadd",slug:"groupadd",normalizedTitle:"groupadd",charIndex:642},{level:4,title:"groupdel",slug:"groupdel",normalizedTitle:"groupdel",charIndex:664},{level:4,title:"groups",slug:"groups",normalizedTitle:"groups",charIndex:686},{level:4,title:"usermod",slug:"usermod",normalizedTitle:"usermod",charIndex:706},{level:4,title:"chgrp",slug:"chgrp",normalizedTitle:"chgrp",charIndex:727},{level:4,title:"chown",slug:"chown",normalizedTitle:"chown",charIndex:746},{level:3,title:"文件权限管理",slug:"文件权限管理",normalizedTitle:"文件权限管理",charIndex:761},{level:4,title:"chmod",slug:"chmod",normalizedTitle:"chmod",charIndex:781},{level:4,title:"数字分配权限",slug:"数字分配权限",normalizedTitle:"数字分配权限",charIndex:800},{level:4,title:"用字母来分配权限",slug:"用字母来分配权限",normalizedTitle:"用字母来分配权限",charIndex:820},{level:2,title:"查找文件",slug:"查找文件",normalizedTitle:"查找文件",charIndex:833},{level:3,title:"locate",slug:"locate",normalizedTitle:"locate",charIndex:847},{level:4,title:"安装 locate",slug:"安装-locate",normalizedTitle:"安装 locate",charIndex:867},{level:3,title:"find",slug:"find",normalizedTitle:"find",charIndex:886},{level:4,title:"根据文件名查找",slug:"根据文件名查找",normalizedTitle:"根据文件名查找",charIndex:904},{level:4,title:"根据文件大小查找",slug:"根据文件大小查找",normalizedTitle:"根据文件大小查找",charIndex:925},{level:4,title:"根据文件最近访问时间查找",slug:"根据文件最近访问时间查找",normalizedTitle:"根据文件最近访问时间查找",charIndex:947},{level:4,title:"仅查找目录或文件",slug:"仅查找目录或文件",normalizedTitle:"仅查找目录或文件",charIndex:973},{level:4,title:"操作查找结果",slug:"操作查找结果",normalizedTitle:"操作查找结果",charIndex:995}],headersStr:"目录 什么是 Linux Linux 系统内核与 Linux 发行套件的区别 Linux 系统种类 Shell 命令 命令行提示符 文件和目录 文件的组织 查看路径 pwd which 浏览和切换目录 ls cd du 浏览和创建文件 cat less head tail touch mkdir 文件的复制和移动 cp mv 文件的删除和链接 rm ln 硬链接 软链接 用户与权限 用户 sudo useradd + passwd userdel su 群组的管理 groupadd groupdel groups usermod chgrp chown 文件权限管理 chmod 数字分配权限 用字母来分配权限 查找文件 locate 安装 locate find 根据文件名查找 根据文件大小查找 根据文件最近访问时间查找 仅查找目录或文件 操作查找结果",content:'# 目录\n\n * 什么是 Linux\n   \n   * Linux 系统内核与 Linux 发行套件的区别\n   \n   * Linux 系统种类\n\n * Shell\n\n * 命令\n   \n   * 命令行提示符\n\n * 文件和目录\n   \n   * 文件的组织\n   \n   * 查看路径\n     \n     * pwd\n     \n     * which\n   \n   * 浏览和切换目录\n     \n     * ls\n     \n     * cd\n     \n     * du\n   \n   * 浏览和创建文件\n     \n     * cat\n     \n     * less\n     \n     * head\n     \n     * tail\n     \n     * touch\n     \n     * mkdir\n   \n   * 文件的复制和移动\n     \n     * cp\n     \n     * mv\n   \n   * 文件的删除和链接\n     \n     * rm\n     \n     * ln\n     \n     * 硬链接\n     \n     * 软链接\n\n * 用户与权限\n   \n   * 用户\n     \n     * sudo\n     \n     * useradd + passwd\n     \n     * userdel\n     \n     * su\n   \n   * 群组的管理\n     \n     * groupadd\n     \n     * groupdel\n     \n     * groups\n     \n     * usermod\n     \n     * chgrp\n     \n     * chown\n   \n   * 文件权限管理\n     \n     * chmod\n     \n     * 数字分配权限\n     \n     * 用字母来分配权限\n\n * 查找文件\n   \n   * locate\n     \n     * 安装 locate\n   \n   * find\n     \n     * 根据文件名查找\n     \n     * 根据文件大小查找\n     \n     * 根据文件最近访问时间查找\n     \n     * 仅查找目录或文件\n     \n     * 操作查找结果\n\n\n# 带你实现Linux命令自由\n\n来自——小夕学算法\n\n----------------------------------------\n\n\n# 什么是 Linux\n\n\n# Linux 系统内核与 Linux 发行套件的区别\n\n * Linux 系统内核指的是由 Linus Torvalds 负责维护，提供硬件抽象层、硬盘及文件系统控制及多任务功能的系统核心程序。\n\n * Linux 发行套件系统是我们常说的 Linux 操作系统，也即是由 Linux 内核与各种常用软件的集合产品。\n\n总结：真正的  指的是系统内核，而我们常说的  指的是“发行版完整的包含一些基础软件的操作系统”。\n\n\n# Linux 系统种类\n\n * 红帽企业版 Linux ：RHEL 是全世界内使用最广泛的 Linux 系统。它具有极强的性能与稳定性，是众多生成环境中使用的（收费的）系统。\n\n * Fedora ：由红帽公司发布的桌面版系统套件，用户可以免费体验到最新的技术或工具，这些技术或工具在成熟后会被加入到 RHEL 系统中，因此 Fedora 也成为 RHEL 系统的试验版本。\n\n * CentOS ：通过把 RHEL 系统重新编译并发布给用户免费使用的 Linux 系统，具有广泛的使用人群。\n\n * Deepin ：中国发行，对优秀的开源成品进行集成和配置。\n\n * Debian ：稳定性、安全性强，提供了免费的基础支持，在国外拥有很高的认可度和使用率。\n\n * Ubuntu ：是一款派生自 Debian 的操作系统，对新款硬件具有极强的兼容能力。Ubuntu 与 Fedora 都是极其出色的 Linux 桌面系统，而且 Ubuntu 也可用于服务器领域。\n\n\n# Shell\n\nShell 这个单词的原意是“外壳”，跟 kernel（内核）相对应，比喻内核外面的一层，即用户跟内核交互的对话界面。\n\n * Shell 是一个程序，提供一个与用户对话的环境。这个环境只有一个命令提示符，让用户从键盘输入命令，所以又称为命令行环境（ command line interface ，简写为 CLI ）。Shell 接收到用户输入的命令，将命令送入操作系统执行，并将结果返回给用户。\n\n * Shell 是一个命令解释器，解释用户输入的命令。它支持变量、条件判断、循环操作等语法，所以用户可以用 Shell 命令写出各种小程序，又称为 Shell 脚本。这些脚本都通过Shell 的解释执行，而不通过编译。\n\n * Shell 是一个工具箱，提供了各种小工具，供用户方便地使用操作系统的功能。\n\nBash 是目前最常用的 Shell 。MacOS 中的默认 Shell 就是 Bash 。 通过执行 echo $SHELL 命令可以查看到当前正在使用的 Shell 。还可以通过 cat /etc/shells 查看当前系统安装的所有 Shell 种类。\n\n\n# 命令\n\n\n# 命令行提示符\n\n进入命令行环境以后，用户会看到 Shell 的提示符。提示符往往是一串前缀，最后以一个美元符号 $ 结尾，用户可以在这个符号后面输入各种命令。\n\n命令解析：\n\n * root：表示用户名；\n\n * iZm5e8dsxce9ufaic7hi3uZ：表示主机名；\n\n * ~：表示目前所在目录为家目录，其中 root 用户的家目录是 /root 普通用户的家目录在 /home 下；\n\n * #：指示你所具有的权限（ root 用户为 # ，普通用户为 $ ）。\n\n * 执行 whoami 命令可以查看当前用户名；\n\n * 执行 hostname 命令可以查看当前主机名；\n\n关于如何创建、切换、删除用户，在后面的用户与权限会具体讲解，这里先使用 root 用户进行演示。\n\n[备注] root 是超级用户，具备操作系统的一切权限。切换到root：su root，每次登陆系统root的密码都不一样，是随机的。但可以修改。\n\n\n# 文件和目录\n\n\n# 文件的组织\n\n\n\n\n# 查看路径\n\n# pwd\n\n显示当前目录的路径\n\n\n\n# which\n\n查看命令的可执行文件所在路径， Linux 下，每一条命令其实都对应一个可执行程序，在终端中输入命令，按回车的时候，就是执行了对应的那个程序， which 命令本身对应的程序也存在于 Linux 中。\n\n总的来说一个命令就是一个可执行程序。\n\n\n\n\n# 浏览和切换目录\n\n# ls\n\n列出文件和目录，它是 Linux 最常用的命令之一。\n\n【常用参数】\n\n * -a 显示所有文件和目录包括隐藏的\n\n * -l 显示详细列表\n\n * -h 适合人类阅读的\n\n * -t 按文件最近一次修改时间排序\n\n * -i 显示文件的 inode （ inode 是文件内容的标识）\n\n\n\n# cd\n\ncd 是英语 change directory 的缩写，表示切换目录。\n\ncd / --\x3e 跳转到根目录 cd ~ --\x3e 跳转到家目录 cd .. --\x3e 跳转到上级目录 cd ./home --\x3e 跳转到当前目录的home目录下 cd /home/lion --\x3e 跳转到根目录下的home目录下的lion目录 cd --\x3e 不添加任何参数，也是回到家目录 复制代码\n\n[注意] 输入cd /ho + 单次 tab 键会自动补全路径 + 两次 tab 键会列出所有可能的目录列表。\n\n# du\n\n列举目录大小信息。\n\n【常用参数】\n\n * -h 适合人类阅读的；\n\n * -a 同时列举出目录下文件的大小信息；\n\n * -s 只显示总计大小，不显示具体信息。\n\n\n# 浏览和创建文件\n\n# cat\n\n一次性显示文件所有内容，更适合查看小的文件。\n\ncat cloud-init.log 复制代码\n\n【常用参数】\n\n * -n 显示行号。\n\n# less\n\n分页显示文件内容，更适合查看大的文件。\n\nless cloud-init.log 复制代码\n\n【快捷操作】\n\n * 空格键：前进一页（一个屏幕）；\n\n * b 键：后退一页；\n\n * 回车键：前进一行；\n\n * y 键：后退一行；\n\n * 上下键：回退或前进一行；\n\n * d 键：前进半页；\n\n * u 键：后退半页；\n\n * q 键：停止读取文件，中止 less 命令；\n\n * = 键：显示当前页面的内容是文件中的第几行到第几行以及一些其它关于本页内容的详细信息；\n\n * h 键：显示帮助文档；\n\n * / 键：进入搜索模式后，按 n 键跳到一个符合项目，按 N 键跳到上一个符合项目，同时也可以输入正则表达式匹配。\n\n# head\n\n显示文件的开头几行（默认是10行）\n\nhead cloud-init.log 复制代码\n\n【参数】\n\n * -n 指定行数 head cloud-init.log -n 2\n\n# tail\n\n显示文件的结尾几行（默认是10行）\n\ntail cloud-init.log复制代码\n\n【参数】\n\n * -n 指定行数 tail cloud-init.log -n 2\n\n * -f 会每过1秒检查下文件是否有更新内容，也可以用 -s 参数指定间隔时间 tail -f -s 4 xxx.log\n\n# touch\n\n创建一个文件\n\ntouch new_file复制代码\n\n# mkdir\n\n创建一个目录\n\nmkdir new_folder复制代码\n\n【常用参数】\n\n * -p 递归的创建目录结构 mkdir -p one/two/three\n\n\n# 文件的复制和移动\n\n# cp\n\n拷贝文件和目录\n\ncp file file_copy --\x3e file 是目标文件，file_copy 是拷贝出来的文件\ncp file one --\x3e 把 file 文件拷贝到 one 目录下，并且文件名依然为 file\ncp file one/file_copy --\x3e 把 file 文件拷贝到 one 目录下，文件名为file_copy\ncp *.txt folder --\x3e 把当前目录下所有 txt 文件拷贝到 folder 目录下复制代码   \n\n\n1\n2\n3\n4\n\n\n【常用参数】\n\n * -r 递归的拷贝，常用来拷贝一整个目录\n\n# mv\n\n移动（重命名）文件或目录，与cp命令用法相似。\n\nmv file one --\x3e 将 file 文件移动到 one 目录下\nmv new_folder one --\x3e 将 new_folder 文件夹移动到one目录下\nmv *.txt folder --\x3e 把当前目录下所有 txt 文件移动到 folder 目录下\nmv file new_file --\x3e file 文件重命名为 new_file复制代码   \n\n\n1\n2\n3\n4\n\n\n\n# 文件的删除和链接\n\n# rm\n\n删除文件和目录，由于 Linux 下没有回收站，一旦删除非常难恢复，因此需要谨慎操作\n\nrm new_file  --\x3e 删除 new_file 文件\nrm f1 f2 f3  --\x3e 同时删除 f1 f2 f3 3个文件复制代码   \n\n\n1\n2\n\n\n【常用参数】\n\n * -i 向用户确认是否删除；\n\n * -f 文件强制删除；\n\n * -r 递归删除文件夹，著名的删除操作 rm -rf 。\n\n# ln\n\n英文 Link 的缩写，表示创建链接。\n\n学习创建链接之前，首先要理解链接是什么，我们先来看看 Linux 的文件是如何存储的：\n\nLinux 文件的存储方式分为3个部分，文件名、文件内容以及权限，其中文件名的列表是存储在硬盘的其它地方和文件内容是分开存放的，每个文件名通过 inode 标识绑定到文件内容。\n\nLinux 下有两种链接类型：硬链接和软链接。\n\n# 硬链接\n\n使链接的两个文件共享同样文件内容，就是同样的 inode ，一旦文件1和文件2之间有了硬链接，那么修改任何一个文件，修改的都是同一块内容，它的缺点是，只能创建指向文件的硬链接，不能创建指向目录的（其实也可以，但比较复杂）而软链接都可以，因此软链接使用更加广泛。\n\nln file1 file2  --\x3e 创建 file2 为 file1 的硬链接复制代码 \n\n\n1\n\n\n\n\n如果我们用 rm file1 来删除 file1 ，对 file2 没有什么影响，对于硬链接来说，删除任意一方的文件，共同指向的文件内容并不会从硬盘上删除。只有同时删除了 file1 与file2 后，它们共同指向的文件内容才会消失。\n\n# 软链接\n\n软链接就类似 windows 下快捷方式。\n\nln -s file1 file2复制代码   \n\n\n1\n\n\n\n\n执行 ls -l 命名查看当前目录下文件的具体信息\n\ntotal 0-rw-r--r-- 1 root root 0 Jan 14 06:29 file1lrwxrwxrwx 1 root root 5 Jan 14 06:42 file2 -> file1  # 表示file2 指向 file1复制代码   \n\n\n1\n\n\n其实 file2 只是 file1 的一个快捷方式，它指向的是 file1 ，所以显示的是 file1 的内容，但其实 file2 的 inode 与 file1 并不相同。如果我们删除了 file2 的话， file1是不会受影响的，但如果删除 file1 的话， file2 就会变成死链接，因为指向的文件不见了。\n\n\n# 用户与权限\n\n\n# 用户\n\nLinux 是一个多用户的操作系统。在 Linux 中，理论上来说，我们可以创建无数个用户，但是这些用户是被划分到不同的群组里面的，有一个用户，名叫 root ，是一个很特殊的用户，它是超级用户，拥有最高权限。\n\n\n\n自己创建的用户是有限权限的用户，这样大大提高了 Linux 系统的安全性，有效防止误操作或是病毒攻击，但是我们执行的某些命令需要更高权限时可以使用 sudo 命令。\n\n# sudo\n\n以 root 身份运行命令\n\nsudo date  --\x3e 当然查看日期是不需要sudo的这里只是演示，sudo 完之后一般还需要输入用户密码的复制代码   \n\n\n1\n\n\n# useradd + passwd\n\n * useradd 添加新用户\n\n * passwd 修改用户密码\n\n这两个命令需要 root 用户权限\n\nuseradd lion --\x3e 添加一个lion用户，添加完之后在 /home 路径下可以查看passwd lion --\x3e 修改lion用户的密码复制代码   \n\n\n1\n\n\n# userdel\n\n删除用户，需要 root 用户权限\n\nuserdel lion --\x3e 只会删除用户名，不会从/home中删除对应文件夹userdel lion -r --\x3e 会同时删除/home下的对应文件夹复制代码 \n\n\n1\n\n\n# su\n\n切换用户，需要 root 用户权限\n\nsudo su --\x3e 切换为root用户（exit 命令或 CTRL + D 快捷键都可以使普通用户切换为 root 用户）\nsu lion --\x3e 切换为普通用户su - --\x3e 切换为root用户复制代码   \n\n\n1\n2\n\n\n\n# 群组的管理\n\nLinux 中每个用户都属于一个特定的群组，如果你不设置用户的群组，默认会创建一个和它的用户名一样的群组，并且把用户划归到这个群组。\n\n# groupadd\n\n创建群组，用法和 useradd 类似。\n\ngroupadd friends复制代码   \n\n\n1\n\n\n# groupdel\n\n删除一个已存在的群组\n\ngroupdel foo  --\x3e 删除foo群组复制代码   \n\n\n1\n\n\n# groups\n\n查看用户所在群组\n\ngroups lion  --\x3e 查看 lion 用户所在的群组复制代码\n\n\n1\n\n\n# usermod\n\n用于修改用户的账户。\n\n【常用参数】\n\n * -l 对用户重命名。需要注意的是 /home 中的用户家目录的名字不会改变，需要手动修改。\n\n * -g 修改用户所在的群组，例如 usermod -g friends lion修改 lion 用户的群组为 friends 。\n\n * -G 一次性让用户添加多个群组，例如 usermod -G friends,foo,bar lion 。\n\n * -a -G 会让你离开原先的群组，如果你不想这样做的话，就得再添加 -a 参数，意味着append 追加的意思。\n\n# chgrp\n\n用于修改文件的群组。\n\nchgrp bar file.txt --\x3e file.txt文件的群组修改为bar复制代码 \n\n\n1\n\n\n# chown\n\n改变文件的所有者，需要 root 身份才能运行。\n\nchown lion file.txt --\x3e 把其它用户创建的file.txt转让给lion用户chown lion:bar file.txt --\x3e 把file.txt的用户改为lion，群组改为bar复制代码   \n\n\n1\n\n\n【常用参数】\n\n * -R 递归设置子目录和子文件， chown -R lion:lion /home/frank 把 frank 文件夹的用户和群组都改为 lion 。\n\n\n# 文件权限管理\n\n# chmod\n\n修改访问权限。\n\nchmod 740 file.txt\n\n\n1\n\n\n【常用参数】\n\n * -R 可以递归地修改文件访问权限，例如 chmod -R 777 /home/lion\n\n修改权限的确简单，但是理解其深层次的意义才是更加重要的。下面我们来系统的学习Linux 的文件权限。\n\n[root@lion ~]# ls -ldrwxr-xr-x 5 root root 4096 Apr 13  2020 climblrwxrwxrwx 1 root root    7 Jan 14 06:41 hello2.c -> hello.c-rw-r--r-- 1 root root  149 Jan 13 06:14 hello.c复制代码   \n\n\n1\n\n\n其中 drwxr-xr-x 表示文件或目录的权限。让我们一起来解读它具体代表什么？\n\n * d ：表示目录，就是说这是一个目录，普通文件是 - ，链接是 l 。\n\n * r ：read 表示文件可读。\n\n * w ：write 表示文件可写，一般有写的权限，就有删除的权限。\n\n * x ：execute 表示文件可执行。\n\n * - ：表示没有相应权限。\n\n权限的整体是按用户来划分的，如下图所示：\n\n\n\n现在再来理解这句权限 drwxr-xr-x 的意思：\n\n * 它是一个文件夹；\n\n * 它的所有者具有：读、写、执行权限；\n\n * 它的群组用户具有：读、执行的权限，没有写的权限；\n\n * 它的其它用户具有：读、执行的权限，没有写的权限。\n\n现在理解了权限，我们使用 chmod 来尝试修改权限。chmod 它不需要是 root 用户才能运行的，只要你是此文件所有者，就可以用 chmod 来修改文件的访问权限。\n\n# 数字分配权限\n\n权限   数字\nr    4\nw    2\nx    1\n\n因此要改变权限，只要做一些简单的加法就行：\n\nchmod 640 hello.c # 分析6 = 4 + 2 + 0 表示所有者具有 rw 权限4 = 4 + 0 + 0 表示群组用户具有 r 权限0 = 0 + 0 + 0 表示其它用户没有权限对应文字权限为：-rw-r-----复制代码\n\n\n1\n\n\n# 用字母来分配权限\n\n * u ：user 的缩写，用户的意思，表示所有者。\n\n * g ：group 的缩写，群组的意思，表示群组用户。\n\n * o ：other 的缩写，其它的意思，表示其它用户。\n\n * a ：all 的缩写，所有的意思，表示所有用户。\n\n * + ：加号，表示添加权限。\n\n * - ：减号，表示去除权限。\n\n * = ：等于号，表示分配权限。\n\nchmod u+rx file --\x3e 文件file的所有者增加读和运行的权限\nchmod g+r file --\x3e 文件file的群组用户增加读的权限\nchmod o-r file --\x3e 文件file的其它用户移除读的权限\nchmod g+r o-r file --\x3e 文件file的群组用户增加读的权限，其它用户移除读的权限\nchmod go-r file --\x3e 文件file的群组和其他用户移除读的权限\nchmod +x file --\x3e 文件file的所有用户增加运行的权限\nchmod u=rwx,g=r,o=- file --\x3e 文件file的所有者分配读写和执行的权限，群组其它用户分配读的权限，其他用户没有任何权限复制代码   \n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# 查找文件\n\n\n# locate\n\n搜索包含关键字的所有文件和目录。后接需要查找的文件名，也可以用正则表达式。\n\n# 安装 locate\n\nyum -y install mlocate --\x3e 安装包updatedb --\x3e 更新数据库复制代码locate file.txtlocate fil*.txt复制代码\n\n[注意] locate 命令会去文件数据库中查找命令，而不是全磁盘查找，因此刚创建的文件并不会更新到数据库中，所以无法被查找到，可以执行 updatedb 命令去更新数据库。\n\n\n# find\n\n用于查找文件，它会去遍历你的实际硬盘进行查找，而且它允许我们对每个找到的文件进行后续操作，功能非常强大。\n\nfind <何处> <何物> <做什么>复制代码\n\n * 何处：指定在哪个目录查找，此目录的所有子目录也会被查找。\n\n * 何物：查找什么，可以根据文件的名字来查找，也可以根据其大小来查找，还可以根据其最近访问时间来查找。\n\n * 做什么：找到文件后，可以进行后续处理，如果不指定这个参数， find 命令只会显示找到的文件。\n\n# 根据文件名查找\n\nfind -name "file.txt" --\x3e 当前目录以及子目录下通过名称查找文件find . -name "syslog" --\x3e 当前目录以及子目录下通过名称查找文件find / -name "syslog" --\x3e 整个硬盘下查找syslogfind /var/log -name "syslog" --\x3e 在指定的目录/var/log下查找syslog文件find /var/log -name "syslog*" --\x3e 查找syslog1、syslog2 ... 等文件，通配符表示所有find /var/log -name "*syslog*" --\x3e 查找包含syslog的文件 复制代码\n\n[注意] find 命令只会查找完全符合 “何物” 字符串的文件，而 locate 会查找所有包含关键字的文件。\n\n# 根据文件大小查找\n\nfind /var -size +10M --\x3e /var 目录下查找文件大小超过 10M 的文件find /var -size -50k --\x3e /var 目录下查找文件大小小于 50k 的文件find /var -size +1G --\x3e /var 目录下查找文件大小查过 1G 的文件find /var -size 1M --\x3e /var 目录下查找文件大小等于 1M 的文件复制代码\n\n# 根据文件最近访问时间查找\n\nfind -name "*.txt" -atime -7  --\x3e 近 7天内访问过的.txt结尾的文件复制代码\n\n# 仅查找目录或文件\n\nfind . -name "file" -type f  --\x3e 只查找当前目录下的file文件find . -name "file" -type d  --\x3e 只查找当前目录下的file目录复制代码\n\n# 操作查找结果\n\nfind -name "*.txt" -printf "%p - %u\\n" --\x3e 找出所有后缀为txt的文件，并按照 %p - %u\\n 格式打印，其中%p=文件名，%u=文件所有者find -name "*.jpg" -delete --\x3e 删除当前目录以及子目录下所有.jpg为后缀的文件，不会有删除提示，因此要慎用find -name "*.c" -exec chmod 600 {} \\; --\x3e 对每个.c结尾的文件，都进行 -exec 参数指定的操作，{} 会被查找到的文件替代，\\; 是必须的结尾find -name "*.c" -ok chmod 600 {} \\; --\x3e 和上面的功能一直，会多一个确认提示复制代码',normalizedContent:'# 目录\n\n * 什么是 linux\n   \n   * linux 系统内核与 linux 发行套件的区别\n   \n   * linux 系统种类\n\n * shell\n\n * 命令\n   \n   * 命令行提示符\n\n * 文件和目录\n   \n   * 文件的组织\n   \n   * 查看路径\n     \n     * pwd\n     \n     * which\n   \n   * 浏览和切换目录\n     \n     * ls\n     \n     * cd\n     \n     * du\n   \n   * 浏览和创建文件\n     \n     * cat\n     \n     * less\n     \n     * head\n     \n     * tail\n     \n     * touch\n     \n     * mkdir\n   \n   * 文件的复制和移动\n     \n     * cp\n     \n     * mv\n   \n   * 文件的删除和链接\n     \n     * rm\n     \n     * ln\n     \n     * 硬链接\n     \n     * 软链接\n\n * 用户与权限\n   \n   * 用户\n     \n     * sudo\n     \n     * useradd + passwd\n     \n     * userdel\n     \n     * su\n   \n   * 群组的管理\n     \n     * groupadd\n     \n     * groupdel\n     \n     * groups\n     \n     * usermod\n     \n     * chgrp\n     \n     * chown\n   \n   * 文件权限管理\n     \n     * chmod\n     \n     * 数字分配权限\n     \n     * 用字母来分配权限\n\n * 查找文件\n   \n   * locate\n     \n     * 安装 locate\n   \n   * find\n     \n     * 根据文件名查找\n     \n     * 根据文件大小查找\n     \n     * 根据文件最近访问时间查找\n     \n     * 仅查找目录或文件\n     \n     * 操作查找结果\n\n\n# 带你实现linux命令自由\n\n来自——小夕学算法\n\n----------------------------------------\n\n\n# 什么是 linux\n\n\n# linux 系统内核与 linux 发行套件的区别\n\n * linux 系统内核指的是由 linus torvalds 负责维护，提供硬件抽象层、硬盘及文件系统控制及多任务功能的系统核心程序。\n\n * linux 发行套件系统是我们常说的 linux 操作系统，也即是由 linux 内核与各种常用软件的集合产品。\n\n总结：真正的  指的是系统内核，而我们常说的  指的是“发行版完整的包含一些基础软件的操作系统”。\n\n\n# linux 系统种类\n\n * 红帽企业版 linux ：rhel 是全世界内使用最广泛的 linux 系统。它具有极强的性能与稳定性，是众多生成环境中使用的（收费的）系统。\n\n * fedora ：由红帽公司发布的桌面版系统套件，用户可以免费体验到最新的技术或工具，这些技术或工具在成熟后会被加入到 rhel 系统中，因此 fedora 也成为 rhel 系统的试验版本。\n\n * centos ：通过把 rhel 系统重新编译并发布给用户免费使用的 linux 系统，具有广泛的使用人群。\n\n * deepin ：中国发行，对优秀的开源成品进行集成和配置。\n\n * debian ：稳定性、安全性强，提供了免费的基础支持，在国外拥有很高的认可度和使用率。\n\n * ubuntu ：是一款派生自 debian 的操作系统，对新款硬件具有极强的兼容能力。ubuntu 与 fedora 都是极其出色的 linux 桌面系统，而且 ubuntu 也可用于服务器领域。\n\n\n# shell\n\nshell 这个单词的原意是“外壳”，跟 kernel（内核）相对应，比喻内核外面的一层，即用户跟内核交互的对话界面。\n\n * shell 是一个程序，提供一个与用户对话的环境。这个环境只有一个命令提示符，让用户从键盘输入命令，所以又称为命令行环境（ command line interface ，简写为 cli ）。shell 接收到用户输入的命令，将命令送入操作系统执行，并将结果返回给用户。\n\n * shell 是一个命令解释器，解释用户输入的命令。它支持变量、条件判断、循环操作等语法，所以用户可以用 shell 命令写出各种小程序，又称为 shell 脚本。这些脚本都通过shell 的解释执行，而不通过编译。\n\n * shell 是一个工具箱，提供了各种小工具，供用户方便地使用操作系统的功能。\n\nbash 是目前最常用的 shell 。macos 中的默认 shell 就是 bash 。 通过执行 echo $shell 命令可以查看到当前正在使用的 shell 。还可以通过 cat /etc/shells 查看当前系统安装的所有 shell 种类。\n\n\n# 命令\n\n\n# 命令行提示符\n\n进入命令行环境以后，用户会看到 shell 的提示符。提示符往往是一串前缀，最后以一个美元符号 $ 结尾，用户可以在这个符号后面输入各种命令。\n\n命令解析：\n\n * root：表示用户名；\n\n * izm5e8dsxce9ufaic7hi3uz：表示主机名；\n\n * ~：表示目前所在目录为家目录，其中 root 用户的家目录是 /root 普通用户的家目录在 /home 下；\n\n * #：指示你所具有的权限（ root 用户为 # ，普通用户为 $ ）。\n\n * 执行 whoami 命令可以查看当前用户名；\n\n * 执行 hostname 命令可以查看当前主机名；\n\n关于如何创建、切换、删除用户，在后面的用户与权限会具体讲解，这里先使用 root 用户进行演示。\n\n[备注] root 是超级用户，具备操作系统的一切权限。切换到root：su root，每次登陆系统root的密码都不一样，是随机的。但可以修改。\n\n\n# 文件和目录\n\n\n# 文件的组织\n\n\n\n\n# 查看路径\n\n# pwd\n\n显示当前目录的路径\n\n\n\n# which\n\n查看命令的可执行文件所在路径， linux 下，每一条命令其实都对应一个可执行程序，在终端中输入命令，按回车的时候，就是执行了对应的那个程序， which 命令本身对应的程序也存在于 linux 中。\n\n总的来说一个命令就是一个可执行程序。\n\n\n\n\n# 浏览和切换目录\n\n# ls\n\n列出文件和目录，它是 linux 最常用的命令之一。\n\n【常用参数】\n\n * -a 显示所有文件和目录包括隐藏的\n\n * -l 显示详细列表\n\n * -h 适合人类阅读的\n\n * -t 按文件最近一次修改时间排序\n\n * -i 显示文件的 inode （ inode 是文件内容的标识）\n\n\n\n# cd\n\ncd 是英语 change directory 的缩写，表示切换目录。\n\ncd / --\x3e 跳转到根目录 cd ~ --\x3e 跳转到家目录 cd .. --\x3e 跳转到上级目录 cd ./home --\x3e 跳转到当前目录的home目录下 cd /home/lion --\x3e 跳转到根目录下的home目录下的lion目录 cd --\x3e 不添加任何参数，也是回到家目录 复制代码\n\n[注意] 输入cd /ho + 单次 tab 键会自动补全路径 + 两次 tab 键会列出所有可能的目录列表。\n\n# du\n\n列举目录大小信息。\n\n【常用参数】\n\n * -h 适合人类阅读的；\n\n * -a 同时列举出目录下文件的大小信息；\n\n * -s 只显示总计大小，不显示具体信息。\n\n\n# 浏览和创建文件\n\n# cat\n\n一次性显示文件所有内容，更适合查看小的文件。\n\ncat cloud-init.log 复制代码\n\n【常用参数】\n\n * -n 显示行号。\n\n# less\n\n分页显示文件内容，更适合查看大的文件。\n\nless cloud-init.log 复制代码\n\n【快捷操作】\n\n * 空格键：前进一页（一个屏幕）；\n\n * b 键：后退一页；\n\n * 回车键：前进一行；\n\n * y 键：后退一行；\n\n * 上下键：回退或前进一行；\n\n * d 键：前进半页；\n\n * u 键：后退半页；\n\n * q 键：停止读取文件，中止 less 命令；\n\n * = 键：显示当前页面的内容是文件中的第几行到第几行以及一些其它关于本页内容的详细信息；\n\n * h 键：显示帮助文档；\n\n * / 键：进入搜索模式后，按 n 键跳到一个符合项目，按 n 键跳到上一个符合项目，同时也可以输入正则表达式匹配。\n\n# head\n\n显示文件的开头几行（默认是10行）\n\nhead cloud-init.log 复制代码\n\n【参数】\n\n * -n 指定行数 head cloud-init.log -n 2\n\n# tail\n\n显示文件的结尾几行（默认是10行）\n\ntail cloud-init.log复制代码\n\n【参数】\n\n * -n 指定行数 tail cloud-init.log -n 2\n\n * -f 会每过1秒检查下文件是否有更新内容，也可以用 -s 参数指定间隔时间 tail -f -s 4 xxx.log\n\n# touch\n\n创建一个文件\n\ntouch new_file复制代码\n\n# mkdir\n\n创建一个目录\n\nmkdir new_folder复制代码\n\n【常用参数】\n\n * -p 递归的创建目录结构 mkdir -p one/two/three\n\n\n# 文件的复制和移动\n\n# cp\n\n拷贝文件和目录\n\ncp file file_copy --\x3e file 是目标文件，file_copy 是拷贝出来的文件\ncp file one --\x3e 把 file 文件拷贝到 one 目录下，并且文件名依然为 file\ncp file one/file_copy --\x3e 把 file 文件拷贝到 one 目录下，文件名为file_copy\ncp *.txt folder --\x3e 把当前目录下所有 txt 文件拷贝到 folder 目录下复制代码   \n\n\n1\n2\n3\n4\n\n\n【常用参数】\n\n * -r 递归的拷贝，常用来拷贝一整个目录\n\n# mv\n\n移动（重命名）文件或目录，与cp命令用法相似。\n\nmv file one --\x3e 将 file 文件移动到 one 目录下\nmv new_folder one --\x3e 将 new_folder 文件夹移动到one目录下\nmv *.txt folder --\x3e 把当前目录下所有 txt 文件移动到 folder 目录下\nmv file new_file --\x3e file 文件重命名为 new_file复制代码   \n\n\n1\n2\n3\n4\n\n\n\n# 文件的删除和链接\n\n# rm\n\n删除文件和目录，由于 linux 下没有回收站，一旦删除非常难恢复，因此需要谨慎操作\n\nrm new_file  --\x3e 删除 new_file 文件\nrm f1 f2 f3  --\x3e 同时删除 f1 f2 f3 3个文件复制代码   \n\n\n1\n2\n\n\n【常用参数】\n\n * -i 向用户确认是否删除；\n\n * -f 文件强制删除；\n\n * -r 递归删除文件夹，著名的删除操作 rm -rf 。\n\n# ln\n\n英文 link 的缩写，表示创建链接。\n\n学习创建链接之前，首先要理解链接是什么，我们先来看看 linux 的文件是如何存储的：\n\nlinux 文件的存储方式分为3个部分，文件名、文件内容以及权限，其中文件名的列表是存储在硬盘的其它地方和文件内容是分开存放的，每个文件名通过 inode 标识绑定到文件内容。\n\nlinux 下有两种链接类型：硬链接和软链接。\n\n# 硬链接\n\n使链接的两个文件共享同样文件内容，就是同样的 inode ，一旦文件1和文件2之间有了硬链接，那么修改任何一个文件，修改的都是同一块内容，它的缺点是，只能创建指向文件的硬链接，不能创建指向目录的（其实也可以，但比较复杂）而软链接都可以，因此软链接使用更加广泛。\n\nln file1 file2  --\x3e 创建 file2 为 file1 的硬链接复制代码 \n\n\n1\n\n\n\n\n如果我们用 rm file1 来删除 file1 ，对 file2 没有什么影响，对于硬链接来说，删除任意一方的文件，共同指向的文件内容并不会从硬盘上删除。只有同时删除了 file1 与file2 后，它们共同指向的文件内容才会消失。\n\n# 软链接\n\n软链接就类似 windows 下快捷方式。\n\nln -s file1 file2复制代码   \n\n\n1\n\n\n\n\n执行 ls -l 命名查看当前目录下文件的具体信息\n\ntotal 0-rw-r--r-- 1 root root 0 jan 14 06:29 file1lrwxrwxrwx 1 root root 5 jan 14 06:42 file2 -> file1  # 表示file2 指向 file1复制代码   \n\n\n1\n\n\n其实 file2 只是 file1 的一个快捷方式，它指向的是 file1 ，所以显示的是 file1 的内容，但其实 file2 的 inode 与 file1 并不相同。如果我们删除了 file2 的话， file1是不会受影响的，但如果删除 file1 的话， file2 就会变成死链接，因为指向的文件不见了。\n\n\n# 用户与权限\n\n\n# 用户\n\nlinux 是一个多用户的操作系统。在 linux 中，理论上来说，我们可以创建无数个用户，但是这些用户是被划分到不同的群组里面的，有一个用户，名叫 root ，是一个很特殊的用户，它是超级用户，拥有最高权限。\n\n\n\n自己创建的用户是有限权限的用户，这样大大提高了 linux 系统的安全性，有效防止误操作或是病毒攻击，但是我们执行的某些命令需要更高权限时可以使用 sudo 命令。\n\n# sudo\n\n以 root 身份运行命令\n\nsudo date  --\x3e 当然查看日期是不需要sudo的这里只是演示，sudo 完之后一般还需要输入用户密码的复制代码   \n\n\n1\n\n\n# useradd + passwd\n\n * useradd 添加新用户\n\n * passwd 修改用户密码\n\n这两个命令需要 root 用户权限\n\nuseradd lion --\x3e 添加一个lion用户，添加完之后在 /home 路径下可以查看passwd lion --\x3e 修改lion用户的密码复制代码   \n\n\n1\n\n\n# userdel\n\n删除用户，需要 root 用户权限\n\nuserdel lion --\x3e 只会删除用户名，不会从/home中删除对应文件夹userdel lion -r --\x3e 会同时删除/home下的对应文件夹复制代码 \n\n\n1\n\n\n# su\n\n切换用户，需要 root 用户权限\n\nsudo su --\x3e 切换为root用户（exit 命令或 ctrl + d 快捷键都可以使普通用户切换为 root 用户）\nsu lion --\x3e 切换为普通用户su - --\x3e 切换为root用户复制代码   \n\n\n1\n2\n\n\n\n# 群组的管理\n\nlinux 中每个用户都属于一个特定的群组，如果你不设置用户的群组，默认会创建一个和它的用户名一样的群组，并且把用户划归到这个群组。\n\n# groupadd\n\n创建群组，用法和 useradd 类似。\n\ngroupadd friends复制代码   \n\n\n1\n\n\n# groupdel\n\n删除一个已存在的群组\n\ngroupdel foo  --\x3e 删除foo群组复制代码   \n\n\n1\n\n\n# groups\n\n查看用户所在群组\n\ngroups lion  --\x3e 查看 lion 用户所在的群组复制代码\n\n\n1\n\n\n# usermod\n\n用于修改用户的账户。\n\n【常用参数】\n\n * -l 对用户重命名。需要注意的是 /home 中的用户家目录的名字不会改变，需要手动修改。\n\n * -g 修改用户所在的群组，例如 usermod -g friends lion修改 lion 用户的群组为 friends 。\n\n * -g 一次性让用户添加多个群组，例如 usermod -g friends,foo,bar lion 。\n\n * -a -g 会让你离开原先的群组，如果你不想这样做的话，就得再添加 -a 参数，意味着append 追加的意思。\n\n# chgrp\n\n用于修改文件的群组。\n\nchgrp bar file.txt --\x3e file.txt文件的群组修改为bar复制代码 \n\n\n1\n\n\n# chown\n\n改变文件的所有者，需要 root 身份才能运行。\n\nchown lion file.txt --\x3e 把其它用户创建的file.txt转让给lion用户chown lion:bar file.txt --\x3e 把file.txt的用户改为lion，群组改为bar复制代码   \n\n\n1\n\n\n【常用参数】\n\n * -r 递归设置子目录和子文件， chown -r lion:lion /home/frank 把 frank 文件夹的用户和群组都改为 lion 。\n\n\n# 文件权限管理\n\n# chmod\n\n修改访问权限。\n\nchmod 740 file.txt\n\n\n1\n\n\n【常用参数】\n\n * -r 可以递归地修改文件访问权限，例如 chmod -r 777 /home/lion\n\n修改权限的确简单，但是理解其深层次的意义才是更加重要的。下面我们来系统的学习linux 的文件权限。\n\n[root@lion ~]# ls -ldrwxr-xr-x 5 root root 4096 apr 13  2020 climblrwxrwxrwx 1 root root    7 jan 14 06:41 hello2.c -> hello.c-rw-r--r-- 1 root root  149 jan 13 06:14 hello.c复制代码   \n\n\n1\n\n\n其中 drwxr-xr-x 表示文件或目录的权限。让我们一起来解读它具体代表什么？\n\n * d ：表示目录，就是说这是一个目录，普通文件是 - ，链接是 l 。\n\n * r ：read 表示文件可读。\n\n * w ：write 表示文件可写，一般有写的权限，就有删除的权限。\n\n * x ：execute 表示文件可执行。\n\n * - ：表示没有相应权限。\n\n权限的整体是按用户来划分的，如下图所示：\n\n\n\n现在再来理解这句权限 drwxr-xr-x 的意思：\n\n * 它是一个文件夹；\n\n * 它的所有者具有：读、写、执行权限；\n\n * 它的群组用户具有：读、执行的权限，没有写的权限；\n\n * 它的其它用户具有：读、执行的权限，没有写的权限。\n\n现在理解了权限，我们使用 chmod 来尝试修改权限。chmod 它不需要是 root 用户才能运行的，只要你是此文件所有者，就可以用 chmod 来修改文件的访问权限。\n\n# 数字分配权限\n\n权限   数字\nr    4\nw    2\nx    1\n\n因此要改变权限，只要做一些简单的加法就行：\n\nchmod 640 hello.c # 分析6 = 4 + 2 + 0 表示所有者具有 rw 权限4 = 4 + 0 + 0 表示群组用户具有 r 权限0 = 0 + 0 + 0 表示其它用户没有权限对应文字权限为：-rw-r-----复制代码\n\n\n1\n\n\n# 用字母来分配权限\n\n * u ：user 的缩写，用户的意思，表示所有者。\n\n * g ：group 的缩写，群组的意思，表示群组用户。\n\n * o ：other 的缩写，其它的意思，表示其它用户。\n\n * a ：all 的缩写，所有的意思，表示所有用户。\n\n * + ：加号，表示添加权限。\n\n * - ：减号，表示去除权限。\n\n * = ：等于号，表示分配权限。\n\nchmod u+rx file --\x3e 文件file的所有者增加读和运行的权限\nchmod g+r file --\x3e 文件file的群组用户增加读的权限\nchmod o-r file --\x3e 文件file的其它用户移除读的权限\nchmod g+r o-r file --\x3e 文件file的群组用户增加读的权限，其它用户移除读的权限\nchmod go-r file --\x3e 文件file的群组和其他用户移除读的权限\nchmod +x file --\x3e 文件file的所有用户增加运行的权限\nchmod u=rwx,g=r,o=- file --\x3e 文件file的所有者分配读写和执行的权限，群组其它用户分配读的权限，其他用户没有任何权限复制代码   \n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# 查找文件\n\n\n# locate\n\n搜索包含关键字的所有文件和目录。后接需要查找的文件名，也可以用正则表达式。\n\n# 安装 locate\n\nyum -y install mlocate --\x3e 安装包updatedb --\x3e 更新数据库复制代码locate file.txtlocate fil*.txt复制代码\n\n[注意] locate 命令会去文件数据库中查找命令，而不是全磁盘查找，因此刚创建的文件并不会更新到数据库中，所以无法被查找到，可以执行 updatedb 命令去更新数据库。\n\n\n# find\n\n用于查找文件，它会去遍历你的实际硬盘进行查找，而且它允许我们对每个找到的文件进行后续操作，功能非常强大。\n\nfind <何处> <何物> <做什么>复制代码\n\n * 何处：指定在哪个目录查找，此目录的所有子目录也会被查找。\n\n * 何物：查找什么，可以根据文件的名字来查找，也可以根据其大小来查找，还可以根据其最近访问时间来查找。\n\n * 做什么：找到文件后，可以进行后续处理，如果不指定这个参数， find 命令只会显示找到的文件。\n\n# 根据文件名查找\n\nfind -name "file.txt" --\x3e 当前目录以及子目录下通过名称查找文件find . -name "syslog" --\x3e 当前目录以及子目录下通过名称查找文件find / -name "syslog" --\x3e 整个硬盘下查找syslogfind /var/log -name "syslog" --\x3e 在指定的目录/var/log下查找syslog文件find /var/log -name "syslog*" --\x3e 查找syslog1、syslog2 ... 等文件，通配符表示所有find /var/log -name "*syslog*" --\x3e 查找包含syslog的文件 复制代码\n\n[注意] find 命令只会查找完全符合 “何物” 字符串的文件，而 locate 会查找所有包含关键字的文件。\n\n# 根据文件大小查找\n\nfind /var -size +10m --\x3e /var 目录下查找文件大小超过 10m 的文件find /var -size -50k --\x3e /var 目录下查找文件大小小于 50k 的文件find /var -size +1g --\x3e /var 目录下查找文件大小查过 1g 的文件find /var -size 1m --\x3e /var 目录下查找文件大小等于 1m 的文件复制代码\n\n# 根据文件最近访问时间查找\n\nfind -name "*.txt" -atime -7  --\x3e 近 7天内访问过的.txt结尾的文件复制代码\n\n# 仅查找目录或文件\n\nfind . -name "file" -type f  --\x3e 只查找当前目录下的file文件find . -name "file" -type d  --\x3e 只查找当前目录下的file目录复制代码\n\n# 操作查找结果\n\nfind -name "*.txt" -printf "%p - %u\\n" --\x3e 找出所有后缀为txt的文件，并按照 %p - %u\\n 格式打印，其中%p=文件名，%u=文件所有者find -name "*.jpg" -delete --\x3e 删除当前目录以及子目录下所有.jpg为后缀的文件，不会有删除提示，因此要慎用find -name "*.c" -exec chmod 600 {} \\; --\x3e 对每个.c结尾的文件，都进行 -exec 参数指定的操作，{} 会被查找到的文件替代，\\; 是必须的结尾find -name "*.c" -ok chmod 600 {} \\; --\x3e 和上面的功能一直，会多一个确认提示复制代码',charsets:{cjk:!0},lastUpdated:"2023/01/24, 08:14:58",lastUpdatedTimestamp:1674548098e3},{title:"LSM 树",frontmatter:{title:"LSM 树",date:"2023-05-24T09:44:43.000Z",permalink:"/pages/c2aef8/",categories:["基础","数据结构","常见数据结构"],tags:[null]},regularPath:"/%E5%9F%BA%E7%A1%80/15.%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/05.%E5%B8%B8%E8%A7%81%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/05.LSM%20%E6%A0%91.html",relativePath:"基础/15.数据结构/05.常见数据结构/05.LSM 树.md",key:"v-2bcd0941",path:"/pages/c2aef8/",headers:[{level:2,title:"1. LSM 树数据结构定义",slug:"_1-lsm-树数据结构定义",normalizedTitle:"1. lsm 树数据结构定义",charIndex:165},{level:2,title:"2. LSM 树的增删改查",slug:"_2-lsm-树的增删改查",normalizedTitle:"2. lsm 树的增删改查",charIndex:1225},{level:3,title:"2.1 插入操作",slug:"_2-1-插入操作",normalizedTitle:"2.1 插入操作",charIndex:1243},{level:3,title:"2.2 删除操作",slug:"_2-2-删除操作",normalizedTitle:"2.2 删除操作",charIndex:1427},{level:4,title:"2.2.1 待删除数据在内存中",slug:"_2-2-1-待删除数据在内存中",normalizedTitle:"2.2.1 待删除数据在内存中",charIndex:1532},{level:4,title:"2.2.2 待删除数据在磁盘中",slug:"_2-2-2-待删除数据在磁盘中",normalizedTitle:"2.2.2 待删除数据在磁盘中",charIndex:1610},{level:4,title:"2.2.3 待删除数据不存在",slug:"_2-2-3-待删除数据不存在",normalizedTitle:"2.2.3 待删除数据不存在",charIndex:1707},{level:3,title:"2.3 修改操作",slug:"_2-3-修改操作",normalizedTitle:"2.3 修改操作",charIndex:1904},{level:4,title:"2.3.1 待修改数据在内存中",slug:"_2-3-1-待修改数据在内存中",normalizedTitle:"2.3.1 待修改数据在内存中",charIndex:1970},{level:4,title:"2.3.2 待修改数据在磁盘中",slug:"_2-3-2-待修改数据在磁盘中",normalizedTitle:"2.3.2 待修改数据在磁盘中",charIndex:2046},{level:4,title:"2.3.3 该数据不存在",slug:"_2-3-3-该数据不存在",normalizedTitle:"2.3.3 该数据不存在",charIndex:2141},{level:3,title:"2.4 查询操作",slug:"_2-4-查询操作",normalizedTitle:"2.4 查询操作",charIndex:2371},{level:4,title:"2.4.1 待查询数据在内存中",slug:"_2-4-1-待查询数据在内存中",normalizedTitle:"2.4.1 待查询数据在内存中",charIndex:2543},{level:4,title:"2.4.2 待查询数据在磁盘中",slug:"_2-4-2-待查询数据在磁盘中",normalizedTitle:"2.4.2 待查询数据在磁盘中",charIndex:2714},{level:2,title:"3. LSM 树的合并操作",slug:"_3-lsm-树的合并操作",normalizedTitle:"3. lsm 树的合并操作",charIndex:3024},{level:3,title:"3.1 内存数据写入磁盘的场景",slug:"_3-1-内存数据写入磁盘的场景",normalizedTitle:"3.1 内存数据写入磁盘的场景",charIndex:3281},{level:3,title:"3.2 磁盘中多个块的归并",slug:"_3-2-磁盘中多个块的归并",normalizedTitle:"3.2 磁盘中多个块的归并",charIndex:3494},{level:2,title:"4. 优缺点分析",slug:"_4-优缺点分析",normalizedTitle:"4. 优缺点分析",charIndex:3815},{level:2,title:"5. 总结",slug:"_5-总结",normalizedTitle:"5. 总结",charIndex:4329}],headersStr:"1. LSM 树数据结构定义 2. LSM 树的增删改查 2.1 插入操作 2.2 删除操作 2.2.1 待删除数据在内存中 2.2.2 待删除数据在磁盘中 2.2.3 待删除数据不存在 2.3 修改操作 2.3.1 待修改数据在内存中 2.3.2 待修改数据在磁盘中 2.3.3 该数据不存在 2.4 查询操作 2.4.1 待查询数据在内存中 2.4.2 待查询数据在磁盘中 3. LSM 树的合并操作 3.1 内存数据写入磁盘的场景 3.2 磁盘中多个块的归并 4. 优缺点分析 5. 总结",content:'> 参考：深入浅出分析LSM树（日志结构合并树）\n\n使用场景：很多 NoSQL 数据库的底层存储引擎都是 LSM 树，如 RocksDB、LevelDB、HBase 以及 Prometheus 等。相比于B/B+树或者倒排索引，LSMTree采用了“疯狂到不顾一切”的干啥都磁盘顺序写的方案，赋予了它无与伦比的写吞吐量。\n\n\n# 1. LSM 树数据结构定义\n\nLSM 树并没有一种固定死的实现方式，更多的是一种将几种特性统一在一起的思想：\n\n * “磁盘顺序写”\n * “多个树(状数据结构)”\n * “冷热（新老）数据分级”\n * “定期归并”\n * “非原地更新”\n\nLSM树的定义：\n\n 1. LSM树是一个横跨内存和磁盘的，包含多颗"子树"的一个森林。\n 2. LSM树分为Level 0，Level 1，Level 2 ... Level n 多颗子树，其中只有Level 0在内存中，其余Level 1-n在磁盘中。\n 3. 内存中的Level 0子树一般采用排序树（红黑树/AVL树）、跳表或者TreeMap等这类有序的数据结构，方便后续顺序写磁盘。\n 4. 磁盘中的Level 1-n子树，本质是数据排好序后顺序写到磁盘上的文件，只是叫做树而已。\n 5. 每一层的子树都有一个阈值大小，达到阈值后会进行合并，合并结果写入下一层。\n 6. 只有内存中数据允许原地更新，磁盘上数据的变更只允许追加写，不做原地更新。\n\n以上6条定义组成了LSM树，如下图。\n\n * 图1中分成了左侧绿色的内存部分和右侧蓝色的磁盘部分（定义1）。\n * 图1左侧绿色的内存部分只包含Level 0树，右侧蓝色的磁盘部分则包含Level 1-n等多棵"树"（定义2）\n * 图1左侧绿色的内存部分中Level 0是一颗二叉排序树（定义3）。注意这里的有序性，该性质决定了LSM树优异的读写性能。\n * 图1右侧蓝色的磁盘部分所包含的Level 1到Level n多颗树，虽然叫做“树”，但本质是按数据key排好序后，顺序写在磁盘上的一个个文件（定义4） ，注意这里再次出现了有序性。\n * 内存中的Level 0树在达到阈值后，会在内存中遍历排好序的Level 0树并顺序写入磁盘的Level 1。同样的，在磁盘中的Level n（n>0）达到阈值时，则会将Level n层的多个文件进行归并，写入Level n+1层。（定义5） 除了内存中的Level 0层做原地更新外，对已写入磁盘上的数据，都采用Append形式的磁盘顺序写，即更新和删除操作并不去修改老数据，只是简单的追加新数据。图1中右侧蓝色的磁盘部分，Level 1和Level 2均包含key为2的数据，同时图1左侧绿色内存中的Level 0树也包含key为2的数据节点。（定义6）\n\n下面我们遵循 LSM 树的 6 条定义，通过动图对 LSM 树的增、删、改、查和归并进行详细分析。\n\n\n# 2. LSM 树的增删改查\n\n\n# 2.1 插入操作\n\nLSM树的插入较简单，数据无脑往内存中的Level 0排序树丢即可，并不关心该数据是否已经在内存或磁盘中存在。（已经存在该数据的话，则场景转换成更新操作）\n\n插入数据时，按照 key 的大小，插入内存中的 Level 0 排序树中，该操作复杂度为树高 log(n)，n 为 Level 0 树的数据量，所以代价很低，能实现极高的写吞吐量。\n\n\n# 2.2 删除操作\n\nLSM树的删除操作并不是直接删除数据，而是通过一种叫“墓碑标记”的特殊数据来标识数据的删除。\n\n删除操作分为：待删除数据在内存中、待删除数据在磁盘中 和 该数据根本不存在 三种情况。\n\n# 2.2.1 待删除数据在内存中\n\n将 Level 0 树中的对应节点采用墓碑标记将其覆盖。\n\n示例：删除 key 等于 2 的数据，结果如下图所示：\n\n# 2.2.2 待删除数据在磁盘中\n\n不去修改磁盘上的数据（理都不理它），而是直接向内存中的 Level 0 树中插入墓碑标记即可。\n\n示例：删除 key 等于 2 的数据，结果如下图所示：\n\n# 2.2.3 待删除数据不存在\n\n这种情况等价于在内存的 Level 0 树中新增一条墓碑标记，场景转换为情况 2.2.3 的内存中插入墓碑标记操作。\n\n----------------------------------------\n\n综合看待上述三种情况，发现不论数据有没有、在哪里，删除操作都是等价于向 Level 0 树中写入墓碑标记。该操作复杂度为树高log(n)，代价很低。\n\n\n# 2.3 修改操作\n\nLSM 树的修改操作和删除操作很像，也是分为三种情况：待修改数据在内存中、在磁盘中和 该数据根本不存在。\n\n# 2.3.1 待修改数据在内存中\n\n示例：修改 key=7 的数据。直接定位到内存中 Level 0 树上黄色的旧 key=7 的位置，将其覆盖。\n\n# 2.3.2 待修改数据在磁盘中\n\nLSM 树并不会去磁盘中的 Level 1 树上原地更新老的 key=7 的数据，而是直接将新的蓝色的节点 7 插入内存中的 Level 0 树中。\n\n# 2.3.3 该数据不存在\n\n此场景等价于情况b，直接向内存中的Level 0树插入新的数据即可。\n\n----------------------------------------\n\n综上三种情况可以看出，修改操作都是对内存中 Level 0 进行覆盖/新增操作。该操作复杂度为树高 log(n)，代价很低。\n\n我们会发现，LSM 树的增加、删除、修改（这三个都属于写操作）都是在内存中倒腾，完全没涉及到磁盘操作，所以速度飞快，写吞吐量高的离谱。。。\n\n\n# 2.4 查询操作\n\nLSM 树的查询操作会按顺序查找 Level 0、Level 1、Level 2 ... Level n 每一颗树，一旦匹配便返回目标数据，不再继续查询。该策略保证了查到的一定是目标 key 最新版本的数据（有点MVCC的感觉）。\n\n我们来分场景分析：依然分为 待查询数据在内存中 和 待查询数据在磁盘中 两种情况。\n\n# 2.4.1 待查询数据在内存中\n\n沿着内存中已排好序的Level 0树递归向下比较查询，返回目标节点即可。我们注意到磁盘上的Level 1树中同样包括一个key=6的较老的数据。但LSM树查询的时候会按照Level 0、1、2 ... n的顺序查询，一旦查到第一个就返回，因此磁盘上老的key=6的数据没人理它，更不会作为结果被返回。\n\n# 2.4.2 待查询数据在磁盘中\n\n先查询内存中的Level 0树，没查到便查询磁盘中的Level 1树，还是没查到，于是查询磁盘中的Level 2树，匹配后返回key=6的数据。\n\n----------------------------------------\n\n综合上述两种情况，我们发现，LSM 树的查询操作相对来说代价比较高，需要从Level 0到Level n一直顺序查下去。极端情况是LSM树中不存在该数据，则需要把整个库从Level 0到Level n给扫了一遍，然后返回查无此人（可以通过 布隆过滤器 + 建立稀疏索引 来优化查询操作）。代价大于以B/B+树为基本数据结构的传统RDB存储引擎。\n\n\n# 3. LSM 树的合并操作\n\n合并操作是LSM树的核心（毕竟LSM树的名字就叫: 日志结构合并树，直接点名了合并这一操作）\n\n之所以在增、删、改、查这四个基本操作之外还需要合并操作：\n\n * 一是 内存 => 磁盘。因为内存不是无限大，Level 0树达到阈值时，需要将数据从内存刷到磁盘中；\n * 二是 磁盘块1 + 磁盘块2 => 归并入下一层。需要对磁盘上达到阈值的顺序文件进行归并，并将归并结果写入下一层，归并过程中会清理重复的数据和被删除的数据(墓碑标记)。\n\n我们分别对上述两个场景进行分析：\n\n\n# 3.1 内存数据写入磁盘的场景\n\n下图展示了内存中 Level 0 树在达到阈值后，归并写入磁盘 Level 1 树的场景。\n\n归并之前：\n\n归并之后：\n\n对内存中的Level 0树进行中序遍历，将数据顺序写入磁盘的Level 1层即可，我们可以看到因为Level 0树是已经排好序的，所以写入的Level 1中的新块也是有序的（有序性保证了查询和归并操作的高效）。\n\n此时磁盘的Level 1层有两个Block块。\n\n\n# 3.2 磁盘中多个块的归并\n\n下图展示了磁盘中 Level 1 层达到阈值时，对其包含的两个 Block 块进行归并，并将归并结果写入 Level 2 层的过程。\n\n归并之前：\n\n归并之后：\n\n我们注意到 key=5 和 key=7 的数据同时存在于较老的Block 1和较新的Block 2中。而归并的过程是保留较新的数据，于是我们看到结果中，key=5和7的数据都是红色的（来自于较新的Block2）。\n\n----------------------------------------\n\n综上我们可以看到，不论是场景6.1还是场景6.2，由于原始数据都是有序的，因此归并的过程只需要对数据集进行一次扫描即可，复杂度为O(n)。\n\n\n# 4. 优缺点分析\n\n可以看到 LSM 树将增、删、改这三种操作都转化为内存 insert + 磁盘顺序写(当Level 0满的时候)，通过这种方式得到了无与伦比的写吞吐量。\n\nLSM 树的查询能力则相对被弱化，相比于 B+ 树的最多3~4次磁盘 IO，LSM 树则要从 Level 0 一路查询 Level n，极端情况下等于做了全表扫描。（即便做了稀疏索引，也是lg(N0)+lg(N1)+...+lg(Nn)的复杂度，大于B+树的lg(N0+N1+...+Nn)的时间复杂度）。\n\n同时，LSM树只append追加不原地修改的特性引入了归并操作，归并操作涉及到大量的磁盘IO，比较消耗性能，需要合理设置触发该操作的参数。\n\n综上我们可以给出LSM树的优缺点：\n\n * 优：增、删、改操作飞快，写吞吐量极大。\n * 缺：读操作性能相对被弱化；不擅长区间范围的读操作； 归并操作较耗费资源。\n\nLSMTree的增、删、改、查四种基本操作的时间复杂度分析如下所示：\n\n操作   平均代价   最坏情况代价\n删除   1      1\n插入   1      1\n修改   1      1\n查找   lgN    lgN\n\n\n# 5. 总结\n\nLSM树的设计原则：\n\n * 先内存再磁盘\n * 内存原地更新\n * 磁盘追加更新\n * 归并保留新值\n\n如果说B/B+树的读写性能基本平衡的话，LSM树的设计原则通过舍弃部分读性能，换取了无与伦比的写性能。该数据结构适合用于写吞吐量远远大于读吞吐量的场景，得到了NoSQL届的喜爱和好评。',normalizedContent:'> 参考：深入浅出分析lsm树（日志结构合并树）\n\n使用场景：很多 nosql 数据库的底层存储引擎都是 lsm 树，如 rocksdb、leveldb、hbase 以及 prometheus 等。相比于b/b+树或者倒排索引，lsmtree采用了“疯狂到不顾一切”的干啥都磁盘顺序写的方案，赋予了它无与伦比的写吞吐量。\n\n\n# 1. lsm 树数据结构定义\n\nlsm 树并没有一种固定死的实现方式，更多的是一种将几种特性统一在一起的思想：\n\n * “磁盘顺序写”\n * “多个树(状数据结构)”\n * “冷热（新老）数据分级”\n * “定期归并”\n * “非原地更新”\n\nlsm树的定义：\n\n 1. lsm树是一个横跨内存和磁盘的，包含多颗"子树"的一个森林。\n 2. lsm树分为level 0，level 1，level 2 ... level n 多颗子树，其中只有level 0在内存中，其余level 1-n在磁盘中。\n 3. 内存中的level 0子树一般采用排序树（红黑树/avl树）、跳表或者treemap等这类有序的数据结构，方便后续顺序写磁盘。\n 4. 磁盘中的level 1-n子树，本质是数据排好序后顺序写到磁盘上的文件，只是叫做树而已。\n 5. 每一层的子树都有一个阈值大小，达到阈值后会进行合并，合并结果写入下一层。\n 6. 只有内存中数据允许原地更新，磁盘上数据的变更只允许追加写，不做原地更新。\n\n以上6条定义组成了lsm树，如下图。\n\n * 图1中分成了左侧绿色的内存部分和右侧蓝色的磁盘部分（定义1）。\n * 图1左侧绿色的内存部分只包含level 0树，右侧蓝色的磁盘部分则包含level 1-n等多棵"树"（定义2）\n * 图1左侧绿色的内存部分中level 0是一颗二叉排序树（定义3）。注意这里的有序性，该性质决定了lsm树优异的读写性能。\n * 图1右侧蓝色的磁盘部分所包含的level 1到level n多颗树，虽然叫做“树”，但本质是按数据key排好序后，顺序写在磁盘上的一个个文件（定义4） ，注意这里再次出现了有序性。\n * 内存中的level 0树在达到阈值后，会在内存中遍历排好序的level 0树并顺序写入磁盘的level 1。同样的，在磁盘中的level n（n>0）达到阈值时，则会将level n层的多个文件进行归并，写入level n+1层。（定义5） 除了内存中的level 0层做原地更新外，对已写入磁盘上的数据，都采用append形式的磁盘顺序写，即更新和删除操作并不去修改老数据，只是简单的追加新数据。图1中右侧蓝色的磁盘部分，level 1和level 2均包含key为2的数据，同时图1左侧绿色内存中的level 0树也包含key为2的数据节点。（定义6）\n\n下面我们遵循 lsm 树的 6 条定义，通过动图对 lsm 树的增、删、改、查和归并进行详细分析。\n\n\n# 2. lsm 树的增删改查\n\n\n# 2.1 插入操作\n\nlsm树的插入较简单，数据无脑往内存中的level 0排序树丢即可，并不关心该数据是否已经在内存或磁盘中存在。（已经存在该数据的话，则场景转换成更新操作）\n\n插入数据时，按照 key 的大小，插入内存中的 level 0 排序树中，该操作复杂度为树高 log(n)，n 为 level 0 树的数据量，所以代价很低，能实现极高的写吞吐量。\n\n\n# 2.2 删除操作\n\nlsm树的删除操作并不是直接删除数据，而是通过一种叫“墓碑标记”的特殊数据来标识数据的删除。\n\n删除操作分为：待删除数据在内存中、待删除数据在磁盘中 和 该数据根本不存在 三种情况。\n\n# 2.2.1 待删除数据在内存中\n\n将 level 0 树中的对应节点采用墓碑标记将其覆盖。\n\n示例：删除 key 等于 2 的数据，结果如下图所示：\n\n# 2.2.2 待删除数据在磁盘中\n\n不去修改磁盘上的数据（理都不理它），而是直接向内存中的 level 0 树中插入墓碑标记即可。\n\n示例：删除 key 等于 2 的数据，结果如下图所示：\n\n# 2.2.3 待删除数据不存在\n\n这种情况等价于在内存的 level 0 树中新增一条墓碑标记，场景转换为情况 2.2.3 的内存中插入墓碑标记操作。\n\n----------------------------------------\n\n综合看待上述三种情况，发现不论数据有没有、在哪里，删除操作都是等价于向 level 0 树中写入墓碑标记。该操作复杂度为树高log(n)，代价很低。\n\n\n# 2.3 修改操作\n\nlsm 树的修改操作和删除操作很像，也是分为三种情况：待修改数据在内存中、在磁盘中和 该数据根本不存在。\n\n# 2.3.1 待修改数据在内存中\n\n示例：修改 key=7 的数据。直接定位到内存中 level 0 树上黄色的旧 key=7 的位置，将其覆盖。\n\n# 2.3.2 待修改数据在磁盘中\n\nlsm 树并不会去磁盘中的 level 1 树上原地更新老的 key=7 的数据，而是直接将新的蓝色的节点 7 插入内存中的 level 0 树中。\n\n# 2.3.3 该数据不存在\n\n此场景等价于情况b，直接向内存中的level 0树插入新的数据即可。\n\n----------------------------------------\n\n综上三种情况可以看出，修改操作都是对内存中 level 0 进行覆盖/新增操作。该操作复杂度为树高 log(n)，代价很低。\n\n我们会发现，lsm 树的增加、删除、修改（这三个都属于写操作）都是在内存中倒腾，完全没涉及到磁盘操作，所以速度飞快，写吞吐量高的离谱。。。\n\n\n# 2.4 查询操作\n\nlsm 树的查询操作会按顺序查找 level 0、level 1、level 2 ... level n 每一颗树，一旦匹配便返回目标数据，不再继续查询。该策略保证了查到的一定是目标 key 最新版本的数据（有点mvcc的感觉）。\n\n我们来分场景分析：依然分为 待查询数据在内存中 和 待查询数据在磁盘中 两种情况。\n\n# 2.4.1 待查询数据在内存中\n\n沿着内存中已排好序的level 0树递归向下比较查询，返回目标节点即可。我们注意到磁盘上的level 1树中同样包括一个key=6的较老的数据。但lsm树查询的时候会按照level 0、1、2 ... n的顺序查询，一旦查到第一个就返回，因此磁盘上老的key=6的数据没人理它，更不会作为结果被返回。\n\n# 2.4.2 待查询数据在磁盘中\n\n先查询内存中的level 0树，没查到便查询磁盘中的level 1树，还是没查到，于是查询磁盘中的level 2树，匹配后返回key=6的数据。\n\n----------------------------------------\n\n综合上述两种情况，我们发现，lsm 树的查询操作相对来说代价比较高，需要从level 0到level n一直顺序查下去。极端情况是lsm树中不存在该数据，则需要把整个库从level 0到level n给扫了一遍，然后返回查无此人（可以通过 布隆过滤器 + 建立稀疏索引 来优化查询操作）。代价大于以b/b+树为基本数据结构的传统rdb存储引擎。\n\n\n# 3. lsm 树的合并操作\n\n合并操作是lsm树的核心（毕竟lsm树的名字就叫: 日志结构合并树，直接点名了合并这一操作）\n\n之所以在增、删、改、查这四个基本操作之外还需要合并操作：\n\n * 一是 内存 => 磁盘。因为内存不是无限大，level 0树达到阈值时，需要将数据从内存刷到磁盘中；\n * 二是 磁盘块1 + 磁盘块2 => 归并入下一层。需要对磁盘上达到阈值的顺序文件进行归并，并将归并结果写入下一层，归并过程中会清理重复的数据和被删除的数据(墓碑标记)。\n\n我们分别对上述两个场景进行分析：\n\n\n# 3.1 内存数据写入磁盘的场景\n\n下图展示了内存中 level 0 树在达到阈值后，归并写入磁盘 level 1 树的场景。\n\n归并之前：\n\n归并之后：\n\n对内存中的level 0树进行中序遍历，将数据顺序写入磁盘的level 1层即可，我们可以看到因为level 0树是已经排好序的，所以写入的level 1中的新块也是有序的（有序性保证了查询和归并操作的高效）。\n\n此时磁盘的level 1层有两个block块。\n\n\n# 3.2 磁盘中多个块的归并\n\n下图展示了磁盘中 level 1 层达到阈值时，对其包含的两个 block 块进行归并，并将归并结果写入 level 2 层的过程。\n\n归并之前：\n\n归并之后：\n\n我们注意到 key=5 和 key=7 的数据同时存在于较老的block 1和较新的block 2中。而归并的过程是保留较新的数据，于是我们看到结果中，key=5和7的数据都是红色的（来自于较新的block2）。\n\n----------------------------------------\n\n综上我们可以看到，不论是场景6.1还是场景6.2，由于原始数据都是有序的，因此归并的过程只需要对数据集进行一次扫描即可，复杂度为o(n)。\n\n\n# 4. 优缺点分析\n\n可以看到 lsm 树将增、删、改这三种操作都转化为内存 insert + 磁盘顺序写(当level 0满的时候)，通过这种方式得到了无与伦比的写吞吐量。\n\nlsm 树的查询能力则相对被弱化，相比于 b+ 树的最多3~4次磁盘 io，lsm 树则要从 level 0 一路查询 level n，极端情况下等于做了全表扫描。（即便做了稀疏索引，也是lg(n0)+lg(n1)+...+lg(nn)的复杂度，大于b+树的lg(n0+n1+...+nn)的时间复杂度）。\n\n同时，lsm树只append追加不原地修改的特性引入了归并操作，归并操作涉及到大量的磁盘io，比较消耗性能，需要合理设置触发该操作的参数。\n\n综上我们可以给出lsm树的优缺点：\n\n * 优：增、删、改操作飞快，写吞吐量极大。\n * 缺：读操作性能相对被弱化；不擅长区间范围的读操作； 归并操作较耗费资源。\n\nlsmtree的增、删、改、查四种基本操作的时间复杂度分析如下所示：\n\n操作   平均代价   最坏情况代价\n删除   1      1\n插入   1      1\n修改   1      1\n查找   lgn    lgn\n\n\n# 5. 总结\n\nlsm树的设计原则：\n\n * 先内存再磁盘\n * 内存原地更新\n * 磁盘追加更新\n * 归并保留新值\n\n如果说b/b+树的读写性能基本平衡的话，lsm树的设计原则通过舍弃部分读性能，换取了无与伦比的写性能。该数据结构适合用于写吞吐量远远大于读吞吐量的场景，得到了nosql届的喜爱和好评。',charsets:{cjk:!0},lastUpdated:"2023/05/24, 09:11:54",lastUpdatedTimestamp:1684919514e3},{title:"开篇词",frontmatter:{title:"开篇词",date:"2023-05-30T10:34:39.000Z",permalink:"/pages/850e00/",categories:["基础","云原生","Kubernetes入门实战课-罗剑锋"],tags:[null]},regularPath:"/%E5%9F%BA%E7%A1%80/20.%E4%BA%91%E5%8E%9F%E7%94%9F/15.Kubernetes%E5%85%A5%E9%97%A8%E5%AE%9E%E6%88%98%E8%AF%BE-%E7%BD%97%E5%89%91%E9%94%8B/01.%E5%BC%80%E7%AF%87%E8%AF%8D.html",relativePath:"基础/20.云原生/15.Kubernetes入门实战课-罗剑锋/01.开篇词.md",key:"v-6e3c4c48",path:"/pages/850e00/",headers:[{level:2,title:"现在的Kubernetes",slug:"现在的kubernetes",normalizedTitle:"现在的kubernetes",charIndex:2},{level:2,title:"学习 Kubernetes",slug:"学习-kubernetes",normalizedTitle:"学习 kubernetes",charIndex:232}],headersStr:"现在的Kubernetes 学习 Kubernetes",content:"# 现在的Kubernetes\n\nKubernetes 成为了事实上的云原生操作系统，是容器编排领域的王者至尊。\n\n毕竟，现代应用是什么？是微服务，是服务网格，这些统统要围绕着容器来开发、部署和运行，而使用容器就必然要用到容器编排技术，在现在只有唯一的选项，那就是Kubernetes。\n\nDocker和Kubernetes用的都是Go。\n\nWHY USE DOCKER ? 要在客户的环境里部署自研应用，但依赖库差异太大，很难搞定，但用容器会方便很多。\n\n\n# 学习 Kubernetes\n\n * 官网教程 + 参考手册\n * 网络教程\n * 多动手，理论和实际是有差别的\n * 本专栏只是个“入门”\n\nPod 等众多 API 对象之间的关系：",normalizedContent:"# 现在的kubernetes\n\nkubernetes 成为了事实上的云原生操作系统，是容器编排领域的王者至尊。\n\n毕竟，现代应用是什么？是微服务，是服务网格，这些统统要围绕着容器来开发、部署和运行，而使用容器就必然要用到容器编排技术，在现在只有唯一的选项，那就是kubernetes。\n\ndocker和kubernetes用的都是go。\n\nwhy use docker ? 要在客户的环境里部署自研应用，但依赖库差异太大，很难搞定，但用容器会方便很多。\n\n\n# 学习 kubernetes\n\n * 官网教程 + 参考手册\n * 网络教程\n * 多动手，理论和实际是有差别的\n * 本专栏只是个“入门”\n\npod 等众多 api 对象之间的关系：",charsets:{cjk:!0},lastUpdated:"2023/06/07, 00:44:58",lastUpdatedTimestamp:1686098698e3},{title:"初识容器",frontmatter:{title:"初识容器",date:"2023-05-30T11:01:16.000Z",permalink:"/pages/1cc8db/",categories:["基础","云原生","Kubernetes入门实战课-罗剑锋"],tags:[null]},regularPath:"/%E5%9F%BA%E7%A1%80/20.%E4%BA%91%E5%8E%9F%E7%94%9F/15.Kubernetes%E5%85%A5%E9%97%A8%E5%AE%9E%E6%88%98%E8%AF%BE-%E7%BD%97%E5%89%91%E9%94%8B/02.%E5%88%9D%E8%AF%86%E5%AE%B9%E5%99%A8.html",relativePath:"基础/20.云原生/15.Kubernetes入门实战课-罗剑锋/02.初识容器.md",key:"v-2d5f867f",path:"/pages/1cc8db/",headers:[{level:2,title:"1. 初识容器：万事开头难",slug:"_1-初识容器-万事开头难",normalizedTitle:"1. 初识容器：万事开头难",charIndex:2},{level:3,title:"Docker 的形态",slug:"docker-的形态",normalizedTitle:"docker 的形态",charIndex:20},{level:3,title:"Docker 命令",slug:"docker-命令",normalizedTitle:"docker 命令",charIndex:350},{level:3,title:"Docker 的架构",slug:"docker-的架构",normalizedTitle:"docker 的架构",charIndex:520},{level:3,title:"与虚拟机的区别",slug:"与虚拟机的区别",normalizedTitle:"与虚拟机的区别",charIndex:852},{level:2,title:"2. 被隔离的进程：一起来看看容器的本质",slug:"_2-被隔离的进程-一起来看看容器的本质",normalizedTitle:"2. 被隔离的进程：一起来看看容器的本质",charIndex:864},{level:3,title:"隔离是怎么实现的",slug:"隔离是怎么实现的",normalizedTitle:"隔离是怎么实现的",charIndex:1259},{level:2,title:"3. 容器化的应用",slug:"_3-容器化的应用",normalizedTitle:"3. 容器化的应用",charIndex:1673},{level:3,title:"什么是容器化的应用",slug:"什么是容器化的应用",normalizedTitle:"什么是容器化的应用",charIndex:1687},{level:3,title:"操纵容器化应用（常用命令）",slug:"操纵容器化应用-常用命令",normalizedTitle:"操纵容器化应用（常用命令）",charIndex:2031},{level:2,title:"4. 创建容器镜像（编写Dockerfile）",slug:"_4-创建容器镜像-编写dockerfile",normalizedTitle:"4. 创建容器镜像（编写dockerfile）",charIndex:2049},{level:3,title:"镜像的内部机制:分层",slug:"镜像的内部机制-分层",normalizedTitle:"镜像的内部机制:分层",charIndex:2121},{level:3,title:"Dockerfile 是什么",slug:"dockerfile-是什么",normalizedTitle:"dockerfile 是什么",charIndex:2740},{level:3,title:"怎样编写正确、高效的Dockerfile",slug:"怎样编写正确、高效的dockerfile",normalizedTitle:"怎样编写正确、高效的dockerfile",charIndex:2759},{level:3,title:"docker build是怎么工作的",slug:"docker-build是怎么工作的",normalizedTitle:"docker build是怎么工作的",charIndex:4264},{level:2,title:"5. 镜像仓库：该怎样用好Docker Hub这个宝藏",slug:"_5-镜像仓库-该怎样用好docker-hub这个宝藏",normalizedTitle:"5. 镜像仓库：该怎样用好docker hub这个宝藏",charIndex:4516},{level:2,title:"6. 打破次元壁：容器该如何与外界互联互通",slug:"_6-打破次元壁-容器该如何与外界互联互通",normalizedTitle:"6. 打破次元壁：容器该如何与外界互联互通",charIndex:4553},{level:3,title:"如何拷贝容器内的数据",slug:"如何拷贝容器内的数据",normalizedTitle:"如何拷贝容器内的数据",charIndex:4920},{level:3,title:"如何共享主机上的文件：挂载",slug:"如何共享主机上的文件-挂载",normalizedTitle:"如何共享主机上的文件：挂载",charIndex:5314},{level:3,title:"如何实现网络互通",slug:"如何实现网络互通",normalizedTitle:"如何实现网络互通",charIndex:6317},{level:3,title:"如何分配服务端口号",slug:"如何分配服务端口号",normalizedTitle:"如何分配服务端口号",charIndex:7664}],headersStr:"1. 初识容器：万事开头难 Docker 的形态 Docker 命令 Docker 的架构 与虚拟机的区别 2. 被隔离的进程：一起来看看容器的本质 隔离是怎么实现的 3. 容器化的应用 什么是容器化的应用 操纵容器化应用（常用命令） 4. 创建容器镜像（编写Dockerfile） 镜像的内部机制:分层 Dockerfile 是什么 怎样编写正确、高效的Dockerfile docker build是怎么工作的 5. 镜像仓库：该怎样用好Docker Hub这个宝藏 6. 打破次元壁：容器该如何与外界互联互通 如何拷贝容器内的数据 如何共享主机上的文件：挂载 如何实现网络互通 如何分配服务端口号",content:'# 1. 初识容器：万事开头难\n\n\n# Docker 的形态\n\n目前使用Docker基本上有两个选择： Docker Desktop 和 Docker Engine。\n\n * Docker Desktop是专门针对个人使用而设计的，支持Mac和Windows快速安装，具有直观的图形界面，还集成了许多周边工具，方便易用。只是对个人学习免费，受条款限制不能商用，我们在日常工作中难免会“踩到雷区”。\n * Docker Engine 只能在Linux上运行，只能使用命令行操作，缺乏辅助工具，需要我们自己动手DIY运行环境。不过要是较起真来，它才是Docker当初的真正形态，“血脉”最纯正，也是现在各个公司在生产环境中实际使用的Docker产品，毕竟机房里99%的服务器跑的都是Linux。\n\n\n# Docker 命令\n\nDocker Engine需要使用命令行操作，主命令是 docker，后面再接各种子命令。\n\n查看Docker的基本信息的命令是 docker version 和 docker info ，其他常用的命令有 docker ps、 docker pull、 docker images、 docker run。\n\n\n# Docker 的架构\n\n我们敲的命令行 docker 实际上是一个客户端client ，它会与Docker Engine里的后台服务Docker daemon通信，而镜像则存储在远端的仓库Registry里，客户端并不能直接访问镜像仓库。\n\nDocker client可以通过 build、 pull、 run 等命令向Docker daemon发送请求，而Docker daemon则是容器和镜像的“大管家”，负责从远端拉取镜像、在本地存储镜像，还有从镜像生成容器、管理容器等所有功能。 所以，在Docker Engine里，真正干活的其实是默默运行在后台的Docker daemon，而我们实际操作的命令行工具“docker”只是个“传声筒”的角色。\n\n\n# 与虚拟机的区别\n\n\n# 2. 被隔离的进程：一起来看看容器的本质\n\n广义上来说，容器技术是动态的容器、静态的镜像和远端的仓库这三者的组合。今天就来看看究竟什么是容器（即狭义的、动态的容器）。\n\n容器封装了运行中的进程，并把进程与外界环境隔离开，让进程与外部系统互不影响。它就是一个特殊的隔离环境，它能够让进程只看到这个环境里的有限信息，不能对外界环境施加影响。\n\n使用容器技术，我们就可以让应用程序运行在一个有严密防护的**“沙盒”（Sandbox）**环境之内，就好像是把进程请进了“隔离酒店”，它可以在这个环境里自由活动，但绝不允许“越界”，从而保证了容器外系统的安全。\n\n容器技术的另一个本领就是为应用程序加上资源隔离，在系统里切分出一部分资源，让它只能使用指定的配额。这可以避免容器内进程的过渡系统消耗，并充分利用计算机硬件，让有限的资源能够提供稳定可靠的服务。\n\n容器本质上就是一种特殊的进程。\n\n\n# 隔离是怎么实现的\n\n奥秘在于 Linux 内核所提供的三个技术：namespace、cgroup 和 chroot，虽然这三个技术的初衷都不是为了实现容器，但结合在一起就会发生奇妙的”化学反应“。\n\n * namespace：它可以创建出独立的文件系统、主机名、进程号、网络等资源空间，相当于给进程盖了一间小板房，这样就实现了系统全局资源和进程局部资源的隔离。\n * cgroup：全称是 Linux Control Group，用来实现对进程的 CPU、内存等资源的优先级和配额限制，相当于给进程的小板房加了一个天花板。\n * chroot：它可以更改进程的根目录，也就是限制访问文件系统，相当于给进程的小板房铺上了地砖。 综合运用以上三个技术，一个四四方方、具有完善的隔离特性的容器就此出现了，进程也就可以搬进去快乐生活啦。\n\n> 目前容器技术基本不再使用古老的 chroot 了，而是改用 pivot_root。\n\n\n# 3. 容器化的应用\n\n\n# 什么是容器化的应用\n\n镜像是容器的静态形式，它打包了应用程序的所有运行依赖项，方便保存和传输。使用容器技术运行镜像，就形成了动态的容器，由于镜像只读不可修改，所以应用程序的运行环境总是一致的。\n\n任何应用都能够打包再分发后运行，这也是无数开发者梦寐以求的“一次编写，到处运行（Build once, Run anywhere）”的至高境界。所以， 所谓的“容器化的应用”，或者“应用的容器化”，就是指应用程序不再直接和操作系统打交道，而是封装成镜像，再交给容器环境去运行。\n\n现在你就应该知道了，镜像就是静态的应用容器，容器就是动态的应用镜像，两者互相依存，互相转化，密不可分。\n\n> Docker只不过是众多容器运行时（Container Runtime）中最出名的一款而已。\n\n\n# 操纵容器化应用（常用命令）\n\n\n# 4. 创建容器镜像（编写Dockerfile）\n\n本节讲解镜像的内部机制，还有高效、正确地编写Dockerfile制作容器镜像的方法。\n\n\n# 镜像的内部机制:分层\n\n镜像就是一个打包文件，里面包含了应用程序还有它运行所依赖的环境，例如文件系统、环境变量、配置参数等等。\n\n * 环境变量、配置参数：用一个manifest清单就可以管理\n * 文件系统：较麻烦。为了保证容器运行环境的一致性，镜像必须把应用程序所在操作系统的根目录（rootfs），都包含进来。\n\n为避免多个镜像都对Ubuntu根目录文件打包，造成对磁盘存储、网络传输的浪费，针对容器镜像有了“分层”（layer）的概念。\n\n> 容器镜像是由多个只读的Layer构成的，同一个Layer可以被不同的镜像共享，减少了存储和传输的成本。\n\n容器镜像内部并不是一个平坦的结构，而是由许多的镜像层组成的，每层都是只读不可修改的一组文件，相同的层可以在镜像之间共享，然后多个层像搭积木一样堆叠起来，再使用一种叫“ Union FS联合文件系统”的技术把它们合并在一起，就形成了容器最终看到的文件系统（ 图片来源）。\n\n可以用命令 docker inspect 来查看镜像的分层信息，它的分层信息在“RootFS”部分。\n\n相信你现在也就明白，之前在使用 docker pull、 docker rmi 等命令操作镜像的时候，那些“奇怪”的输出信息是什么了，其实就是镜像里的各个Layer。Docker会检查是否有重复的层，如果本地已经存在就不会重复下载，如果层被其他镜像共享就不会删除，这样就可以节约磁盘和网络成本。\n\n\n# Dockerfile 是什么\n\n\n# 怎样编写正确、高效的Dockerfile\n\n * FROM: 基础镜像\n * COPY: 一些需要打包进镜像里的源码、配置等文件\n * ADD: 与 COPY 的区别是COPY的SRC只能是本地文件，其他用法一致\n * RUN: 执行任意的Shell命令，比如更新系统、安装应用、下载文件、创建目录、编译程序等等，实现任意的镜像构建步骤，非常灵活\n * ARG: 创建的变量只在镜像构建过程中可见，容器运行时不可见\n * ENV: 创建的变量不仅能够在构建镜像的过程中使用，在容器运行时也能够以环境变量的形式被应用程序使用\n * EXPOSE: 声明容器对外服务的端口号\n * ENTRYPOINT:\n\nEXPOSE 443           # 默认是tcp协议\nEXPOSE 53/udp        # 可以指定udp协议\n\n\n\n1\n2\n3\n\n关于 RUN 指令的一些细节\n\nRUN 通常会是Dockerfile里最复杂的指令，会包含很多的Shell命令，但Dockerfile里一条指令只能是一行，所以有的 RUN 指令会在每行的末尾使用续行符 \\，命令之间也会用 && 来连接，这样保证在逻辑上是一行，就像下面这样：\n\nRUN apt-get update \\\n    && apt-get install -y \\\n        build-essential \\\n        curl \\\n        make \\\n        unzip \\\n    && cd /tmp \\\n    && curl -fSL xxx.tar.gz -o xxx.tar.gz\\\n    && tar xzf xxx.tar.gz \\\n    && cd xxx \\\n    && ./config \\\n    && make \\\n    && make clean\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n有的时候在Dockerfile里写这种超长的 RUN 指令很不美观，而且一旦写错了，每次调试都要重新构建也很麻烦，所以你可以采用一种变通的技巧： 把这些Shell命令集中到一个脚本文件里，用 COPY 命令拷贝进去再用 RUN 来执行：\n\nCOPY setup.sh  /tmp/                # 拷贝脚本到/tmp目录\n\nRUN cd /tmp && chmod +x setup.sh \\  # 添加执行权限\n    && ./setup.sh && rm setup.sh    # 运行脚本然后再删除\n\n\n\n1\n2\n3\n4\n5\n\n\nRUN 指令实际上就是Shell编程，如果你对它有所了解，就应该知道它有变量的概念，可以实现参数化运行，这在Dockerfile里也可以做到，需要使用两个指令 ARG 和 ENV。\n\n`ARG` 和 `ENV` 的区别\n\n下面是一个简单的例子，使用 ARG 定义了基础镜像的名字（可以用在“FROM”指令里），使用 ENV 定义了两个环境变量：\n\nARG IMAGE_BASE="node"\nARG IMAGE_TAG="alpine"\n\nENV PATH=$PATH:/tmp\nENV DEBUG=OFF\n\n\n1\n2\n3\n4\n5\n\n\n讲了这些Dockerfile指令之后，我还要特别强调一下，因为因为 RUN, COPY, ADD 会生成新的镜像层，其它指令只会产生临时层，不影响构建大小，所以Dockerfile里最好不要滥用指令，尽量精简合并，否则太多的层会导致镜像臃肿不堪。\n\n\n# docker build是怎么工作的\n\nDockerfile必须要经过 docker build 才能生效，所以我们再来看看 docker build 的详细用法。\n\n参数：\n\n * -f: 指定Dockerfile，如果不指定就使用当前目录下名字是“Dockerfile”的文件\n * -t: 为镜像起一个有意义的名字，方便管理\n\n> docker build 需要指定“构建上下文”，其中的文件会打包上传到Docker daemon，所以尽量不要在“构建上下文”中存放多余的文件。\n\n待补充\n\n\n# 5. 镜像仓库：该怎样用好Docker Hub这个宝藏\n\n待补充\n\n\n# 6. 打破次元壁：容器该如何与外界互联互通\n\n在前面的几节课里，我们已经学习了容器、镜像、镜像仓库的概念和用法，也知道了应该如何创建镜像，再以容器的形式启动应用。\n\n不过，用容器来运行“busybox”“hello world”这样比较简单的应用还好，如果是Nginx、Redis、MySQL这样的后台服务应用，因为它们运行在容器的“沙盒”里，完全与外界隔离，无法对外提供服务，也就失去了价值。这个时候，容器的隔离环境反而成为了一种负面特性。\n\n所以，容器的这个“小板房”不应该是一个完全密闭的铁屋子，而是应该给它开几扇门窗，让应用在“足不出户”的情况下，也能够与外界交换数据、互通有无，这样“有限的隔离”才是我们真正所需要的运行环境。\n\n那么今天，我就以Docker为例，来讲讲有哪些手段能够在容器与外部系统之间沟通交流。\n\n\n# 如何拷贝容器内的数据\n\nDocker提供的 docker cp 命令，很类似Linux的“cp”“scp”，它可以在宿主机和容器之间拷贝文件，是最基本的一种数据交换功能。\n\n用法：\n\n * 把文件拷贝进容器：docker cp [src path] [container id/name]:[dest path]\n * 把文件拷贝出容器: 更换源路径（src path）和目标路径（dest path）就可以了\n\n假设当前目录下有一个“a.txt”的文件，现在我们要把它拷贝进Redis容器的“/tmp”目录，如果使用容器ID，命令就会是这样：\n\ndocker cp a.txt 062:/tmp\n\n\n1\n\n\n> docker cp 的用法模仿了操作系统的拷贝命令，偶尔一两次的文件共享还可以应付，如果容器运行时经常有文件来往互通，这样反复地拷来拷去就显得很麻烦，也很容易出错。\n\n\n# 如何共享主机上的文件：挂载\n\n容器提供了类似虚拟机共享宿主机目录的功能，效果也几乎一样，用起来很方便，只需要在 docker run 命令启动容器的时候使用 -v 参数就行，具体的格式是“ 宿主机路径:容器内路径”。--\x3e 把宿主机目录挂载进容器内部.\n\n> -v 挂载目录时若发现源路径不存在，会自动创建，这有时候会是一个“坑”，当主机目录被意外删除时会导致容器里出现空目录，让应用无法按预想的流程工作。 -v 挂载目录默认是可读可写的，但也可以加上ro变成只读，可以防止容器意外修改文件，例如 -Vtmp:/tmp:ro。\n\n一个文件挂载的例子\n\n我还是以Redis为例，启动容器，使用 -v 参数把本机的“/tmp”目录挂载到容器里的“/tmp”目录，也就是说让容器共享宿主机的“/tmp”目录：\n\ndocker run -d --rm -v /tmp:/tmp redis\n\n\n1\n\n\n然后我们再用 docker exec 进入容器，查看一下容器内的“/tmp”目录，应该就可以看到文件与宿主机是完全一致的。\n\ndocker exec -it b5a sh    # b5a是容器ID\n\n\n1\n\n\n-v 参数挂载宿主机目录的这个功能，对于我们日常开发测试工作来说非常有用，我们可以在不变动本机环境的前提下，使用镜像安装任意的应用，然后直接以容器来运行我们本地的源码、脚本，非常方便。\n\n这里我举一个简单的例子。比如我本机上只有Python 2.7，但我想用Python 3开发，如果同时安装Python 2和Python 3很容易就会把系统搞乱，所以我就可以这么做：\n\n 1. 先使用 docker pull 拉取一个Python 3的镜像，因为它打包了完整的运行环境，运行时有隔离，所以不会对现有系统的Python 2.7产生任何影响。\n 2. 在本地的某个目录编写Python代码，然后用 -v 参数让容器共享这个目录。\n 3. 现在就可以在容器里以Python 3来安装各种包，再运行脚本做开发了。\n\ndocker pull python:alpine\ndocker run -it --rm -v `pwd`:/tmp python:alpine sh\n\n\n\n1\n2\n3\n\n\n显然，这种方式比把文件打包到镜像或者 docker cp 会更加灵活，非常适合有频繁修改的开发测试工作。\n\n\n# 如何实现网络互通\n\n使用 docker cp 和 docker run -v 可以解决容器与外界的文件互通问题，但对于Nginx、Redis这些服务器来说，网络互通才是更要紧的问题。网络互通的关键在于“打通”容器内外的网络。\n\nDocker提供了三种网络模式，分别是 null、 host 和 bridge。\n\n * null 是最简单的模式，也就是没有网络，但允许其他的网络插件来自定义网络连接\n * host 的意思是直接使用宿主机网络，相当于去掉了容器的网络隔离（其他隔离依然保留），所有的容器会共享宿主机的IP地址和网卡。这种模式没有中间层，自然通信效率高，但缺少了隔离，运行太多的容器也容易导致端口冲突。\n   * host模式需要在 docker run 时使用 --net=host 参数\n\n使用 host 网络模式的例子\n\n下面用--net=host这个参数启动Nginx：\n\ndocker run -d --rm --net=host nginx:alpine\n\n\n1\n\n\n为了验证效果，我们可以在本机和容器里分别执行 ip addr 命令，查看网卡信息:\n\nip addr                    # 本机查看网卡\ndocker exec xxx ip addr    # 容器查看网卡\n\n\n1\n2\n\n\n可以发现这两个命令的输出信息是完全一样的，如网卡 ensxxx 和 IP 地址。\n\n * bridge，也就是桥接模式，它有点类似现实世界里的交换机、路由器，只不过是由软件虚拟出来的，容器和宿主机再通过虚拟网卡接入这个网桥（图中的docker0），那么它们之间也就可以正常的收发网络数据包了。不过和host模式相比，bridge模式多了虚拟网桥和网卡，通信效率会低一些。\n   * 可以用 --net=bridge 来启用桥接模式，但其实不必要，因为Docker默认的网络模式就是bridge，所以一般不需要显式指定。\n   * \n\n使用 bridge 网络模式的例子\n\n下面我们启动两个容器Nginx和Redis，就像刚才说的，没有特殊指定就会使用bridge模式：\n\ndocker run -d --rm nginx:alpine    # 默认使用桥接模式\ndocker run -d --rm redis           # 默认使用桥接模式\n\n\n1\n2\n\n\n然后我们还是在本机和容器里执行 ip addr 命令（Redis容器里没有ip命令，所以只能在Nginx容器里执行）：\n\n对比一下刚才host模式的输出，就可以发现容器里的网卡设置与宿主机完全不同，eth0是一个虚拟网卡，IP地址是B类私有地址“172.17.0.4”。\n\n我们还可以用 docker inspect 直接查看容器的ip地址：\n\ndocker inspect xxx |grep IPAddress\n\n\n1\n\n\n这显示出两个容器的IP地址分别是“172.17.0.3”和“172.17.0.4”，而宿主机的IP地址则是“172.17.0.1”，所以它们都在“172.17.0.0/16”这个Docker的默认网段，彼此之间就能够使用IP地址来实现网络通信了。\n\n\n# 如何分配服务端口号\n\n服务器应用都必须要有端口号才能对外提供服务。前面第4节我们在学习编写Dockerfile的时候也看到过，可以用 EXPOSE 指令声明容器对外的端口号。\n\n一台主机上的端口号数量是有限的，而且多个服务之间还不能够冲突，但我们打包镜像应用的时候通常都使用的是默认端口，容器实际运行起来就很容易因为端口号被占用而无法启动。\n\n解决这个问题的方法就是加入一个“中间层”，由容器环境例如Docker来统一管理分配端口号，在本机端口和容器端口之间做一个“映射”操作，容器内部还是用自己的端口号，但外界看到的却是另外一个端口号，这样就很好地避免了冲突。\n\n端口号映射需要使用bridge模式，并且在 docker run 启动容器时使用 -p 参数，形式和共享目录的 -v 参数很类似，用 : 分隔本机端口和容器端口。\n\n分配服务端口号的例子\n\n如果要启动两个Nginx容器，分别跑在80和8080端口上：\n\ndocker run -d -p 80:80 --rm nginx:alpine\ndocker run -d -p 8080:80 --rm nginx:alpine\n\n\n1\n2\n\n\n这样就把本机的80和8080端口分别“映射”到了两个容器里的80端口，不会发生冲突，我们可以用curl再验证一下。\n\n使用 docker ps 命令能够在“PORTS”栏里更直观地看到端口的映射情况。',normalizedContent:'# 1. 初识容器：万事开头难\n\n\n# docker 的形态\n\n目前使用docker基本上有两个选择： docker desktop 和 docker engine。\n\n * docker desktop是专门针对个人使用而设计的，支持mac和windows快速安装，具有直观的图形界面，还集成了许多周边工具，方便易用。只是对个人学习免费，受条款限制不能商用，我们在日常工作中难免会“踩到雷区”。\n * docker engine 只能在linux上运行，只能使用命令行操作，缺乏辅助工具，需要我们自己动手diy运行环境。不过要是较起真来，它才是docker当初的真正形态，“血脉”最纯正，也是现在各个公司在生产环境中实际使用的docker产品，毕竟机房里99%的服务器跑的都是linux。\n\n\n# docker 命令\n\ndocker engine需要使用命令行操作，主命令是 docker，后面再接各种子命令。\n\n查看docker的基本信息的命令是 docker version 和 docker info ，其他常用的命令有 docker ps、 docker pull、 docker images、 docker run。\n\n\n# docker 的架构\n\n我们敲的命令行 docker 实际上是一个客户端client ，它会与docker engine里的后台服务docker daemon通信，而镜像则存储在远端的仓库registry里，客户端并不能直接访问镜像仓库。\n\ndocker client可以通过 build、 pull、 run 等命令向docker daemon发送请求，而docker daemon则是容器和镜像的“大管家”，负责从远端拉取镜像、在本地存储镜像，还有从镜像生成容器、管理容器等所有功能。 所以，在docker engine里，真正干活的其实是默默运行在后台的docker daemon，而我们实际操作的命令行工具“docker”只是个“传声筒”的角色。\n\n\n# 与虚拟机的区别\n\n\n# 2. 被隔离的进程：一起来看看容器的本质\n\n广义上来说，容器技术是动态的容器、静态的镜像和远端的仓库这三者的组合。今天就来看看究竟什么是容器（即狭义的、动态的容器）。\n\n容器封装了运行中的进程，并把进程与外界环境隔离开，让进程与外部系统互不影响。它就是一个特殊的隔离环境，它能够让进程只看到这个环境里的有限信息，不能对外界环境施加影响。\n\n使用容器技术，我们就可以让应用程序运行在一个有严密防护的**“沙盒”（sandbox）**环境之内，就好像是把进程请进了“隔离酒店”，它可以在这个环境里自由活动，但绝不允许“越界”，从而保证了容器外系统的安全。\n\n容器技术的另一个本领就是为应用程序加上资源隔离，在系统里切分出一部分资源，让它只能使用指定的配额。这可以避免容器内进程的过渡系统消耗，并充分利用计算机硬件，让有限的资源能够提供稳定可靠的服务。\n\n容器本质上就是一种特殊的进程。\n\n\n# 隔离是怎么实现的\n\n奥秘在于 linux 内核所提供的三个技术：namespace、cgroup 和 chroot，虽然这三个技术的初衷都不是为了实现容器，但结合在一起就会发生奇妙的”化学反应“。\n\n * namespace：它可以创建出独立的文件系统、主机名、进程号、网络等资源空间，相当于给进程盖了一间小板房，这样就实现了系统全局资源和进程局部资源的隔离。\n * cgroup：全称是 linux control group，用来实现对进程的 cpu、内存等资源的优先级和配额限制，相当于给进程的小板房加了一个天花板。\n * chroot：它可以更改进程的根目录，也就是限制访问文件系统，相当于给进程的小板房铺上了地砖。 综合运用以上三个技术，一个四四方方、具有完善的隔离特性的容器就此出现了，进程也就可以搬进去快乐生活啦。\n\n> 目前容器技术基本不再使用古老的 chroot 了，而是改用 pivot_root。\n\n\n# 3. 容器化的应用\n\n\n# 什么是容器化的应用\n\n镜像是容器的静态形式，它打包了应用程序的所有运行依赖项，方便保存和传输。使用容器技术运行镜像，就形成了动态的容器，由于镜像只读不可修改，所以应用程序的运行环境总是一致的。\n\n任何应用都能够打包再分发后运行，这也是无数开发者梦寐以求的“一次编写，到处运行（build once, run anywhere）”的至高境界。所以， 所谓的“容器化的应用”，或者“应用的容器化”，就是指应用程序不再直接和操作系统打交道，而是封装成镜像，再交给容器环境去运行。\n\n现在你就应该知道了，镜像就是静态的应用容器，容器就是动态的应用镜像，两者互相依存，互相转化，密不可分。\n\n> docker只不过是众多容器运行时（container runtime）中最出名的一款而已。\n\n\n# 操纵容器化应用（常用命令）\n\n\n# 4. 创建容器镜像（编写dockerfile）\n\n本节讲解镜像的内部机制，还有高效、正确地编写dockerfile制作容器镜像的方法。\n\n\n# 镜像的内部机制:分层\n\n镜像就是一个打包文件，里面包含了应用程序还有它运行所依赖的环境，例如文件系统、环境变量、配置参数等等。\n\n * 环境变量、配置参数：用一个manifest清单就可以管理\n * 文件系统：较麻烦。为了保证容器运行环境的一致性，镜像必须把应用程序所在操作系统的根目录（rootfs），都包含进来。\n\n为避免多个镜像都对ubuntu根目录文件打包，造成对磁盘存储、网络传输的浪费，针对容器镜像有了“分层”（layer）的概念。\n\n> 容器镜像是由多个只读的layer构成的，同一个layer可以被不同的镜像共享，减少了存储和传输的成本。\n\n容器镜像内部并不是一个平坦的结构，而是由许多的镜像层组成的，每层都是只读不可修改的一组文件，相同的层可以在镜像之间共享，然后多个层像搭积木一样堆叠起来，再使用一种叫“ union fs联合文件系统”的技术把它们合并在一起，就形成了容器最终看到的文件系统（ 图片来源）。\n\n可以用命令 docker inspect 来查看镜像的分层信息，它的分层信息在“rootfs”部分。\n\n相信你现在也就明白，之前在使用 docker pull、 docker rmi 等命令操作镜像的时候，那些“奇怪”的输出信息是什么了，其实就是镜像里的各个layer。docker会检查是否有重复的层，如果本地已经存在就不会重复下载，如果层被其他镜像共享就不会删除，这样就可以节约磁盘和网络成本。\n\n\n# dockerfile 是什么\n\n\n# 怎样编写正确、高效的dockerfile\n\n * from: 基础镜像\n * copy: 一些需要打包进镜像里的源码、配置等文件\n * add: 与 copy 的区别是copy的src只能是本地文件，其他用法一致\n * run: 执行任意的shell命令，比如更新系统、安装应用、下载文件、创建目录、编译程序等等，实现任意的镜像构建步骤，非常灵活\n * arg: 创建的变量只在镜像构建过程中可见，容器运行时不可见\n * env: 创建的变量不仅能够在构建镜像的过程中使用，在容器运行时也能够以环境变量的形式被应用程序使用\n * expose: 声明容器对外服务的端口号\n * entrypoint:\n\nexpose 443           # 默认是tcp协议\nexpose 53/udp        # 可以指定udp协议\n\n\n\n1\n2\n3\n\n关于 run 指令的一些细节\n\nrun 通常会是dockerfile里最复杂的指令，会包含很多的shell命令，但dockerfile里一条指令只能是一行，所以有的 run 指令会在每行的末尾使用续行符 \\，命令之间也会用 && 来连接，这样保证在逻辑上是一行，就像下面这样：\n\nrun apt-get update \\\n    && apt-get install -y \\\n        build-essential \\\n        curl \\\n        make \\\n        unzip \\\n    && cd /tmp \\\n    && curl -fsl xxx.tar.gz -o xxx.tar.gz\\\n    && tar xzf xxx.tar.gz \\\n    && cd xxx \\\n    && ./config \\\n    && make \\\n    && make clean\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n有的时候在dockerfile里写这种超长的 run 指令很不美观，而且一旦写错了，每次调试都要重新构建也很麻烦，所以你可以采用一种变通的技巧： 把这些shell命令集中到一个脚本文件里，用 copy 命令拷贝进去再用 run 来执行：\n\ncopy setup.sh  /tmp/                # 拷贝脚本到/tmp目录\n\nrun cd /tmp && chmod +x setup.sh \\  # 添加执行权限\n    && ./setup.sh && rm setup.sh    # 运行脚本然后再删除\n\n\n\n1\n2\n3\n4\n5\n\n\nrun 指令实际上就是shell编程，如果你对它有所了解，就应该知道它有变量的概念，可以实现参数化运行，这在dockerfile里也可以做到，需要使用两个指令 arg 和 env。\n\n`arg` 和 `env` 的区别\n\n下面是一个简单的例子，使用 arg 定义了基础镜像的名字（可以用在“from”指令里），使用 env 定义了两个环境变量：\n\narg image_base="node"\narg image_tag="alpine"\n\nenv path=$path:/tmp\nenv debug=off\n\n\n1\n2\n3\n4\n5\n\n\n讲了这些dockerfile指令之后，我还要特别强调一下，因为因为 run, copy, add 会生成新的镜像层，其它指令只会产生临时层，不影响构建大小，所以dockerfile里最好不要滥用指令，尽量精简合并，否则太多的层会导致镜像臃肿不堪。\n\n\n# docker build是怎么工作的\n\ndockerfile必须要经过 docker build 才能生效，所以我们再来看看 docker build 的详细用法。\n\n参数：\n\n * -f: 指定dockerfile，如果不指定就使用当前目录下名字是“dockerfile”的文件\n * -t: 为镜像起一个有意义的名字，方便管理\n\n> docker build 需要指定“构建上下文”，其中的文件会打包上传到docker daemon，所以尽量不要在“构建上下文”中存放多余的文件。\n\n待补充\n\n\n# 5. 镜像仓库：该怎样用好docker hub这个宝藏\n\n待补充\n\n\n# 6. 打破次元壁：容器该如何与外界互联互通\n\n在前面的几节课里，我们已经学习了容器、镜像、镜像仓库的概念和用法，也知道了应该如何创建镜像，再以容器的形式启动应用。\n\n不过，用容器来运行“busybox”“hello world”这样比较简单的应用还好，如果是nginx、redis、mysql这样的后台服务应用，因为它们运行在容器的“沙盒”里，完全与外界隔离，无法对外提供服务，也就失去了价值。这个时候，容器的隔离环境反而成为了一种负面特性。\n\n所以，容器的这个“小板房”不应该是一个完全密闭的铁屋子，而是应该给它开几扇门窗，让应用在“足不出户”的情况下，也能够与外界交换数据、互通有无，这样“有限的隔离”才是我们真正所需要的运行环境。\n\n那么今天，我就以docker为例，来讲讲有哪些手段能够在容器与外部系统之间沟通交流。\n\n\n# 如何拷贝容器内的数据\n\ndocker提供的 docker cp 命令，很类似linux的“cp”“scp”，它可以在宿主机和容器之间拷贝文件，是最基本的一种数据交换功能。\n\n用法：\n\n * 把文件拷贝进容器：docker cp [src path] [container id/name]:[dest path]\n * 把文件拷贝出容器: 更换源路径（src path）和目标路径（dest path）就可以了\n\n假设当前目录下有一个“a.txt”的文件，现在我们要把它拷贝进redis容器的“/tmp”目录，如果使用容器id，命令就会是这样：\n\ndocker cp a.txt 062:/tmp\n\n\n1\n\n\n> docker cp 的用法模仿了操作系统的拷贝命令，偶尔一两次的文件共享还可以应付，如果容器运行时经常有文件来往互通，这样反复地拷来拷去就显得很麻烦，也很容易出错。\n\n\n# 如何共享主机上的文件：挂载\n\n容器提供了类似虚拟机共享宿主机目录的功能，效果也几乎一样，用起来很方便，只需要在 docker run 命令启动容器的时候使用 -v 参数就行，具体的格式是“ 宿主机路径:容器内路径”。--\x3e 把宿主机目录挂载进容器内部.\n\n> -v 挂载目录时若发现源路径不存在，会自动创建，这有时候会是一个“坑”，当主机目录被意外删除时会导致容器里出现空目录，让应用无法按预想的流程工作。 -v 挂载目录默认是可读可写的，但也可以加上ro变成只读，可以防止容器意外修改文件，例如 -vtmp:/tmp:ro。\n\n一个文件挂载的例子\n\n我还是以redis为例，启动容器，使用 -v 参数把本机的“/tmp”目录挂载到容器里的“/tmp”目录，也就是说让容器共享宿主机的“/tmp”目录：\n\ndocker run -d --rm -v /tmp:/tmp redis\n\n\n1\n\n\n然后我们再用 docker exec 进入容器，查看一下容器内的“/tmp”目录，应该就可以看到文件与宿主机是完全一致的。\n\ndocker exec -it b5a sh    # b5a是容器id\n\n\n1\n\n\n-v 参数挂载宿主机目录的这个功能，对于我们日常开发测试工作来说非常有用，我们可以在不变动本机环境的前提下，使用镜像安装任意的应用，然后直接以容器来运行我们本地的源码、脚本，非常方便。\n\n这里我举一个简单的例子。比如我本机上只有python 2.7，但我想用python 3开发，如果同时安装python 2和python 3很容易就会把系统搞乱，所以我就可以这么做：\n\n 1. 先使用 docker pull 拉取一个python 3的镜像，因为它打包了完整的运行环境，运行时有隔离，所以不会对现有系统的python 2.7产生任何影响。\n 2. 在本地的某个目录编写python代码，然后用 -v 参数让容器共享这个目录。\n 3. 现在就可以在容器里以python 3来安装各种包，再运行脚本做开发了。\n\ndocker pull python:alpine\ndocker run -it --rm -v `pwd`:/tmp python:alpine sh\n\n\n\n1\n2\n3\n\n\n显然，这种方式比把文件打包到镜像或者 docker cp 会更加灵活，非常适合有频繁修改的开发测试工作。\n\n\n# 如何实现网络互通\n\n使用 docker cp 和 docker run -v 可以解决容器与外界的文件互通问题，但对于nginx、redis这些服务器来说，网络互通才是更要紧的问题。网络互通的关键在于“打通”容器内外的网络。\n\ndocker提供了三种网络模式，分别是 null、 host 和 bridge。\n\n * null 是最简单的模式，也就是没有网络，但允许其他的网络插件来自定义网络连接\n * host 的意思是直接使用宿主机网络，相当于去掉了容器的网络隔离（其他隔离依然保留），所有的容器会共享宿主机的ip地址和网卡。这种模式没有中间层，自然通信效率高，但缺少了隔离，运行太多的容器也容易导致端口冲突。\n   * host模式需要在 docker run 时使用 --net=host 参数\n\n使用 host 网络模式的例子\n\n下面用--net=host这个参数启动nginx：\n\ndocker run -d --rm --net=host nginx:alpine\n\n\n1\n\n\n为了验证效果，我们可以在本机和容器里分别执行 ip addr 命令，查看网卡信息:\n\nip addr                    # 本机查看网卡\ndocker exec xxx ip addr    # 容器查看网卡\n\n\n1\n2\n\n\n可以发现这两个命令的输出信息是完全一样的，如网卡 ensxxx 和 ip 地址。\n\n * bridge，也就是桥接模式，它有点类似现实世界里的交换机、路由器，只不过是由软件虚拟出来的，容器和宿主机再通过虚拟网卡接入这个网桥（图中的docker0），那么它们之间也就可以正常的收发网络数据包了。不过和host模式相比，bridge模式多了虚拟网桥和网卡，通信效率会低一些。\n   * 可以用 --net=bridge 来启用桥接模式，但其实不必要，因为docker默认的网络模式就是bridge，所以一般不需要显式指定。\n   * \n\n使用 bridge 网络模式的例子\n\n下面我们启动两个容器nginx和redis，就像刚才说的，没有特殊指定就会使用bridge模式：\n\ndocker run -d --rm nginx:alpine    # 默认使用桥接模式\ndocker run -d --rm redis           # 默认使用桥接模式\n\n\n1\n2\n\n\n然后我们还是在本机和容器里执行 ip addr 命令（redis容器里没有ip命令，所以只能在nginx容器里执行）：\n\n对比一下刚才host模式的输出，就可以发现容器里的网卡设置与宿主机完全不同，eth0是一个虚拟网卡，ip地址是b类私有地址“172.17.0.4”。\n\n我们还可以用 docker inspect 直接查看容器的ip地址：\n\ndocker inspect xxx |grep ipaddress\n\n\n1\n\n\n这显示出两个容器的ip地址分别是“172.17.0.3”和“172.17.0.4”，而宿主机的ip地址则是“172.17.0.1”，所以它们都在“172.17.0.0/16”这个docker的默认网段，彼此之间就能够使用ip地址来实现网络通信了。\n\n\n# 如何分配服务端口号\n\n服务器应用都必须要有端口号才能对外提供服务。前面第4节我们在学习编写dockerfile的时候也看到过，可以用 expose 指令声明容器对外的端口号。\n\n一台主机上的端口号数量是有限的，而且多个服务之间还不能够冲突，但我们打包镜像应用的时候通常都使用的是默认端口，容器实际运行起来就很容易因为端口号被占用而无法启动。\n\n解决这个问题的方法就是加入一个“中间层”，由容器环境例如docker来统一管理分配端口号，在本机端口和容器端口之间做一个“映射”操作，容器内部还是用自己的端口号，但外界看到的却是另外一个端口号，这样就很好地避免了冲突。\n\n端口号映射需要使用bridge模式，并且在 docker run 启动容器时使用 -p 参数，形式和共享目录的 -v 参数很类似，用 : 分隔本机端口和容器端口。\n\n分配服务端口号的例子\n\n如果要启动两个nginx容器，分别跑在80和8080端口上：\n\ndocker run -d -p 80:80 --rm nginx:alpine\ndocker run -d -p 8080:80 --rm nginx:alpine\n\n\n1\n2\n\n\n这样就把本机的80和8080端口分别“映射”到了两个容器里的80端口，不会发生冲突，我们可以用curl再验证一下。\n\n使用 docker ps 命令能够在“ports”栏里更直观地看到端口的映射情况。',charsets:{cjk:!0},lastUpdated:"2023/06/07, 00:44:58",lastUpdatedTimestamp:1686098698e3},{title:"Kubernetes 的安装与基本架构",frontmatter:{title:"Kubernetes 的安装与基本架构",date:"2023-06-04T21:22:52.000Z",permalink:"/pages/757154/",categories:["基础","云原生","Kubernetes入门实战课-罗剑锋"],tags:[null]},regularPath:"/%E5%9F%BA%E7%A1%80/20.%E4%BA%91%E5%8E%9F%E7%94%9F/15.Kubernetes%E5%85%A5%E9%97%A8%E5%AE%9E%E6%88%98%E8%AF%BE-%E7%BD%97%E5%89%91%E9%94%8B/09.Kubernetes%20%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84.html",relativePath:"基础/20.云原生/15.Kubernetes入门实战课-罗剑锋/09.Kubernetes 的安装与基本架构.md",key:"v-7a34202e",path:"/pages/757154/",headers:[{level:2,title:"Kubernetes 的安装与基本架构",slug:"kubernetes-的安装与基本架构",normalizedTitle:"kubernetes 的安装与基本架构",charIndex:2},{level:3,title:"走进云原生：在本机搭建 Kubernetes 小集群",slug:"走进云原生-在本机搭建-kubernetes-小集群",normalizedTitle:"走进云原生：在本机搭建 kubernetes 小集群",charIndex:26},{level:3,title:"安装环境",slug:"安装环境",normalizedTitle:"安装环境",charIndex:116},{level:3,title:"实际验证 minikuybe 环境",slug:"实际验证-minikuybe-环境",normalizedTitle:"实际验证 minikuybe 环境",charIndex:628},{level:3,title:"在Kubernetes里运行一个Nginx应用",slug:"在kubernetes里运行一个nginx应用",normalizedTitle:"在kubernetes里运行一个nginx应用",charIndex:1200},{level:3,title:"关于云原生",slug:"关于云原生",normalizedTitle:"关于云原生",charIndex:1493},{level:2,title:"自动化的运维管理：探究 Kubernetes 工作机制的奥秘",slug:"自动化的运维管理-探究-kubernetes-工作机制的奥秘",normalizedTitle:"自动化的运维管理：探究 kubernetes 工作机制的奥秘",charIndex:1686},{level:3,title:"云计算时代的操作系统",slug:"云计算时代的操作系统",normalizedTitle:"云计算时代的操作系统",charIndex:1768},{level:3,title:"Kubernetes的基本架构",slug:"kubernetes的基本架构",normalizedTitle:"kubernetes的基本架构",charIndex:2004},{level:3,title:"节点内部的结构",slug:"节点内部的结构",normalizedTitle:"节点内部的结构",charIndex:2870},{level:4,title:"(1) Master里的组件有哪些",slug:"_1-master里的组件有哪些",normalizedTitle:"(1) master里的组件有哪些",charIndex:3061},{level:4,title:"(2) Node 里的组件有哪些？",slug:"_2-node-里的组件有哪些",normalizedTitle:"(2) node 里的组件有哪些？",charIndex:4480},{level:4,title:"(3) 插件（Addons）有哪些？",slug:"_3-插件-addons-有哪些",normalizedTitle:"(3) 插件（addons）有哪些？",charIndex:6328},{level:3,title:"小结",slug:"小结",normalizedTitle:"小结",charIndex:7001}],headersStr:"Kubernetes 的安装与基本架构 走进云原生：在本机搭建 Kubernetes 小集群 安装环境 实际验证 minikuybe 环境 在Kubernetes里运行一个Nginx应用 关于云原生 自动化的运维管理：探究 Kubernetes 工作机制的奥秘 云计算时代的操作系统 Kubernetes的基本架构 节点内部的结构 (1) Master里的组件有哪些 (2) Node 里的组件有哪些？ (3) 插件（Addons）有哪些？ 小结",content:'# Kubernetes 的安装与基本架构\n\n\n# 走进云原生：在本机搭建 Kubernetes 小集群\n\nKubernetes就是一个 生产级别的容器编排平台和集群管理系统，不仅能够创建、调度容器，还能够监控、管理服务器\n\n\n# 安装环境\n\n * minicube\n   * kind 和 minikube，它们都可以在本机上运行完整的Kubernetes环境。\n   * minikube最大特点就是“小而美”，可执行文件仅有不到100MB，运行镜像也不过1GB，但就在这么小的空间里却集成了Kubernetes的绝大多数功能特性，不仅有核心的容器编排功能，还有丰富的插件，例如Dashboard、GPU、Ingress、Istio、Kong、Registry等等，综合来看非常完善。\n   * minikube只能够搭建Kubernetes环境\n * kubectl\n   * 用来操作Kubernetes的客户端工具\n   * kubectl的作用有点类似之前我们学习容器技术时候的工具“docker”，它也是一个命令行工具，作用也比较类似，同样是与Kubernetes后台服务通信，把我们的命令转发给Kubernetes，实现容器和集群的管理功能。\n\n所以，在minikube环境里，我们会用到两个客户端：minikube管理Kubernetes集群环境，kubectl操作实际的Kubernetes功能，和Docker比起来有点复杂。\n\n\n# 实际验证 minikuybe 环境\n\n前面的工作都做完之后，我们就可以在本机上运行minikube，创建Kubernetes实验环境了。\n\n使用命令 minikube start 会从Docker Hub上拉取镜像时，命令：minikube start --kubernetes-version=v1.23.3 会出现问题，\n\n> The "docker" driver should not be used with root privileges. (无法用 root 权限执行 docker 驱动)\n\n因为不能用 root 权限启动 minikube。对命令指定一些参数就可以了，命令改为如下：\n\n minikube start --kubernetes-version=v1.23.3 --driver=docker --container-runtime=containerd --image-mirror-country=cn --force\n\n\n1\n\n\n> 参考博客\n\n现在Kubernetes集群就已经在我们本地运行了，你可以使用 minikube status、 minikube node list 这两个命令来查看集群的状态：\n\nminikube status\nminikube node list\n\n\n1\n2\n\n\n\n# 在Kubernetes里运行一个Nginx应用\n\n命令与Docker一样，也是 run，不过形式上有点区别，需要用 --image 指定镜像**，然后Kubernetes会自动拉取并运行：\n\nkubectl run ngx --image=nginx:alpine\n\n\n1\n\n\n这里涉及Kubernetes里的一个非常重要的概念： Pod，你可以暂时把它理解成是“穿了马甲”的容器，查看Pod列表需要使用命令 kubectl get pod，它的效果类似 docker ps。\n\nkubectl的用法与docker类似，也可以拉取镜像运行，但操作的不是简单的容器，而是Pod。\n\n\n# 关于云原生\n\n所谓的“云”，现在就指的是Kubernetes，那么“云原生”的意思就是应用的开发、部署、运维等一系列工作都要向Kubernetes看齐，使用容器、微服务、声明式API等技术，保证应用的整个生命周期都能够在Kubernetes环境里顺利实施，不需要附加额外的条件。\n\n换句话说，“云原生”就是Kubernetes里的“原住民”，而不是从其他环境迁过来的“移民”。\n\n\n# 自动化的运维管理：探究 Kubernetes 工作机制的奥秘\n\n这一节就来看一下 Kubernetes 的内部架构和工作机制，了解它能傲视群雄的秘密所在。\n\n\n# 云计算时代的操作系统\n\nKubernetes 管理了资源、服务，从某种角度来看，它可以说是一个集群级别的操作系统，主要功能就是资源管理和作业调度。Kubernetes 这个操作系统与 Linux 还有一点区别你值得注意。Linux 的用户通常是两类人：Dev 和 Ops，而在 Kubernetes 里则只有一类人：DevOps。\n\n> 由于云原生的兴起，开发人员从一开始就必须考虑后续的部署运维工作，而运维人员也需要在早期介入开发，才能做好应用的运维监控工作。\n\n\n# Kubernetes的基本架构\n\nKubernetes 的架构图如下图所示：\n\nKubernetes 采用了现今流行的“控制面/数据面”（Control Plane / Data Plane）架构，集群里的计算机被称为“节点”（Node），可以是实机也可以是虚机，少量的节点用作控制面来执行集群的管理维护工作，其他的大部分节点都被划归数据面，用来跑业务应用。\n\n * Control Plan 的节点叫做 Master Node，一般简称 Master，可以说是 Kubernetes 的大脑和心脏。\n * Data Plan 的节点叫做 Worker Node，一般简称 Worker 或 Node，相当于 Kubernetes 的手和脚，在 Master 的指挥下干活。\n\nNode 的数量非常多，构成了一个资源池，Kubernetes 就在这个池里分配资源，调度应用。因为资源被“池化”了，所以管理也就变得比较简单，可以在集群中任意添加或者删除节点。\n\n在这张架构图里，我们还可以看到有一个 kubectl，它就是 Kubernetes 的客户端工具，用来操作 Kubernetes，但它位于集群之外，理论上不属于集群。可以使用命令 kubectl get node 来查看 k8s 的节点状态：\n\n$ kubectl get node\nNAME       STATUS   ROLES                  AGE   VERSION\nminikube   Ready    control-plane,master   93m   v1.23.3\n\n\n1\n2\n3\n\n\n可以看到当前的 minikube 集群里只有一个 Master，那 Node 怎么不见了？这是因为 Master 和 Node 的划分不是绝对的。当集群的规模较小，工作负载较少的时候，Master 也可以承担 Node 的工作，就像我们搭建的 minikube 环境，它就只有一个节点，这个节点既是 Master 又是 Node。\n\n\n# 节点内部的结构\n\nKubernetes的节点内部也具有复杂的结构，是由很多的模块构成的，这些模块又可以分成组件（Component）和插件（Addon）两类。\n\n * 组件实现了Kubernetes的核心功能特性，没有这些组件Kubernetes就无法启动\n * 插件则是Kubernetes的一些附加功能，属于“锦上添花”，不安装也不会影响Kubernetes的正常运行。\n\n# (1) Master里的组件有哪些\n\nMaster里有4个组件，分别是 apiserver、 etcd、 scheduler、 controller-manager。\n\n * apiserver：整个 Kubernetes 系统的唯一入口，它对外公开了一系列的 RESTful API，并且加上了验证、授权等功能，所有其他组件都只能和它直接通信，可以说是 Kubernetes 里的联络员。\n * etcd：一个高可用的 KV 数据库，用来持久化存储系统里的各种资源对象和状态。注意它只与 apiserver 有直接联系，也就是说任何其他组件想要读写 etcd 里的数据都必须经过 apiserver。\n * scheduler：负责容器的编排工作，检查节点的资源状态，把 Pod 调度到最适合的节点上运行，相当于部署人员。因为节点状态和 Pod 信息都存储在 etcd 里，所以 scheduler 必须通过 apiserver 才能获得。\n * controller-manager：负责维护容器和节点等资源的状态，实现故障检测、服务迁移、应用伸缩等功能，相当于监控运维人员。同样地，它也必须通过 apiserver 获得存储在 etcd 里的信息，才能够实现对资源的各种操作。\n\n> API 对象就被 apiserver 存储在数据库 etcd 里，然后 kubelet、scheduler、controller-manager 等组件通过 apiserver 来操作它们，就在API对象这个抽象层次实现了对整个集群的管理。\n\n这4个组件也都被容器化了，运行在集群的 Pod 里，我们可以用 kubectl 来查看它们的状态，使用命令：\n\n\n\n\n\n \n \n \n\n \n\n\n\n$ kubectl get pod -n kube-system\nNAME                               READY   STATUS             RESTARTS   AGE\ncoredns-64897985d-64hv8            1/1     Running            0          100m\netcd-minikube                      1/1     Running            0          100m\nkube-apiserver-minikube            1/1     Running            0          100m\nkube-controller-manager-minikube   1/1     Running            0          100m\nkube-proxy-r2b4g                   1/1     Running            0          100m\nkube-scheduler-minikube            1/1     Running            0          100m\nstorage-provisioner                0/1     ImagePullBackOff   0          100m\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n# (2) Node 里的组件有哪些？\n\nMaster里的apiserver、scheduler等组件需要获取节点的各种信息才能够作出管理决策，那这些信息该怎么来呢？这就需要Node里的3个组件了，分别是 kubelet、kube-proxy、container-runtime：\n\n * kubelet：Node 的代理，负责管理 Node 相关的绝大部分操作，Node 上只有它能够与 apiserver 通信，实现状态报告、命令下发、启停容器等功能，相当于是 Node 上的一个“小管家”。\n * kube-proxy：Node 的网络代理，只负责管理容器的网络通信，简单来说就是为 Pod 转发 TCP/UDP 数据包，相当于是专职的“小邮差”。\n * container-runtime：它是容器和镜像的实际使用者，通常为 Docker，在 kubelet 的指挥下创建容器，管理 Pod 的生命周期，是真正干活的“苦力”。\n\n> 我们一定要注意，因为 Kubernetes 的定位是容器编排平台，所以它没有限定 container-runtime 必须是 Docker，完全可以替换成任何符合标准的其他容器运行时，例如 containerd、CRI-O 等等，只不过在这里我们使用的是 Docker。\n\n这3个组件中只有 kube-proxy 被容器化了，而 kubelet 因为必须要管理整个节点，容器化会限制它的能力，所以它必须在 container-runtime 之外运行。\n\n使用 minikube ssh 命令登录到节点后，可以用 docker ps 看到 kube-proxy：\n\n \n\n\n \n\n\n\n\n$ minikube ssh\nLast login: Sat Apr 22 11:43:55 2023 from 192.168.49.1\n\ndocker@minikube:~$ docker ps | grep kube-proxy\n2089b7b713b1   9b7cc9982109           "/usr/local/bin/kube…"   2 hours ago      Up 2 hours                k8s_kube-proxy_kube-proxy-r2b4g_kube-system_86dd0c2b-f392-4327-82b8-32422e441a75_0\n4d3598fc2131   k8s.gcr.io/pause:3.6   "/pause"                 2 hours ago      Up 2 hours                k8s_POD_kube-proxy-r2b4g_kube-system_86dd0c2b-f392-4327-82b8-32422e441a75_0\n\n\n1\n2\n3\n4\n5\n6\n\n\n> ????????????为啥我执行这个有问题？？？？？\n\n而 kubelet 用 docker ps 是找不到的，需要用操作系统的 ps 命令：\n\nps -ef | grep kubelet\n\n\n1\n\n\n现在，我们再把 Node 里的组件和 Master 里的组件放在一起来看，就能够明白 Kubernetes 的大致工作流程了：\n\n * 每个 Node 上的 kubelet 会定期向 apiserver 上报节点状态，apiserver 再存到 etcd 里。\n * 每个 Node 上的 kube-proxy 实现了 TCP/UDP 反向代理，让容器对外提供稳定的服务。\n * scheduler 通过 apiserver 得到当前的节点状态，调度 Pod，然后 apiserver 下发命令给某个 Node 的 kubelet，kubelet 调用 container-runtime 启动容器。\n * controller-manager 也通过 apiserver 得到实时的节点状态，监控可能的异常情况，再使用相应的手段去调节恢复。\n\n其实，这和我们在 Kubernetes 出现之前的操作流程也差不了多少，但 Kubernetes 的高明之处就在于把这些都抽象化规范化了。于是，这些组件就好像是无数个不知疲倦的运维工程师，把原先繁琐低效的人力工作搬进了高效的计算机里，就能够随时发现集群里的变化和异常，再互相协作，维护集群的健康状态。\n\n# (3) 插件（Addons）有哪些？\n\n只要服务器节点上运行了 apiserver、scheduler、kubelet、kube-proxy、container-runtime 等组件，就可以说是一个功能齐全的 Kubernetes 集群了。\n\n不过就像Linux一样，操作系统提供的基础功能虽然“可用”，但想达到“好用”的程度，还是要再安装一些附加功能，这在Kubernetes里就是插件（Addon）。由于Kubernetes本身的设计非常灵活，所以就有大量的插件用来扩展、增强它对应用和集群的管理能力。\n\nminikube也支持很多的插件，使用命令 minikube addons list 就可以查看插件列表：\n\n插件中我个人认为比较重要的有两个：DNS 和 Dashboard。\n\n * DNS 在 Kubernetes 集群里实现了域名解析服务，能够让我们以域名而不是 IP 地址的方式来互相通信，是服务发现和负载均衡的基础。由于它对微服务、服务网格等架构至关重要，所以基本上是 Kubernetes 的必备插件。\n * Dashboard 就是仪表盘，为 Kubernetes 提供了一个图形化的操作界面，非常直观友好，虽然大多数 Kubernetes 工作都是使用命令行 kubectl，但有的时候在 Dashboard 上查看信息也是挺方便的。\n\n你只要在 minikube 环境里执行一条简单的命令，就可以自动用浏览器打开 Dashboard 页面，而且还支持中文：\n\nminikube dashboard\n\n\n1\n\n\n\n# 小结\n\n小结一下这一节的要点：\n\n 1. Kubernetes 能够在集群级别管理应用和服务器，可以认为是一种集群操作系统。它使用“控制面/数据面”的基本架构，Master 节点实现管理控制功能，Worker 节点运行具体业务。\n 2. Kubernetes 由很多模块组成，可分为核心的组件和选配的插件两类。\n 3. Master 里有 4 个组件，分别是 apiserver、etcd、scheduler、controller-manager。\n 4. Node 里有 3 个组件，分别是 kubelet、kube-proxy、container-runtime。\n 5. 通常必备的插件有 DNS 和 Dashboard。\n\n课外小贴士：\n\n * 为确保控制面的高可用，Kubernetes 集群里都会部署多个 Master 节点，数量一般会是奇数 (3/5/7)，这是由 etcd 的特性决定的。\n * etcd 由 CoreOS 公司开发，基于类 Paxos 的 Raft 算法实现数据一致性。\n * controller-manager 是很多个 controller 的集合体每一个 controller 负责一种控制循环 (如 node con-troller、namespace controller)，但为了简化被合并在一个进程里执行。\n * minikube 的 Dashboard 只允许在本机运行的浏览器访问，不过你也可以给它配置 Nginx 反向代理。',normalizedContent:'# kubernetes 的安装与基本架构\n\n\n# 走进云原生：在本机搭建 kubernetes 小集群\n\nkubernetes就是一个 生产级别的容器编排平台和集群管理系统，不仅能够创建、调度容器，还能够监控、管理服务器\n\n\n# 安装环境\n\n * minicube\n   * kind 和 minikube，它们都可以在本机上运行完整的kubernetes环境。\n   * minikube最大特点就是“小而美”，可执行文件仅有不到100mb，运行镜像也不过1gb，但就在这么小的空间里却集成了kubernetes的绝大多数功能特性，不仅有核心的容器编排功能，还有丰富的插件，例如dashboard、gpu、ingress、istio、kong、registry等等，综合来看非常完善。\n   * minikube只能够搭建kubernetes环境\n * kubectl\n   * 用来操作kubernetes的客户端工具\n   * kubectl的作用有点类似之前我们学习容器技术时候的工具“docker”，它也是一个命令行工具，作用也比较类似，同样是与kubernetes后台服务通信，把我们的命令转发给kubernetes，实现容器和集群的管理功能。\n\n所以，在minikube环境里，我们会用到两个客户端：minikube管理kubernetes集群环境，kubectl操作实际的kubernetes功能，和docker比起来有点复杂。\n\n\n# 实际验证 minikuybe 环境\n\n前面的工作都做完之后，我们就可以在本机上运行minikube，创建kubernetes实验环境了。\n\n使用命令 minikube start 会从docker hub上拉取镜像时，命令：minikube start --kubernetes-version=v1.23.3 会出现问题，\n\n> the "docker" driver should not be used with root privileges. (无法用 root 权限执行 docker 驱动)\n\n因为不能用 root 权限启动 minikube。对命令指定一些参数就可以了，命令改为如下：\n\n minikube start --kubernetes-version=v1.23.3 --driver=docker --container-runtime=containerd --image-mirror-country=cn --force\n\n\n1\n\n\n> 参考博客\n\n现在kubernetes集群就已经在我们本地运行了，你可以使用 minikube status、 minikube node list 这两个命令来查看集群的状态：\n\nminikube status\nminikube node list\n\n\n1\n2\n\n\n\n# 在kubernetes里运行一个nginx应用\n\n命令与docker一样，也是 run，不过形式上有点区别，需要用 --image 指定镜像**，然后kubernetes会自动拉取并运行：\n\nkubectl run ngx --image=nginx:alpine\n\n\n1\n\n\n这里涉及kubernetes里的一个非常重要的概念： pod，你可以暂时把它理解成是“穿了马甲”的容器，查看pod列表需要使用命令 kubectl get pod，它的效果类似 docker ps。\n\nkubectl的用法与docker类似，也可以拉取镜像运行，但操作的不是简单的容器，而是pod。\n\n\n# 关于云原生\n\n所谓的“云”，现在就指的是kubernetes，那么“云原生”的意思就是应用的开发、部署、运维等一系列工作都要向kubernetes看齐，使用容器、微服务、声明式api等技术，保证应用的整个生命周期都能够在kubernetes环境里顺利实施，不需要附加额外的条件。\n\n换句话说，“云原生”就是kubernetes里的“原住民”，而不是从其他环境迁过来的“移民”。\n\n\n# 自动化的运维管理：探究 kubernetes 工作机制的奥秘\n\n这一节就来看一下 kubernetes 的内部架构和工作机制，了解它能傲视群雄的秘密所在。\n\n\n# 云计算时代的操作系统\n\nkubernetes 管理了资源、服务，从某种角度来看，它可以说是一个集群级别的操作系统，主要功能就是资源管理和作业调度。kubernetes 这个操作系统与 linux 还有一点区别你值得注意。linux 的用户通常是两类人：dev 和 ops，而在 kubernetes 里则只有一类人：devops。\n\n> 由于云原生的兴起，开发人员从一开始就必须考虑后续的部署运维工作，而运维人员也需要在早期介入开发，才能做好应用的运维监控工作。\n\n\n# kubernetes的基本架构\n\nkubernetes 的架构图如下图所示：\n\nkubernetes 采用了现今流行的“控制面/数据面”（control plane / data plane）架构，集群里的计算机被称为“节点”（node），可以是实机也可以是虚机，少量的节点用作控制面来执行集群的管理维护工作，其他的大部分节点都被划归数据面，用来跑业务应用。\n\n * control plan 的节点叫做 master node，一般简称 master，可以说是 kubernetes 的大脑和心脏。\n * data plan 的节点叫做 worker node，一般简称 worker 或 node，相当于 kubernetes 的手和脚，在 master 的指挥下干活。\n\nnode 的数量非常多，构成了一个资源池，kubernetes 就在这个池里分配资源，调度应用。因为资源被“池化”了，所以管理也就变得比较简单，可以在集群中任意添加或者删除节点。\n\n在这张架构图里，我们还可以看到有一个 kubectl，它就是 kubernetes 的客户端工具，用来操作 kubernetes，但它位于集群之外，理论上不属于集群。可以使用命令 kubectl get node 来查看 k8s 的节点状态：\n\n$ kubectl get node\nname       status   roles                  age   version\nminikube   ready    control-plane,master   93m   v1.23.3\n\n\n1\n2\n3\n\n\n可以看到当前的 minikube 集群里只有一个 master，那 node 怎么不见了？这是因为 master 和 node 的划分不是绝对的。当集群的规模较小，工作负载较少的时候，master 也可以承担 node 的工作，就像我们搭建的 minikube 环境，它就只有一个节点，这个节点既是 master 又是 node。\n\n\n# 节点内部的结构\n\nkubernetes的节点内部也具有复杂的结构，是由很多的模块构成的，这些模块又可以分成组件（component）和插件（addon）两类。\n\n * 组件实现了kubernetes的核心功能特性，没有这些组件kubernetes就无法启动\n * 插件则是kubernetes的一些附加功能，属于“锦上添花”，不安装也不会影响kubernetes的正常运行。\n\n# (1) master里的组件有哪些\n\nmaster里有4个组件，分别是 apiserver、 etcd、 scheduler、 controller-manager。\n\n * apiserver：整个 kubernetes 系统的唯一入口，它对外公开了一系列的 restful api，并且加上了验证、授权等功能，所有其他组件都只能和它直接通信，可以说是 kubernetes 里的联络员。\n * etcd：一个高可用的 kv 数据库，用来持久化存储系统里的各种资源对象和状态。注意它只与 apiserver 有直接联系，也就是说任何其他组件想要读写 etcd 里的数据都必须经过 apiserver。\n * scheduler：负责容器的编排工作，检查节点的资源状态，把 pod 调度到最适合的节点上运行，相当于部署人员。因为节点状态和 pod 信息都存储在 etcd 里，所以 scheduler 必须通过 apiserver 才能获得。\n * controller-manager：负责维护容器和节点等资源的状态，实现故障检测、服务迁移、应用伸缩等功能，相当于监控运维人员。同样地，它也必须通过 apiserver 获得存储在 etcd 里的信息，才能够实现对资源的各种操作。\n\n> api 对象就被 apiserver 存储在数据库 etcd 里，然后 kubelet、scheduler、controller-manager 等组件通过 apiserver 来操作它们，就在api对象这个抽象层次实现了对整个集群的管理。\n\n这4个组件也都被容器化了，运行在集群的 pod 里，我们可以用 kubectl 来查看它们的状态，使用命令：\n\n\n\n\n\n \n \n \n\n \n\n\n\n$ kubectl get pod -n kube-system\nname                               ready   status             restarts   age\ncoredns-64897985d-64hv8            1/1     running            0          100m\netcd-minikube                      1/1     running            0          100m\nkube-apiserver-minikube            1/1     running            0          100m\nkube-controller-manager-minikube   1/1     running            0          100m\nkube-proxy-r2b4g                   1/1     running            0          100m\nkube-scheduler-minikube            1/1     running            0          100m\nstorage-provisioner                0/1     imagepullbackoff   0          100m\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n# (2) node 里的组件有哪些？\n\nmaster里的apiserver、scheduler等组件需要获取节点的各种信息才能够作出管理决策，那这些信息该怎么来呢？这就需要node里的3个组件了，分别是 kubelet、kube-proxy、container-runtime：\n\n * kubelet：node 的代理，负责管理 node 相关的绝大部分操作，node 上只有它能够与 apiserver 通信，实现状态报告、命令下发、启停容器等功能，相当于是 node 上的一个“小管家”。\n * kube-proxy：node 的网络代理，只负责管理容器的网络通信，简单来说就是为 pod 转发 tcp/udp 数据包，相当于是专职的“小邮差”。\n * container-runtime：它是容器和镜像的实际使用者，通常为 docker，在 kubelet 的指挥下创建容器，管理 pod 的生命周期，是真正干活的“苦力”。\n\n> 我们一定要注意，因为 kubernetes 的定位是容器编排平台，所以它没有限定 container-runtime 必须是 docker，完全可以替换成任何符合标准的其他容器运行时，例如 containerd、cri-o 等等，只不过在这里我们使用的是 docker。\n\n这3个组件中只有 kube-proxy 被容器化了，而 kubelet 因为必须要管理整个节点，容器化会限制它的能力，所以它必须在 container-runtime 之外运行。\n\n使用 minikube ssh 命令登录到节点后，可以用 docker ps 看到 kube-proxy：\n\n \n\n\n \n\n\n\n\n$ minikube ssh\nlast login: sat apr 22 11:43:55 2023 from 192.168.49.1\n\ndocker@minikube:~$ docker ps | grep kube-proxy\n2089b7b713b1   9b7cc9982109           "/usr/local/bin/kube…"   2 hours ago      up 2 hours                k8s_kube-proxy_kube-proxy-r2b4g_kube-system_86dd0c2b-f392-4327-82b8-32422e441a75_0\n4d3598fc2131   k8s.gcr.io/pause:3.6   "/pause"                 2 hours ago      up 2 hours                k8s_pod_kube-proxy-r2b4g_kube-system_86dd0c2b-f392-4327-82b8-32422e441a75_0\n\n\n1\n2\n3\n4\n5\n6\n\n\n> ????????????为啥我执行这个有问题？？？？？\n\n而 kubelet 用 docker ps 是找不到的，需要用操作系统的 ps 命令：\n\nps -ef | grep kubelet\n\n\n1\n\n\n现在，我们再把 node 里的组件和 master 里的组件放在一起来看，就能够明白 kubernetes 的大致工作流程了：\n\n * 每个 node 上的 kubelet 会定期向 apiserver 上报节点状态，apiserver 再存到 etcd 里。\n * 每个 node 上的 kube-proxy 实现了 tcp/udp 反向代理，让容器对外提供稳定的服务。\n * scheduler 通过 apiserver 得到当前的节点状态，调度 pod，然后 apiserver 下发命令给某个 node 的 kubelet，kubelet 调用 container-runtime 启动容器。\n * controller-manager 也通过 apiserver 得到实时的节点状态，监控可能的异常情况，再使用相应的手段去调节恢复。\n\n其实，这和我们在 kubernetes 出现之前的操作流程也差不了多少，但 kubernetes 的高明之处就在于把这些都抽象化规范化了。于是，这些组件就好像是无数个不知疲倦的运维工程师，把原先繁琐低效的人力工作搬进了高效的计算机里，就能够随时发现集群里的变化和异常，再互相协作，维护集群的健康状态。\n\n# (3) 插件（addons）有哪些？\n\n只要服务器节点上运行了 apiserver、scheduler、kubelet、kube-proxy、container-runtime 等组件，就可以说是一个功能齐全的 kubernetes 集群了。\n\n不过就像linux一样，操作系统提供的基础功能虽然“可用”，但想达到“好用”的程度，还是要再安装一些附加功能，这在kubernetes里就是插件（addon）。由于kubernetes本身的设计非常灵活，所以就有大量的插件用来扩展、增强它对应用和集群的管理能力。\n\nminikube也支持很多的插件，使用命令 minikube addons list 就可以查看插件列表：\n\n插件中我个人认为比较重要的有两个：dns 和 dashboard。\n\n * dns 在 kubernetes 集群里实现了域名解析服务，能够让我们以域名而不是 ip 地址的方式来互相通信，是服务发现和负载均衡的基础。由于它对微服务、服务网格等架构至关重要，所以基本上是 kubernetes 的必备插件。\n * dashboard 就是仪表盘，为 kubernetes 提供了一个图形化的操作界面，非常直观友好，虽然大多数 kubernetes 工作都是使用命令行 kubectl，但有的时候在 dashboard 上查看信息也是挺方便的。\n\n你只要在 minikube 环境里执行一条简单的命令，就可以自动用浏览器打开 dashboard 页面，而且还支持中文：\n\nminikube dashboard\n\n\n1\n\n\n\n# 小结\n\n小结一下这一节的要点：\n\n 1. kubernetes 能够在集群级别管理应用和服务器，可以认为是一种集群操作系统。它使用“控制面/数据面”的基本架构，master 节点实现管理控制功能，worker 节点运行具体业务。\n 2. kubernetes 由很多模块组成，可分为核心的组件和选配的插件两类。\n 3. master 里有 4 个组件，分别是 apiserver、etcd、scheduler、controller-manager。\n 4. node 里有 3 个组件，分别是 kubelet、kube-proxy、container-runtime。\n 5. 通常必备的插件有 dns 和 dashboard。\n\n课外小贴士：\n\n * 为确保控制面的高可用，kubernetes 集群里都会部署多个 master 节点，数量一般会是奇数 (3/5/7)，这是由 etcd 的特性决定的。\n * etcd 由 coreos 公司开发，基于类 paxos 的 raft 算法实现数据一致性。\n * controller-manager 是很多个 controller 的集合体每一个 controller 负责一种控制循环 (如 node con-troller、namespace controller)，但为了简化被合并在一个进程里执行。\n * minikube 的 dashboard 只允许在本机运行的浏览器访问，不过你也可以给它配置 nginx 反向代理。',charsets:{cjk:!0},lastUpdated:"2023/06/09, 05:49:53",lastUpdatedTimestamp:1686289793e3},{title:"YAML、Pod、Job、CronJob、ConfigMap、Secret",frontmatter:{title:"YAML、Pod、Job、CronJob、ConfigMap、Secret",date:"2023-06-06T21:10:06.000Z",permalink:"/pages/c0d84b/",categories:["基础","云原生","Kubernetes入门实战课-罗剑锋"],tags:[null]},regularPath:"/%E5%9F%BA%E7%A1%80/20.%E4%BA%91%E5%8E%9F%E7%94%9F/15.Kubernetes%E5%85%A5%E9%97%A8%E5%AE%9E%E6%88%98%E8%AF%BE-%E7%BD%97%E5%89%91%E9%94%8B/11.YAML%E3%80%81Pod%E3%80%81Job%E3%80%81CronJob%E3%80%81ConfigMap%E3%80%81Secret.html",relativePath:"基础/20.云原生/15.Kubernetes入门实战课-罗剑锋/11.YAML、Pod、Job、CronJob、ConfigMap、Secret.md",key:"v-ac009106",path:"/pages/c0d84b/",headers:[{level:2,title:"1. YAML：Kubernetes世界里的通用语",slug:"_1-yaml-kubernetes世界里的通用语",normalizedTitle:"1. yaml：kubernetes世界里的通用语",charIndex:2},{level:3,title:"1.1 声明式与命令式是怎么回事",slug:"_1-1-声明式与命令式是怎么回事",normalizedTitle:"1.1 声明式与命令式是怎么回事",charIndex:61},{level:3,title:"1.2 什么是 YAML",slug:"_1-2-什么是-yaml",normalizedTitle:"1.2 什么是 yaml",charIndex:846},{level:3,title:"1.3 什么是 API 对象",slug:"_1-3-什么是-api-对象",normalizedTitle:"1.3 什么是 api 对象",charIndex:1006},{level:3,title:"1.4 如何描述API对象",slug:"_1-4-如何描述api对象",normalizedTitle:"1.4 如何描述api对象",charIndex:1927},{level:3,title:"1.5 如何编写 YAML",slug:"_1-5-如何编写-yaml",normalizedTitle:"1.5 如何编写 yaml",charIndex:3846},{level:3,title:"1.6 课外小贴士",slug:"_1-6-课外小贴士",normalizedTitle:"1.6 课外小贴士",charIndex:5164},{level:2,title:"2. Pod：如何理解这个Kubernetes里最核心的概念？",slug:"_2-pod-如何理解这个kubernetes里最核心的概念",normalizedTitle:"2. pod：如何理解这个kubernetes里最核心的概念？",charIndex:5447},{level:3,title:"2.1 为什么要有 Pod",slug:"_2-1-为什么要有-pod",normalizedTitle:"2.1 为什么要有 pod",charIndex:5483},{level:2,title:"3. Job/CronJob：为什么不直接用Pod来处理业务？",slug:"_3-job-cronjob-为什么不直接用pod来处理业务",normalizedTitle:"3. job/cronjob：为什么不直接用pod来处理业务？",charIndex:5770},{level:3,title:"3.1 为什么不直接使用Pod",slug:"_3-1-为什么不直接使用pod",normalizedTitle:"3.1 为什么不直接使用pod",charIndex:6146},{level:3,title:"小结",slug:"小结",normalizedTitle:"小结",charIndex:6166},{level:2,title:"4. ConfigMap/Secret：怎样配置、定制我的应用",slug:"_4-configmap-secret-怎样配置、定制我的应用",normalizedTitle:"4. configmap/secret：怎样配置、定制我的应用",charIndex:6701},{level:3,title:"4.1 ConfigMap/Secret",slug:"_4-1-configmap-secret",normalizedTitle:"4.1 configmap/secret",charIndex:6853},{level:4,title:"4.1.1 什么是ConfigMap",slug:"_4-1-1-什么是configmap",normalizedTitle:"4.1.1 什么是configmap",charIndex:7118},{level:4,title:"4.1.2 什么是Secret",slug:"_4-1-2-什么是secret",normalizedTitle:"4.1.2 什么是secret",charIndex:8035},{level:3,title:"4.2 如何使用",slug:"_4-2-如何使用",normalizedTitle:"4.2 如何使用",charIndex:9341},{level:4,title:"4.2.1 以环境变量的方式使用",slug:"_4-2-1-以环境变量的方式使用",normalizedTitle:"4.2.1 以环境变量的方式使用",charIndex:9353},{level:4,title:"4.2.2 以Volume的方式使用",slug:"_4-2-2-以volume的方式使用",normalizedTitle:"4.2.2 以volume的方式使用",charIndex:11096},{level:3,title:"4.3 小结",slug:"_4-3-小结",normalizedTitle:"4.3 小结",charIndex:12819}],headersStr:"1. YAML：Kubernetes世界里的通用语 1.1 声明式与命令式是怎么回事 1.2 什么是 YAML 1.3 什么是 API 对象 1.4 如何描述API对象 1.5 如何编写 YAML 1.6 课外小贴士 2. Pod：如何理解这个Kubernetes里最核心的概念？ 2.1 为什么要有 Pod 3. Job/CronJob：为什么不直接用Pod来处理业务？ 3.1 为什么不直接使用Pod 小结 4. ConfigMap/Secret：怎样配置、定制我的应用 4.1 ConfigMap/Secret 4.1.1 什么是ConfigMap 4.1.2 什么是Secret 4.2 如何使用 4.2.1 以环境变量的方式使用 4.2.2 以Volume的方式使用 4.3 小结",content:'# 1. YAML：Kubernetes世界里的通用语\n\nKubernetes世界里的标准工作语言是 YAML。\n\n\n# 1.1 声明式与命令式是怎么回事\n\n> YAML 是“声明式”。\n\nDocker命令和Dockerfile就属于“命令式”，大多数编程语言也属于命令式，它的特点是交互性强，注重顺序和过程，你必须“告诉”计算机每步该做什么，所有的步骤都列清楚，这样程序才能够一步步走下去，最后完成任务，显得计算机有点“笨”。\n\n“声明式”，在Kubernetes出现之前比较少见，它与“命令式”完全相反，不关心具体的过程，更注重结果。我们不需要“教”计算机该怎么做，只要告诉它一个目标状态，它自己就会想办法去完成任务，相比起来自动化、智能化程度更高。\n\n以“打车”来形象地解释一下“命令式”和“声明式”的区别。\n\n * 假设你要打车去高铁站，但司机不熟悉路况，你就只好不厌其烦地告诉他该走哪条路、在哪个路口转向、在哪里进出主路、停哪个站口。虽然最后到达了目的地，但这一路上也费了很多口舌，发出了无数的“命令”。很显然，这段路程就属于“命令式”。\n * 同样是去高铁站，但司机经验丰富，他知道哪里有拥堵、哪条路的红绿灯多、哪段路有临时管控、哪里可以抄小道，此时你再多嘴无疑会干扰他的正常驾驶，所以，你只要给他一个“声明”：我要去高铁站，接下来就可以舒舒服服地躺在后座上休息，顺利到达目的地了\n\n在这个“打车”的例子里，Kubernetes就是这样的一位熟练的司机，Master/Node架构让它对整个集群的状态了如指掌，内部的众多组件和插件也能够自动监控管理应用。我们最好是做一个“ 甩手掌柜”，用“声明式”把任务的目标告诉它，比如使用哪个镜像、什么时候运行，让它自己去处理执行过程中的细节。\n\n那么，YAML 语言就是给 Kubernetes 发出一个“声明”的方式。\n\n> 容器技术里的Shell脚本和Dockerfile可以很好地描述“命令式”，但对于“声明式”就不太合适了\n\n\n# 1.2 什么是 YAML\n\n> YAML v.s. XML:\n> \n>  * XML 是一种类似 HTML 的标签式语言，有很多繁文缛节。\n>  * YAML 实质上与XML完全不同，更适合人类阅读，计算机解析起来也很容易\n\n把YAML的数组、对象组合起来，我们就可以描述出任意的Kubernetes资源对象。\n\n\n# 1.3 什么是 API 对象\n\nYAML语言只相当于“语法”，要与Kubernetes对话，我们还必须有足够的“词汇”来表示“语义”。作为一个集群操作系统，Kubernetes归纳总结了Google多年的经验，在理论层面抽象出了很多个概念，用来描述系统的管理运维工作，这些概念就叫做“ API对象”。\n\n说到这个名字，你也许会联想到上次课里讲到的Kubernetes组件 apiserver。没错，它正是来源于此。因为apiserver是Kubernetes系统的唯一入口，外部用户和内部组件都必须和它通信，而它采用了HTTP协议的URL资源理念，API风格也用RESTful的GET/POST/DELETE等等，所以，这些概念很自然地就被称为是“API对象”了。\n\n那都有哪些API对象呢？\n\n使用 kubectl api-resources 来查看当前Kubernetes版本支持的所有对象：\n\nkubectl api-resources\n\n\n1\n\n\n在输出的“NAME”一栏，就是对象的名字，比如ConfigMap、Pod、Service等等，第二栏“SHORTNAMES”则是这种资源的简写，在我们使用kubectl命令的时候很有用，可以少敲几次键盘，比如Pod可以简写成po，Service可以简写成svc。\n\n在使用kubectl命令的时候，你还可以加上一个参数 --v=9，它会显示出详细的命令执行过程，清楚地看到发出的HTTP请求，比如：\n\nkubectl get pod --v=9\n\n\n1\n\n\n从截图里可以看到，kubectl客户端等价于调用了curl，向8443端口发送了HTTP GET 请求，URL是 /api/v1/namespaces/default/pods。\n\n目前的Kubernetes 1.23版本有50多种API对象，全面地描述了集群的节点、应用、配置、服务、账号等等信息，apiserver会把它们都存储在数据库etcd里，然后kubelet、scheduler、controller-manager等组件通过apiserver来操作它们，就在API对象这个抽象层次实现了对整个集群的管理。\n\n\n# 1.4 如何描述API对象\n\n> Kubernetes把集群里的一切资源都定义为API对象，通过RESTful接口来管理。描述API对象需要使用YAML语言，必须的字段是 apiVersion、kind、metadata。\n\n之前我们使用 kubectl 运行 nginx 的命令用的是命令式的 kubectl run：\n\nkubectl run ngx --image=nginx:alpine\n\n\n1\n\n\n下面看一下如何以 YAML 语言来声明式地在 k8s 中描述并创建 API 对象。在 YAML 中，我们需要说清楚我们的目标状态，让 Kubernetes 自己去决定如何拉取镜像并运行：\n\napiVersion: v1\nkind: Pod\nmetadata:\n  name: ngx-pod\n  labels:\n    env: demo\n    owner: nrich\n\nspec:\n  containers:\n  - image: nginx:alpine\n    name: ngx\n    ports:\n    - containerPort: 80\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n可以看出，这里是创建一个 pod，要使用 nginx:alpine 的 image 来创建一个 container，并开放 80 端口，而其他部分就是 k8s 对 API 对象强制的格式要求了。\n\n因为API对象采用标准的 HTTP 协议，为了方便理解，我们可以借鉴一下 HTTP 的报文格式，把 API 对象的描述分成“header”和“body”两部分。\n\nheader 包含的是 API 对象的基本信息，有三个字段：\n\n * apiVersion：表示操作这种资源的 API 版本号，由于 Kubernetes 的迭代速度很快，不同的版本创建的对象会有差异，为了区分这些版本就需要使用 apiVersion 这个字段，比如 v1、v1alpha1、v1beta1 等等。\n * kind：表示资源对象的类型，比如 Pod、Node、Job、Service 等。\n * metadata：表示的是资源的一些元信息，也就是用来标记对象，方便 Kubernetes 管理的一些信息。在上面的示例中有两个元信息：\n   * name：给 pod 起了个名字\n   * labels：给 pod 贴上一些便于查找的标签，分别是 env 和 owner。\n\n以上信息都被 kubectl 用于生成 HTTP 请求发给 apiserver，你可以用 --v=9 参数在请求的 URL 里看到它们，比如：\n\nhttps://192.168.49.2:8443/api/v1/namespaces/default/pods/ngx-pod\n\n\n1\n\n\nheader 中的 apiVersion、kind、metadata 这三个字段都是任何对象都必须有的，而 body 部分则会与对象特定相关，每种对象会有不同的规格定义，在 YAML 里就表现为 spec 字段（即 specification），表示我们对对象的“期望状态”（desired status）。\n\n还是来看这个 Pod，它的 spec 里就是一个 containers 数组，里面的每个元素又是一个对象，指定了名字、镜像、端口等信息：\n\nspec:\n  containers:\n  - image: nginx:alpine\n    name: ngx\n    ports:\n    - containerPort: 80\n\n\n1\n2\n3\n4\n5\n6\n\n\n现在把这些字段综合起来，我们就能够看出，这份 YAML 文档完整地描述了一个类型是 Pod 的 API 对象，要求使用 v1 版本的 API 接口去管理，其他更具体的名称、标签、状态等细节都记录在了 metadata 和 spec 字段等里。\n\n使用 kubectl apply、 kubectl delete，再加上参数 -f，你就可以使用这个 YAML 文件，创建或者删除对象了：\n\nkubectl apply -f ngx-pod.yml    # 创建 API 对象\nkubectl delete -f ngx-pod.yml   # 删除 API 对象\n\n\n1\n2\n\n\nKubernetes 收到这份“声明式”的数据，再根据 HTTP 请求里的 POST/DELETE 等方法，就会自动操作这个资源对象，至于对象在哪个节点上、怎么创建、怎么删除完全不用我们操心。\n\n\n# 1.5 如何编写 YAML\n\n这么多字段，我们怎样才能编写正确的 YAML 呢？\n\n这个问题的最权威的答案自然是 k8s 的官方文档，API 对象的所有字段都可以在里面找到。但这内容太多，下面介绍一些实用的小技巧。\n\n第一个技巧其实前面已经说过了，就是 kubectl api-resources 命令，它会显示出资源对象相应的API版本和类型，比如Pod的版本是“v1”，Ingress的版本是“networking.k8s.io/v1”，照着它写绝对不会错。\n\n第二个技巧，是命令 kubectl explain，它相当于是Kubernetes自带的API文档，会给出对象字段的详细说明，这样我们就不必去网上查找了。比如想要看Pod里的字段该怎么写，就可以这样：\n\nkubectl explain pod\nkubectl explain pod.metadata\nkubectl explain pod.spec\nkubectl explain pod.spec.containers\n\n\n1\n2\n3\n4\n\n\n使用前两个技巧编写 YAML 就基本上没有难度了。\n\n⭐️ 第三个技巧就是kubectl的两个特殊参数 --dry-run=client 和 -o yaml，前者是空运行，后者是生成YAML格式，结合起来使用就会让 kubectl 不会有实际的创建动作，而只生成 YAML 文件。例如，想要生成一个Pod的YAML样板示例，可以在 kubectl run 后面加上这两个参数：\n\nkubectl run ngx --image=nginx:alpine --dry-run=client -o yaml\n\n\n1\n\n\n就会生成一个绝对正确的 YAML 文件：\n\napiVersion: v1\nkind: Pod\nmetadata:\n  creationTimestamp: null\n  labels:\n    run: ngx\n  name: ngx\nspec:\n  containers:\n  - image: nginx:alpine\n    name: ngx\n    resources: {}\n  dnsPolicy: ClusterFirst\n  restartPolicy: Always\nstatus: {}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n接下来你要做的，就是查阅对象的说明文档，添加或者删除字段来定制这个 YAML 了。\n\n这个小技巧还可以再进化一下，把这段参数定义成Shell变量（名字任意，比如$do/$go，这里用的是 $out），用起来会更省事，比如：\n\nexport out="--dry-run=client -o yaml"\nkubectl run ngx --image=nginx:alpine $out\n\n\n1\n2\n\n\n今后除了一些特殊情况，我们都不会再使用 kubectl run 这样的命令去直接创建 Pod，而是会编写 YAML，用“声明式”来描述对象，再用 kubectl apply 去发布 YAML 来创建对象。\n\n\n# 1.6 课外小贴士\n\n * .推荐一个知名的 JSON/YAML 工具网站: BEJSON，支持 JSON 格式校验也可以转换 YAML。\n * Kubernetes 的 API 版本命名有明确规范，正式版本(GA，Generally available) 是 v1 这样的纯数字，试验性质、不稳定的是 alpha,比较稳定、即将发布的是 beta。\n * 因为 Kubernetes 的开发语言是 Go，所以 API 对象字段用的都是 Go 语法规范，例如字段命名遵循“Camel Case”，类型是 boolean、string、[]Object 等。\n\n\n# 2. Pod：如何理解这个Kubernetes里最核心的概念？\n\n\n# 2.1 为什么要有 Pod\n\nPod这个词原意是“豌豆荚”，后来又延伸出“舱室”“太空舱”等含义，形象地来说Pod就是包含了很多组件、成员的一种结构。\n\n为了解决多应用联合运行的问题，同时还要不破坏容器的隔离，就需要在容器外面再建立一个“收纳舱”，让多个容器既保持相对独立，又能够小范围共享网络、存储等资源，而且永远是“绑在一起”的状态。\n\n所以，出现了Pod的概念，容器正是“豆荚”里那些小小的“豌豆”，你可以在Pod的YAML里看到，“spec.containers”字段其实是一个数组，里面允许定义多个容器。Pod 能让进程住得更舒服。\n\nTODO: 待补充\n\n\n# 3. Job/CronJob：为什么不直接用Pod来处理业务？\n\nKubernetes的核心对象Pod，用来编排一个或多个容器，让这些容器共享网络、存储等资源，总是共同调度，从而紧密协同工作。Pod比容器更能够表示实际的应用，所以Kubernetes不会在容器层面来编排业务，而是把Pod作为在集群里调度运维的最小单位。\n\n前面我们也看到了一张Kubernetes的资源对象关系图，以Pod为中心，延伸出了很多表示各种业务的其他资源对象。那么你会不会有这样的疑问：Pod的功能已经足够完善了，为什么还要定义这些额外的对象呢？为什么不直接在Pod里添加功能，来处理业务需求呢？\n\n这个问题体现了Google对大规模计算集群管理的深度思考，今天我就说说Kubernetes基于Pod的设计理念，先从最简单的两种对象——Job和CronJob讲起。\n\n\n# 3.1 为什么不直接使用Pod\n\n\n# 小结\n\n好了，今天我们以面向对象思想分析了一下Kubernetes里的资源对象设计，它强调“职责单一”和“对象组合”，简单来说就是“对象套对象”。\n\n通过这种嵌套方式，Kubernetes里的这些API对象就形成了一个“控制链”：\n\nCronJob使用定时规则控制Job，Job使用并发数量控制Pod，Pod再定义参数控制容器，容器再隔离控制进程，进程最终实现业务功能，层层递进的形式有点像设计模式里的Decorator（装饰模式），链条里的每个环节都各司其职，在Kubernetes的统一指挥下完成任务。\n\n小结一下今天的内容：\n\n 1. Pod是Kubernetes的最小调度单元，但为了保持它的独立性，不应该向它添加多余的功能。\n 2. Kubernetes为离线业务提供了Job和CronJob两种API对象，分别处理“临时任务”和“定时任务”。\n 3. Job的关键字段是 spec.template，里面定义了用来运行业务的Pod模板，其他的重要字段有 completions、 parallelism 等\n 4. CronJob的关键字段是 spec.jobTemplate 和 spec.schedule，分别定义了Job模板和定时运行的规则。\n\n\n# 4. ConfigMap/Secret：怎样配置、定制我的应用\n\n本节要解决的问题：使用 YAML 语言来定义 API 对象，再组合起来实现动态配置。\n\n下面讲解Kubernetes里专门用来管理配置信息的两种对象： ConfigMap 和 Secret，使用它们来灵活地配置、定制我们的应用。\n\n\n# 4.1 ConfigMap/Secret\n\n首先你要知道，应用程序有很多类别的配置信息，但从数据安全的角度来看可以分成两类：\n\n * 一类是明文配置，也就是不保密，可以任意查询修改，比如服务端口、运行参数、文件路径等等。\n * 另一类则是机密配置，由于涉及敏感信息需要保密，不能随便查看，比如密码、密钥、证书等等。\n\n这两类配置信息本质上都是字符串，只是由于安全性的原因，在存放和使用方面有些差异，所以Kubernetes也就定义了两个API对象， ConfigMap 用来保存明文配置， Secret 用来保存秘密配置。\n\n# 4.1.1 什么是ConfigMap\n\nConfigMap 的简写：“cm”，后面都可以直接用简写代替。用命令 kubectl create 来创建一个它的YAML样板。\n\nexport out="--dry-run=client -o yaml"        # 定义Shell变量\nkubectl create cm info [--from-literal=k=v] $out\n\n\n1\n2\n\n\n参数 --from-literal=k=v 是表示要生成带有“data”字段的YAML样板。注意，因为在ConfigMap里的数据都是Key-Value结构，所以 --from-literal 参数需要使用 k=v 的形式。\n\n得到的样板文件大概是这个样子：\n\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: info\ndata:\n  k: v\n\n\n1\n2\n3\n4\n5\n6\n\n\n把YAML样板文件修改一下，再多增添一些Key-Value，就得到了一个比较完整的ConfigMap对象：\n\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: info\n\ndata:\n  count: \'10\'\n  debug: \'on\'\n  path: \'/etc/systemd\'\n  greeting: |\n    say hello to kubernetes.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n现在就可以使用 kubectl apply 把这个YAML交给Kubernetes，让它创建ConfigMap对象了：\n\nkubectl apply -f cm.yml\n\n\n1\n\n\n创建成功后，我们还是可以用 kubectl get、 kubectl describe 来查看ConfigMap的状态：\n\nkubectl get cm\nkubectl describe cm info\n\n\n1\n2\n\n\n你可以看到，现在ConfigMap的Key-Value信息就已经存入了etcd数据库，后续就可以被其他API对象使用。\n\n# 4.1.2 什么是Secret\n\nSecret 和ConfigMap的结构和用法很类似，不过在Kubernetes里Secret对象又细分出很多类，比如：\n\n * 访问私有镜像仓库的认证信息\n * 身份识别的凭证信息\n * HTTPS通信的证书和私钥\n * 一般的机密信息（格式由用户自行解释）\n\n前几种我们现在暂时用不到，所以就只使用最后一种，创建YAML样板的命令是 kubectl create secret generic ，同样，也要使用参数 --from-literal 给出Key-Value值：\n\nkubectl create secret generic user --from-literal=name=root $out\n\n\n1\n\n\n得到的Secret对象大概是这个样子：\n\napiVersion: v1\nkind: Secret\nmetadata:\n  name: user\n\ndata:\n  name: cm9vdA==\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nSecret对象只是“kind”字段由“ConfigMap”变成了“Secret”，后面同样也是“data”字段，里面也是Key-Value的数据。但Secret 不能像ConfigMap那样直接保存明文了，对数据使用了 BASE64 编码（根本算不上真正的加密）。所以 Secret 对象不让用户直接看到原始数据，起到一定的保密作用。\n\n自己用Linux工具对数据进行 base64 编码\n\n我们完全可以绕开kubectl，自己用Linux小工具“base64”来对数据编码，然后写入YAML文件，比如：\n\necho -n "123456" | base64\nMTIzNDU2\n\n\n1\n2\n\n\n要注意这条命令里的 echo ，必须要加参数 -n 去掉字符串里隐含的换行符，否则Base64编码出来的字符串就是错误的。\n\n我们再来重新编辑Secret的YAML，为它添加两个新的数据，方式可以是参数 --from-literal 自动编码，也可以是自己手动编码：\n\napiVersion: v1\nkind: Secret\nmetadata:\n  name: user\n\ndata:\n  name: cm9vdA==  # root\n  pwd: MTIzNDU2   # 123456\n  db: bXlzcWw=    # mysql\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n接下来的创建和查看对象操作和ConfigMap是一样的，使用 kubectl apply、 kubectl get、 kubectl describe：\n\nkubectl apply  -f secret.yml\nkubectl get secret\nkubectl describe secret user\n\n\n\n1\n2\n3\n4\n\n\n这样一个存储敏感信息的Secret对象也就创建好了，而且因为它是保密的，使用 kubectl describe 不能直接看到内容，只能看到数据的大小，你可以和ConfigMap对比一下。\n\n\n# 4.2 如何使用\n\n# 4.2.1 以环境变量的方式使用\n\n下面我就把引用了ConfigMap和Secret对象的Pod列出来，给你做个示范，为了提醒你注意，我把“ env”字段提到了前面：\n\napiVersion: v1\nkind: Pod\nmetadata:\n  name: env-pod\n\nspec:\n  containers:\n  - env:\n      - name: COUNT\n        valueFrom:\n          configMapKeyRef:\n            name: info\n            key: count\n      - name: GREETING\n        valueFrom:\n          configMapKeyRef:\n            name: info\n            key: greeting\n      - name: USERNAME\n        valueFrom:\n          secretKeyRef:\n            name: user\n            key: name\n      - name: PASSWORD\n        valueFrom:\n          secretKeyRef:\n            name: user\n            key: pwd\n\n    image: busybox\n    name: busy\n    imagePullPolicy: IfNotPresent\n    command: ["/bin/sleep", "300"]\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n\n\n这个Pod的名字是“env-pod”，镜像是“busybox”，执行命令sleep睡眠300秒，我们可以在这段时间里使用命令 kubectl exec 进入Pod观察环境变量。\n\n你需要重点关注的是它的“env”字段，里面定义了4个环境变量， COUNT、 GREETING、 USERNAME、 PASSWORD。\n\n对于明文配置数据， COUNT、 GREETING 引用的是ConfigMap对象，所以使用字段“ configMapKeyRef”，里面的“name”是ConfigMap对象的名字，也就是之前我们创建的“info”，而“key”字段分别是“info”对象里的 count 和 greeting。\n\n同样的对于机密配置数据， USERNAME、 PASSWORD 引用的是Secret对象，要使用字段“ secretKeyRef”，再用“name”指定Secret对象的名字 user，用“key”字段应用它里面的 name 和 pwd 。\n\nConfigMap和Secret在Pod里的组合关系如图所示：\n\n从这张图你就应该能够比较清楚地看出Pod与ConfigMap、Secret的“松耦合”关系，它们不是直接嵌套包含，而是使用“KeyRef”字段间接引用对象，这样，同一段配置信息就可以在不同的对象之间共享。\n\n弄清楚了环境变量的注入方式之后，让我们用 kubectl apply 创建Pod，再用 kubectl exec 进入Pod，验证环境变量是否生效：\n\nkubectl apply -f env-pod.yml\nkubectl exec -it env-pod -- sh\n\necho $COUNT\necho $GREETING\necho $USERNAME $PASSWORD\n\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n这张截图就显示了Pod的运行结果，可以看到在Pod里使用 echo 命令确实输出了我们在两个YAML里定义的配置信息，也就证明Pod对象成功组合了ConfigMap和Secret对象。\n\n以环境变量的方式使用ConfigMap/Secret还是比较简单的，下面来看第二种加载文件的方式。\n\n# 4.2.2 以Volume的方式使用\n\nKubernetes为Pod定义了一个“ Volume”的概念，可以翻译成是“存储卷”。如果把Pod理解成是一个虚拟机，那么Volume就相当于是虚拟机里的磁盘。\n\n我们可以为Pod“挂载（mount）”多个Volume，里面存放供Pod访问的数据，这种方式有点类似 docker run -v，虽然用法复杂了一些，但功能也相应强大一些。\n\n在Pod里挂载Volume很容易，只需要在“ spec”里增加一个“ volumes”字段，然后再定义卷的名字和引用的ConfigMap/Secret就可以了。要注意的是Volume属于Pod，不属于容器，所以它和字段“containers”是同级的，都属于“spec”。\n\n下面我们先定义两个Volume，分别引用ConfigMap和Secret，名字是 cm-vol 和 sec-vol。有了Volume的定义之后，就可以在容器里挂载了，这要用到“ volumeMounts”字段，正如它的字面含义，可以把定义好的Volume挂载到容器里的某个路径下，所以需要在里面用“ mountPath”“ name”明确地指定挂载路径和Volume的名字。\n\n把“ volumes”和“ volumeMounts”字段都写好之后，配置信息就可以加载成文件了。下图表示他们之间的引用关系：\n\n你可以看到，挂载Volume的方式和环境变量又不太相同。环境变量是直接引用了ConfigMap/Secret，而Volume又多加了一个环节，需要先用Volume引用ConfigMap/Secret，然后在容器里挂载Volume，有点“兜圈子”“弯弯绕”。\n\n这种方式的好处在于：以Volume的概念统一抽象了所有的存储，不仅现在支持ConfigMap/Secret，以后还能够支持临时卷、持久卷、动态卷、快照卷等许多形式的存储，扩展性非常好。\n\n现在我把Pod的完整YAML描述列出来，然后使用 kubectl apply 创建它：\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\napiVersion: v1\nkind: Pod\nmetadata:\n  name: vol-pod11\n\nspec:\n  volumes:\n  - name: cm-vol\n    configMap:\n      name: info\n  - name: sec-vol\n    secret:\n      secretName: user1\n\n  containers:\n  - volumeMounts:\n    - mountPath: /tmp/cm-items\n      name: cm-vol\n    - mountPath: /tmp/sec-items\n      name: sec-vol\n\n    image: busybox:latest\n    name: busy11\n    imagePullPolicy: IfNotPresent\n    command: ["/bin/sleep", "300"]\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n创建之后，我们还是用 kubectl exec 进入Pod，看看配置信息被加载成了什么形式：\n\nkubectl apply -f vol-pod.yml\nkubectl get pod\nkubectl exec -it vol-pod -- sh\n\n\n1\n2\n3\n\n\n你会看到，ConfigMap和Secret都变成了目录的形式，而它们里面的Key-Value变成了一个个的文件，而文件名就是Key。(Key => 文件名，Value => 文件内容)\n\n因为这种形式上的差异，以Volume的方式来使用ConfigMap/Secret，就和环境变量不太一样。环境变量用法简单，更适合存放简短的字符串，而Volume更适合存放大数据量的配置文件，在Pod里加载成文件后让应用直接读取使用。\n\n\n# 4.3 小结\n\n以上学习了两种在Kubernetes里管理配置信息的API对象ConfigMap和Secret，它们分别代表了明文信息和机密敏感信息，存储在etcd里，在需要的时候可以注入Pod供Pod使用。',normalizedContent:'# 1. yaml：kubernetes世界里的通用语\n\nkubernetes世界里的标准工作语言是 yaml。\n\n\n# 1.1 声明式与命令式是怎么回事\n\n> yaml 是“声明式”。\n\ndocker命令和dockerfile就属于“命令式”，大多数编程语言也属于命令式，它的特点是交互性强，注重顺序和过程，你必须“告诉”计算机每步该做什么，所有的步骤都列清楚，这样程序才能够一步步走下去，最后完成任务，显得计算机有点“笨”。\n\n“声明式”，在kubernetes出现之前比较少见，它与“命令式”完全相反，不关心具体的过程，更注重结果。我们不需要“教”计算机该怎么做，只要告诉它一个目标状态，它自己就会想办法去完成任务，相比起来自动化、智能化程度更高。\n\n以“打车”来形象地解释一下“命令式”和“声明式”的区别。\n\n * 假设你要打车去高铁站，但司机不熟悉路况，你就只好不厌其烦地告诉他该走哪条路、在哪个路口转向、在哪里进出主路、停哪个站口。虽然最后到达了目的地，但这一路上也费了很多口舌，发出了无数的“命令”。很显然，这段路程就属于“命令式”。\n * 同样是去高铁站，但司机经验丰富，他知道哪里有拥堵、哪条路的红绿灯多、哪段路有临时管控、哪里可以抄小道，此时你再多嘴无疑会干扰他的正常驾驶，所以，你只要给他一个“声明”：我要去高铁站，接下来就可以舒舒服服地躺在后座上休息，顺利到达目的地了\n\n在这个“打车”的例子里，kubernetes就是这样的一位熟练的司机，master/node架构让它对整个集群的状态了如指掌，内部的众多组件和插件也能够自动监控管理应用。我们最好是做一个“ 甩手掌柜”，用“声明式”把任务的目标告诉它，比如使用哪个镜像、什么时候运行，让它自己去处理执行过程中的细节。\n\n那么，yaml 语言就是给 kubernetes 发出一个“声明”的方式。\n\n> 容器技术里的shell脚本和dockerfile可以很好地描述“命令式”，但对于“声明式”就不太合适了\n\n\n# 1.2 什么是 yaml\n\n> yaml v.s. xml:\n> \n>  * xml 是一种类似 html 的标签式语言，有很多繁文缛节。\n>  * yaml 实质上与xml完全不同，更适合人类阅读，计算机解析起来也很容易\n\n把yaml的数组、对象组合起来，我们就可以描述出任意的kubernetes资源对象。\n\n\n# 1.3 什么是 api 对象\n\nyaml语言只相当于“语法”，要与kubernetes对话，我们还必须有足够的“词汇”来表示“语义”。作为一个集群操作系统，kubernetes归纳总结了google多年的经验，在理论层面抽象出了很多个概念，用来描述系统的管理运维工作，这些概念就叫做“ api对象”。\n\n说到这个名字，你也许会联想到上次课里讲到的kubernetes组件 apiserver。没错，它正是来源于此。因为apiserver是kubernetes系统的唯一入口，外部用户和内部组件都必须和它通信，而它采用了http协议的url资源理念，api风格也用restful的get/post/delete等等，所以，这些概念很自然地就被称为是“api对象”了。\n\n那都有哪些api对象呢？\n\n使用 kubectl api-resources 来查看当前kubernetes版本支持的所有对象：\n\nkubectl api-resources\n\n\n1\n\n\n在输出的“name”一栏，就是对象的名字，比如configmap、pod、service等等，第二栏“shortnames”则是这种资源的简写，在我们使用kubectl命令的时候很有用，可以少敲几次键盘，比如pod可以简写成po，service可以简写成svc。\n\n在使用kubectl命令的时候，你还可以加上一个参数 --v=9，它会显示出详细的命令执行过程，清楚地看到发出的http请求，比如：\n\nkubectl get pod --v=9\n\n\n1\n\n\n从截图里可以看到，kubectl客户端等价于调用了curl，向8443端口发送了http get 请求，url是 /api/v1/namespaces/default/pods。\n\n目前的kubernetes 1.23版本有50多种api对象，全面地描述了集群的节点、应用、配置、服务、账号等等信息，apiserver会把它们都存储在数据库etcd里，然后kubelet、scheduler、controller-manager等组件通过apiserver来操作它们，就在api对象这个抽象层次实现了对整个集群的管理。\n\n\n# 1.4 如何描述api对象\n\n> kubernetes把集群里的一切资源都定义为api对象，通过restful接口来管理。描述api对象需要使用yaml语言，必须的字段是 apiversion、kind、metadata。\n\n之前我们使用 kubectl 运行 nginx 的命令用的是命令式的 kubectl run：\n\nkubectl run ngx --image=nginx:alpine\n\n\n1\n\n\n下面看一下如何以 yaml 语言来声明式地在 k8s 中描述并创建 api 对象。在 yaml 中，我们需要说清楚我们的目标状态，让 kubernetes 自己去决定如何拉取镜像并运行：\n\napiversion: v1\nkind: pod\nmetadata:\n  name: ngx-pod\n  labels:\n    env: demo\n    owner: nrich\n\nspec:\n  containers:\n  - image: nginx:alpine\n    name: ngx\n    ports:\n    - containerport: 80\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n可以看出，这里是创建一个 pod，要使用 nginx:alpine 的 image 来创建一个 container，并开放 80 端口，而其他部分就是 k8s 对 api 对象强制的格式要求了。\n\n因为api对象采用标准的 http 协议，为了方便理解，我们可以借鉴一下 http 的报文格式，把 api 对象的描述分成“header”和“body”两部分。\n\nheader 包含的是 api 对象的基本信息，有三个字段：\n\n * apiversion：表示操作这种资源的 api 版本号，由于 kubernetes 的迭代速度很快，不同的版本创建的对象会有差异，为了区分这些版本就需要使用 apiversion 这个字段，比如 v1、v1alpha1、v1beta1 等等。\n * kind：表示资源对象的类型，比如 pod、node、job、service 等。\n * metadata：表示的是资源的一些元信息，也就是用来标记对象，方便 kubernetes 管理的一些信息。在上面的示例中有两个元信息：\n   * name：给 pod 起了个名字\n   * labels：给 pod 贴上一些便于查找的标签，分别是 env 和 owner。\n\n以上信息都被 kubectl 用于生成 http 请求发给 apiserver，你可以用 --v=9 参数在请求的 url 里看到它们，比如：\n\nhttps://192.168.49.2:8443/api/v1/namespaces/default/pods/ngx-pod\n\n\n1\n\n\nheader 中的 apiversion、kind、metadata 这三个字段都是任何对象都必须有的，而 body 部分则会与对象特定相关，每种对象会有不同的规格定义，在 yaml 里就表现为 spec 字段（即 specification），表示我们对对象的“期望状态”（desired status）。\n\n还是来看这个 pod，它的 spec 里就是一个 containers 数组，里面的每个元素又是一个对象，指定了名字、镜像、端口等信息：\n\nspec:\n  containers:\n  - image: nginx:alpine\n    name: ngx\n    ports:\n    - containerport: 80\n\n\n1\n2\n3\n4\n5\n6\n\n\n现在把这些字段综合起来，我们就能够看出，这份 yaml 文档完整地描述了一个类型是 pod 的 api 对象，要求使用 v1 版本的 api 接口去管理，其他更具体的名称、标签、状态等细节都记录在了 metadata 和 spec 字段等里。\n\n使用 kubectl apply、 kubectl delete，再加上参数 -f，你就可以使用这个 yaml 文件，创建或者删除对象了：\n\nkubectl apply -f ngx-pod.yml    # 创建 api 对象\nkubectl delete -f ngx-pod.yml   # 删除 api 对象\n\n\n1\n2\n\n\nkubernetes 收到这份“声明式”的数据，再根据 http 请求里的 post/delete 等方法，就会自动操作这个资源对象，至于对象在哪个节点上、怎么创建、怎么删除完全不用我们操心。\n\n\n# 1.5 如何编写 yaml\n\n这么多字段，我们怎样才能编写正确的 yaml 呢？\n\n这个问题的最权威的答案自然是 k8s 的官方文档，api 对象的所有字段都可以在里面找到。但这内容太多，下面介绍一些实用的小技巧。\n\n第一个技巧其实前面已经说过了，就是 kubectl api-resources 命令，它会显示出资源对象相应的api版本和类型，比如pod的版本是“v1”，ingress的版本是“networking.k8s.io/v1”，照着它写绝对不会错。\n\n第二个技巧，是命令 kubectl explain，它相当于是kubernetes自带的api文档，会给出对象字段的详细说明，这样我们就不必去网上查找了。比如想要看pod里的字段该怎么写，就可以这样：\n\nkubectl explain pod\nkubectl explain pod.metadata\nkubectl explain pod.spec\nkubectl explain pod.spec.containers\n\n\n1\n2\n3\n4\n\n\n使用前两个技巧编写 yaml 就基本上没有难度了。\n\n⭐️ 第三个技巧就是kubectl的两个特殊参数 --dry-run=client 和 -o yaml，前者是空运行，后者是生成yaml格式，结合起来使用就会让 kubectl 不会有实际的创建动作，而只生成 yaml 文件。例如，想要生成一个pod的yaml样板示例，可以在 kubectl run 后面加上这两个参数：\n\nkubectl run ngx --image=nginx:alpine --dry-run=client -o yaml\n\n\n1\n\n\n就会生成一个绝对正确的 yaml 文件：\n\napiversion: v1\nkind: pod\nmetadata:\n  creationtimestamp: null\n  labels:\n    run: ngx\n  name: ngx\nspec:\n  containers:\n  - image: nginx:alpine\n    name: ngx\n    resources: {}\n  dnspolicy: clusterfirst\n  restartpolicy: always\nstatus: {}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n接下来你要做的，就是查阅对象的说明文档，添加或者删除字段来定制这个 yaml 了。\n\n这个小技巧还可以再进化一下，把这段参数定义成shell变量（名字任意，比如$do/$go，这里用的是 $out），用起来会更省事，比如：\n\nexport out="--dry-run=client -o yaml"\nkubectl run ngx --image=nginx:alpine $out\n\n\n1\n2\n\n\n今后除了一些特殊情况，我们都不会再使用 kubectl run 这样的命令去直接创建 pod，而是会编写 yaml，用“声明式”来描述对象，再用 kubectl apply 去发布 yaml 来创建对象。\n\n\n# 1.6 课外小贴士\n\n * .推荐一个知名的 json/yaml 工具网站: bejson，支持 json 格式校验也可以转换 yaml。\n * kubernetes 的 api 版本命名有明确规范，正式版本(ga，generally available) 是 v1 这样的纯数字，试验性质、不稳定的是 alpha,比较稳定、即将发布的是 beta。\n * 因为 kubernetes 的开发语言是 go，所以 api 对象字段用的都是 go 语法规范，例如字段命名遵循“camel case”，类型是 boolean、string、[]object 等。\n\n\n# 2. pod：如何理解这个kubernetes里最核心的概念？\n\n\n# 2.1 为什么要有 pod\n\npod这个词原意是“豌豆荚”，后来又延伸出“舱室”“太空舱”等含义，形象地来说pod就是包含了很多组件、成员的一种结构。\n\n为了解决多应用联合运行的问题，同时还要不破坏容器的隔离，就需要在容器外面再建立一个“收纳舱”，让多个容器既保持相对独立，又能够小范围共享网络、存储等资源，而且永远是“绑在一起”的状态。\n\n所以，出现了pod的概念，容器正是“豆荚”里那些小小的“豌豆”，你可以在pod的yaml里看到，“spec.containers”字段其实是一个数组，里面允许定义多个容器。pod 能让进程住得更舒服。\n\ntodo: 待补充\n\n\n# 3. job/cronjob：为什么不直接用pod来处理业务？\n\nkubernetes的核心对象pod，用来编排一个或多个容器，让这些容器共享网络、存储等资源，总是共同调度，从而紧密协同工作。pod比容器更能够表示实际的应用，所以kubernetes不会在容器层面来编排业务，而是把pod作为在集群里调度运维的最小单位。\n\n前面我们也看到了一张kubernetes的资源对象关系图，以pod为中心，延伸出了很多表示各种业务的其他资源对象。那么你会不会有这样的疑问：pod的功能已经足够完善了，为什么还要定义这些额外的对象呢？为什么不直接在pod里添加功能，来处理业务需求呢？\n\n这个问题体现了google对大规模计算集群管理的深度思考，今天我就说说kubernetes基于pod的设计理念，先从最简单的两种对象——job和cronjob讲起。\n\n\n# 3.1 为什么不直接使用pod\n\n\n# 小结\n\n好了，今天我们以面向对象思想分析了一下kubernetes里的资源对象设计，它强调“职责单一”和“对象组合”，简单来说就是“对象套对象”。\n\n通过这种嵌套方式，kubernetes里的这些api对象就形成了一个“控制链”：\n\ncronjob使用定时规则控制job，job使用并发数量控制pod，pod再定义参数控制容器，容器再隔离控制进程，进程最终实现业务功能，层层递进的形式有点像设计模式里的decorator（装饰模式），链条里的每个环节都各司其职，在kubernetes的统一指挥下完成任务。\n\n小结一下今天的内容：\n\n 1. pod是kubernetes的最小调度单元，但为了保持它的独立性，不应该向它添加多余的功能。\n 2. kubernetes为离线业务提供了job和cronjob两种api对象，分别处理“临时任务”和“定时任务”。\n 3. job的关键字段是 spec.template，里面定义了用来运行业务的pod模板，其他的重要字段有 completions、 parallelism 等\n 4. cronjob的关键字段是 spec.jobtemplate 和 spec.schedule，分别定义了job模板和定时运行的规则。\n\n\n# 4. configmap/secret：怎样配置、定制我的应用\n\n本节要解决的问题：使用 yaml 语言来定义 api 对象，再组合起来实现动态配置。\n\n下面讲解kubernetes里专门用来管理配置信息的两种对象： configmap 和 secret，使用它们来灵活地配置、定制我们的应用。\n\n\n# 4.1 configmap/secret\n\n首先你要知道，应用程序有很多类别的配置信息，但从数据安全的角度来看可以分成两类：\n\n * 一类是明文配置，也就是不保密，可以任意查询修改，比如服务端口、运行参数、文件路径等等。\n * 另一类则是机密配置，由于涉及敏感信息需要保密，不能随便查看，比如密码、密钥、证书等等。\n\n这两类配置信息本质上都是字符串，只是由于安全性的原因，在存放和使用方面有些差异，所以kubernetes也就定义了两个api对象， configmap 用来保存明文配置， secret 用来保存秘密配置。\n\n# 4.1.1 什么是configmap\n\nconfigmap 的简写：“cm”，后面都可以直接用简写代替。用命令 kubectl create 来创建一个它的yaml样板。\n\nexport out="--dry-run=client -o yaml"        # 定义shell变量\nkubectl create cm info [--from-literal=k=v] $out\n\n\n1\n2\n\n\n参数 --from-literal=k=v 是表示要生成带有“data”字段的yaml样板。注意，因为在configmap里的数据都是key-value结构，所以 --from-literal 参数需要使用 k=v 的形式。\n\n得到的样板文件大概是这个样子：\n\napiversion: v1\nkind: configmap\nmetadata:\n  name: info\ndata:\n  k: v\n\n\n1\n2\n3\n4\n5\n6\n\n\n把yaml样板文件修改一下，再多增添一些key-value，就得到了一个比较完整的configmap对象：\n\napiversion: v1\nkind: configmap\nmetadata:\n  name: info\n\ndata:\n  count: \'10\'\n  debug: \'on\'\n  path: \'/etc/systemd\'\n  greeting: |\n    say hello to kubernetes.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n现在就可以使用 kubectl apply 把这个yaml交给kubernetes，让它创建configmap对象了：\n\nkubectl apply -f cm.yml\n\n\n1\n\n\n创建成功后，我们还是可以用 kubectl get、 kubectl describe 来查看configmap的状态：\n\nkubectl get cm\nkubectl describe cm info\n\n\n1\n2\n\n\n你可以看到，现在configmap的key-value信息就已经存入了etcd数据库，后续就可以被其他api对象使用。\n\n# 4.1.2 什么是secret\n\nsecret 和configmap的结构和用法很类似，不过在kubernetes里secret对象又细分出很多类，比如：\n\n * 访问私有镜像仓库的认证信息\n * 身份识别的凭证信息\n * https通信的证书和私钥\n * 一般的机密信息（格式由用户自行解释）\n\n前几种我们现在暂时用不到，所以就只使用最后一种，创建yaml样板的命令是 kubectl create secret generic ，同样，也要使用参数 --from-literal 给出key-value值：\n\nkubectl create secret generic user --from-literal=name=root $out\n\n\n1\n\n\n得到的secret对象大概是这个样子：\n\napiversion: v1\nkind: secret\nmetadata:\n  name: user\n\ndata:\n  name: cm9vda==\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nsecret对象只是“kind”字段由“configmap”变成了“secret”，后面同样也是“data”字段，里面也是key-value的数据。但secret 不能像configmap那样直接保存明文了，对数据使用了 base64 编码（根本算不上真正的加密）。所以 secret 对象不让用户直接看到原始数据，起到一定的保密作用。\n\n自己用linux工具对数据进行 base64 编码\n\n我们完全可以绕开kubectl，自己用linux小工具“base64”来对数据编码，然后写入yaml文件，比如：\n\necho -n "123456" | base64\nmtizndu2\n\n\n1\n2\n\n\n要注意这条命令里的 echo ，必须要加参数 -n 去掉字符串里隐含的换行符，否则base64编码出来的字符串就是错误的。\n\n我们再来重新编辑secret的yaml，为它添加两个新的数据，方式可以是参数 --from-literal 自动编码，也可以是自己手动编码：\n\napiversion: v1\nkind: secret\nmetadata:\n  name: user\n\ndata:\n  name: cm9vda==  # root\n  pwd: mtizndu2   # 123456\n  db: bxlzcww=    # mysql\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n接下来的创建和查看对象操作和configmap是一样的，使用 kubectl apply、 kubectl get、 kubectl describe：\n\nkubectl apply  -f secret.yml\nkubectl get secret\nkubectl describe secret user\n\n\n\n1\n2\n3\n4\n\n\n这样一个存储敏感信息的secret对象也就创建好了，而且因为它是保密的，使用 kubectl describe 不能直接看到内容，只能看到数据的大小，你可以和configmap对比一下。\n\n\n# 4.2 如何使用\n\n# 4.2.1 以环境变量的方式使用\n\n下面我就把引用了configmap和secret对象的pod列出来，给你做个示范，为了提醒你注意，我把“ env”字段提到了前面：\n\napiversion: v1\nkind: pod\nmetadata:\n  name: env-pod\n\nspec:\n  containers:\n  - env:\n      - name: count\n        valuefrom:\n          configmapkeyref:\n            name: info\n            key: count\n      - name: greeting\n        valuefrom:\n          configmapkeyref:\n            name: info\n            key: greeting\n      - name: username\n        valuefrom:\n          secretkeyref:\n            name: user\n            key: name\n      - name: password\n        valuefrom:\n          secretkeyref:\n            name: user\n            key: pwd\n\n    image: busybox\n    name: busy\n    imagepullpolicy: ifnotpresent\n    command: ["/bin/sleep", "300"]\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n\n\n这个pod的名字是“env-pod”，镜像是“busybox”，执行命令sleep睡眠300秒，我们可以在这段时间里使用命令 kubectl exec 进入pod观察环境变量。\n\n你需要重点关注的是它的“env”字段，里面定义了4个环境变量， count、 greeting、 username、 password。\n\n对于明文配置数据， count、 greeting 引用的是configmap对象，所以使用字段“ configmapkeyref”，里面的“name”是configmap对象的名字，也就是之前我们创建的“info”，而“key”字段分别是“info”对象里的 count 和 greeting。\n\n同样的对于机密配置数据， username、 password 引用的是secret对象，要使用字段“ secretkeyref”，再用“name”指定secret对象的名字 user，用“key”字段应用它里面的 name 和 pwd 。\n\nconfigmap和secret在pod里的组合关系如图所示：\n\n从这张图你就应该能够比较清楚地看出pod与configmap、secret的“松耦合”关系，它们不是直接嵌套包含，而是使用“keyref”字段间接引用对象，这样，同一段配置信息就可以在不同的对象之间共享。\n\n弄清楚了环境变量的注入方式之后，让我们用 kubectl apply 创建pod，再用 kubectl exec 进入pod，验证环境变量是否生效：\n\nkubectl apply -f env-pod.yml\nkubectl exec -it env-pod -- sh\n\necho $count\necho $greeting\necho $username $password\n\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n这张截图就显示了pod的运行结果，可以看到在pod里使用 echo 命令确实输出了我们在两个yaml里定义的配置信息，也就证明pod对象成功组合了configmap和secret对象。\n\n以环境变量的方式使用configmap/secret还是比较简单的，下面来看第二种加载文件的方式。\n\n# 4.2.2 以volume的方式使用\n\nkubernetes为pod定义了一个“ volume”的概念，可以翻译成是“存储卷”。如果把pod理解成是一个虚拟机，那么volume就相当于是虚拟机里的磁盘。\n\n我们可以为pod“挂载（mount）”多个volume，里面存放供pod访问的数据，这种方式有点类似 docker run -v，虽然用法复杂了一些，但功能也相应强大一些。\n\n在pod里挂载volume很容易，只需要在“ spec”里增加一个“ volumes”字段，然后再定义卷的名字和引用的configmap/secret就可以了。要注意的是volume属于pod，不属于容器，所以它和字段“containers”是同级的，都属于“spec”。\n\n下面我们先定义两个volume，分别引用configmap和secret，名字是 cm-vol 和 sec-vol。有了volume的定义之后，就可以在容器里挂载了，这要用到“ volumemounts”字段，正如它的字面含义，可以把定义好的volume挂载到容器里的某个路径下，所以需要在里面用“ mountpath”“ name”明确地指定挂载路径和volume的名字。\n\n把“ volumes”和“ volumemounts”字段都写好之后，配置信息就可以加载成文件了。下图表示他们之间的引用关系：\n\n你可以看到，挂载volume的方式和环境变量又不太相同。环境变量是直接引用了configmap/secret，而volume又多加了一个环节，需要先用volume引用configmap/secret，然后在容器里挂载volume，有点“兜圈子”“弯弯绕”。\n\n这种方式的好处在于：以volume的概念统一抽象了所有的存储，不仅现在支持configmap/secret，以后还能够支持临时卷、持久卷、动态卷、快照卷等许多形式的存储，扩展性非常好。\n\n现在我把pod的完整yaml描述列出来，然后使用 kubectl apply 创建它：\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\napiversion: v1\nkind: pod\nmetadata:\n  name: vol-pod11\n\nspec:\n  volumes:\n  - name: cm-vol\n    configmap:\n      name: info\n  - name: sec-vol\n    secret:\n      secretname: user1\n\n  containers:\n  - volumemounts:\n    - mountpath: /tmp/cm-items\n      name: cm-vol\n    - mountpath: /tmp/sec-items\n      name: sec-vol\n\n    image: busybox:latest\n    name: busy11\n    imagepullpolicy: ifnotpresent\n    command: ["/bin/sleep", "300"]\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n创建之后，我们还是用 kubectl exec 进入pod，看看配置信息被加载成了什么形式：\n\nkubectl apply -f vol-pod.yml\nkubectl get pod\nkubectl exec -it vol-pod -- sh\n\n\n1\n2\n3\n\n\n你会看到，configmap和secret都变成了目录的形式，而它们里面的key-value变成了一个个的文件，而文件名就是key。(key => 文件名，value => 文件内容)\n\n因为这种形式上的差异，以volume的方式来使用configmap/secret，就和环境变量不太一样。环境变量用法简单，更适合存放简短的字符串，而volume更适合存放大数据量的配置文件，在pod里加载成文件后让应用直接读取使用。\n\n\n# 4.3 小结\n\n以上学习了两种在kubernetes里管理配置信息的api对象configmap和secret，它们分别代表了明文信息和机密敏感信息，存储在etcd里，在需要的时候可以注入pod供pod使用。',charsets:{cjk:!0},lastUpdated:"2023/06/10, 02:04:21",lastUpdatedTimestamp:1686362661e3},{title:"Git基础",frontmatter:{title:"Git基础",date:"2022-03-29T08:34:25.000Z",permalink:"/pages/0d79ac/",categories:["开发","Git"],tags:[null]},regularPath:"/%E5%9F%BA%E7%A1%80/5.Git/05.Git%E5%9F%BA%E7%A1%80.html",relativePath:"基础/5.Git/05.Git基础.md",key:"v-31ed6925",path:"/pages/0d79ac/",headers:[{level:3,title:"1. 三种状态",slug:"_1-三种状态",normalizedTitle:"1. 三种状态",charIndex:49},{level:3,title:"2. 获取Git仓库",slug:"_2-获取git仓库",normalizedTitle:"2. 获取git仓库",charIndex:687},{level:4,title:"2.1 在现有目录中初始化仓库",slug:"_2-1-在现有目录中初始化仓库",normalizedTitle:"2.1 在现有目录中初始化仓库",charIndex:775},{level:4,title:"2.2 克隆现有的仓库",slug:"_2-2-克隆现有的仓库",normalizedTitle:"2.2 克隆现有的仓库",charIndex:1155},{level:3,title:"3.记录每次更新到仓库",slug:"_3-记录每次更新到仓库",normalizedTitle:"3.记录每次更新到仓库",charIndex:1500},{level:4,title:"3.1 检查当前文件状态",slug:"_3-1-检查当前文件状态",normalizedTitle:"3.1 检查当前文件状态",charIndex:1790},{level:4,title:"3.2 跟踪新文件",slug:"_3-2-跟踪新文件",normalizedTitle:"3.2 跟踪新文件",charIndex:2131},{level:4,title:"3.3 暂存已修改文件",slug:"_3-3-暂存已修改文件",normalizedTitle:"3.3 暂存已修改文件",charIndex:2206},{level:4,title:"3.4 忽略文件",slug:"_3-4-忽略文件",normalizedTitle:"3.4 忽略文件",charIndex:2486},{level:4,title:"3.5 查看已暂存和未暂存的修改",slug:"_3-5-查看已暂存和未暂存的修改",normalizedTitle:"3.5 查看已暂存和未暂存的修改",charIndex:2645},{level:4,title:"3.6 提交更新",slug:"_3-6-提交更新",normalizedTitle:"3.6 提交更新",charIndex:3062},{level:3,title:"4. 查看提交历史",slug:"_4-查看提交历史",normalizedTitle:"4. 查看提交历史",charIndex:3465},{level:3,title:"5. 撤消操作",slug:"_5-撤消操作",normalizedTitle:"5. 撤消操作",charIndex:3933},{level:4,title:"5.1 取消暂存的文件",slug:"_5-1-取消暂存的文件",normalizedTitle:"5.1 取消暂存的文件",charIndex:4268},{level:4,title:"5.2 撤消对文件的修改",slug:"_5-2-撤消对文件的修改",normalizedTitle:"5.2 撤消对文件的修改",charIndex:5260}],headersStr:"1. 三种状态 2. 获取Git仓库 2.1 在现有目录中初始化仓库 2.2 克隆现有的仓库 3.记录每次更新到仓库 3.1 检查当前文件状态 3.2 跟踪新文件 3.3 暂存已修改文件 3.4 忽略文件 3.5 查看已暂存和未暂存的修改 3.6 提交更新 4. 查看提交历史 5. 撤消操作 5.1 取消暂存的文件 5.2 撤消对文件的修改",content:'# Git 基础\n\nGit 保存的不是文件的变化或者差异，而是一系列不同时刻的文件快照。\n\n\n# 1. 三种状态\n\nGit 有三种状态，你的文件可能处于其中之一：\n\n * 已提交（committed）\n   \n   表示数据已经安全的保存在本地数据库中。\n\n * 已修改（modified）\n   \n   表示修改了文件，但还没保存到数据库中。\n\n * 已暂存（staged）\n   \n   表示对一个已修改文件的当前版本做了标记，使之包含在下次提交的快照中。\n\nGit 项目的三个工作区域的概念：\n\n * Git 仓库\n   \n   是 Git 用来保存项目的元数据和对象数据库的地方。 这是 Git 中最重要的部分，从其它计算机克隆仓库时，拷贝的就是这里的数据。\n\n * 工作目录\n   \n   是对项目的某个版本独立提取出来的内容。 这些从 Git 仓库的压缩数据库中提取出来的文件，放在磁盘上供你使用或修改。\n\n * 暂存区域\n   \n   是一个文件，保存了下次将提交的文件列表信息，一般在 Git 仓库目录中。 有时候也被称作“索引”，不过一般说法还是叫暂存区域。\n   \n   \n\n基本的 Git 工作流程如下：\n\n 1. 在工作目录中修改文件。\n 2. 暂存文件，将文件的快照放入暂存区域。\n 3. 提交更新，找到暂存区域的文件，将快照永久性存储到 Git 仓库目录。\n\n如果 Git 目录中保存着的特定版本文件，就属于已提交状态。 如果作了修改并已放入暂存区域，就属于已暂存状态。 如果自上次取出后，作了修改但还没有放到暂存区域，就是已修改状态。\n\n\n# 2. 获取Git仓库\n\n有两种取得 Git 项目仓库的方法。 第一种是在现有项目或目录下导入所有文件到 Git 中； 第二种是从一个服务器克隆一个现有的 Git 仓库。\n\n# 2.1 在现有目录中初始化仓库\n\n如果你打算使用 Git 来对现有的项目进行管理，你只需要进入该项目目录并输入：\n\n$ git init\n\n\n1\n\n\n该命令将创建一个名为 .git 的子目录，这个子目录含有你初始化的 Git 仓库中所有的必须文件，这些文件是 Git 仓库的骨干。 但是，在这个时候，我们仅仅是做了一个初始化的操作，你的项目里的文件还没有被跟踪。\n\n如果你是在一个已经存在文件的文件夹（而不是空文件夹）中初始化 Git 仓库来进行版本控制的话，你应该开始跟踪这些文件并提交。 你可通过 git add 命令来实现对指定文件的跟踪，然后执行 git commit 提交：\n\n$ git add *.c\n$ git add LICENSE\n$ git commit -m \'initial project version\'\n\n\n1\n2\n3\n\n\n# 2.2 克隆现有的仓库\n\n如果你想获得一份已经存在了的 Git 仓库的拷贝，比如说，你想为某个开源项目贡献自己的一份力，这时就要用到 git clone 命令。\n\n克隆仓库的命令格式是 git clone [url] 。 比如，要克隆 Git 的可链接库 libgit2，可以用下面的命令：\n\n$ git clone https://github.com/libgit2/libgit2\n\n\n1\n\n\n如果你想在克隆远程仓库的时候，自定义本地仓库的名字，你可以使用如下命令：\n\n$ git clone https://github.com/libgit2/libgit2 mylibgit\n\n\n1\n\n\n这将执行与上一个命令相同的操作，不过在本地创建的仓库名字变为 mylibgit。\n\n\n# 3.记录每次更新到仓库\n\n现在我们手上有了一个真实项目的 Git 仓库，并从这个仓库中取出了所有文件的工作拷贝。 接下来，对这些文件做些修改，在完成了一个阶段的目标之后，提交本次更新到仓库。\n\n请记住，你工作目录下的每一个文件都不外乎这两种状态：已跟踪或未跟踪。已跟踪的文件是指那些被纳入了版本控制的文件，在上一次快照中有它们的记录，在工作一段时间后，它们的状态可能处于未修改，已修改或已放入暂存区。\n\n\n\n新建一个文件，此时是 Untracked 状态；若使用git add命令将文件暂存，则是 Staged 状态；此时commit则会变为 Unmodified 状态。\n\n# 3.1 检查当前文件状态\n\n要查看哪些文件处于什么状态，可以用 git status 命令。\n\n运行 git status 命令，出现在 Changes not staged for commit 这行下面，说明已跟踪文件的内容发生了变化，但还没有放到暂存区。 要暂存这次更新，需要运行 git add 命令。 这是个多功能命令：可以用它开始跟踪新文件，或者把已跟踪的文件放到暂存区，还能用于合并时把有冲突的文件标记为已解决状态等。 将这个命令理解为“添加内容到下一次提交中”而不是“将一个文件添加到项目中”要更加合适。\n\n只要在 Changes to be committed 这行下面的，就说明是已暂存状态。 如果此时提交，那么该文件此时此刻的版本将被留存在历史记录中。\n\n# 3.2 跟踪新文件\n\n使用命令 git add 开始跟踪一个文件。运行 git status 命令，会看到相应的文件已被跟踪，并处于暂存状态。\n\n# 3.3 暂存已修改文件\n\n如3.1中所述进行暂存，若git add之后又进行对相关文件（假设是CONTRIBUTING.md）的修改，要进行提交，此时文件会同时出现在暂存区和非暂存区。这怎么可能呢？ 好吧，实际上 Git 只不过暂存了你运行 git add 命令时的版本， 如果你现在提交，CONTRIBUTING.md 的版本是你最后一次运行 git add 命令时的那个版本，而不是你运行 git commit 时，在工作目录中的当前版本。 所以，运行了 git add 之后又作了修订的文件，需要重新运行 git add 把最新版本重新暂存起来。\n\n# 3.4 忽略文件\n\n一般我们总会有些文件无需纳入 Git 的管理，也不希望它们总出现在未跟踪文件列表。 通常都是些自动生成的文件，比如日志文件，或者编译过程中创建的临时文件等。 在这种情况下，我们可以创建一个名为 .gitignore 的文件，列出要忽略的文件模式。\n\n详见《Pro Git 中文版（第二版）》\n\n# 3.5 查看已暂存和未暂存的修改\n\n如果 git status 命令的输出对于你来说过于模糊，你想知道具体修改了什么地方，可以用 git diff 命令。通常会用它来回答这两个问题：当前做的哪些更新还没有暂存？ 有哪些更新已经暂存起来准备好了下次提交？\n\n要查看尚未暂存的文件更新了哪些部分，不加参数直接输入 git diff，此命令比较的是工作目录中当前文件和暂存区域快照之间的差异， 也就是修改之后还没有暂存起来的变化内容。\n\n若要查看已暂存的将要添加到下次提交里的内容，可以用 git diff --cached 命令。（Git 1.6.1 及更高版本还允许使用 git diff --staged，效果是相同的，但更好记些。）\n\n请注意，git diff 本身只显示尚未暂存的改动，而不是自上次提交以来所做的所有改动。 所以有时候你一下子暂存了所有更新过的文件后，运行 git diff 后却什么也没有，就是这个原因。\n\n# 3.6 提交更新\n\n 1. 每次准备提交前，先用 git status 看下，是不是都已暂存起来了， 然后再运行提交命令 git commit：\n\n$ git commit\n\n\n1\n\n\n这种方式会启动文本编辑器以便输入本次提交的说明。 (默认会启用 shell 的环境变量 $EDITOR 所指定的软件，一般都是 vim 或 emacs。\n\n 2. 可以在 commit 命令后添加 -m 选项，将提交信息与命令放在同一行，\n\n提交后它会告诉你，当前是在哪个分支（master）提交的，本次提交的完整 SHA-1 校验和是什么（463dc4f），以及在本次提交中，有多少文件修订过，多少行添加和删改过。\n\n请记住，提交时记录的是放在暂存区域的快照。 任何还未暂存的仍然保持已修改状态，可以在下次提交时纳入版本管理。 每一次运行提交操作，都是对你项目作一次快照，以后可以回到这个状态，或者进行比较。\n\n\n# 4. 查看提交历史\n\n完成这个任务最简单而又有效的工具是 git log 命令。\n\n默认不用任何参数的话，git log 会按提交时间列出所有的更新，最近的更新排在最上面。 正如你所看到的，这个命令会列出每个提交的 SHA-1 校验和、作者的名字和电子邮件地址、提交时间以及提交说明。\n\ngit log 有许多选项可以帮助你搜寻你所要找的提交， 接下来我们介绍些最常用的。\n\n * 一个常用的选项是 -p，用来显示每次提交的内容差异。 你也可以加上 -2 来仅显示最近两次提交。\n * --stat 选项在每次提交的下面列出额所有被修改过的文件、有多少文件被修改了以及被修改过的文件的哪些行被移除或是添加了。 在每次提交的最后还有一个总结。\n * --pretty。 这个选项可以指定使用不同于默认格式的方式展示提交历史。 这个选项有一些内建的子选项供你使用。 比如用 oneline 将每个提交放在一行显示，查看的提交数很大时非常有用。 另外还有 short，full 和 fuller 可以用，展示的信息或多或少有些不同。\n\n\n# 5. 撤消操作\n\n在任何一个阶段，你都有可能想要撤消某些操作。 这里，我们将会学习几个撤消你所做修改的基本工具。 注意，有些撤消操作是不可逆的。 这是在使用 Git 的过程中，会因为操作失误而导致之前的工作丢失的少有的几个地方之一。\n\n有时候我们提交完了才发现漏掉了几个文件没有添加，或者提交信息写错了。 此时，可以运行带有 --amend 选项的提交命令尝试重新提交：\n\n$ git commit --amend\n\n\n1\n\n\n这个命令会将暂存区中的文件提交。 如果自上次提交以来你还未做任何修改（例如，在上次提交后马上执行了此命令），那么快照会保持不变，而你所修改的只是提交信息。\n\n文本编辑器启动后，可以看到之前的提交信息。 编辑后保存会覆盖原来的提交信息。\n\n# 5.1 取消暂存的文件\n\n接下来的两个小节演示如何操作暂存区域与工作目录中已修改的文件。 这些命令在修改文件状态的同时，也会提示如何撤消操作。 例如，你已经修改了两个文件并且想要将它们作为两次独立的修改提交，但是却意外地输入了 git add * 暂存了它们两个。 如何只取消暂存两个中的一个呢？ git status 命令提示了你：\n\n$ git add *\n$ git status\nOn branch master\nChanges to be committed:\n  (use "git reset HEAD <file>..." to unstage)\n\n    renamed:    README.md -> README\n    modified:   CONTRIBUTING.md\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n在 “Changes to be committed” 文字正下方，提示使用 git reset HEAD <file>... 来取消暂存。 所以，我们可以这样来取消暂存 CONTRIBUTING.md 文件：\n\n$ git reset HEAD CONTRIBUTING.md\nUnstaged changes after reset:\nM\tCONTRIBUTING.md\n$ git status\nOn branch master\nChanges to be committed:\n  (use "git reset HEAD <file>..." to unstage)\n\n    renamed:    README.md -> README\n\nChanges not staged for commit:\n  (use "git add <file>..." to update what will be committed)\n  (use "git checkout -- <file>..." to discard changes in working directory)\n\n    modified:   CONTRIBUTING.md\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n这个命令有点儿奇怪，但是起作用了。 CONTRIBUTING.md 文件已经是修改未暂存的状态了。\n\n# 5.2 撤消对文件的修改\n\n如果你并不想保留对 CONTRIBUTING.md 文件的修改怎么办？ 你该如何方便地撤消修改 - 将它还原成上次提交时的样子（或者刚克隆完的样子，或者刚把它放入工作目录时的样子）？ 幸运的是，git status 也告诉了你应该如何做。\n\n记住，在 Git 中任何 已提交的 东西几乎总是可以恢复的。 甚至那些被删除的分支中的提交或使用 --amend 选项覆盖的提交也可以恢复（阅读 数据恢复 了解数据恢复）。 然而，任何你未提交的东西丢失后很可能再也找不到了。\n\n> 动手： 如何新建一个gitee仓库_小慈的博客-CSDN博客_gitee创建仓库',normalizedContent:'# git 基础\n\ngit 保存的不是文件的变化或者差异，而是一系列不同时刻的文件快照。\n\n\n# 1. 三种状态\n\ngit 有三种状态，你的文件可能处于其中之一：\n\n * 已提交（committed）\n   \n   表示数据已经安全的保存在本地数据库中。\n\n * 已修改（modified）\n   \n   表示修改了文件，但还没保存到数据库中。\n\n * 已暂存（staged）\n   \n   表示对一个已修改文件的当前版本做了标记，使之包含在下次提交的快照中。\n\ngit 项目的三个工作区域的概念：\n\n * git 仓库\n   \n   是 git 用来保存项目的元数据和对象数据库的地方。 这是 git 中最重要的部分，从其它计算机克隆仓库时，拷贝的就是这里的数据。\n\n * 工作目录\n   \n   是对项目的某个版本独立提取出来的内容。 这些从 git 仓库的压缩数据库中提取出来的文件，放在磁盘上供你使用或修改。\n\n * 暂存区域\n   \n   是一个文件，保存了下次将提交的文件列表信息，一般在 git 仓库目录中。 有时候也被称作“索引”，不过一般说法还是叫暂存区域。\n   \n   \n\n基本的 git 工作流程如下：\n\n 1. 在工作目录中修改文件。\n 2. 暂存文件，将文件的快照放入暂存区域。\n 3. 提交更新，找到暂存区域的文件，将快照永久性存储到 git 仓库目录。\n\n如果 git 目录中保存着的特定版本文件，就属于已提交状态。 如果作了修改并已放入暂存区域，就属于已暂存状态。 如果自上次取出后，作了修改但还没有放到暂存区域，就是已修改状态。\n\n\n# 2. 获取git仓库\n\n有两种取得 git 项目仓库的方法。 第一种是在现有项目或目录下导入所有文件到 git 中； 第二种是从一个服务器克隆一个现有的 git 仓库。\n\n# 2.1 在现有目录中初始化仓库\n\n如果你打算使用 git 来对现有的项目进行管理，你只需要进入该项目目录并输入：\n\n$ git init\n\n\n1\n\n\n该命令将创建一个名为 .git 的子目录，这个子目录含有你初始化的 git 仓库中所有的必须文件，这些文件是 git 仓库的骨干。 但是，在这个时候，我们仅仅是做了一个初始化的操作，你的项目里的文件还没有被跟踪。\n\n如果你是在一个已经存在文件的文件夹（而不是空文件夹）中初始化 git 仓库来进行版本控制的话，你应该开始跟踪这些文件并提交。 你可通过 git add 命令来实现对指定文件的跟踪，然后执行 git commit 提交：\n\n$ git add *.c\n$ git add license\n$ git commit -m \'initial project version\'\n\n\n1\n2\n3\n\n\n# 2.2 克隆现有的仓库\n\n如果你想获得一份已经存在了的 git 仓库的拷贝，比如说，你想为某个开源项目贡献自己的一份力，这时就要用到 git clone 命令。\n\n克隆仓库的命令格式是 git clone [url] 。 比如，要克隆 git 的可链接库 libgit2，可以用下面的命令：\n\n$ git clone https://github.com/libgit2/libgit2\n\n\n1\n\n\n如果你想在克隆远程仓库的时候，自定义本地仓库的名字，你可以使用如下命令：\n\n$ git clone https://github.com/libgit2/libgit2 mylibgit\n\n\n1\n\n\n这将执行与上一个命令相同的操作，不过在本地创建的仓库名字变为 mylibgit。\n\n\n# 3.记录每次更新到仓库\n\n现在我们手上有了一个真实项目的 git 仓库，并从这个仓库中取出了所有文件的工作拷贝。 接下来，对这些文件做些修改，在完成了一个阶段的目标之后，提交本次更新到仓库。\n\n请记住，你工作目录下的每一个文件都不外乎这两种状态：已跟踪或未跟踪。已跟踪的文件是指那些被纳入了版本控制的文件，在上一次快照中有它们的记录，在工作一段时间后，它们的状态可能处于未修改，已修改或已放入暂存区。\n\n\n\n新建一个文件，此时是 untracked 状态；若使用git add命令将文件暂存，则是 staged 状态；此时commit则会变为 unmodified 状态。\n\n# 3.1 检查当前文件状态\n\n要查看哪些文件处于什么状态，可以用 git status 命令。\n\n运行 git status 命令，出现在 changes not staged for commit 这行下面，说明已跟踪文件的内容发生了变化，但还没有放到暂存区。 要暂存这次更新，需要运行 git add 命令。 这是个多功能命令：可以用它开始跟踪新文件，或者把已跟踪的文件放到暂存区，还能用于合并时把有冲突的文件标记为已解决状态等。 将这个命令理解为“添加内容到下一次提交中”而不是“将一个文件添加到项目中”要更加合适。\n\n只要在 changes to be committed 这行下面的，就说明是已暂存状态。 如果此时提交，那么该文件此时此刻的版本将被留存在历史记录中。\n\n# 3.2 跟踪新文件\n\n使用命令 git add 开始跟踪一个文件。运行 git status 命令，会看到相应的文件已被跟踪，并处于暂存状态。\n\n# 3.3 暂存已修改文件\n\n如3.1中所述进行暂存，若git add之后又进行对相关文件（假设是contributing.md）的修改，要进行提交，此时文件会同时出现在暂存区和非暂存区。这怎么可能呢？ 好吧，实际上 git 只不过暂存了你运行 git add 命令时的版本， 如果你现在提交，contributing.md 的版本是你最后一次运行 git add 命令时的那个版本，而不是你运行 git commit 时，在工作目录中的当前版本。 所以，运行了 git add 之后又作了修订的文件，需要重新运行 git add 把最新版本重新暂存起来。\n\n# 3.4 忽略文件\n\n一般我们总会有些文件无需纳入 git 的管理，也不希望它们总出现在未跟踪文件列表。 通常都是些自动生成的文件，比如日志文件，或者编译过程中创建的临时文件等。 在这种情况下，我们可以创建一个名为 .gitignore 的文件，列出要忽略的文件模式。\n\n详见《pro git 中文版（第二版）》\n\n# 3.5 查看已暂存和未暂存的修改\n\n如果 git status 命令的输出对于你来说过于模糊，你想知道具体修改了什么地方，可以用 git diff 命令。通常会用它来回答这两个问题：当前做的哪些更新还没有暂存？ 有哪些更新已经暂存起来准备好了下次提交？\n\n要查看尚未暂存的文件更新了哪些部分，不加参数直接输入 git diff，此命令比较的是工作目录中当前文件和暂存区域快照之间的差异， 也就是修改之后还没有暂存起来的变化内容。\n\n若要查看已暂存的将要添加到下次提交里的内容，可以用 git diff --cached 命令。（git 1.6.1 及更高版本还允许使用 git diff --staged，效果是相同的，但更好记些。）\n\n请注意，git diff 本身只显示尚未暂存的改动，而不是自上次提交以来所做的所有改动。 所以有时候你一下子暂存了所有更新过的文件后，运行 git diff 后却什么也没有，就是这个原因。\n\n# 3.6 提交更新\n\n 1. 每次准备提交前，先用 git status 看下，是不是都已暂存起来了， 然后再运行提交命令 git commit：\n\n$ git commit\n\n\n1\n\n\n这种方式会启动文本编辑器以便输入本次提交的说明。 (默认会启用 shell 的环境变量 $editor 所指定的软件，一般都是 vim 或 emacs。\n\n 2. 可以在 commit 命令后添加 -m 选项，将提交信息与命令放在同一行，\n\n提交后它会告诉你，当前是在哪个分支（master）提交的，本次提交的完整 sha-1 校验和是什么（463dc4f），以及在本次提交中，有多少文件修订过，多少行添加和删改过。\n\n请记住，提交时记录的是放在暂存区域的快照。 任何还未暂存的仍然保持已修改状态，可以在下次提交时纳入版本管理。 每一次运行提交操作，都是对你项目作一次快照，以后可以回到这个状态，或者进行比较。\n\n\n# 4. 查看提交历史\n\n完成这个任务最简单而又有效的工具是 git log 命令。\n\n默认不用任何参数的话，git log 会按提交时间列出所有的更新，最近的更新排在最上面。 正如你所看到的，这个命令会列出每个提交的 sha-1 校验和、作者的名字和电子邮件地址、提交时间以及提交说明。\n\ngit log 有许多选项可以帮助你搜寻你所要找的提交， 接下来我们介绍些最常用的。\n\n * 一个常用的选项是 -p，用来显示每次提交的内容差异。 你也可以加上 -2 来仅显示最近两次提交。\n * --stat 选项在每次提交的下面列出额所有被修改过的文件、有多少文件被修改了以及被修改过的文件的哪些行被移除或是添加了。 在每次提交的最后还有一个总结。\n * --pretty。 这个选项可以指定使用不同于默认格式的方式展示提交历史。 这个选项有一些内建的子选项供你使用。 比如用 oneline 将每个提交放在一行显示，查看的提交数很大时非常有用。 另外还有 short，full 和 fuller 可以用，展示的信息或多或少有些不同。\n\n\n# 5. 撤消操作\n\n在任何一个阶段，你都有可能想要撤消某些操作。 这里，我们将会学习几个撤消你所做修改的基本工具。 注意，有些撤消操作是不可逆的。 这是在使用 git 的过程中，会因为操作失误而导致之前的工作丢失的少有的几个地方之一。\n\n有时候我们提交完了才发现漏掉了几个文件没有添加，或者提交信息写错了。 此时，可以运行带有 --amend 选项的提交命令尝试重新提交：\n\n$ git commit --amend\n\n\n1\n\n\n这个命令会将暂存区中的文件提交。 如果自上次提交以来你还未做任何修改（例如，在上次提交后马上执行了此命令），那么快照会保持不变，而你所修改的只是提交信息。\n\n文本编辑器启动后，可以看到之前的提交信息。 编辑后保存会覆盖原来的提交信息。\n\n# 5.1 取消暂存的文件\n\n接下来的两个小节演示如何操作暂存区域与工作目录中已修改的文件。 这些命令在修改文件状态的同时，也会提示如何撤消操作。 例如，你已经修改了两个文件并且想要将它们作为两次独立的修改提交，但是却意外地输入了 git add * 暂存了它们两个。 如何只取消暂存两个中的一个呢？ git status 命令提示了你：\n\n$ git add *\n$ git status\non branch master\nchanges to be committed:\n  (use "git reset head <file>..." to unstage)\n\n    renamed:    readme.md -> readme\n    modified:   contributing.md\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n在 “changes to be committed” 文字正下方，提示使用 git reset head <file>... 来取消暂存。 所以，我们可以这样来取消暂存 contributing.md 文件：\n\n$ git reset head contributing.md\nunstaged changes after reset:\nm\tcontributing.md\n$ git status\non branch master\nchanges to be committed:\n  (use "git reset head <file>..." to unstage)\n\n    renamed:    readme.md -> readme\n\nchanges not staged for commit:\n  (use "git add <file>..." to update what will be committed)\n  (use "git checkout -- <file>..." to discard changes in working directory)\n\n    modified:   contributing.md\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n这个命令有点儿奇怪，但是起作用了。 contributing.md 文件已经是修改未暂存的状态了。\n\n# 5.2 撤消对文件的修改\n\n如果你并不想保留对 contributing.md 文件的修改怎么办？ 你该如何方便地撤消修改 - 将它还原成上次提交时的样子（或者刚克隆完的样子，或者刚把它放入工作目录时的样子）？ 幸运的是，git status 也告诉了你应该如何做。\n\n记住，在 git 中任何 已提交的 东西几乎总是可以恢复的。 甚至那些被删除的分支中的提交或使用 --amend 选项覆盖的提交也可以恢复（阅读 数据恢复 了解数据恢复）。 然而，任何你未提交的东西丢失后很可能再也找不到了。\n\n> 动手： 如何新建一个gitee仓库_小慈的博客-csdn博客_gitee创建仓库',charsets:{cjk:!0},lastUpdated:"2022/08/02, 02:37:31",lastUpdatedTimestamp:1659407851e3},{title:"Git的使用",frontmatter:{title:"Git的使用",date:"2022-03-29T11:00:58.000Z",permalink:"/pages/dc4ebe/",categories:["开发","Git"],tags:[null]},regularPath:"/%E5%9F%BA%E7%A1%80/5.Git/10.Git%E7%9A%84%E4%BD%BF%E7%94%A8.html",relativePath:"基础/5.Git/10.Git的使用.md",key:"v-45526b4e",path:"/pages/dc4ebe/",headers:[{level:3,title:"!image-20220329110148709",slug:"image-20220329110148709-https-blog-1310567564-cos-ap-beijing-myqcloud-com-img-image-20220329110148709-png",normalizedTitle:"!image-20220329110148709",charIndex:null},{level:4,title:"查看版本",slug:"查看版本",normalizedTitle:"查看版本",charIndex:163},{level:4,title:"查看操作记录",slug:"查看操作记录",normalizedTitle:"查看操作记录",charIndex:180},{level:4,title:"回退版本",slug:"回退版本",normalizedTitle:"回退版本",charIndex:202},{level:4,title:"创建新分支",slug:"创建新分支",normalizedTitle:"创建新分支",charIndex:477},{level:4,title:"查看分支",slug:"查看分支",normalizedTitle:"查看分支",charIndex:648},{level:4,title:"切换分支",slug:"切换分支",normalizedTitle:"切换分支",charIndex:747},{level:4,title:"合并分支的变更",slug:"合并分支的变更",normalizedTitle:"合并分支的变更",charIndex:808}],headersStr:"!image-20220329110148709 查看版本 查看操作记录 回退版本 创建新分支 查看分支 切换分支 合并分支的变更",content:"# Git的使用\n\n文件变更时，先git add将文件变绿， 再 git commit descrp提交此次变更到仓库。\n\n\n#\n\n已经add了一个文件，后悔了，在commit之前可以git reset <filename>将绿色文件变成红色（已修改，未加到暂存区）。\n\n> 此处所说的绿：缓冲区状态，红：已修改状态。\n\n# 查看版本\n\ngit log\n\n# 查看操作记录\n\ngit reglog\n\n# 回退版本\n\ngit reset <commitID>\n\n再次 git log时，会发现被回退掉的版本消失了。\n\n若想回到更新的版本，则需要查看操作记录找到当时的 commitID ，进行 reset。若想回到最新的版本，则只需 git pull即可。\n\n关于commitID\n\n是个 hash 值，很长，但通常只需要前7位就可以确定某个特定 ID 。\n\ngit reset 的参数：\n\n * --hard 不保存所有变更\n * --soft 保留变更且变更内容处于 Staged\n * --mixed 保留变更且变更内容处于 Modified\n\n# 创建新分支\n\ngit checkout -b <name> <template>\n\n-- name参数，新分支名字\n\n-- template 参数，指以哪个分支或 commit 为模板，默认以当前所在分支为模板\n\n模板理解\n\n以一个模板创建新分支，相当于创建了一个这个模板的分身，这个分身可以干自己的事情，并且他自己不影响本体的生死。\n\n# 查看分支\n\n 1. 查看所有分支\n    \n    git branch -a\n\n 2. 查看当前使用的分支(结果列表中前面标*号的表示当前使用分支)\n    \n    git branch\n\n# 切换分支\n\ngit checkout <name>\n\n切换版本新的方法\n\n可直接切换分支，而不必一直切换 ID 。\n\n# 合并分支的变更\n\ngit merge <branch Name>\n\n合并分支的变更，而非分支的内容",normalizedContent:"# git的使用\n\n文件变更时，先git add将文件变绿， 再 git commit descrp提交此次变更到仓库。\n\n\n#\n\n已经add了一个文件，后悔了，在commit之前可以git reset <filename>将绿色文件变成红色（已修改，未加到暂存区）。\n\n> 此处所说的绿：缓冲区状态，红：已修改状态。\n\n# 查看版本\n\ngit log\n\n# 查看操作记录\n\ngit reglog\n\n# 回退版本\n\ngit reset <commitid>\n\n再次 git log时，会发现被回退掉的版本消失了。\n\n若想回到更新的版本，则需要查看操作记录找到当时的 commitid ，进行 reset。若想回到最新的版本，则只需 git pull即可。\n\n关于commitid\n\n是个 hash 值，很长，但通常只需要前7位就可以确定某个特定 id 。\n\ngit reset 的参数：\n\n * --hard 不保存所有变更\n * --soft 保留变更且变更内容处于 staged\n * --mixed 保留变更且变更内容处于 modified\n\n# 创建新分支\n\ngit checkout -b <name> <template>\n\n-- name参数，新分支名字\n\n-- template 参数，指以哪个分支或 commit 为模板，默认以当前所在分支为模板\n\n模板理解\n\n以一个模板创建新分支，相当于创建了一个这个模板的分身，这个分身可以干自己的事情，并且他自己不影响本体的生死。\n\n# 查看分支\n\n 1. 查看所有分支\n    \n    git branch -a\n\n 2. 查看当前使用的分支(结果列表中前面标*号的表示当前使用分支)\n    \n    git branch\n\n# 切换分支\n\ngit checkout <name>\n\n切换版本新的方法\n\n可直接切换分支，而不必一直切换 id 。\n\n# 合并分支的变更\n\ngit merge <branch name>\n\n合并分支的变更，而非分支的内容",charsets:{cjk:!0},lastUpdated:"2022/04/09, 07:49:44",lastUpdatedTimestamp:1649490584e3},{title:"Java 基础语法",frontmatter:{title:"Java 基础语法",date:"2023-01-24T10:56:01.000Z",permalink:"/pages/483565/",categories:["开发","Java","黑马Java入门基础-学习笔记"],tags:[null]},regularPath:"/%E5%BC%80%E5%8F%91/10.Java/05.%E9%BB%91%E9%A9%ACJava%E5%85%A5%E9%97%A8%E5%9F%BA%E7%A1%80-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/05.Java%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95.html",relativePath:"开发/10.Java/05.黑马Java入门基础-学习笔记/05.Java基础语法.md",key:"v-11669a46",path:"/pages/483565/",headers:[{level:2,title:"0. 类型转换问题",slug:"_0-类型转换问题",normalizedTitle:"0. 类型转换问题",charIndex:15},{level:4,title:"类型转换（理解）",slug:"类型转换-理解",normalizedTitle:"类型转换（理解）",charIndex:28},{level:4,title:"自动类型转换",slug:"自动类型转换",normalizedTitle:"自动类型转换",charIndex:90},{level:4,title:"表达式的自动类型转换",slug:"表达式的自动类型转换",normalizedTitle:"表达式的自动类型转换",charIndex:359},{level:4,title:"强制类型转换",slug:"强制类型转换",normalizedTitle:"强制类型转换",charIndex:97},{level:2,title:"1. 运算符",slug:"_1-运算符",normalizedTitle:"1. 运算符",charIndex:896},{level:3,title:"1.1 算术运算符（理解）",slug:"_1-1-算术运算符-理解",normalizedTitle:"1.1 算术运算符（理解）",charIndex:907},{level:4,title:"字符的“+”操作",slug:"字符的-操作",normalizedTitle:"字符的“+”操作",charIndex:924},{level:3,title:"1.2 逻辑运算符（应用）",slug:"_1-2-逻辑运算符-应用",normalizedTitle:"1.2 逻辑运算符（应用）",charIndex:1971},{level:4,title:"短路逻辑运算符",slug:"短路逻辑运算符",normalizedTitle:"短路逻辑运算符",charIndex:2058},{level:3,title:"1.3 三元运算符（理解）",slug:"_1-3-三元运算符-理解",normalizedTitle:"1.3 三元运算符（理解）",charIndex:2374}],headersStr:"0. 类型转换问题 类型转换（理解） 自动类型转换 表达式的自动类型转换 强制类型转换 1. 运算符 1.1 算术运算符（理解） 字符的“+”操作 1.2 逻辑运算符（应用） 短路逻辑运算符 1.3 三元运算符（理解）",content:"# Java基础语法\n\n\n# 0. 类型转换问题\n\n# 类型转换（理解）\n\n在Java中，会存在不同类型的数据需要一起参与运算，所以这些数据类型之间是需要相互转换的，分为两种情况：自动类型转换和强制类型转换。\n\n# 自动类型转换\n\n*类型范围小的变量，可以直接赋值给类型范围大**的变量。\n\n\n\n把一个表示数据范围小的数值或者变量赋值给另一个表示数据范围大的变量。这种转换方式是自动的，直接书写即可。例如：\n\ndouble num = 10; // 将int类型的10直接赋值给double类型\nSystem.out.println(num); // 输出10.0\n\nbyte a = 12 ;\nint b = a;\nSystem.out.println(b); // 12\n\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n# 表达式的自动类型转换\n\n在表达式中，小范围类型的变量会自动转换成当前较大范围的类型再运算。\n\n\n\n注意事项：\n\n * 表达式的最终结果类型由表达式中的最高类型决定。\n\n * 在表达式中，byte、short、char 是直接转换成int类型参与运算的。\n\nbyte b1 = 10;\nbyte b2 = 20;\nbyte b3 = b1 + b2; \n// 第三行代码会报错，b1和b2会自动转换为int类型，计算结果为int，int赋值给byte需要强制类型转换。\n// 修改为:\nint num = b1 + b2;\n// 或者：\nbyte b3 = (byte) (b1 + b2);\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * boolean类型不能与其他基本数据类型相互转换。\n\n# 强制类型转换\n\n类型范围大的数据或者变量，不能直接赋值给类型范围小的变量，会报错，把一个表示数据范围大的数值或者变量赋值给另一个表示数据范围小的变量必须进行强制类型转换。\n\n强制类型转换格式：目标数据类型 变量名 = (目标数据类型)值或者变量;\n\n注意事项：\n\n * 强制类型转换可能造成数据(丢失)溢出；\n * 浮点型强转成整型，直接丢掉小数部分，保留整数部分返回。\n\n\n# 1. 运算符\n\n\n# 1.1 算术运算符（理解）\n\n# 字符的“+”操作\n\nchar类型参与算术运算，使用的是计算机底层对应的十进制数值。需要我们记住三个字符对应的数值：\n\n * 'a' -- 97 a-z是连续的，所以'b'对应的数值是98，'c'是99，依次递加\n\n * 'A' -- 65 A-Z是连续的，所以'B'对应的数值是66，'C'是67，依次递加\n\n * '0' -- 48 0-9是连续的，所以'1'对应的数值是49，'2'是50，依次递加\n\n// 可以通过使用字符与整数做算术运算，得出字符对应的数值是多少\nchar ch1 = 'a';\nSystem.out.println(ch1 + 1); // 输出98，97 + 1 = 98\n\nchar ch2 = 'A';\nSystem.out.println(ch2 + 1); // 输出66，65 + 1 = 66\n\nchar ch3 = '0';\nSystem.out.println(ch3 + 1); // 输出49，48 + 1 = 49\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n算术表达式中包含不同的基本数据类型的值的时候，整个算术表达式的类型会自动进行提升。\n\ntips：正是由于上述原因，所以在程序开发中我们很少使用byte或者short类型定义整数。也很少会使用char类型定义字符，而使用字符串类型，更不会使用char类型做算术运算。\n\n提示\n\n两个整数相除想得到小数结果：除数或被除数 x0.1\n\npublic class OperatorDemo1 {\n    public static void main(String[] args) {\n        int a = 10;\n        int b = 3;\n        System.out.println(a / b); // 3.3333 ==> 3\n        System,out.println(a * 1. / b); // 3.3333\n        System.out.println(3 / 2);\n        System.out.println(3 * 1.0 / 2); // 1.5\n        System.out.println(3 / 2 * 1.0); // 1.0\n        System.out.printin(a % b); // 1\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# 1.2 逻辑运算符（应用）\n\n逻辑运算符把各个运算的关系表达式连接起来组成一个复杂的逻辑表达式，以判断程序中的表达式是否成立，判断的结果是 true 或 false。\n\n# 短路逻辑运算符\n\n符号   作用    说明\n&&   短路与   作用和&相同，但是有短路效果\n||   短路或   作用和|相同，但是有短路效果\n\n在逻辑与运算中，只要有一个表达式的值为false，那么结果就可以判定为false了，没有必要将所有表达式的值都计算出来，短路与操作就有这样的效果，可以提高效率。同理在逻辑或运算中，一旦发现值为true，右边的表达式将不再参与运算。\n\n * 逻辑与&，无论左边真假，右边都要执行。\n\n * 短路与&&，如果左边为真，右边执行；如果左边为假，右边不执行。\n\n * 逻辑或|，无论左边真假，右边都要执行。\n\n * 短路或||，如果左边为假，右边执行；如果左边为真，右边不执行。\n\n\n# 1.3 三元运算符（理解）\n\n三元运算符语法格式：\n\n关系表达式 ? 表达式1 : 表达式2;\n\n\n1\n",normalizedContent:"# java基础语法\n\n\n# 0. 类型转换问题\n\n# 类型转换（理解）\n\n在java中，会存在不同类型的数据需要一起参与运算，所以这些数据类型之间是需要相互转换的，分为两种情况：自动类型转换和强制类型转换。\n\n# 自动类型转换\n\n*类型范围小的变量，可以直接赋值给类型范围大**的变量。\n\n\n\n把一个表示数据范围小的数值或者变量赋值给另一个表示数据范围大的变量。这种转换方式是自动的，直接书写即可。例如：\n\ndouble num = 10; // 将int类型的10直接赋值给double类型\nsystem.out.println(num); // 输出10.0\n\nbyte a = 12 ;\nint b = a;\nsystem.out.println(b); // 12\n\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n# 表达式的自动类型转换\n\n在表达式中，小范围类型的变量会自动转换成当前较大范围的类型再运算。\n\n\n\n注意事项：\n\n * 表达式的最终结果类型由表达式中的最高类型决定。\n\n * 在表达式中，byte、short、char 是直接转换成int类型参与运算的。\n\nbyte b1 = 10;\nbyte b2 = 20;\nbyte b3 = b1 + b2; \n// 第三行代码会报错，b1和b2会自动转换为int类型，计算结果为int，int赋值给byte需要强制类型转换。\n// 修改为:\nint num = b1 + b2;\n// 或者：\nbyte b3 = (byte) (b1 + b2);\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * boolean类型不能与其他基本数据类型相互转换。\n\n# 强制类型转换\n\n类型范围大的数据或者变量，不能直接赋值给类型范围小的变量，会报错，把一个表示数据范围大的数值或者变量赋值给另一个表示数据范围小的变量必须进行强制类型转换。\n\n强制类型转换格式：目标数据类型 变量名 = (目标数据类型)值或者变量;\n\n注意事项：\n\n * 强制类型转换可能造成数据(丢失)溢出；\n * 浮点型强转成整型，直接丢掉小数部分，保留整数部分返回。\n\n\n# 1. 运算符\n\n\n# 1.1 算术运算符（理解）\n\n# 字符的“+”操作\n\nchar类型参与算术运算，使用的是计算机底层对应的十进制数值。需要我们记住三个字符对应的数值：\n\n * 'a' -- 97 a-z是连续的，所以'b'对应的数值是98，'c'是99，依次递加\n\n * 'a' -- 65 a-z是连续的，所以'b'对应的数值是66，'c'是67，依次递加\n\n * '0' -- 48 0-9是连续的，所以'1'对应的数值是49，'2'是50，依次递加\n\n// 可以通过使用字符与整数做算术运算，得出字符对应的数值是多少\nchar ch1 = 'a';\nsystem.out.println(ch1 + 1); // 输出98，97 + 1 = 98\n\nchar ch2 = 'a';\nsystem.out.println(ch2 + 1); // 输出66，65 + 1 = 66\n\nchar ch3 = '0';\nsystem.out.println(ch3 + 1); // 输出49，48 + 1 = 49\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n算术表达式中包含不同的基本数据类型的值的时候，整个算术表达式的类型会自动进行提升。\n\ntips：正是由于上述原因，所以在程序开发中我们很少使用byte或者short类型定义整数。也很少会使用char类型定义字符，而使用字符串类型，更不会使用char类型做算术运算。\n\n提示\n\n两个整数相除想得到小数结果：除数或被除数 x0.1\n\npublic class operatordemo1 {\n    public static void main(string[] args) {\n        int a = 10;\n        int b = 3;\n        system.out.println(a / b); // 3.3333 ==> 3\n        system,out.println(a * 1. / b); // 3.3333\n        system.out.println(3 / 2);\n        system.out.println(3 * 1.0 / 2); // 1.5\n        system.out.println(3 / 2 * 1.0); // 1.0\n        system.out.printin(a % b); // 1\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# 1.2 逻辑运算符（应用）\n\n逻辑运算符把各个运算的关系表达式连接起来组成一个复杂的逻辑表达式，以判断程序中的表达式是否成立，判断的结果是 true 或 false。\n\n# 短路逻辑运算符\n\n符号   作用    说明\n&&   短路与   作用和&相同，但是有短路效果\n||   短路或   作用和|相同，但是有短路效果\n\n在逻辑与运算中，只要有一个表达式的值为false，那么结果就可以判定为false了，没有必要将所有表达式的值都计算出来，短路与操作就有这样的效果，可以提高效率。同理在逻辑或运算中，一旦发现值为true，右边的表达式将不再参与运算。\n\n * 逻辑与&，无论左边真假，右边都要执行。\n\n * 短路与&&，如果左边为真，右边执行；如果左边为假，右边不执行。\n\n * 逻辑或|，无论左边真假，右边都要执行。\n\n * 短路或||，如果左边为假，右边执行；如果左边为真，右边不执行。\n\n\n# 1.3 三元运算符（理解）\n\n三元运算符语法格式：\n\n关系表达式 ? 表达式1 : 表达式2;\n\n\n1\n",charsets:{cjk:!0},lastUpdated:"2023/01/24, 08:14:58",lastUpdatedTimestamp:1674548098e3},{title:"数组",frontmatter:{title:"数组",date:"2023-01-24T20:27:46.000Z",permalink:"/pages/a6522a/",categories:["开发","Java","黑马Java入门基础-学习笔记"],tags:[null]},regularPath:"/%E5%BC%80%E5%8F%91/10.Java/05.%E9%BB%91%E9%A9%ACJava%E5%85%A5%E9%97%A8%E5%9F%BA%E7%A1%80-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/10.%E6%95%B0%E7%BB%84.html",relativePath:"开发/10.Java/05.黑马Java入门基础-学习笔记/10.数组.md",key:"v-2c0bb97b",path:"/pages/a6522a/",headers:[{level:2,title:"1. 数组定义格式【记忆】",slug:"_1-数组定义格式【记忆】",normalizedTitle:"1. 数组定义格式【记忆】",charIndex:82},{level:2,title:"2. 数组初始化【应用】",slug:"_2-数组初始化【应用】",normalizedTitle:"2. 数组初始化【应用】",charIndex:252},{level:3,title:"2.1 静态初始化数组",slug:"_2-1-静态初始化数组",normalizedTitle:"2.1 静态初始化数组",charIndex:269},{level:4,title:"2.1.1 格式：",slug:"_2-1-1-格式",normalizedTitle:"2.1.1 格式：",charIndex:301},{level:3,title:"2.2 动态初始化数组",slug:"_2-2-动态初始化数组",normalizedTitle:"2.2 动态初始化数组",charIndex:486},{level:4,title:"2.2.1 格式：",slug:"_2-2-1-格式",normalizedTitle:"2.2.1 格式：",charIndex:535},{level:4,title:"2.2.2 动态初始化数组的元素默认值",slug:"_2-2-2-动态初始化数组的元素默认值",normalizedTitle:"2.2.2 动态初始化数组的元素默认值",charIndex:607},{level:2,title:"3. 数组元素访问【应用】",slug:"_3-数组元素访问【应用】",normalizedTitle:"3. 数组元素访问【应用】",charIndex:698},{level:2,title:"4. Java 内存分配【理解】",slug:"_4-java-内存分配【理解】",normalizedTitle:"4. java 内存分配【理解】",charIndex:1142},{level:3,title:"4.1 内存概述",slug:"_4-1-内存概述",normalizedTitle:"4.1 内存概述",charIndex:1163},{level:3,title:"4.2 java中的内存分配",slug:"_4-2-java中的内存分配",normalizedTitle:"4.2 java中的内存分配",charIndex:1295}],headersStr:"1. 数组定义格式【记忆】 2. 数组初始化【应用】 2.1 静态初始化数组 2.1.1 格式： 2.2 动态初始化数组 2.2.1 格式： 2.2.2 动态初始化数组的元素默认值 3. 数组元素访问【应用】 4. Java 内存分配【理解】 4.1 内存概述 4.2 java中的内存分配",content:"# 数组\n\n数组变量名中存储的是数组在内存中的地址，数组是引用类型（不同于基本类型）。\n\n提示\n\n数组一旦定义出来，程序执行的过程中，长度、类型就固定了。\n\n\n# 1. 数组定义格式【记忆】\n\n第一种\n\n数据类型[] 数组名\n\n示例：\n\nint[] arr;        \ndouble[] arr;      \nchar[] arr;\n\n\n1\n2\n3\n\n\n第二种\n\n数据类型 数组名[]\n\n示例：\n\nint arr[];\ndouble arr[];\nchar arr[];\n\n\n1\n2\n3\n\n\n\n# 2. 数组初始化【应用】\n\n\n# 2.1 静态初始化数组\n\n定义数组的时候直接给数组赋值。\n\n# 2.1.1 格式：\n\n * 完整版格式\n\n数据类型[] 数组名 = new 数据类型[]{元素1，元素2 ，元素3… };\nint[] ages = new int[]{12, 24, 36}\n\n\n1\n2\n\n * 简化版格式\n\n数据类型[] 数组名 = { 元素1，元素2 ，元素3，… };\nint[] ages = {12, 24, 36};\n\n\n1\n2\n\n\n\n# 2.2 动态初始化数组\n\n定义数组的时候只确定元素的类型和数组的长度，之后再存入具体数据。\n\n# 2.2.1 格式：\n\n数据类型[] 数组名 = new 数据类型[长度];\nint[] arr = new int[3];\n\n\n1\n2\n\n\n# 2.2.2 动态初始化数组的元素默认值\n\n两种数组初始化的特点和场景区别\n\n * 当前已经知道存入的元素值，用静态初始化。\n * 当前还不清楚要存入哪些数据，用动态初始化。\n\n\n# 3. 数组元素访问【应用】\n\n * 数组的长度：数组名称.length\n\n * 获取数组的最大索引：数组名称.length - 1\n   \n   ⚠️ 此方法获取数组的最大索引，需要元素个数大于0的前提。\n\n * 遍历数组元素时，注意判断是否为null，或是否长度为0。\n   \n   int[] nums = null;   // 数组为 null\n   int[] nums2 = {};    // 数组长度为 0\n   \n   public static int getMax(int[] arr) {\n       if (arr != null && arr.length > 0) {\n           // 方法的逻辑\n       } else {\n           // 数组为空或长度为0的处理\n       }\n   }\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   10\n   \n\n\n# 4. Java 内存分配【理解】\n\n\n# 4.1 内存概述\n\n内存是计算机中的重要原件，临时存储区域，作用是运行程序。\n\n我们编写的程序是存放在硬盘中的，在硬盘中的程序是不会运行的。\n\n必须放进内存中才能运行，运行完毕后会清空内存。\n\nJava虚拟机要运行程序，必须要对内存进行空间的分配和管理。\n\n\n# 4.2 java中的内存分配\n\n * 目前我们只需要记住两个内存，分别是：栈内存和堆内存\n\n区域名称    作用\n寄存器     给CPU使用，和我们开发无关。\n本地方法栈   JVM在使用操作系统功能的时候使用，和我们开发无关。\n方法区     存储可以运行的class文件。\n堆内存     存储对象或者数组，new来创建的，都存储在堆内存。\n方法栈     方法运行时使用的内存，比如main方法运行，进入方法栈中执行。",normalizedContent:"# 数组\n\n数组变量名中存储的是数组在内存中的地址，数组是引用类型（不同于基本类型）。\n\n提示\n\n数组一旦定义出来，程序执行的过程中，长度、类型就固定了。\n\n\n# 1. 数组定义格式【记忆】\n\n第一种\n\n数据类型[] 数组名\n\n示例：\n\nint[] arr;        \ndouble[] arr;      \nchar[] arr;\n\n\n1\n2\n3\n\n\n第二种\n\n数据类型 数组名[]\n\n示例：\n\nint arr[];\ndouble arr[];\nchar arr[];\n\n\n1\n2\n3\n\n\n\n# 2. 数组初始化【应用】\n\n\n# 2.1 静态初始化数组\n\n定义数组的时候直接给数组赋值。\n\n# 2.1.1 格式：\n\n * 完整版格式\n\n数据类型[] 数组名 = new 数据类型[]{元素1，元素2 ，元素3… };\nint[] ages = new int[]{12, 24, 36}\n\n\n1\n2\n\n * 简化版格式\n\n数据类型[] 数组名 = { 元素1，元素2 ，元素3，… };\nint[] ages = {12, 24, 36};\n\n\n1\n2\n\n\n\n# 2.2 动态初始化数组\n\n定义数组的时候只确定元素的类型和数组的长度，之后再存入具体数据。\n\n# 2.2.1 格式：\n\n数据类型[] 数组名 = new 数据类型[长度];\nint[] arr = new int[3];\n\n\n1\n2\n\n\n# 2.2.2 动态初始化数组的元素默认值\n\n两种数组初始化的特点和场景区别\n\n * 当前已经知道存入的元素值，用静态初始化。\n * 当前还不清楚要存入哪些数据，用动态初始化。\n\n\n# 3. 数组元素访问【应用】\n\n * 数组的长度：数组名称.length\n\n * 获取数组的最大索引：数组名称.length - 1\n   \n   ⚠️ 此方法获取数组的最大索引，需要元素个数大于0的前提。\n\n * 遍历数组元素时，注意判断是否为null，或是否长度为0。\n   \n   int[] nums = null;   // 数组为 null\n   int[] nums2 = {};    // 数组长度为 0\n   \n   public static int getmax(int[] arr) {\n       if (arr != null && arr.length > 0) {\n           // 方法的逻辑\n       } else {\n           // 数组为空或长度为0的处理\n       }\n   }\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   10\n   \n\n\n# 4. java 内存分配【理解】\n\n\n# 4.1 内存概述\n\n内存是计算机中的重要原件，临时存储区域，作用是运行程序。\n\n我们编写的程序是存放在硬盘中的，在硬盘中的程序是不会运行的。\n\n必须放进内存中才能运行，运行完毕后会清空内存。\n\njava虚拟机要运行程序，必须要对内存进行空间的分配和管理。\n\n\n# 4.2 java中的内存分配\n\n * 目前我们只需要记住两个内存，分别是：栈内存和堆内存\n\n区域名称    作用\n寄存器     给cpu使用，和我们开发无关。\n本地方法栈   jvm在使用操作系统功能的时候使用，和我们开发无关。\n方法区     存储可以运行的class文件。\n堆内存     存储对象或者数组，new来创建的，都存储在堆内存。\n方法栈     方法运行时使用的内存，比如main方法运行，进入方法栈中执行。",charsets:{cjk:!0},lastUpdated:"2023/01/24, 15:21:13",lastUpdatedTimestamp:1674573673e3},{title:"方法",frontmatter:{title:"方法",date:"2023-01-24T23:03:17.000Z",permalink:"/pages/615479/",categories:["开发","Java","黑马Java入门基础-学习笔记"],tags:[null]},regularPath:"/%E5%BC%80%E5%8F%91/10.Java/05.%E9%BB%91%E9%A9%ACJava%E5%85%A5%E9%97%A8%E5%9F%BA%E7%A1%80-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/15.%E6%96%B9%E6%B3%95.html",relativePath:"开发/10.Java/05.黑马Java入门基础-学习笔记/15.方法.md",key:"v-43f0e09d",path:"/pages/615479/",headers:[{level:2,title:"1. 方法调用过程图解（理解）",slug:"_1-方法调用过程图解-理解",normalizedTitle:"1. 方法调用过程图解（理解）",charIndex:9},{level:2,title:"2. 方法的参数传递机制",slug:"_2-方法的参数传递机制",normalizedTitle:"2. 方法的参数传递机制",charIndex:160},{level:2,title:"3. 方法重载",slug:"_3-方法重载",normalizedTitle:"3. 方法重载",charIndex:273},{level:3,title:"3.1 方法重载概念",slug:"_3-1-方法重载概念",normalizedTitle:"3.1 方法重载概念",charIndex:285},{level:3,title:"3.2 方法重载的识别技巧",slug:"_3-2-方法重载的识别技巧",normalizedTitle:"3.2 方法重载的识别技巧",charIndex:399},{level:2,title:"4. 单独使用return关键字",slug:"_4-单独使用return关键字",normalizedTitle:"4. 单独使用return关键字",charIndex:519}],headersStr:"1. 方法调用过程图解（理解） 2. 方法的参数传递机制 3. 方法重载 3.1 方法重载概念 3.2 方法重载的识别技巧 4. 单独使用return关键字",content:'# 方法\n\n\n# 1. 方法调用过程图解（理解）\n\n每个方法在被调用执行的时候，都会进入栈内存，并且拥有自己独立的内存空间，方法内部代码调用完毕之后，会从栈内存中弹栈消失。\n\n * 方法没有被调用的时候，在方法区中的字节码文件中存放\n\n * 方法被调用的时候，需要进入到栈内存中运行——方法的运行区域在栈内存中\n\n\n# 2. 方法的参数传递机制\n\n 1. 基本类型的参数传递\n\n 2. 引用类型的参数传递\n\n两种参数传递机制的区别\n\n * 都是值传递。\n\n * 基本类型的参数传输存储的数据值。\n\n * 引用类型的参数传输存储的地址值。\n\n\n# 3. 方法重载\n\n\n# 3.1 方法重载概念\n\n方法重载指同一个类中定义的多个方法之间的关系，满足下列条件的多个方法相互构成重载：\n\n * 多个方法在同一个类中\n * 多个方法具有相同的方法名\n * 多个方法的参数不相同，类型不同或者数量不同\n\n\n# 3.2 方法重载的识别技巧\n\n * 只要是同一个类中，方法名称相同、形参列表不同，那么他们就是重载的方法，其他都不管！ （如：修饰符，返回值类型都无所谓）\n\n * 形参列表不同指的是：形参的个数、类型、顺序不同，不关心形参的名称。\n\n\n# 4. 单独使用return关键字\n\nreturn; ---\x3e 可以立即跳出并结束当前方法的执行; return关键字单独使用可以放在任何方法中。\n\npublic class Test {\n    public static void main(String[] args) {\n        System.out.println("开始");\n        chu(10 , 0);\n        System.out.println("结束");\n    }\n     \n    public static void chu(int a , int b) {\n        if(b == 0){\n            System.err.println("您的数据有误！！不执行！！");\n            return; // 直接结束当前方法chu\n        }\n        int c = a / b;\n        System.out.println("除法结果是："+c);\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n',normalizedContent:'# 方法\n\n\n# 1. 方法调用过程图解（理解）\n\n每个方法在被调用执行的时候，都会进入栈内存，并且拥有自己独立的内存空间，方法内部代码调用完毕之后，会从栈内存中弹栈消失。\n\n * 方法没有被调用的时候，在方法区中的字节码文件中存放\n\n * 方法被调用的时候，需要进入到栈内存中运行——方法的运行区域在栈内存中\n\n\n# 2. 方法的参数传递机制\n\n 1. 基本类型的参数传递\n\n 2. 引用类型的参数传递\n\n两种参数传递机制的区别\n\n * 都是值传递。\n\n * 基本类型的参数传输存储的数据值。\n\n * 引用类型的参数传输存储的地址值。\n\n\n# 3. 方法重载\n\n\n# 3.1 方法重载概念\n\n方法重载指同一个类中定义的多个方法之间的关系，满足下列条件的多个方法相互构成重载：\n\n * 多个方法在同一个类中\n * 多个方法具有相同的方法名\n * 多个方法的参数不相同，类型不同或者数量不同\n\n\n# 3.2 方法重载的识别技巧\n\n * 只要是同一个类中，方法名称相同、形参列表不同，那么他们就是重载的方法，其他都不管！ （如：修饰符，返回值类型都无所谓）\n\n * 形参列表不同指的是：形参的个数、类型、顺序不同，不关心形参的名称。\n\n\n# 4. 单独使用return关键字\n\nreturn; ---\x3e 可以立即跳出并结束当前方法的执行; return关键字单独使用可以放在任何方法中。\n\npublic class test {\n    public static void main(string[] args) {\n        system.out.println("开始");\n        chu(10 , 0);\n        system.out.println("结束");\n    }\n     \n    public static void chu(int a , int b) {\n        if(b == 0){\n            system.err.println("您的数据有误！！不执行！！");\n            return; // 直接结束当前方法chu\n        }\n        int c = a / b;\n        system.out.println("除法结果是："+c);\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n',charsets:{cjk:!0},lastUpdated:"2023/01/24, 15:21:13",lastUpdatedTimestamp:1674573673e3},{title:"面向对象基础",frontmatter:{title:"面向对象基础",date:"2023-01-29T13:55:56.000Z",permalink:"/pages/d4e408/",categories:["开发","Java","黑马Java入门基础-学习笔记"],tags:[null]},regularPath:"/%E5%BC%80%E5%8F%91/10.Java/05.%E9%BB%91%E9%A9%ACJava%E5%85%A5%E9%97%A8%E5%9F%BA%E7%A1%80-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/20.%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E5%9F%BA%E7%A1%80.html",relativePath:"开发/10.Java/05.黑马Java入门基础-学习笔记/20.面向对象基础.md",key:"v-2b382624",path:"/pages/d4e408/",headers:[{level:2,title:"1. 类和对象",slug:"_1-类和对象",normalizedTitle:"1. 类和对象",charIndex:13},{level:3,title:"1.1 类和对象的理解",slug:"_1-1-类和对象的理解",normalizedTitle:"1.1 类和对象的理解",charIndex:25},{level:3,title:"1.2 类的定义",slug:"_1-2-类的定义",normalizedTitle:"1.2 类的定义",charIndex:389},{level:2,title:"2. 对象内存图",slug:"_2-对象内存图",normalizedTitle:"2. 对象内存图",charIndex:925},{level:3,title:"2.1 多个对象内存图",slug:"_2-1-多个对象内存图",normalizedTitle:"2.1 多个对象内存图",charIndex:938},{level:3,title:"2.2 多个对象指向相同内存图",slug:"_2-2-多个对象指向相同内存图",normalizedTitle:"2.2 多个对象指向相同内存图",charIndex:1160},{level:3,title:"2.3 垃圾回收",slug:"_2-3-垃圾回收",normalizedTitle:"2.3 垃圾回收",charIndex:1276},{level:2,title:"3. 构造器",slug:"_3-构造器",normalizedTitle:"3. 构造器",charIndex:1453},{level:3,title:"3.1 构造器的作用",slug:"_3-1-构造器的作用",normalizedTitle:"3.1 构造器的作用",charIndex:1464},{level:3,title:"3.2 构造器的分类",slug:"_3-2-构造器的分类",normalizedTitle:"3.2 构造器的分类",charIndex:1498},{level:2,title:"4. this 关键字",slug:"_4-this-关键字",normalizedTitle:"4. this 关键字",charIndex:1874},{level:2,title:"5. 封装",slug:"_5-封装",normalizedTitle:"5. 封装",charIndex:1960},{level:3,title:"5.1 什么是封装",slug:"_5-1-什么是封装",normalizedTitle:"5.1 什么是封装",charIndex:1970},{level:3,title:"5.2 封装的实现步骤",slug:"_5-2-封装的实现步骤",normalizedTitle:"5.2 封装的实现步骤",charIndex:2041},{level:3,title:"5.3 封装的好处",slug:"_5-3-封装的好处",normalizedTitle:"5.3 封装的好处",charIndex:2250},{level:2,title:"6. 标准 JavaBean",slug:"_6-标准-javabean",normalizedTitle:"6. 标准 javabean",charIndex:2315},{level:2,title:"7.  成员变量和局部变量",slug:"_7-成员变量和局部变量",normalizedTitle:"7.  成员变量和局部变量",charIndex:null},{level:3,title:"7.1 成员变量和局部变量的区别",slug:"_7-1-成员变量和局部变量的区别",normalizedTitle:"7.1 成员变量和局部变量的区别",charIndex:2485}],headersStr:"1. 类和对象 1.1 类和对象的理解 1.2 类的定义 2. 对象内存图 2.1 多个对象内存图 2.2 多个对象指向相同内存图 2.3 垃圾回收 3. 构造器 3.1 构造器的作用 3.2 构造器的分类 4. this 关键字 5. 封装 5.1 什么是封装 5.2 封装的实现步骤 5.3 封装的好处 6. 标准 JavaBean 7.  成员变量和局部变量 7.1 成员变量和局部变量的区别",content:"# 面向对象基础\n\n\n# 1. 类和对象\n\n\n# 1.1 类和对象的理解\n\n客观存在的事物皆为对象 ，所以我们也常常说万物皆对象。\n\n * 类\n   * 类的理解\n     * 类是对现实生活中一类具有共同属性和行为的事物的抽象\n     * 类是对象的数据类型，类是具有相同属性和行为的一组对象的集合\n     * 简单理解：类就是对现实事物的一种描述\n   * 类的组成\n     * 属性：指事物的特征，例如：手机事物（品牌，价格，尺寸）\n     * 行为：指事物能执行的操作，例如：手机事物（打电话，发短信）\n * 类和对象的关系\n   * 类：类是对现实生活中一类具有共同属性和行为的事物的抽象，是对象共同特征的描述\n   * 对象：是能够看得到摸的着的真实存在的实体，是真实存在的具体实例\n   * 简单理解：类是对事物的一种描述，对象则为具体存在的事物\n\n\n# 1.2 类的定义\n\n类的组成是由属性和行为两部分组成\n\n * 属性：在类中通过成员变量来体现（类中方法外的变量）\n * 行为：在类中通过成员方法来体现（和前面的方法相比去掉static关键字即可）\n\n⚠️ 补充注意事项：\n\n * 类名首字母建议大写，且有意义，满足“驼峰模式”。\n\n * 一个Java文件中可以定义多个class类，且只能一个类是public修饰，而且public修饰的类名必须成为代码文件名。 实际开发中建议还是一个文件定义一个class类。\n\n * 成员变量的完整定义格式是：修饰符 数据类型 变量名称 = 初始化值； 一般无需指定初始化值，存在默认值。\n   \n   * 对象的成员变量的默认值规则：\n   \n   * 数据类型   明细                         默认值\n     基本类型   byte、short、char、int、long   0\n     基本类型   float、double               0.0\n     基本类型   boolean                    false\n     引用类型   类、接口、数组、String             null\n\n\n# 2. 对象内存图\n\n\n# 2.1 多个对象内存图\n\n * 对象的成员方法不直接加载到堆内存中，而是在堆内存中引用方法区中的内容。\n * 对象的成员变量存储值在堆内存中修改。\n\n\n\n * 执行到第二个对象创建时，在堆内存中再开辟一个新的空间存此新对象。\n\n\n\n总结：\n\n * 对象放在堆内存中。\n * Car c = new Car(); 语句中，c 变量名中存储的是对象在堆内存中的地址。\n * 成员变量（name、price）的数据放在对象中，存在堆内存中。\n\n\n# 2.2 多个对象指向相同内存图\n\n\n\n总结：\n\n * 当多个对象的引用指向同一个内存空间（变量所记录的地址值是一样的）\n\n * 只要有任何一个对象修改了内存中的数据，随后，无论使用哪一个对象进行数据获取，都是修改后的数据。\n\n\n# 2.3 垃圾回收\n\n * 当堆内存中的类对象或数组对象，没有被任何变量引用（指向）时，就会被判定为内存中的“垃圾”。\n   \n   * 如上图中若代码中后续还有 s1=null; s2=null; ，会导致左侧两条指向堆内存中对象存储区域的红线不存在，此时堆内存的白色区域变成了内存垃圾。\n\n * Java 存在自动垃圾回收器，会定期进行清理。\n\n\n# 3. 构造器\n\n\n# 3.1 构造器的作用\n\n初始化类的对象，并返回对象的地址。\n\n\n# 3.2 构造器的分类\n\n * 无参数构造器\n   \n   * （默认存在的）：初始化对象时，成员变量的数据均采用默认值。\n\n * 有参数构造器\n   \n   * 在初始化对象的时候，同时可以为对象进行赋值。\n\n⚠️ 注意事项：\n\n * 任何类定义出来，默认就自带了无参数构造器，写不写都有。\n\n * 一旦定义了有参数构造器，无参数构造器就没有了，此时就需要自己写一个无参数构造器了。\n\npublic class Car {\n    ...\n    // 无参数构造器（此时需要明确写出来）\n    public Car(){\n        \n    }\n    // 有参数构造器\n    public Car(String n, String b){\n        \n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 4. this 关键字\n\n * 作用\n   * 代表当前对象的地址\n * this关键字在构造器中、成员方法中可以做什么\n   * 可以用于访问当前对象的成员变量\n\n\n# 5. 封装\n\n\n# 5.1 什么是封装\n\n * 面向对象的三大特征：封装，继承，多态\n\n * 隐藏实现细节，暴露出合适的访问方式。（合理隐藏、合理暴露）\n\n\n# 5.2 封装的实现步骤\n\n * 一般对成员变量使用 private (私有)关键字修饰进行隐藏，private 修饰后该成员变量就只能在当前类中访问。\n\n * 提供 public 修饰的公开的 getter、setter 方法暴露其取值和赋值。\n   \n   * IDEA 中可以自动生成 getter、setter 方法\n\n方法和哪个对象封装在一起怎么确定 ？\n\n方法导致谁的属性变化，该方法就属于哪个对象\n\n\n# 5.3 封装的好处\n\n * 加强了程序代码的安全性。\n * 适当的封装可以提升开发效率，同时可以让程序更容易理解与维护。\n\n\n# 6. 标准 JavaBean\n\nJavaBean: 也可以理解成实体类，其对象可以用于在程序中封装数据。\n\n标准JavaBean须满足如下要求：\n\n * 成员变量使用 private 修饰。\n * 提供每一个成员变量对应的 setXxx() / getXxx()。\n * 必须提供一个无参构造器。\n\n\n# 7. 成员变量和局部变量\n\n\n# 7.1 成员变量和局部变量的区别\n\n区别        成员变量                    局部变量\n类中位置不同    类中，方法外                  常见于方法中\n初始化值不同    有默认初始化值                 没有，使用之前需要完成赋值\n内存中位置不同   堆内存                     栈内存\n生命周期不同    随着对象的创建而存在，随着对象的消失而消失   随着方法的调用而存在，随着方法的运行结束而消失\n作用域       (不一定)                   在所归属的大括号中",normalizedContent:"# 面向对象基础\n\n\n# 1. 类和对象\n\n\n# 1.1 类和对象的理解\n\n客观存在的事物皆为对象 ，所以我们也常常说万物皆对象。\n\n * 类\n   * 类的理解\n     * 类是对现实生活中一类具有共同属性和行为的事物的抽象\n     * 类是对象的数据类型，类是具有相同属性和行为的一组对象的集合\n     * 简单理解：类就是对现实事物的一种描述\n   * 类的组成\n     * 属性：指事物的特征，例如：手机事物（品牌，价格，尺寸）\n     * 行为：指事物能执行的操作，例如：手机事物（打电话，发短信）\n * 类和对象的关系\n   * 类：类是对现实生活中一类具有共同属性和行为的事物的抽象，是对象共同特征的描述\n   * 对象：是能够看得到摸的着的真实存在的实体，是真实存在的具体实例\n   * 简单理解：类是对事物的一种描述，对象则为具体存在的事物\n\n\n# 1.2 类的定义\n\n类的组成是由属性和行为两部分组成\n\n * 属性：在类中通过成员变量来体现（类中方法外的变量）\n * 行为：在类中通过成员方法来体现（和前面的方法相比去掉static关键字即可）\n\n⚠️ 补充注意事项：\n\n * 类名首字母建议大写，且有意义，满足“驼峰模式”。\n\n * 一个java文件中可以定义多个class类，且只能一个类是public修饰，而且public修饰的类名必须成为代码文件名。 实际开发中建议还是一个文件定义一个class类。\n\n * 成员变量的完整定义格式是：修饰符 数据类型 变量名称 = 初始化值； 一般无需指定初始化值，存在默认值。\n   \n   * 对象的成员变量的默认值规则：\n   \n   * 数据类型   明细                         默认值\n     基本类型   byte、short、char、int、long   0\n     基本类型   float、double               0.0\n     基本类型   boolean                    false\n     引用类型   类、接口、数组、string             null\n\n\n# 2. 对象内存图\n\n\n# 2.1 多个对象内存图\n\n * 对象的成员方法不直接加载到堆内存中，而是在堆内存中引用方法区中的内容。\n * 对象的成员变量存储值在堆内存中修改。\n\n\n\n * 执行到第二个对象创建时，在堆内存中再开辟一个新的空间存此新对象。\n\n\n\n总结：\n\n * 对象放在堆内存中。\n * car c = new car(); 语句中，c 变量名中存储的是对象在堆内存中的地址。\n * 成员变量（name、price）的数据放在对象中，存在堆内存中。\n\n\n# 2.2 多个对象指向相同内存图\n\n\n\n总结：\n\n * 当多个对象的引用指向同一个内存空间（变量所记录的地址值是一样的）\n\n * 只要有任何一个对象修改了内存中的数据，随后，无论使用哪一个对象进行数据获取，都是修改后的数据。\n\n\n# 2.3 垃圾回收\n\n * 当堆内存中的类对象或数组对象，没有被任何变量引用（指向）时，就会被判定为内存中的“垃圾”。\n   \n   * 如上图中若代码中后续还有 s1=null; s2=null; ，会导致左侧两条指向堆内存中对象存储区域的红线不存在，此时堆内存的白色区域变成了内存垃圾。\n\n * java 存在自动垃圾回收器，会定期进行清理。\n\n\n# 3. 构造器\n\n\n# 3.1 构造器的作用\n\n初始化类的对象，并返回对象的地址。\n\n\n# 3.2 构造器的分类\n\n * 无参数构造器\n   \n   * （默认存在的）：初始化对象时，成员变量的数据均采用默认值。\n\n * 有参数构造器\n   \n   * 在初始化对象的时候，同时可以为对象进行赋值。\n\n⚠️ 注意事项：\n\n * 任何类定义出来，默认就自带了无参数构造器，写不写都有。\n\n * 一旦定义了有参数构造器，无参数构造器就没有了，此时就需要自己写一个无参数构造器了。\n\npublic class car {\n    ...\n    // 无参数构造器（此时需要明确写出来）\n    public car(){\n        \n    }\n    // 有参数构造器\n    public car(string n, string b){\n        \n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 4. this 关键字\n\n * 作用\n   * 代表当前对象的地址\n * this关键字在构造器中、成员方法中可以做什么\n   * 可以用于访问当前对象的成员变量\n\n\n# 5. 封装\n\n\n# 5.1 什么是封装\n\n * 面向对象的三大特征：封装，继承，多态\n\n * 隐藏实现细节，暴露出合适的访问方式。（合理隐藏、合理暴露）\n\n\n# 5.2 封装的实现步骤\n\n * 一般对成员变量使用 private (私有)关键字修饰进行隐藏，private 修饰后该成员变量就只能在当前类中访问。\n\n * 提供 public 修饰的公开的 getter、setter 方法暴露其取值和赋值。\n   \n   * idea 中可以自动生成 getter、setter 方法\n\n方法和哪个对象封装在一起怎么确定 ？\n\n方法导致谁的属性变化，该方法就属于哪个对象\n\n\n# 5.3 封装的好处\n\n * 加强了程序代码的安全性。\n * 适当的封装可以提升开发效率，同时可以让程序更容易理解与维护。\n\n\n# 6. 标准 javabean\n\njavabean: 也可以理解成实体类，其对象可以用于在程序中封装数据。\n\n标准javabean须满足如下要求：\n\n * 成员变量使用 private 修饰。\n * 提供每一个成员变量对应的 setxxx() / getxxx()。\n * 必须提供一个无参构造器。\n\n\n# 7. 成员变量和局部变量\n\n\n# 7.1 成员变量和局部变量的区别\n\n区别        成员变量                    局部变量\n类中位置不同    类中，方法外                  常见于方法中\n初始化值不同    有默认初始化值                 没有，使用之前需要完成赋值\n内存中位置不同   堆内存                     栈内存\n生命周期不同    随着对象的创建而存在，随着对象的消失而消失   随着方法的调用而存在，随着方法的运行结束而消失\n作用域       (不一定)                   在所归属的大括号中",charsets:{cjk:!0},lastUpdated:"2023/01/29, 08:40:33",lastUpdatedTimestamp:1674981633e3},{title:"常用API(String、ArrayList)",frontmatter:{title:"常用API(String、ArrayList)",date:"2023-02-01T10:49:22.000Z",permalink:"/pages/8f676c/",categories:["开发","Java","黑马Java入门基础-学习笔记"],tags:[null]},regularPath:"/%E5%BC%80%E5%8F%91/10.Java/05.%E9%BB%91%E9%A9%ACJava%E5%85%A5%E9%97%A8%E5%9F%BA%E7%A1%80-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/25.%E5%B8%B8%E7%94%A8API(String%E3%80%81ArrayList).html",relativePath:"开发/10.Java/05.黑马Java入门基础-学习笔记/25.常用API(String、ArrayList).md",key:"v-36c9cb62",path:"/pages/8f676c/",headers:[{level:2,title:"1. API",slug:"_1-api",normalizedTitle:"1. api",charIndex:20},{level:3,title:"1.1 API概述",slug:"_1-1-api概述",normalizedTitle:"1.1 api概述",charIndex:31},{level:2,title:"2. String类",slug:"_2-string类",normalizedTitle:"2. string类",charIndex:230},{level:3,title:"2.1 String类概述",slug:"_2-1-string类概述",normalizedTitle:"2.1 string类概述",charIndex:245},{level:3,title:"2.2 String类的特点",slug:"_2-2-string类的特点",normalizedTitle:"2.2 string类的特点",charIndex:422},{level:3,title:"2.3 String类创建对象的2种方式",slug:"_2-3-string类创建对象的2种方式",normalizedTitle:"2.3 string类创建对象的2种方式",charIndex:880},{level:4,title:"2.3.1 两种方式",slug:"_2-3-1-两种方式",normalizedTitle:"2.3.1 两种方式",charIndex:904},{level:4,title:"2.3.2 两种方式的区别？",slug:"_2-3-2-两种方式的区别",normalizedTitle:"2.3.2 两种方式的区别？",charIndex:2257},{level:4,title:"2.3.3 String 常见面试题",slug:"_2-3-3-string-常见面试题",normalizedTitle:"2.3.3 string 常见面试题",charIndex:2737},{level:3,title:"2.4 字符串内容比较",slug:"_2-4-字符串内容比较",normalizedTitle:"2.4 字符串内容比较",charIndex:3684},{level:4,title:"2.4.1 == 号的作用",slug:"_2-4-1-号的作用",normalizedTitle:"2.4.1 == 号的作用",charIndex:3699},{level:4,title:"2.4.2 equals 方法的作用",slug:"_2-4-2-equals-方法的作用",normalizedTitle:"2.4.2 equals 方法的作用",charIndex:3760},{level:3,title:"2.5 String 其他常用API",slug:"_2-5-string-其他常用api",normalizedTitle:"2.5 string 其他常用api",charIndex:4421},{level:2,title:"3. ArrayList",slug:"_3-arraylist",normalizedTitle:"3. arraylist",charIndex:4542},{level:3,title:"3.1 集合概述",slug:"_3-1-集合概述",normalizedTitle:"3.1 集合概述",charIndex:4559},{level:3,title:"3.2 ArrayList 集合",slug:"_3-2-arraylist-集合",normalizedTitle:"3.2 arraylist 集合",charIndex:4788},{level:4,title:"3.2.1 ArrayList集合的对象获取",slug:"_3-2-1-arraylist集合的对象获取",normalizedTitle:"3.2.1 arraylist集合的对象获取",charIndex:4849},{level:4,title:"3.2.2 ArrayList 对于泛型的支持",slug:"_3-2-2-arraylist-对于泛型的支持",normalizedTitle:"3.2.2 arraylist 对于泛型的支持",charIndex:4948},{level:3,title:"3.3 ArrayList 集合常用方法",slug:"_3-3-arraylist-集合常用方法",normalizedTitle:"3.3 arraylist 集合常用方法",charIndex:5195},{level:3,title:"3.4 ArrayList 集合易错点：遍历并删除元素",slug:"_3-4-arraylist-集合易错点-遍历并删除元素",normalizedTitle:"3.4 arraylist 集合易错点：遍历并删除元素",charIndex:5273}],headersStr:"1. API 1.1 API概述 2. String类 2.1 String类概述 2.2 String类的特点 2.3 String类创建对象的2种方式 2.3.1 两种方式 2.3.2 两种方式的区别？ 2.3.3 String 常见面试题 2.4 字符串内容比较 2.4.1 == 号的作用 2.4.2 equals 方法的作用 2.5 String 其他常用API 3. ArrayList 3.1 集合概述 3.2 ArrayList 集合 3.2.1 ArrayList集合的对象获取 3.2.2 ArrayList 对于泛型的支持 3.3 ArrayList 集合常用方法 3.4 ArrayList 集合易错点：遍历并删除元素",content:'12131231\n\n\n# 常用\n\n\n# 1. API\n\n\n# 1.1 API概述\n\n * 什么是API\n   \n   API (Application Programming Interface) ：应用程序编程接口\n\n * java中的API\n   \n   指的就是 JDK 中提供的各种功能的 Java类，这些类将底层的实现封装了起来，我们不需要关心这些类是如何实现的，只需要学习这些类如何使用即可，我们可以通过帮助文档来学习这些API如何使用。\n\n\n# 2. String类\n\n\n# 2.1 String类概述\n\nString 类代表字符串，Java 程序中的所有字符串文字（例如“abc”）都被实现为此类的实例。也就是说，Java 程序中所有的双引号字符串，都是 String 类的对象。String 类在 java.lang 包下，所以使用的时候不需要导包！\n\nString 是字符串类型，可以定义字符串变量指向字符串对象。\n\n\n# 2.2 String类的特点\n\n * String 常被称为不可变字符串类型，它的对象在创建后不能被更改。\n * 虽然 String 的值是不可变的，但是它们可以被共享\n * 字符串效果上相当于字符数组( char[] )，但是底层原理是字节数组( byte[] )\n\n字符串对象存在哪里？\n\n💡 以 “” 方式给出的字符串对象，在字符串常量池中存储。\n\n\n\n上图中，首先由 "" 给出了“传智”字符串常量，存储于字符串常量池；执行到当前此行时，将”教育“也存入字符串常量池，二者拿来做运算，新运算得到的对象“传智教育”直接放在堆内存中，并将 name （String 类变量）指向新的这个对象。因此 String 的对象创建出来之后的确未改变，只是每次都在指向新的对象，故说 String 的对象是不可变对象。\n\n下图同理。\n\n\n\nString 是不可变字符串的原因？\n\n * String 变量每次的修改其实都是产生并指向了新的字符串对象。\n * 原来的字符串对象都是没有改变的，所以称不可变字符串。\n\n\n# 2.3 String类创建对象的2种方式\n\n# 2.3.1 两种方式\n\n * 方式一：直接使用“”定义。（推荐方式）\n   \n   String name = "Nrich";\n\n * 方式二：通过String类的构造器创建对象。\n   \n   * 常用的构造方法：\n   \n   构造器                             说明\n   public String()                 创建一个空白字符串对象，不含有任何内容（基本不用）\n   public String(String original   根据传入的字符串内容，来创建字符串对象（基本不用）\n   public String(char[] chs)       根据字符数组的内容，来创建字符串对象\n   public String(byte[] chs)       根据字节数组的内容，来创建字符串对象\n   \n   * 示例代码\n     \n     public class StringDemo01 {\n         public static void main(String[] args) {\n             //public String()：创建一个空白字符串对象，不含有任何内容 [基本不用]\n             String s1 = new String();\n             System.out.println("s1:" + s1);\n     \n             //public String(char[] chs)：根据字符数组的内容，来创建字符串对象\n             char[] chs = {\'a\', \'b\', \'c\'};\n             String s2 = new String(chs);\n             System.out.println("s2:" + s2);\n     \n             //public String(byte[] bys)：根据字节数组的内容，来创建字符串对象\n             byte[] bys = {97, 98, 99};\n             String s3 = new String(bys);\n             System.out.println("s3:" + s3);\n     \n             //String s = “abc”;\t直接赋值的方式创建字符串对象，内容就是abc\n             String s4 = "abc";\n             System.out.println("s4:" + s4);\n         }\n     }\n     \n     \n     1\n     2\n     3\n     4\n     5\n     6\n     7\n     8\n     9\n     10\n     11\n     12\n     13\n     14\n     15\n     16\n     17\n     18\n     19\n     20\n     21\n     \n\n# 2.3.2 两种方式的区别？\n\n * 以“”方式给出的字符串对象，在字符串常量池中存储，而且相同内容只会在其中存储一份，以节省内存资源。\n   \n   下图中比较结果为 true，因为比较的是变量中所存的地址，输出是地址中的内容是因为做了别的处理。\n   \n   \n\n * 通过构造器new对象，每new一次都会产生一个新对象，放在堆内存中。\n\n\n\n * 代码示例：\n   \n   String s1 = "abc";\n   String s2 = "abc";\n   System.out.println(s1 == s2); // true\n   \n   char[] chs = {\'a\', \'b\', \'c\'};\n   String s3 = new String(chs);\n   String s4 = new String(chs);\n   \n   System.out.println(s3 == s4); // false\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   \n\n# 2.3.3 String 常见面试题\n\n问题 1 ：下列代码的运行结果是？\n\npublic class Test2 {\n    public static void main(String[] args) {\n        \n        String s2 = new String("abc");\n        \n        String s1 = "abc";\n        System.out.println(s1 == s2);\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n结果：false ⚠️\n\n说明：\n\nLine 4 实际上创建了两个对象，“abc” 在字符串常量池创建了一个，new 又在堆内存创建了一个。\n\nLine 6 实际上没有创建对象，直接共用 Line 4 在字符串常量池中创建的对象。\n\n堆内存图如下：\n\n问题 2 ：下列代码的运行结果分别是？\n\npublic class Test3 {\n    public static void main(String[] args) {\n        String s1 = "abc";\n        String s2 = "ab";\n        String s3 = s2 + "c";\n        System.out.println(s1 == s3);\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n结果：false\n\npublic class Test4 {\n    public static void main(String[] args) {\n        String s1 = "abc";\n        String s2 = "a" + "b" + "c";\n        System.out.println(s1 == s2);\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n结果：true ⚠️\n\n说明：Java存在编译优化机制，程序在编译时： “a” + “b” + “c” 会直接转成 "abc"。因为在编译时已可以确定这个值是啥，故不等到运行时再浪费性能进行计算。但当存在变量时，无法在编译阶段确定值是啥。\n\n\n# 2.4 字符串内容比较\n\n# 2.4.1 == 号的作用\n\n * 比较基本数据类型：比较的是具体的值\n * 比较引用数据类型：比较的是对象地址值\n\n# 2.4.2 equals 方法的作用\n\n方法名                                                      说明\npublic boolean equals (Object anObject)                  将此字符串与指定对象进行比较。只关心字符内容是否一致！\npublic boolean equalsIgnoreCase (String anotherString)   将此字符串与指定对象进行比较，忽略大小写比较字符串。只关心字符内容是否一致！\n\n * 示例代码\n   \n   public class StringDemo02 {\n       public static void main(String[] args) {\n           //构造方法的方式得到对象\n           char[] chs = {\'a\', \'b\', \'c\'};\n           String s1 = new String(chs);\n           String s2 = new String(chs);\n   \n           //比较字符串内容是否相同\n           System.out.println(s1.equals(s2));\n       }\n   }\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   10\n   11\n   \n\n\n# 2.5 String 其他常用API\n\n\n\n提示\n\n * Ctrl + Alt + V 可以直接生成变量\n * 截取倒数第 7 位到倒数第 4 位的子串：s.substring(s.length()-7, s.length()-4)\n\n\n# 3. ArrayList\n\n\n# 3.1 集合概述\n\n集合是与数组类似，也是一种容器，用于装数据的。\n\n * 数组的特点：\n   \n   数组定义完成并启动后，类型确定、长度固定。\n\n * 集合的特点\n   \n   集合的大小不固定，启动后可以动态变化，类型也可以选择不固定。\n   \n   集合非常适合做元素个数不确定，且要进行增删操作的业务场景。\n   \n   集合还提供了许多丰富、好用的功能，而数组的功能很单一。\n\n💡 注：集合中存储的元素并不是对象本身，而是对象的地址。\n\n\n# 3.2 ArrayList 集合\n\nArrayList是集合中的一种，它支持索引。底层是数组实现的，长度可以变化。\n\n# 3.2.1 ArrayList集合的对象获取\n\n使用构造器 public ArrayList()，创建一个空的集合对象。如：ArrayList list = new ArrayList();\n\n# 3.2.2 ArrayList 对于泛型的支持\n\nArrayList<E> ：一个泛型类，可以在编译阶段约束集合对象只能操作某种 E 数据类型。\n\n例如：\n\n * ArrayList<String> ：此集合只能操作字符串类型的元素。\n\n * ArrayList<Integer>：此集合只能操作整数类型的元素。\n\n⚠️ 注意：\n\n集合中只能存储引用类型，不支持基本数据类型。\n\nArrayList 一般都会使用泛型，哪怕需要啥类型都支持，也会加 ArrayList<Object>。\n\n\n# 3.3 ArrayList 集合常用方法\n\n * ArrayList 集合添加元素的方法：\n\n\n\n * ArrayList 集合其他常用方法：\n\n\n\n\n# 3.4 ArrayList 集合易错点：遍历并删除元素\n\n错误做法：\n\npublic class ArrayListTest {\n    public static void main(String[] args) {\n        //创建集合对象\n        ArrayList<Integer> scores = new ArrayList<>();\n\n        //添加成绩到集合中\n        scores.add(98);\n        scores.add(20);\n        scores.add(78);\n\n        //遍历集合，采用通用遍历格式实现\n        for (int i = 0; i < scores.size(); i++) {\n            int score = scores.get(i);\n            if (score < 80){\n                // 去掉成绩低于80分的\n                scores.remove(i);  \n            }\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n出现的问题：\n\n采用以上的常规 fori 形式边遍历边删除，会导致漏删部分元素。因为 ArrayList 的长度是动态变化的，删除之后会出现补位的情况。\n\n解决：\n\n① remove 之后， i-- 。即 Line 16 之后添加 i--;\n\n② 从集合后面倒着遍历然后删除，代码如下：\n\nfor (int i = scores.size() - 1; i >= 0 ; i--) {\n    int score = scores.get(i);\n    if (score < 80){\n        scores.remove(i);  \n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n',normalizedContent:'12131231\n\n\n# 常用\n\n\n# 1. api\n\n\n# 1.1 api概述\n\n * 什么是api\n   \n   api (application programming interface) ：应用程序编程接口\n\n * java中的api\n   \n   指的就是 jdk 中提供的各种功能的 java类，这些类将底层的实现封装了起来，我们不需要关心这些类是如何实现的，只需要学习这些类如何使用即可，我们可以通过帮助文档来学习这些api如何使用。\n\n\n# 2. string类\n\n\n# 2.1 string类概述\n\nstring 类代表字符串，java 程序中的所有字符串文字（例如“abc”）都被实现为此类的实例。也就是说，java 程序中所有的双引号字符串，都是 string 类的对象。string 类在 java.lang 包下，所以使用的时候不需要导包！\n\nstring 是字符串类型，可以定义字符串变量指向字符串对象。\n\n\n# 2.2 string类的特点\n\n * string 常被称为不可变字符串类型，它的对象在创建后不能被更改。\n * 虽然 string 的值是不可变的，但是它们可以被共享\n * 字符串效果上相当于字符数组( char[] )，但是底层原理是字节数组( byte[] )\n\n字符串对象存在哪里？\n\n💡 以 “” 方式给出的字符串对象，在字符串常量池中存储。\n\n\n\n上图中，首先由 "" 给出了“传智”字符串常量，存储于字符串常量池；执行到当前此行时，将”教育“也存入字符串常量池，二者拿来做运算，新运算得到的对象“传智教育”直接放在堆内存中，并将 name （string 类变量）指向新的这个对象。因此 string 的对象创建出来之后的确未改变，只是每次都在指向新的对象，故说 string 的对象是不可变对象。\n\n下图同理。\n\n\n\nstring 是不可变字符串的原因？\n\n * string 变量每次的修改其实都是产生并指向了新的字符串对象。\n * 原来的字符串对象都是没有改变的，所以称不可变字符串。\n\n\n# 2.3 string类创建对象的2种方式\n\n# 2.3.1 两种方式\n\n * 方式一：直接使用“”定义。（推荐方式）\n   \n   string name = "nrich";\n\n * 方式二：通过string类的构造器创建对象。\n   \n   * 常用的构造方法：\n   \n   构造器                             说明\n   public string()                 创建一个空白字符串对象，不含有任何内容（基本不用）\n   public string(string original   根据传入的字符串内容，来创建字符串对象（基本不用）\n   public string(char[] chs)       根据字符数组的内容，来创建字符串对象\n   public string(byte[] chs)       根据字节数组的内容，来创建字符串对象\n   \n   * 示例代码\n     \n     public class stringdemo01 {\n         public static void main(string[] args) {\n             //public string()：创建一个空白字符串对象，不含有任何内容 [基本不用]\n             string s1 = new string();\n             system.out.println("s1:" + s1);\n     \n             //public string(char[] chs)：根据字符数组的内容，来创建字符串对象\n             char[] chs = {\'a\', \'b\', \'c\'};\n             string s2 = new string(chs);\n             system.out.println("s2:" + s2);\n     \n             //public string(byte[] bys)：根据字节数组的内容，来创建字符串对象\n             byte[] bys = {97, 98, 99};\n             string s3 = new string(bys);\n             system.out.println("s3:" + s3);\n     \n             //string s = “abc”;\t直接赋值的方式创建字符串对象，内容就是abc\n             string s4 = "abc";\n             system.out.println("s4:" + s4);\n         }\n     }\n     \n     \n     1\n     2\n     3\n     4\n     5\n     6\n     7\n     8\n     9\n     10\n     11\n     12\n     13\n     14\n     15\n     16\n     17\n     18\n     19\n     20\n     21\n     \n\n# 2.3.2 两种方式的区别？\n\n * 以“”方式给出的字符串对象，在字符串常量池中存储，而且相同内容只会在其中存储一份，以节省内存资源。\n   \n   下图中比较结果为 true，因为比较的是变量中所存的地址，输出是地址中的内容是因为做了别的处理。\n   \n   \n\n * 通过构造器new对象，每new一次都会产生一个新对象，放在堆内存中。\n\n\n\n * 代码示例：\n   \n   string s1 = "abc";\n   string s2 = "abc";\n   system.out.println(s1 == s2); // true\n   \n   char[] chs = {\'a\', \'b\', \'c\'};\n   string s3 = new string(chs);\n   string s4 = new string(chs);\n   \n   system.out.println(s3 == s4); // false\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   \n\n# 2.3.3 string 常见面试题\n\n问题 1 ：下列代码的运行结果是？\n\npublic class test2 {\n    public static void main(string[] args) {\n        \n        string s2 = new string("abc");\n        \n        string s1 = "abc";\n        system.out.println(s1 == s2);\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n结果：false ⚠️\n\n说明：\n\nline 4 实际上创建了两个对象，“abc” 在字符串常量池创建了一个，new 又在堆内存创建了一个。\n\nline 6 实际上没有创建对象，直接共用 line 4 在字符串常量池中创建的对象。\n\n堆内存图如下：\n\n问题 2 ：下列代码的运行结果分别是？\n\npublic class test3 {\n    public static void main(string[] args) {\n        string s1 = "abc";\n        string s2 = "ab";\n        string s3 = s2 + "c";\n        system.out.println(s1 == s3);\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n结果：false\n\npublic class test4 {\n    public static void main(string[] args) {\n        string s1 = "abc";\n        string s2 = "a" + "b" + "c";\n        system.out.println(s1 == s2);\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n结果：true ⚠️\n\n说明：java存在编译优化机制，程序在编译时： “a” + “b” + “c” 会直接转成 "abc"。因为在编译时已可以确定这个值是啥，故不等到运行时再浪费性能进行计算。但当存在变量时，无法在编译阶段确定值是啥。\n\n\n# 2.4 字符串内容比较\n\n# 2.4.1 == 号的作用\n\n * 比较基本数据类型：比较的是具体的值\n * 比较引用数据类型：比较的是对象地址值\n\n# 2.4.2 equals 方法的作用\n\n方法名                                                      说明\npublic boolean equals (object anobject)                  将此字符串与指定对象进行比较。只关心字符内容是否一致！\npublic boolean equalsignorecase (string anotherstring)   将此字符串与指定对象进行比较，忽略大小写比较字符串。只关心字符内容是否一致！\n\n * 示例代码\n   \n   public class stringdemo02 {\n       public static void main(string[] args) {\n           //构造方法的方式得到对象\n           char[] chs = {\'a\', \'b\', \'c\'};\n           string s1 = new string(chs);\n           string s2 = new string(chs);\n   \n           //比较字符串内容是否相同\n           system.out.println(s1.equals(s2));\n       }\n   }\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   10\n   11\n   \n\n\n# 2.5 string 其他常用api\n\n\n\n提示\n\n * ctrl + alt + v 可以直接生成变量\n * 截取倒数第 7 位到倒数第 4 位的子串：s.substring(s.length()-7, s.length()-4)\n\n\n# 3. arraylist\n\n\n# 3.1 集合概述\n\n集合是与数组类似，也是一种容器，用于装数据的。\n\n * 数组的特点：\n   \n   数组定义完成并启动后，类型确定、长度固定。\n\n * 集合的特点\n   \n   集合的大小不固定，启动后可以动态变化，类型也可以选择不固定。\n   \n   集合非常适合做元素个数不确定，且要进行增删操作的业务场景。\n   \n   集合还提供了许多丰富、好用的功能，而数组的功能很单一。\n\n💡 注：集合中存储的元素并不是对象本身，而是对象的地址。\n\n\n# 3.2 arraylist 集合\n\narraylist是集合中的一种，它支持索引。底层是数组实现的，长度可以变化。\n\n# 3.2.1 arraylist集合的对象获取\n\n使用构造器 public arraylist()，创建一个空的集合对象。如：arraylist list = new arraylist();\n\n# 3.2.2 arraylist 对于泛型的支持\n\narraylist<e> ：一个泛型类，可以在编译阶段约束集合对象只能操作某种 e 数据类型。\n\n例如：\n\n * arraylist<string> ：此集合只能操作字符串类型的元素。\n\n * arraylist<integer>：此集合只能操作整数类型的元素。\n\n⚠️ 注意：\n\n集合中只能存储引用类型，不支持基本数据类型。\n\narraylist 一般都会使用泛型，哪怕需要啥类型都支持，也会加 arraylist<object>。\n\n\n# 3.3 arraylist 集合常用方法\n\n * arraylist 集合添加元素的方法：\n\n\n\n * arraylist 集合其他常用方法：\n\n\n\n\n# 3.4 arraylist 集合易错点：遍历并删除元素\n\n错误做法：\n\npublic class arraylisttest {\n    public static void main(string[] args) {\n        //创建集合对象\n        arraylist<integer> scores = new arraylist<>();\n\n        //添加成绩到集合中\n        scores.add(98);\n        scores.add(20);\n        scores.add(78);\n\n        //遍历集合，采用通用遍历格式实现\n        for (int i = 0; i < scores.size(); i++) {\n            int score = scores.get(i);\n            if (score < 80){\n                // 去掉成绩低于80分的\n                scores.remove(i);  \n            }\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n出现的问题：\n\n采用以上的常规 fori 形式边遍历边删除，会导致漏删部分元素。因为 arraylist 的长度是动态变化的，删除之后会出现补位的情况。\n\n解决：\n\n① remove 之后， i-- 。即 line 16 之后添加 i--;\n\n② 从集合后面倒着遍历然后删除，代码如下：\n\nfor (int i = scores.size() - 1; i >= 0 ; i--) {\n    int score = scores.get(i);\n    if (score < 80){\n        scores.remove(i);  \n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n',charsets:{cjk:!0},lastUpdated:"2023/02/01, 05:47:49",lastUpdatedTimestamp:1675230469e3},{title:"面向对象进阶1（static、单例、代码块、继承）",frontmatter:{title:"面向对象进阶1（static、单例、代码块、继承）",date:"2023-02-24T09:46:01.000Z",permalink:"/pages/46cfbb/",categories:["开发","Java","黑马Java入门基础-学习笔记"],tags:[null]},regularPath:"/%E5%BC%80%E5%8F%91/10.Java/05.%E9%BB%91%E9%A9%ACJava%E5%85%A5%E9%97%A8%E5%9F%BA%E7%A1%80-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/30.%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%BF%9B%E9%98%B61%EF%BC%88static%E3%80%81%E5%8D%95%E4%BE%8B%E3%80%81%E4%BB%A3%E7%A0%81%E5%9D%97%E3%80%81%E7%BB%A7%E6%89%BF%EF%BC%89.html",relativePath:"开发/10.Java/05.黑马Java入门基础-学习笔记/30.面向对象进阶1（static、单例、代码块、继承）.md",key:"v-7e68add3",path:"/pages/46cfbb/",headers:[{level:2,title:"1. static 关键字",slug:"_1-static-关键字",normalizedTitle:"1. static 关键字",charIndex:32},{level:3,title:"1.1 static 是什么、修饰成员变量和成员方法的用法",slug:"_1-1-static-是什么、修饰成员变量和成员方法的用法",normalizedTitle:"1.1 static 是什么、修饰成员变量和成员方法的用法",charIndex:50},{level:4,title:"1.1.1 static 是什么",slug:"_1-1-1-static-是什么",normalizedTitle:"1.1.1 static 是什么",charIndex:83},{level:4,title:"1.1.2 成员变量",slug:"_1-1-2-成员变量",normalizedTitle:"1.1.2 成员变量",charIndex:183},{level:4,title:"1.1.3 成员方法",slug:"_1-1-3-成员方法",normalizedTitle:"1.1.3 成员方法",charIndex:610},{level:3,title:"1.2 static 修饰成员变量的内存原理",slug:"_1-2-static-修饰成员变量的内存原理",normalizedTitle:"1.2 static 修饰成员变量的内存原理",charIndex:844},{level:3,title:"1.3 static 修饰成员方法的内存原理",slug:"_1-3-static-修饰成员方法的内存原理",normalizedTitle:"1.3 static 修饰成员方法的内存原理",charIndex:1073},{level:3,title:"1.4 static 访问的注意事项",slug:"_1-4-static-访问的注意事项",normalizedTitle:"1.4 static 访问的注意事项",charIndex:1266},{level:2,title:"2. static 应用知识",slug:"_2-static-应用知识",normalizedTitle:"2. static 应用知识",charIndex:1561},{level:3,title:"2.1 工具类",slug:"_2-1-工具类",normalizedTitle:"2.1 工具类",charIndex:1580},{level:4,title:"2.1.1 什么是工具类",slug:"_2-1-1-什么是工具类",normalizedTitle:"2.1.1 什么是工具类",charIndex:1591},{level:4,title:"2.1.2 工具类的好处",slug:"_2-1-2-工具类的好处",normalizedTitle:"2.1.2 工具类的好处",charIndex:1687},{level:4,title:"2.1.3 为什么工具类中的方法不用实例方法做？",slug:"_2-1-3-为什么工具类中的方法不用实例方法做",normalizedTitle:"2.1.3 为什么工具类中的方法不用实例方法做？",charIndex:1734},{level:4,title:"2.1.4 工具类定义时的其他要求（锦上添花）",slug:"_2-1-4-工具类定义时的其他要求-锦上添花",normalizedTitle:"2.1.4 工具类定义时的其他要求（锦上添花）",charIndex:1800},{level:3,title:"2.2 代码块",slug:"_2-2-代码块",normalizedTitle:"2.2 代码块",charIndex:1899},{level:4,title:"2.2.1 代码块概述",slug:"_2-2-1-代码块概述",normalizedTitle:"2.2.1 代码块概述",charIndex:1910},{level:4,title:"2.2.2 代码块分类",slug:"_2-2-2-代码块分类",normalizedTitle:"2.2.2 代码块分类",charIndex:2007},{level:4,title:"2.2.3 案例——斗地主游戏",slug:"_2-2-3-案例-斗地主游戏",normalizedTitle:"2.2.3 案例——斗地主游戏",charIndex:2877},{level:3,title:"2.3 设计模式：单例",slug:"_2-3-设计模式-单例",normalizedTitle:"2.3 设计模式：单例",charIndex:3126},{level:4,title:"2.3.1 什么是设计模式",slug:"_2-3-1-什么是设计模式",normalizedTitle:"2.3.1 什么是设计模式",charIndex:3141},{level:4,title:"2.3.2 单例模式",slug:"_2-3-2-单例模式",normalizedTitle:"2.3.2 单例模式",charIndex:3331},{level:4,title:"2.3.3 饿汉单例模式",slug:"_2-3-3-饿汉单例模式",normalizedTitle:"2.3.3 饿汉单例模式",charIndex:3456},{level:4,title:"2.3.4 懒汉单例模式",slug:"_2-3-4-懒汉单例模式",normalizedTitle:"2.3.4 懒汉单例模式",charIndex:4112},{level:4,title:"2.3.5 饿汉单例模式 VS 懒汉单例模式",slug:"_2-3-5-饿汉单例模式-vs-懒汉单例模式",normalizedTitle:"2.3.5 饿汉单例模式 vs 懒汉单例模式",charIndex:5035},{level:2,title:"4. 面向对象三大特征之二：继承",slug:"_4-面向对象三大特征之二-继承",normalizedTitle:"4. 面向对象三大特征之二：继承",charIndex:5124},{level:3,title:"4.1 继承概述",slug:"_4-1-继承概述",normalizedTitle:"4.1 继承概述",charIndex:5145},{level:3,title:"4.2 继承的设计规范",slug:"_4-2-继承的设计规范",normalizedTitle:"4.2 继承的设计规范",charIndex:5334},{level:3,title:"4.3 继承的内存运行原理",slug:"_4-3-继承的内存运行原理",normalizedTitle:"4.3 继承的内存运行原理",charIndex:5401},{level:3,title:"4.4 继承的特点",slug:"_4-4-继承的特点",normalizedTitle:"4.4 继承的特点",charIndex:5484},{level:3,title:"4.5 继承之后的特点",slug:"_4-5-继承之后的特点",normalizedTitle:"4.5 继承之后的特点",charIndex:6061},{level:4,title:"4.5.1 成员变量、成员方法的访问特点",slug:"_4-5-1-成员变量、成员方法的访问特点",normalizedTitle:"4.5.1 成员变量、成员方法的访问特点",charIndex:6076},{level:4,title:"4.5.2 继承后：方法重写",slug:"_4-5-2-继承后-方法重写",normalizedTitle:"4.5.2 继承后：方法重写",charIndex:6275},{level:4,title:"4.5.3 继承后：子类构造器的特点",slug:"_4-5-3-继承后-子类构造器的特点",normalizedTitle:"4.5.3 继承后：子类构造器的特点",charIndex:6892},{level:4,title:"4.5.4 继承后：子类构造器访问父类有参构造器",slug:"_4-5-4-继承后-子类构造器访问父类有参构造器",normalizedTitle:"4.5.4 继承后：子类构造器访问父类有参构造器",charIndex:7113},{level:3,title:"4.6 this、super 使用总结",slug:"_4-6-this、super-使用总结",normalizedTitle:"4.6 this、super 使用总结",charIndex:7392}],headersStr:"1. static 关键字 1.1 static 是什么、修饰成员变量和成员方法的用法 1.1.1 static 是什么 1.1.2 成员变量 1.1.3 成员方法 1.2 static 修饰成员变量的内存原理 1.3 static 修饰成员方法的内存原理 1.4 static 访问的注意事项 2. static 应用知识 2.1 工具类 2.1.1 什么是工具类 2.1.2 工具类的好处 2.1.3 为什么工具类中的方法不用实例方法做？ 2.1.4 工具类定义时的其他要求（锦上添花） 2.2 代码块 2.2.1 代码块概述 2.2.2 代码块分类 2.2.3 案例——斗地主游戏 2.3 设计模式：单例 2.3.1 什么是设计模式 2.3.2 单例模式 2.3.3 饿汉单例模式 2.3.4 懒汉单例模式 2.3.5 饿汉单例模式 VS 懒汉单例模式 4. 面向对象三大特征之二：继承 4.1 继承概述 4.2 继承的设计规范 4.3 继承的内存运行原理 4.4 继承的特点 4.5 继承之后的特点 4.5.1 成员变量、成员方法的访问特点 4.5.2 继承后：方法重写 4.5.3 继承后：子类构造器的特点 4.5.4 继承后：子类构造器访问父类有参构造器 4.6 this、super 使用总结",content:'# 面向对象进阶1（static、单例、代码块、继承）\n\n\n# 1. static 关键字\n\n\n# 1.1 static 是什么、修饰成员变量和成员方法的用法\n\n# 1.1.1 static 是什么\n\n * static 是静态的意思，可用来修饰成员变量和成员方法\n\n * static 修饰成员变量表示该成员变量只在内存中只存储一份，可以被共享访问、修改。\n\n# 1.1.2 成员变量\n\n成员变量可以分为2类：\n\n * 静态成员变量\n   \n   * 有 static 修饰，属于类，内存中加载一次\n   \n   * 常表示如在线人数信息、等需要被共享的信息，可以被共享访问\n   \n   * 示例代码\n     \n     public class User {\n         // 静态成员变量\n         public static String onlineNumber= 161;\n     }\n     \n     \n     1\n     2\n     3\n     4\n     \n   \n   * 访问格式：推荐使用 类名.静态成员变量，不推荐 对象.静态成员变量\n\n * 实例成员变量\n   \n   * 无static修饰，存在于每个对象中\n   * 常表示姓名name、年龄age、等属于每个对象的信息。属于每个对象，且每个对象的信息不同\n   * 访问格式：对象.实例成员变量\n\n# 1.1.3 成员方法\n\n成员方法可以分为2类：\n\n * 静态成员方法\n   * 有 static 修饰，属于类\n   * 使用场景：如果该方法是以执行一个共用功能为目的，则可以申明成静态方法\n   * 访问：建议用类名访问，也可以用对象访问。类名.静态成员方法\n * 实例成员方法\n   * 无 static 修饰，属于对象\n   * 使用场景：表示对象自己的行为的，且方法中需要访问实例成员的，则该方法必须申明成实例方法\n   * 访问：只能用对象触发访问\n\n\n# 1.2 static 修饰成员变量的内存原理\n\n在加载一个类时，会先将此类加载到方法区，同时会在堆内存中开辟一块此类的静态变量区\n\n-> 然后将 main 方法加载进栈内存运行\n\n注：此时内存中还没有 name、age 实例成员变量，因为他们是属于对象的\n\n\n\n-> 在创建对象时，才在堆内存中开辟一个新的空间出来。\n\n\n\n-> 有新的对象创建时，在堆内存中开辟另一个空间表示此对象。\n\n\n\n提示\n\n同一个类中访问静态成员变量时，类名可以省略不写。\n\n\n# 1.3 static 修饰成员方法的内存原理\n\n在初始加载类时，便会将该类的静态方法同时加载到内存的方法区中，但实例成员方法此时还不会加载进来。 执行图中的 getMax 方法时，将该方法提到栈内存中运行，输出结果之后进行下一步。\n\n\n\n-> 创建一个对象之后，在堆内存中开辟空间，并将实例成员方法 study 加载入方法区，在对象中指向对相应静态方法和该实例方法的引用。\n\n\n\n\n# 1.4 static 访问的注意事项\n\n * 静态方法只能访问静态的成员，不可以直接访问实例成员。\n   \n   * 只是不能直接在一个静态方法中访问实例成员变量，但可以先在此方法中先创建一个实例成员变量，然后访问其变量。\n   * 同时也不能直接访问实例成员方法。\n\n * 实例方法可以访问静态的成员，也可以访问实例成员。\n\n * 静态方法中是不可以出现 this 关键字的。\n   \n   * 因为 this 代表当前对象，但是静态方法可以不通过对象来调用。\n\n> 实例方法/变量 ∈ 对象，静态方法/变量 ∈ 类。 静态成员变量一般设为 public ，因为它全局只有一份。\n\n\n# 2. static 应用知识\n\n\n# 2.1 工具类\n\n# 2.1.1 什么是工具类\n\n工具类中定义的都是一些静态方法，每个方法都是以完成一个共用的功能为目的。\n\n比如：一个系统的很多部分都需要生成验证码，此时可以开发一个生成验证码的静态方法。\n\n# 2.1.2 工具类的好处\n\n * 调用方便\n * 提高了代码复用（一次编写，处处可用）\n\n# 2.1.3 为什么工具类中的方法不用实例方法做？\n\n实例方法需要创建对象调用，此时用对象只是为了调用方法，这样只会浪费内存。\n\n# 2.1.4 工具类定义时的其他要求（锦上添花）\n\n * 工具类中都是静态方法，直接用类名访问即可。\n * 工具类无需创建对象，建议将工具类的构造器进行私有化。（用 private 阉割掉）\n\n\n# 2.2 代码块\n\n# 2.2.1 代码块概述\n\n * 代码块是类的5大成分之一（成员变量、构造器，方法，代码块，内部类），定义在类中方法外。\n\n * 在Java类下，使用 { } 括起来的代码被称为代码块 。\n\n# 2.2.2 代码块分类\n\n * 静态代码块\n   \n   * 格式：static{}\n   \n   * 特点：需要通过 static 关键字修饰，随着类的加载而加载，并且自动触发、只执行一次\n   \n   * 作用：若要在启动系统时对数据进行初始化，建议使用静态代码块完成数据的初始化操作，代码优雅\n   \n   * 使用场景：在类加载的时候做一些静态数据初始化的操作，以便后续使用。比如，数据库的连接可以在 static { } 中执行，进行静态资源的初始化。\n   \n   * 代码示例：\n     \n     public class StaticDemo {\n         \n         public static void main(String[] args) {\n             System.out.println("----main方法执行----");\n         }\n         \n         /**\n          静态代码块：有static修饰，属于类，与类一起优先加载一次，自动触发执行\n         */\n         static {\n             System.out.println("----静态代码块被触发执行了----");\n         }\n     }\n     \n     // 以上代码中先触发静态代码块，然后执行main方法\n     \n     \n     1\n     2\n     3\n     4\n     5\n     6\n     7\n     8\n     9\n     10\n     11\n     12\n     13\n     14\n     15\n     \n\n * 构造代码块（了解，用的少）\n   \n   * 也可以叫实例代码块\n   * 格式：{}\n   * 特点：每次创建对象，调用构造器执行时，都会执行该代码块中的代码，并且在构造器执行前执行\n   * 使用场景：初始化实例资源。\n\n# 2.2.3 案例——斗地主游戏\n\n需求：\n\n在启动游戏房间的时候，应该提前准备好54张牌，后续才可以直接使用这些牌数据。\n\n分析：\n\n①该房间只需要一副牌。\n\n②定义一个静态的 ArrayList 集合存储 54 张牌对象，静态的集合只会加载一份。\n\n③在启动游戏房间前，应该将 54 张牌初始化好\n\n④当系统启动的同时需要准备好 54 张牌数据，此时可以用静态代码块完成。\n\n总结：\n\n需要提前准备数据，并且是只需要一份这个数据，因此使用 static 修饰的时候，需要用到静态代码块。\n\n\n# 2.3 设计模式：单例\n\n# 2.3.1 什么是设计模式\n\n * 开发中经常遇到一些问题，一个问题通常有n种解法的，但其中有一种解法是最优的，这个最优的解法被总结出来，称之为设计模式。\n\n * 设计模式有20多种，对应20多种软件开发中会遇到的问题，学设计模式主要是学2点：\n   \n   * 第一：这种模式用来解决什么问题。\n   * 第二：遇到这种问题了，该模式是怎么写的，他是如何解决这个问题的。\n\n# 2.3.2 单例模式\n\n可以保证系统中，应用该模式的这个类永远只有一个实例，即保证一个类永远只能创建一个对象。例如任务管理器对象我们只需要一个就可以解决问题了，这样可以节省内存空间。\n\n单例的实现方式有很多，如饿汉单例模式、懒汉单例模式，……\n\n# 2.3.3 饿汉单例模式\n\n * 在用类获取对象的时候，对象已经提前为你创建好了。\n\n * 设计步骤：\n   \n   * 定义一个类，把构造器私有\n   \n   * 定义一个静态变量存储一个对象\n\n * 代码示例：\n   \n   /** a、定义一个单例类 */\n   public class SingleInstance {\n       /** c.定义一个静态变量存储一个对象即可：属于类，与类一起加载一次 */\n       public static SingleInstance instance = new SingleInstance();\n       \n       /** b.单例必须私有构造器*/\n       private SingleInstance(){\n           System.out.println("创建了一个对象");\n       }\n   }\n   \n   \n   /** \n     别的类中的使用：直接获取该单例的对象\n   */\n   SingleInstance s1 = SingleInstance.instance;\n   \n   // 当有多条语句创建s1、s2、s3...时，他们都是相等的，是同一个对象\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   10\n   11\n   12\n   13\n   14\n   15\n   16\n   17\n   18\n   \n\n# 2.3.4 懒汉单例模式\n\n * 在真正需要该对象的时候，才去创建一个对象(延迟加载对象)。\n\n * 设计步骤：\n   \n   * 定义一个类，把构造器私有\n   * 定义一个静态变量存储一个对象\n   * 提供一个返回单例对象的方法\n\n * 代码示例：\n   \n   /** 定义一个单例类 */\n   class SingleInstance{\n       /** 定义一个静态变量存储一个对象即可:属于类，与类一起加载一次 */\n       private static SingleInstance instance ; // 默认值：null\n       \n       /** 单例必须私有构造器*/\n       private SingleInstance(){\n           \n       }\n       \n       /** 必须提供一个方法返回一个单例对象  */\n       public static SingleInstance getInstance(){\n           if(instance == null){\n           \t// 第一次来拿对象：此时需要创建对象    \n   \t        instance = new SingleInstance();\n           }\n           return instance;\n       }\n   }\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   10\n   11\n   12\n   13\n   14\n   15\n   16\n   17\n   18\n   19\n   \n   \n   ⚠️ 上述代码中，line 4 中用 private 修饰对象，此时无法从该类外部使用 SingleInstance s1 = SingleInstance.instance 获取对象了，只能使用SingleInstance s1 = SingleInstance.getInstance() 获取。否则可能会拿到 null 值，不符合需求。\n\n# 2.3.5 饿汉单例模式 VS 懒汉单例模式\n\n懒汉单例模式节省内存，在不需要创建对象时，不会在栈内存中创建内存。\n\n饿汉单例模式更快些，当需要对象时，已经在内存中了。\n\n\n# 4. 面向对象三大特征之二：继承\n\n\n# 4.1 继承概述\n\n * 关键字：extends，建立两个类之间的父子关系\n\n * 基本使用：public class Student extends People {} 。 Student 称为子类（派生类），People 称为父类(基类 或超类)。\n\n * 好处：子类继承父类后，可以直接使用父类公共的属性和方法了。因此，用好这个技术可以很好的我们提高代码的复用性\n\n\n# 4.2 继承的设计规范\n\n子类们相同特征（共性属性，共性方法）放在父类中定义，子类独有的的属性和行为应该定义在子类自己里面。\n\n\n# 4.3 继承的内存运行原理\n\n创建一个子类对象时，实际会在堆内存中分为父类空间和子类空间两部分；对外是一个对象，对内会分为两部分，整个代表一个子类对象。\n\n\n\n\n# 4.4 继承的特点\n\n * 子类可以继承父类的属性和行为，但是子类不能继承父类的构造器。\n   \n   * 子类有自己的构造器，父类构造器用于初始化父类对象。\n\n * Java是单继承模式：一个类只能继承一个直接父类。\n   \n   * 为啥？反证，当多个爸爸中让你复习不一样的内容，那你就不知道该复习哪门啦，出现了二义性\n\n * Java不支持多继承、但是支持多层继承。\n   \n   * 多层继承：儿子 -> 爸爸 -> 爷爷\n   * 基于就近原则使用父类中的成员变量和成员方法\n\n * Java中所有的类都是 Object 类的子类。\n   \n   * 要么直接继承了Object , 要么默认继承了Object , 要么间接继承了Object\n   * Object是祖宗类。\n\n一些小注意点\n\n 1. 子类是否可以继承父类的私有成员？\n    \n    子类可以继承父类的私有成员，但不能直接访问。如，大头儿子继承了小头爸爸的保险柜，但他没有密码，打不开。\n\n 2. 子类是否可以继承父类的静态成员？\n    \n    有争议的知识点。\n    \n    子类可以直接使用父类的静态成员（共享）。\n    \n    但黑马认为：子类不能继承父类的静态成员。（共享并非继承）。如，爸爸的车给儿子开，这只是共享，不是继承，车没有给儿子。\n\n\n# 4.5 继承之后的特点\n\n# 4.5.1 成员变量、成员方法的访问特点\n\n * 在子类方法中访问成员（成员变量、成员方法）满足：就近原则\n   * 子类局部范围找 → 子类成员范围找 → 父类成员范围找，如果父类范围还没有找到则报错。\n * 在子类中使用父类的重名成员怎么办？\n   * 子类父类出现重名成员，优先使用子类的\n   * 可通过 super 关键字，指定访问父类的成员，格式：super.父类成员变量/方法\n\n# 4.5.2 继承后：方法重写\n\n方法重写的基本知识：\n\n * 什么是方法重写？\n   * 在继承体系中，子类出现了和父类中一模一样的方法声明，称子类的这个方法是重写的方法。\n * 方法重写的应用场景\n   * 子类需要父类的功能，但父类的该功能不完全满足自己的需求时\n * 案例：\n   * 旧手机的功能只能是基本的打电话，发信息\n   * 新手机的功能需要能够：基本的打电话下支持视频通话。基本的发信息下支持发送语音和图片\n\n@override 注解：\n\n * @Override 是放在重写后的方法上，作为重写是否正确的校验注解。\n * 加上该注解后如果重写错误，编译阶段会出现错误提示。\n * 建议重写方法都加 @Override 注解，代码安全，优雅！\n\n方法重写注意事项和要求：\n\n * 重写方法的名称、形参列表必须与被重写方法的名称和参数列表一致（申明必须一样，访问权限也一般都是一样的）。\n   * 申明不变，重新实现\n * 私有方法不能被重写。\n * 子类重写父类方法时，访问权限必须大于或者等于父类 （private < 缺省 < protected < public）\n * 子类不能重写父类的静态方法，如果重写会报错的。\n   * 原因：子类本身就没有继承到父类的静态方法，只是共享，因此无法覆盖它。调用中也是父类的静态方法用 “父类名.父类静态方法名” 调用，子类的用子类对应的方法调用，不会互相影响。\n\n# 4.5.3 继承后：子类构造器的特点\n\n子类继承父类后构造器的特点：\n\n * 子类中所有的构造器默认都会先访问父类的**无参构造器**，再执行自己。\n\n原因：\n\n * 子类在初始化的时候，有可能会使用到父类中的数据，如果父类没有完成初始化，子类将无法使用父类的数据。\n * 子类初始化之前，一定要调用父类构造器先完成父类数据空间的初始化。\n\n怎么调用父类构造器的？\n\n * 子类构造器的第一行语句默认都是：super()，不写也存在。\n\n# 4.5.4 继承后：子类构造器访问父类有参构造器\n\nsuper调用父类有参数构造器的作用：\n\n * 初始化继承自父类的数据。\n * 即，Teacher 类继承了 People 类，在 Teacher 中初始化 People 定义好的 name，age\n\n如果父类中没有无参数构造器，只有有参构造器，会出现什么现象呢？\n\n * 会报错。因为子类默认是调用父类无参构造器的。\n\n * 但子类中如果只调用了父类的有参构造器，是不会报错的。\n\n * 解决：子类构造器中通过 super(…)，手动调用父类的有参数构造器\n\n * 建议：将无参构造器全都写出来\n\n\n# 4.6 this、super 使用总结\n\n * this：代表本类对象的引用；\n\n * super：代表父类存储空间的标识。\n\n * 示例代码\n   \n   /**\n   \t后台创建对象封装数据的时候如果用户没有输入学校，则默认使用“黑马培训中心”;如果用户输入了学校则使用用户输入的学校信息\n   */\n   public class Student {        \n       private String schoolName;\n       private String name;\n      \n       public Student(String name){\n             this(name , “黑马培训中心”);\t// 调用两个参数的构造器\n       }\t\n        \n       public Student(String name , String schoolName ){\n             this.name = name;\n           this.schoolName = schoolName;\n       }\t\n   }\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   10\n   11\n   12\n   13\n   14\n   15\n   16\n   \n\nthis(...) 和 super(...) 使用注意点\n\n * 子类通过 this (...）去调用本类的其他构造器（如有参构造器），本类其他构造器会通过 super 去手动调用父类的构造器，最终还是会调用父类构造器的。\n\n * this(…) super(…) 都只能放在构造器的第一行，所以二者不能共存在同一个构造器中。\n   \n   * 用 this() 构造器时，可能会调用兄弟构造器，兄弟构造器也会调用他爸 super()，若自己也调用super()，会造成调用两次 super()',normalizedContent:'# 面向对象进阶1（static、单例、代码块、继承）\n\n\n# 1. static 关键字\n\n\n# 1.1 static 是什么、修饰成员变量和成员方法的用法\n\n# 1.1.1 static 是什么\n\n * static 是静态的意思，可用来修饰成员变量和成员方法\n\n * static 修饰成员变量表示该成员变量只在内存中只存储一份，可以被共享访问、修改。\n\n# 1.1.2 成员变量\n\n成员变量可以分为2类：\n\n * 静态成员变量\n   \n   * 有 static 修饰，属于类，内存中加载一次\n   \n   * 常表示如在线人数信息、等需要被共享的信息，可以被共享访问\n   \n   * 示例代码\n     \n     public class user {\n         // 静态成员变量\n         public static string onlinenumber= 161;\n     }\n     \n     \n     1\n     2\n     3\n     4\n     \n   \n   * 访问格式：推荐使用 类名.静态成员变量，不推荐 对象.静态成员变量\n\n * 实例成员变量\n   \n   * 无static修饰，存在于每个对象中\n   * 常表示姓名name、年龄age、等属于每个对象的信息。属于每个对象，且每个对象的信息不同\n   * 访问格式：对象.实例成员变量\n\n# 1.1.3 成员方法\n\n成员方法可以分为2类：\n\n * 静态成员方法\n   * 有 static 修饰，属于类\n   * 使用场景：如果该方法是以执行一个共用功能为目的，则可以申明成静态方法\n   * 访问：建议用类名访问，也可以用对象访问。类名.静态成员方法\n * 实例成员方法\n   * 无 static 修饰，属于对象\n   * 使用场景：表示对象自己的行为的，且方法中需要访问实例成员的，则该方法必须申明成实例方法\n   * 访问：只能用对象触发访问\n\n\n# 1.2 static 修饰成员变量的内存原理\n\n在加载一个类时，会先将此类加载到方法区，同时会在堆内存中开辟一块此类的静态变量区\n\n-> 然后将 main 方法加载进栈内存运行\n\n注：此时内存中还没有 name、age 实例成员变量，因为他们是属于对象的\n\n\n\n-> 在创建对象时，才在堆内存中开辟一个新的空间出来。\n\n\n\n-> 有新的对象创建时，在堆内存中开辟另一个空间表示此对象。\n\n\n\n提示\n\n同一个类中访问静态成员变量时，类名可以省略不写。\n\n\n# 1.3 static 修饰成员方法的内存原理\n\n在初始加载类时，便会将该类的静态方法同时加载到内存的方法区中，但实例成员方法此时还不会加载进来。 执行图中的 getmax 方法时，将该方法提到栈内存中运行，输出结果之后进行下一步。\n\n\n\n-> 创建一个对象之后，在堆内存中开辟空间，并将实例成员方法 study 加载入方法区，在对象中指向对相应静态方法和该实例方法的引用。\n\n\n\n\n# 1.4 static 访问的注意事项\n\n * 静态方法只能访问静态的成员，不可以直接访问实例成员。\n   \n   * 只是不能直接在一个静态方法中访问实例成员变量，但可以先在此方法中先创建一个实例成员变量，然后访问其变量。\n   * 同时也不能直接访问实例成员方法。\n\n * 实例方法可以访问静态的成员，也可以访问实例成员。\n\n * 静态方法中是不可以出现 this 关键字的。\n   \n   * 因为 this 代表当前对象，但是静态方法可以不通过对象来调用。\n\n> 实例方法/变量 ∈ 对象，静态方法/变量 ∈ 类。 静态成员变量一般设为 public ，因为它全局只有一份。\n\n\n# 2. static 应用知识\n\n\n# 2.1 工具类\n\n# 2.1.1 什么是工具类\n\n工具类中定义的都是一些静态方法，每个方法都是以完成一个共用的功能为目的。\n\n比如：一个系统的很多部分都需要生成验证码，此时可以开发一个生成验证码的静态方法。\n\n# 2.1.2 工具类的好处\n\n * 调用方便\n * 提高了代码复用（一次编写，处处可用）\n\n# 2.1.3 为什么工具类中的方法不用实例方法做？\n\n实例方法需要创建对象调用，此时用对象只是为了调用方法，这样只会浪费内存。\n\n# 2.1.4 工具类定义时的其他要求（锦上添花）\n\n * 工具类中都是静态方法，直接用类名访问即可。\n * 工具类无需创建对象，建议将工具类的构造器进行私有化。（用 private 阉割掉）\n\n\n# 2.2 代码块\n\n# 2.2.1 代码块概述\n\n * 代码块是类的5大成分之一（成员变量、构造器，方法，代码块，内部类），定义在类中方法外。\n\n * 在java类下，使用 { } 括起来的代码被称为代码块 。\n\n# 2.2.2 代码块分类\n\n * 静态代码块\n   \n   * 格式：static{}\n   \n   * 特点：需要通过 static 关键字修饰，随着类的加载而加载，并且自动触发、只执行一次\n   \n   * 作用：若要在启动系统时对数据进行初始化，建议使用静态代码块完成数据的初始化操作，代码优雅\n   \n   * 使用场景：在类加载的时候做一些静态数据初始化的操作，以便后续使用。比如，数据库的连接可以在 static { } 中执行，进行静态资源的初始化。\n   \n   * 代码示例：\n     \n     public class staticdemo {\n         \n         public static void main(string[] args) {\n             system.out.println("----main方法执行----");\n         }\n         \n         /**\n          静态代码块：有static修饰，属于类，与类一起优先加载一次，自动触发执行\n         */\n         static {\n             system.out.println("----静态代码块被触发执行了----");\n         }\n     }\n     \n     // 以上代码中先触发静态代码块，然后执行main方法\n     \n     \n     1\n     2\n     3\n     4\n     5\n     6\n     7\n     8\n     9\n     10\n     11\n     12\n     13\n     14\n     15\n     \n\n * 构造代码块（了解，用的少）\n   \n   * 也可以叫实例代码块\n   * 格式：{}\n   * 特点：每次创建对象，调用构造器执行时，都会执行该代码块中的代码，并且在构造器执行前执行\n   * 使用场景：初始化实例资源。\n\n# 2.2.3 案例——斗地主游戏\n\n需求：\n\n在启动游戏房间的时候，应该提前准备好54张牌，后续才可以直接使用这些牌数据。\n\n分析：\n\n①该房间只需要一副牌。\n\n②定义一个静态的 arraylist 集合存储 54 张牌对象，静态的集合只会加载一份。\n\n③在启动游戏房间前，应该将 54 张牌初始化好\n\n④当系统启动的同时需要准备好 54 张牌数据，此时可以用静态代码块完成。\n\n总结：\n\n需要提前准备数据，并且是只需要一份这个数据，因此使用 static 修饰的时候，需要用到静态代码块。\n\n\n# 2.3 设计模式：单例\n\n# 2.3.1 什么是设计模式\n\n * 开发中经常遇到一些问题，一个问题通常有n种解法的，但其中有一种解法是最优的，这个最优的解法被总结出来，称之为设计模式。\n\n * 设计模式有20多种，对应20多种软件开发中会遇到的问题，学设计模式主要是学2点：\n   \n   * 第一：这种模式用来解决什么问题。\n   * 第二：遇到这种问题了，该模式是怎么写的，他是如何解决这个问题的。\n\n# 2.3.2 单例模式\n\n可以保证系统中，应用该模式的这个类永远只有一个实例，即保证一个类永远只能创建一个对象。例如任务管理器对象我们只需要一个就可以解决问题了，这样可以节省内存空间。\n\n单例的实现方式有很多，如饿汉单例模式、懒汉单例模式，……\n\n# 2.3.3 饿汉单例模式\n\n * 在用类获取对象的时候，对象已经提前为你创建好了。\n\n * 设计步骤：\n   \n   * 定义一个类，把构造器私有\n   \n   * 定义一个静态变量存储一个对象\n\n * 代码示例：\n   \n   /** a、定义一个单例类 */\n   public class singleinstance {\n       /** c.定义一个静态变量存储一个对象即可：属于类，与类一起加载一次 */\n       public static singleinstance instance = new singleinstance();\n       \n       /** b.单例必须私有构造器*/\n       private singleinstance(){\n           system.out.println("创建了一个对象");\n       }\n   }\n   \n   \n   /** \n     别的类中的使用：直接获取该单例的对象\n   */\n   singleinstance s1 = singleinstance.instance;\n   \n   // 当有多条语句创建s1、s2、s3...时，他们都是相等的，是同一个对象\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   10\n   11\n   12\n   13\n   14\n   15\n   16\n   17\n   18\n   \n\n# 2.3.4 懒汉单例模式\n\n * 在真正需要该对象的时候，才去创建一个对象(延迟加载对象)。\n\n * 设计步骤：\n   \n   * 定义一个类，把构造器私有\n   * 定义一个静态变量存储一个对象\n   * 提供一个返回单例对象的方法\n\n * 代码示例：\n   \n   /** 定义一个单例类 */\n   class singleinstance{\n       /** 定义一个静态变量存储一个对象即可:属于类，与类一起加载一次 */\n       private static singleinstance instance ; // 默认值：null\n       \n       /** 单例必须私有构造器*/\n       private singleinstance(){\n           \n       }\n       \n       /** 必须提供一个方法返回一个单例对象  */\n       public static singleinstance getinstance(){\n           if(instance == null){\n           \t// 第一次来拿对象：此时需要创建对象    \n   \t        instance = new singleinstance();\n           }\n           return instance;\n       }\n   }\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   10\n   11\n   12\n   13\n   14\n   15\n   16\n   17\n   18\n   19\n   \n   \n   ⚠️ 上述代码中，line 4 中用 private 修饰对象，此时无法从该类外部使用 singleinstance s1 = singleinstance.instance 获取对象了，只能使用singleinstance s1 = singleinstance.getinstance() 获取。否则可能会拿到 null 值，不符合需求。\n\n# 2.3.5 饿汉单例模式 vs 懒汉单例模式\n\n懒汉单例模式节省内存，在不需要创建对象时，不会在栈内存中创建内存。\n\n饿汉单例模式更快些，当需要对象时，已经在内存中了。\n\n\n# 4. 面向对象三大特征之二：继承\n\n\n# 4.1 继承概述\n\n * 关键字：extends，建立两个类之间的父子关系\n\n * 基本使用：public class student extends people {} 。 student 称为子类（派生类），people 称为父类(基类 或超类)。\n\n * 好处：子类继承父类后，可以直接使用父类公共的属性和方法了。因此，用好这个技术可以很好的我们提高代码的复用性\n\n\n# 4.2 继承的设计规范\n\n子类们相同特征（共性属性，共性方法）放在父类中定义，子类独有的的属性和行为应该定义在子类自己里面。\n\n\n# 4.3 继承的内存运行原理\n\n创建一个子类对象时，实际会在堆内存中分为父类空间和子类空间两部分；对外是一个对象，对内会分为两部分，整个代表一个子类对象。\n\n\n\n\n# 4.4 继承的特点\n\n * 子类可以继承父类的属性和行为，但是子类不能继承父类的构造器。\n   \n   * 子类有自己的构造器，父类构造器用于初始化父类对象。\n\n * java是单继承模式：一个类只能继承一个直接父类。\n   \n   * 为啥？反证，当多个爸爸中让你复习不一样的内容，那你就不知道该复习哪门啦，出现了二义性\n\n * java不支持多继承、但是支持多层继承。\n   \n   * 多层继承：儿子 -> 爸爸 -> 爷爷\n   * 基于就近原则使用父类中的成员变量和成员方法\n\n * java中所有的类都是 object 类的子类。\n   \n   * 要么直接继承了object , 要么默认继承了object , 要么间接继承了object\n   * object是祖宗类。\n\n一些小注意点\n\n 1. 子类是否可以继承父类的私有成员？\n    \n    子类可以继承父类的私有成员，但不能直接访问。如，大头儿子继承了小头爸爸的保险柜，但他没有密码，打不开。\n\n 2. 子类是否可以继承父类的静态成员？\n    \n    有争议的知识点。\n    \n    子类可以直接使用父类的静态成员（共享）。\n    \n    但黑马认为：子类不能继承父类的静态成员。（共享并非继承）。如，爸爸的车给儿子开，这只是共享，不是继承，车没有给儿子。\n\n\n# 4.5 继承之后的特点\n\n# 4.5.1 成员变量、成员方法的访问特点\n\n * 在子类方法中访问成员（成员变量、成员方法）满足：就近原则\n   * 子类局部范围找 → 子类成员范围找 → 父类成员范围找，如果父类范围还没有找到则报错。\n * 在子类中使用父类的重名成员怎么办？\n   * 子类父类出现重名成员，优先使用子类的\n   * 可通过 super 关键字，指定访问父类的成员，格式：super.父类成员变量/方法\n\n# 4.5.2 继承后：方法重写\n\n方法重写的基本知识：\n\n * 什么是方法重写？\n   * 在继承体系中，子类出现了和父类中一模一样的方法声明，称子类的这个方法是重写的方法。\n * 方法重写的应用场景\n   * 子类需要父类的功能，但父类的该功能不完全满足自己的需求时\n * 案例：\n   * 旧手机的功能只能是基本的打电话，发信息\n   * 新手机的功能需要能够：基本的打电话下支持视频通话。基本的发信息下支持发送语音和图片\n\n@override 注解：\n\n * @override 是放在重写后的方法上，作为重写是否正确的校验注解。\n * 加上该注解后如果重写错误，编译阶段会出现错误提示。\n * 建议重写方法都加 @override 注解，代码安全，优雅！\n\n方法重写注意事项和要求：\n\n * 重写方法的名称、形参列表必须与被重写方法的名称和参数列表一致（申明必须一样，访问权限也一般都是一样的）。\n   * 申明不变，重新实现\n * 私有方法不能被重写。\n * 子类重写父类方法时，访问权限必须大于或者等于父类 （private < 缺省 < protected < public）\n * 子类不能重写父类的静态方法，如果重写会报错的。\n   * 原因：子类本身就没有继承到父类的静态方法，只是共享，因此无法覆盖它。调用中也是父类的静态方法用 “父类名.父类静态方法名” 调用，子类的用子类对应的方法调用，不会互相影响。\n\n# 4.5.3 继承后：子类构造器的特点\n\n子类继承父类后构造器的特点：\n\n * 子类中所有的构造器默认都会先访问父类的**无参构造器**，再执行自己。\n\n原因：\n\n * 子类在初始化的时候，有可能会使用到父类中的数据，如果父类没有完成初始化，子类将无法使用父类的数据。\n * 子类初始化之前，一定要调用父类构造器先完成父类数据空间的初始化。\n\n怎么调用父类构造器的？\n\n * 子类构造器的第一行语句默认都是：super()，不写也存在。\n\n# 4.5.4 继承后：子类构造器访问父类有参构造器\n\nsuper调用父类有参数构造器的作用：\n\n * 初始化继承自父类的数据。\n * 即，teacher 类继承了 people 类，在 teacher 中初始化 people 定义好的 name，age\n\n如果父类中没有无参数构造器，只有有参构造器，会出现什么现象呢？\n\n * 会报错。因为子类默认是调用父类无参构造器的。\n\n * 但子类中如果只调用了父类的有参构造器，是不会报错的。\n\n * 解决：子类构造器中通过 super(…)，手动调用父类的有参数构造器\n\n * 建议：将无参构造器全都写出来\n\n\n# 4.6 this、super 使用总结\n\n * this：代表本类对象的引用；\n\n * super：代表父类存储空间的标识。\n\n * 示例代码\n   \n   /**\n   \t后台创建对象封装数据的时候如果用户没有输入学校，则默认使用“黑马培训中心”;如果用户输入了学校则使用用户输入的学校信息\n   */\n   public class student {        \n       private string schoolname;\n       private string name;\n      \n       public student(string name){\n             this(name , “黑马培训中心”);\t// 调用两个参数的构造器\n       }\t\n        \n       public student(string name , string schoolname ){\n             this.name = name;\n           this.schoolname = schoolname;\n       }\t\n   }\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   10\n   11\n   12\n   13\n   14\n   15\n   16\n   \n\nthis(...) 和 super(...) 使用注意点\n\n * 子类通过 this (...）去调用本类的其他构造器（如有参构造器），本类其他构造器会通过 super 去手动调用父类的构造器，最终还是会调用父类构造器的。\n\n * this(…) super(…) 都只能放在构造器的第一行，所以二者不能共存在同一个构造器中。\n   \n   * 用 this() 构造器时，可能会调用兄弟构造器，兄弟构造器也会调用他爸 super()，若自己也调用super()，会造成调用两次 super()',charsets:{cjk:!0},lastUpdated:"2023/03/15, 14:34:12",lastUpdatedTimestamp:1678890852e3},{title:"面向对象进阶2（包、权限修饰符、抽象类、接口）",frontmatter:{title:"面向对象进阶2（包、权限修饰符、抽象类、接口）",date:"2023-02-28T10:16:51.000Z",permalink:"/pages/b127ae/",categories:["开发","Java","黑马Java入门基础-学习笔记"],tags:[null]},regularPath:"/%E5%BC%80%E5%8F%91/10.Java/05.%E9%BB%91%E9%A9%ACJava%E5%85%A5%E9%97%A8%E5%9F%BA%E7%A1%80-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/31.%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%BF%9B%E9%98%B62%EF%BC%88%E5%8C%85%E3%80%81%E6%9D%83%E9%99%90%E4%BF%AE%E9%A5%B0%E7%AC%A6%E3%80%81%E6%8A%BD%E8%B1%A1%E7%B1%BB%E3%80%81%E6%8E%A5%E5%8F%A3%EF%BC%89.html",relativePath:"开发/10.Java/05.黑马Java入门基础-学习笔记/31.面向对象进阶2（包、权限修饰符、抽象类、接口）.md",key:"v-087079a8",path:"/pages/b127ae/",headers:[{level:2,title:"1. 包",slug:"_1-包",normalizedTitle:"1. 包",charIndex:30},{level:3,title:"1.1 什么是包",slug:"_1-1-什么是包",normalizedTitle:"1.1 什么是包",charIndex:39},{level:3,title:"1.2 导包",slug:"_1-2-导包",normalizedTitle:"1.2 导包",charIndex:302},{level:2,title:"2. 权限修饰符",slug:"_2-权限修饰符",normalizedTitle:"2. 权限修饰符",charIndex:423},{level:3,title:"2.1 什么是权限修饰符？",slug:"_2-1-什么是权限修饰符",normalizedTitle:"2.1 什么是权限修饰符？",charIndex:436},{level:3,title:"2.2 权限修饰符的分类和作用范围",slug:"_2-2-权限修饰符的分类和作用范围",normalizedTitle:"2.2 权限修饰符的分类和作用范围",charIndex:528},{level:3,title:"2.3 权限修饰符的使用",slug:"_2-3-权限修饰符的使用",normalizedTitle:"2.3 权限修饰符的使用",charIndex:843},{level:2,title:"3. final 关键字及常量、枚举",slug:"_3-final-关键字及常量、枚举",normalizedTitle:"3. final 关键字及常量、枚举",charIndex:1033},{level:2,title:"3.1 final 关键字",slug:"_3-1-final-关键字",normalizedTitle:"3.1 final 关键字",charIndex:1056},{level:3,title:"3.2 常量",slug:"_3-2-常量",normalizedTitle:"3.2 常量",charIndex:1563},{level:4,title:"3.2.1 常量概述和基本作用",slug:"_3-2-1-常量概述和基本作用",normalizedTitle:"3.2.1 常量概述和基本作用",charIndex:1573},{level:4,title:"3.2.2 常量做信息标志和分类",slug:"_3-2-2-常量做信息标志和分类",normalizedTitle:"3.2.2 常量做信息标志和分类",charIndex:1834},{level:3,title:"3.3 枚举",slug:"_3-3-枚举",normalizedTitle:"3.3 枚举",charIndex:2058},{level:4,title:"3.3.1 枚举的概述",slug:"_3-3-1-枚举的概述",normalizedTitle:"3.3.1 枚举的概述",charIndex:2068},{level:4,title:"3.3.2 枚举的使用场景",slug:"_3-3-2-枚举的使用场景",normalizedTitle:"3.3.2 枚举的使用场景",charIndex:3171},{level:2,title:"4. 抽象类",slug:"_4-抽象类",normalizedTitle:"4. 抽象类",charIndex:3367},{level:3,title:"4.1 抽象类概述",slug:"_4-1-抽象类概述",normalizedTitle:"4.1 抽象类概述",charIndex:3378},{level:3,title:"4.2 抽象类的案例",slug:"_4-2-抽象类的案例",normalizedTitle:"4.2 抽象类的案例",charIndex:3664},{level:3,title:"4.3 设计模式：模板方法模式",slug:"_4-3-设计模式-模板方法模式",normalizedTitle:"4.3 设计模式：模板方法模式",charIndex:4297},{level:4,title:"4.3.1 模板方法模式的使用场景",slug:"_4-3-1-模板方法模式的使用场景",normalizedTitle:"4.3.1 模板方法模式的使用场景",charIndex:4332},{level:4,title:"4.3.2 模板方法模式的实现步骤",slug:"_4-3-2-模板方法模式的实现步骤",normalizedTitle:"4.3.2 模板方法模式的实现步骤",charIndex:4411},{level:4,title:"4.3.3 案例：中小学生写作文",slug:"_4-3-3-案例-中小学生写作文",normalizedTitle:"4.3.3 案例：中小学生写作文",charIndex:4516},{level:2,title:"5. 接口",slug:"_5-接口",normalizedTitle:"5. 接口",charIndex:4765},{level:3,title:"5.1 接口的概述和特点",slug:"_5-1-接口的概述和特点",normalizedTitle:"5.1 接口的概述和特点",charIndex:4775},{level:4,title:"5.1.1 啥是接口",slug:"_5-1-1-啥是接口",normalizedTitle:"5.1.1 啥是接口",charIndex:4791},{level:4,title:"5.1.2 接口的特点",slug:"_5-1-2-接口的特点",normalizedTitle:"5.1.2 接口的特点",charIndex:4969},{level:3,title:"5.2 接口的基本使用：被实现",slug:"_5-2-接口的基本使用-被实现",normalizedTitle:"5.2 接口的基本使用：被实现",charIndex:5181},{level:3,title:"5.3 JDK8 开始接口新增方法",slug:"_5-3-jdk8-开始接口新增方法",normalizedTitle:"5.3 jdk8 开始接口新增方法",charIndex:5680},{level:4,title:"5.3.1 默认方法",slug:"_5-3-1-默认方法",normalizedTitle:"5.3.1 默认方法",charIndex:5952},{level:4,title:"5.3.2 静态方法",slug:"_5-3-2-静态方法",normalizedTitle:"5.3.2 静态方法",charIndex:6037},{level:4,title:"5.3.3 私有方法",slug:"_5-3-3-私有方法",normalizedTitle:"5.3.3 私有方法",charIndex:6108}],headersStr:"1. 包 1.1 什么是包 1.2 导包 2. 权限修饰符 2.1 什么是权限修饰符？ 2.2 权限修饰符的分类和作用范围 2.3 权限修饰符的使用 3. final 关键字及常量、枚举 3.1 final 关键字 3.2 常量 3.2.1 常量概述和基本作用 3.2.2 常量做信息标志和分类 3.3 枚举 3.3.1 枚举的概述 3.3.2 枚举的使用场景 4. 抽象类 4.1 抽象类概述 4.2 抽象类的案例 4.3 设计模式：模板方法模式 4.3.1 模板方法模式的使用场景 4.3.2 模板方法模式的实现步骤 4.3.3 案例：中小学生写作文 5. 接口 5.1 接口的概述和特点 5.1.1 啥是接口 5.1.2 接口的特点 5.2 接口的基本使用：被实现 5.3 JDK8 开始接口新增方法 5.3.1 默认方法 5.3.2 静态方法 5.3.3 私有方法",content:'# 面向对象进阶2（包、权限修饰符、抽象类、接口）\n\n\n# 1. 包\n\n\n# 1.1 什么是包\n\n * 包是用来分门别类的管理各种不同类的，类似于文件夹、建包利于程序的管理和维护\n\n * 建包的语法格式：package 公司域名倒写.技术名称。报名建议全部英文小写，且具备意义\n   \n   如：\n   \n   package com.itheima.javabean;\n   public class Student {\n          \n   }\n   \n   \n   \n   1\n   2\n   3\n   4\n   5\n   \n\n * 建包语句必须在第一行，一般IDEA工具会帮助创建\n\n\n# 1.2 导包\n\n * 相同包下的类可以直接访问，不同包下的类必须导包，才可以使用！\n\n * 导包格式：import 包名.类名\n\n * 若一个类中要用到不同类，而这个两个类的名称是一样的，那么默认只能导入一个类，另一个类要带包名访问\n\n\n# 2. 权限修饰符\n\n\n# 2.1 什么是权限修饰符？\n\n * 用来控制一个成员能够被访问的范围的。\n\n * 可以修饰成员变量、方法、构造器、内部类，不同权限修饰符修饰的成员能够被访问的范围将受到限制。\n\n\n# 2.2 权限修饰符的分类和作用范围\n\n四种作用范围由小到大为：private -> 缺省 -> protected - > public\n\n缺省为包访问权限。\n\n修饰符         同一个类中   同一个包中 其他类   不同包下的 子类   不同包下的 无关类\nprivate     √                              \n缺省          √       √                      \nprotected   √       √           √          \npublic      √       √           √          √\n\n\n# 2.3 权限修饰符的使用\n\n自己定义成员（方法，成员变量，构造器等）一般满足如下要求：\n\n * 成员变量一般私有。\n * 方法一般公开。\n * 如果该成员只希望本类访问，使用 private 修饰。\n * 如果该成员只希望本类、同一个包下的其他类和子类访问，使用 protected 修饰。\n   * 子类访问是说，要在子类中用子类对象访问，用父类对象访问还是会报错的。\n\n\n# 3. final 关键字及常量、枚举\n\n\n# 3.1 final 关键字\n\n * 可以修饰 方法，变量，类\n   \n   * 修饰方法：表明该方法是最终方法，不能被重写\n   * 修饰变量：表示该变量第一次赋值后，不能再次被赋值(有且仅能被赋值一次)\n     * final 修饰实例成员变量，几乎不用。因为实例成员变量属于对象，当他指定之后，表示每个对象的这个成员变量都是固定的了，没意义。\n     * final 修饰静态成员变量，该变量就变成了常量。\n   * 修饰类：表明该类是最终类，不能被继承 <被绝育了！！>\n     * 比如工具类，就可以用 final 修饰，工具类就不要继承啦，你拿来直接用就行啦~\n\n * final 修饰变量的注意\n   \n   * final 修饰的变量是基本类型：那么变量存储的数据值不能发生改变\n   * final 修饰的变量是引用类型：那么变量存储的地址值不能发生改变，但是地址指向的对象内容是可以发生变化的\n     * 这个地址就相当于钥匙，钥匙不能变了，但家里是可以变化的。\n     * 即当 t 指向了一个对象时，t=null 是不合法的，但 t 指向的内容中的成员变量值是可以变化的。\n\n\n# 3.2 常量\n\n# 3.2.1 常量概述和基本作用\n\n * 啥是常量\n   * 常量是使用了 public static final 修饰的成员变量，必须有初始化值，而且执行的过程中其值不能被改变\n   * 常量的作用和好处：可以用于做系统的配置信息，方便程序的维护，同时也能提高可读性\n * 常量命名规范\n   * 英文单词全部大写，多个单词下划线连接起来\n * 常量的执行原理\n   * 在编译阶段会进行“宏替换”，把使用常量的地方全部替换成真实的字面量\n   * 这样做的好处是让使用常量的程序的执行性能与直接使用字面量是一样的\n\n# 3.2.2 常量做信息标志和分类\n\n案例：开发超级玛丽游戏需要接收用户输入的四个方向的信号（上下左右），以便控制玛丽移动的方向\n\n实现：用 UP=1, DOWN=2, LEFT=3, RIGHT=4 分别表示四种动作，调用移动函数 move() 时，就可以直接传 UP 等常量进来，而不是传 1， 2.... 进来，代码可读性更好。\n\n用常量做信息标志和分类：代码可读性好，实现了软编码形式\n\n⚠️ 用常量做信息标志不是很好，用枚举会更好\n\n\n# 3.3 枚举\n\n# 3.3.1 枚举的概述\n\n * 枚举是 Java 中的一种特殊类型\n\n * 枚举的作用："是为了做信息的标志和信息的分类"\n\n * 定义枚举的格式：\n   \n   * 修饰符 enum 枚举名称{\n      \t第一行都是罗列枚举类实例的名称。\n     }\n     \n     \n     1\n     2\n     3\n     \n   \n   * 例：\n     \n     enum Season{\n         SPRING , SUMMER , AUTUMN , WINTER;\n     }\n     \n     \n     1\n     2\n     3\n     \n     \n     反编译后的结果：\n     \n     Compiled from "Season.java"\n         public final class Season extends java.lang.Enum<Season> {\n             public static final Season SPRING = new Season();\n             public static final Season SUMMER = new Season();\n             public static final Season AUTUMN = new Season();\n             public static final Season WINTER = new Season();\n             public static Season[] values();\n             public static Season valueOf(java.lang.String);\n     \n         }\n     \n     \n     1\n     2\n     3\n     4\n     5\n     6\n     7\n     8\n     9\n     10\n     \n   \n   * 其实就是把普通类定义中的 class 换成了 enum，也可以加权限修饰符\n\n * 枚举的特征\n   \n   * 枚举类都是继承了枚举类型：java.lang.Enum\n   * 枚举都是最终类，不可以被继承\n   * ⚠️ 构造器都是私有的，枚举对外不能创建对象\n   * 枚举类的第一行默认罗列枚举对象的名称\n   * 枚举类相当于多例模式\n     * 对外不能再创建对象了，而内部已经创建了四个对象\n\n# 3.3.2 枚举的使用场景\n\n案例：开发超级玛丽游戏\n\n * 选择常量做信息标志和分类：\n   * 虽然可以实现可读性，但是入参值不受约束，代码相对不够严谨。（定义了 UP=1，我也可以不用 UP，就非得用 1，此时也是可以的。或者我用不合法的数值作为参数，也没有校验）\n * 枚举做信息标志和分类：\n   * 代码可读性好，入参约束严谨，代码优雅，是最好的信息分类技术！建议使用！\n\n\n# 4. 抽象类\n\n\n# 4.1 抽象类概述\n\n若一个类中的某个方法的具体实现不能确定，就可以申明成 abstract 修饰的抽象方法（不能写方法体了），对应的类也必须用 abstract 修饰，被称为抽象类。\n\n示例代码：\n\npublic abstract class Animal{\n    public abstract void run();\n}\n\n\n1\n2\n3\n\n * 抽象类的作用：\n   * 可以被子类继承、充当模板，同时也可以提高代码复用\n * 抽象类的注意事项：\n   * 一个类如果继承了抽象类，那么这个类必须重写完抽象类的全部抽象方法，否则这个类也必须定义成抽象类。\n\n\n# 4.2 抽象类的案例\n\n系统需求：\n\n加油站推出两种支付卡，金卡和银卡，享受不同的打折优惠，金卡8折，银卡8.5折。分别实现2种卡片进入收银系统后的逻辑，卡片需要包含主人名称，余额，支付功能。\n\n分析实现：\n\n创建一张卡片父类：定义属性包括主人名称、余额、支付功能（具体实现交给子类）\n\n创建一张白金卡类：重写支付功能，按照原价的8折计算输出。\n\n创建一张银卡类：重写支付功能，按照原价的8.5折计算输出。\n\n抽象类的特征和注意事项\n\n * 有得有失: 得到了抽象方法，失去了创建对象的能力\n   * 即，抽象类不能创建对象\n   * 原因：\n     * 若能够创建对象，则调用其中的抽象方法无法正常运行（连方法体都没有）\n     * 哪怕这个抽象类中没有抽象方法，也不能实例化\n * 类有的成员（成员变量、方法、构造器）抽象类都具备\n * 抽象类中不一定有抽象方法，有抽象方法的类一定是抽象类\n * 一个类继承了抽象类必须重写完抽象类的全部抽象方法，否则这个类也必须定义成抽象类\n   * 一般不层层抽象使用\n * 不能用abstract修饰变量、代码块、构造器，只能用来修饰类和方法\n\nfinal 和 abstract 的关系\n\nfinal 和 abstract 为**互斥关系**：\n\n * abstract 定义的抽象类作为模板让子类继承，final定 义的类不能被继承\n * 抽象方法定义通用功能让子类重写，final 定义的方法子类不能重写\n\n\n# 4.3 设计模式：模板方法模式\n\n模板方法模式为抽象类的应用。\n\n# 4.3.1 模板方法模式的使用场景\n\n当系统中出现同一个功能多处在开发，而该功能中大部分代码是一样的，只有其中部分可能不同的时候，通常用模板方法模式。\n\n# 4.3.2 模板方法模式的实现步骤\n\n * 把功能定义成一个所谓的模板方法，放在抽象类中，模板方法中只定义通用且能确定的代码（一个通用结构）\n * 模板方法中不能决定的功能定义成抽象方法让具体子类去实现\n\n# 4.3.3 案例：中小学生写作文\n\n需求：中、小学生都要写《我的爸爸》，每类学生的标题、第一段、最后一段的内容必须一样，正文自己发挥。\n\n解决：父类定义为抽象方法，将共同部分实现，剩下的正文书写部分定义为抽象方法，让子类去实现。\n\n模板方法建议使用 final 修饰，更专业，原因：\n\n模板方法是给子类直接使用的，不是让子类重写的，一旦子类重写了模板方法就失效了。\n\n使用者只需要关心自己需要实现的功能即可。\n\n如，下图中，用 final 修饰模板方法 write，防止子类对其重写。\n\n\n\n\n# 5. 接口\n\n\n# 5.1 接口的概述和特点\n\n# 5.1.1 啥是接口\n\n * 接口是一种规范，规范一定是公开的\n\n * 是一种特殊的抽象类\n\n * 关键字：interface\n\n * 定义格式：\n   \n   public interface 接口名 {\n          // 常量\n          // 抽象方法\n   }\n   \n   \n   1\n   2\n   3\n   4\n   \n\n# 5.1.2 接口的特点\n\n * 是一种特殊的抽象类\n * 默认是公开的\n * JDK8 之前接口中只能是抽象方法和常量，没有其他成分了。\n   * 若有其他东西，就变成普通的抽象类了\n * 接口不能实例化。\n * 接口中的成员都是 public 修饰的，写不写都是，因为规范的目的是为了公开化。\n   * 成员变量可以省略 public static，也是默认公开的\n   * 成员方法直接不写 public 常用\n\n\n# 5.2 接口的基本使用：被实现\n\n接口是用来被类实现（implements）的，实现接口的类称为**实现类**。实现类可以理解成所谓的子类。\n\n示例：\n\n修饰符 class 实现类 implements 接口1, 接口2, 接口3 , ... {\n}\n\n\n1\n2\n\n\n接口可以被类单实现，也可以被类多实现。\n\n⚠️ 一个类实现接口，必须重写完全部接口的全部抽象方法，否则这个类需要定义成抽象类\n\ninterface VS abstract\n\n * 接口没对象\n\n * 接口可以多实现（implements）\n\n * 抽象类一个儿子只能有一个亲爸，可以有多个儿子有同一个亲爸\n\n * 接口一个儿子可以有多个干爹\n\n提示\n\n * 类和类的关系：单继承\n * 类和接口的关系：多实现\n * 接口和接口的关系：多继承，一个接口可以同时继承多个接口\n   * 作用：规范合并，整合多个接口为同一个接口，便于子类实现\n   * 例如，篮球运动员要实现运动员、遵纪守法、人的接口，在定义这个类时需要对多个接口进行实现，但若晕哦动员接口已经多继承了遵纪守法、人的接口时，篮球运动员就可以只实现运动员接口了\n\n\n# 5.3 JDK8 开始接口新增方法\n\nJDK8 版本开始后，Java 对接口的成员方法进行了新增。\n\n原因：\n\n当项目 1.0 成功上线没问题之后， 2.0 版本需要对某个接口进行丰富，加入更多抽象方法，此时，如果修改这个接口，就意味着此接口的所有实现类都要去实现所有的这些方法，这些实现类都需要再去修改代码。\n\n问题来啦！ 咋就能在丰富接口功能的同时又不对子类代码进行更改呢？？\n\n——solve：允许接口中直接定义带有方法体的方法，故JDK8 之后新增的方法有：默认方法、静态方法、私有方法三种，他们都会默认被 public 修饰。\n\n# 5.3.1 默认方法\n\n本质上就是之前提到的普通实例方法，必须有 default 修饰。\n\n默认会 public 修饰。\n\n⚠️ 需要用接口的实现类的对象来调用。\n\n# 5.3.2 静态方法\n\n必须 static 修饰，默认会 public 修饰。\n\n⚠️ 注意：接口的静态方法必须用本身的接口名来调用。\n\n# 5.3.3 私有方法\n\n本质就是私有的实例方法，必须使用 private 修饰，从 JDK 1.9 才开始有的。\n\n只能在**本类中（本接口中）**被其他的默认方法或者私有方法访问。\n\n⚠️ 只能在接口内部被调用。\n\n> heima：JDK8 新增的 3 种方法我们自己在开发中很少使用，通常是 Java 源码涉及到的，我们需要理解、识别语法、明白调用关系即可。\n\n接口的注意事项\n\n1、接口不能创建对象。\n\n2、一个类实现多个接口，多个接口中有同样的静态方法不冲突。\n\n因为接口的静态方法只能用接口本身来调用。\n\n3、一个类继承了父类，同时又实现了接口，父类中和接口中有同名方法，默认用父类的。\n\n父类是亲爸，接口是干爹。\n\n一个 class 要先 extends 再implements。\n\n4、一个类实现了多个接口，多个接口中存在同名的默认方法，不冲突，这个类重写该方法即可。\n\n5、一个接口继承多个接口，是没有问题的，如果多个接口中存在规范冲突则不能多继承。',normalizedContent:'# 面向对象进阶2（包、权限修饰符、抽象类、接口）\n\n\n# 1. 包\n\n\n# 1.1 什么是包\n\n * 包是用来分门别类的管理各种不同类的，类似于文件夹、建包利于程序的管理和维护\n\n * 建包的语法格式：package 公司域名倒写.技术名称。报名建议全部英文小写，且具备意义\n   \n   如：\n   \n   package com.itheima.javabean;\n   public class student {\n          \n   }\n   \n   \n   \n   1\n   2\n   3\n   4\n   5\n   \n\n * 建包语句必须在第一行，一般idea工具会帮助创建\n\n\n# 1.2 导包\n\n * 相同包下的类可以直接访问，不同包下的类必须导包，才可以使用！\n\n * 导包格式：import 包名.类名\n\n * 若一个类中要用到不同类，而这个两个类的名称是一样的，那么默认只能导入一个类，另一个类要带包名访问\n\n\n# 2. 权限修饰符\n\n\n# 2.1 什么是权限修饰符？\n\n * 用来控制一个成员能够被访问的范围的。\n\n * 可以修饰成员变量、方法、构造器、内部类，不同权限修饰符修饰的成员能够被访问的范围将受到限制。\n\n\n# 2.2 权限修饰符的分类和作用范围\n\n四种作用范围由小到大为：private -> 缺省 -> protected - > public\n\n缺省为包访问权限。\n\n修饰符         同一个类中   同一个包中 其他类   不同包下的 子类   不同包下的 无关类\nprivate     √                              \n缺省          √       √                      \nprotected   √       √           √          \npublic      √       √           √          √\n\n\n# 2.3 权限修饰符的使用\n\n自己定义成员（方法，成员变量，构造器等）一般满足如下要求：\n\n * 成员变量一般私有。\n * 方法一般公开。\n * 如果该成员只希望本类访问，使用 private 修饰。\n * 如果该成员只希望本类、同一个包下的其他类和子类访问，使用 protected 修饰。\n   * 子类访问是说，要在子类中用子类对象访问，用父类对象访问还是会报错的。\n\n\n# 3. final 关键字及常量、枚举\n\n\n# 3.1 final 关键字\n\n * 可以修饰 方法，变量，类\n   \n   * 修饰方法：表明该方法是最终方法，不能被重写\n   * 修饰变量：表示该变量第一次赋值后，不能再次被赋值(有且仅能被赋值一次)\n     * final 修饰实例成员变量，几乎不用。因为实例成员变量属于对象，当他指定之后，表示每个对象的这个成员变量都是固定的了，没意义。\n     * final 修饰静态成员变量，该变量就变成了常量。\n   * 修饰类：表明该类是最终类，不能被继承 <被绝育了！！>\n     * 比如工具类，就可以用 final 修饰，工具类就不要继承啦，你拿来直接用就行啦~\n\n * final 修饰变量的注意\n   \n   * final 修饰的变量是基本类型：那么变量存储的数据值不能发生改变\n   * final 修饰的变量是引用类型：那么变量存储的地址值不能发生改变，但是地址指向的对象内容是可以发生变化的\n     * 这个地址就相当于钥匙，钥匙不能变了，但家里是可以变化的。\n     * 即当 t 指向了一个对象时，t=null 是不合法的，但 t 指向的内容中的成员变量值是可以变化的。\n\n\n# 3.2 常量\n\n# 3.2.1 常量概述和基本作用\n\n * 啥是常量\n   * 常量是使用了 public static final 修饰的成员变量，必须有初始化值，而且执行的过程中其值不能被改变\n   * 常量的作用和好处：可以用于做系统的配置信息，方便程序的维护，同时也能提高可读性\n * 常量命名规范\n   * 英文单词全部大写，多个单词下划线连接起来\n * 常量的执行原理\n   * 在编译阶段会进行“宏替换”，把使用常量的地方全部替换成真实的字面量\n   * 这样做的好处是让使用常量的程序的执行性能与直接使用字面量是一样的\n\n# 3.2.2 常量做信息标志和分类\n\n案例：开发超级玛丽游戏需要接收用户输入的四个方向的信号（上下左右），以便控制玛丽移动的方向\n\n实现：用 up=1, down=2, left=3, right=4 分别表示四种动作，调用移动函数 move() 时，就可以直接传 up 等常量进来，而不是传 1， 2.... 进来，代码可读性更好。\n\n用常量做信息标志和分类：代码可读性好，实现了软编码形式\n\n⚠️ 用常量做信息标志不是很好，用枚举会更好\n\n\n# 3.3 枚举\n\n# 3.3.1 枚举的概述\n\n * 枚举是 java 中的一种特殊类型\n\n * 枚举的作用："是为了做信息的标志和信息的分类"\n\n * 定义枚举的格式：\n   \n   * 修饰符 enum 枚举名称{\n      \t第一行都是罗列枚举类实例的名称。\n     }\n     \n     \n     1\n     2\n     3\n     \n   \n   * 例：\n     \n     enum season{\n         spring , summer , autumn , winter;\n     }\n     \n     \n     1\n     2\n     3\n     \n     \n     反编译后的结果：\n     \n     compiled from "season.java"\n         public final class season extends java.lang.enum<season> {\n             public static final season spring = new season();\n             public static final season summer = new season();\n             public static final season autumn = new season();\n             public static final season winter = new season();\n             public static season[] values();\n             public static season valueof(java.lang.string);\n     \n         }\n     \n     \n     1\n     2\n     3\n     4\n     5\n     6\n     7\n     8\n     9\n     10\n     \n   \n   * 其实就是把普通类定义中的 class 换成了 enum，也可以加权限修饰符\n\n * 枚举的特征\n   \n   * 枚举类都是继承了枚举类型：java.lang.enum\n   * 枚举都是最终类，不可以被继承\n   * ⚠️ 构造器都是私有的，枚举对外不能创建对象\n   * 枚举类的第一行默认罗列枚举对象的名称\n   * 枚举类相当于多例模式\n     * 对外不能再创建对象了，而内部已经创建了四个对象\n\n# 3.3.2 枚举的使用场景\n\n案例：开发超级玛丽游戏\n\n * 选择常量做信息标志和分类：\n   * 虽然可以实现可读性，但是入参值不受约束，代码相对不够严谨。（定义了 up=1，我也可以不用 up，就非得用 1，此时也是可以的。或者我用不合法的数值作为参数，也没有校验）\n * 枚举做信息标志和分类：\n   * 代码可读性好，入参约束严谨，代码优雅，是最好的信息分类技术！建议使用！\n\n\n# 4. 抽象类\n\n\n# 4.1 抽象类概述\n\n若一个类中的某个方法的具体实现不能确定，就可以申明成 abstract 修饰的抽象方法（不能写方法体了），对应的类也必须用 abstract 修饰，被称为抽象类。\n\n示例代码：\n\npublic abstract class animal{\n    public abstract void run();\n}\n\n\n1\n2\n3\n\n * 抽象类的作用：\n   * 可以被子类继承、充当模板，同时也可以提高代码复用\n * 抽象类的注意事项：\n   * 一个类如果继承了抽象类，那么这个类必须重写完抽象类的全部抽象方法，否则这个类也必须定义成抽象类。\n\n\n# 4.2 抽象类的案例\n\n系统需求：\n\n加油站推出两种支付卡，金卡和银卡，享受不同的打折优惠，金卡8折，银卡8.5折。分别实现2种卡片进入收银系统后的逻辑，卡片需要包含主人名称，余额，支付功能。\n\n分析实现：\n\n创建一张卡片父类：定义属性包括主人名称、余额、支付功能（具体实现交给子类）\n\n创建一张白金卡类：重写支付功能，按照原价的8折计算输出。\n\n创建一张银卡类：重写支付功能，按照原价的8.5折计算输出。\n\n抽象类的特征和注意事项\n\n * 有得有失: 得到了抽象方法，失去了创建对象的能力\n   * 即，抽象类不能创建对象\n   * 原因：\n     * 若能够创建对象，则调用其中的抽象方法无法正常运行（连方法体都没有）\n     * 哪怕这个抽象类中没有抽象方法，也不能实例化\n * 类有的成员（成员变量、方法、构造器）抽象类都具备\n * 抽象类中不一定有抽象方法，有抽象方法的类一定是抽象类\n * 一个类继承了抽象类必须重写完抽象类的全部抽象方法，否则这个类也必须定义成抽象类\n   * 一般不层层抽象使用\n * 不能用abstract修饰变量、代码块、构造器，只能用来修饰类和方法\n\nfinal 和 abstract 的关系\n\nfinal 和 abstract 为**互斥关系**：\n\n * abstract 定义的抽象类作为模板让子类继承，final定 义的类不能被继承\n * 抽象方法定义通用功能让子类重写，final 定义的方法子类不能重写\n\n\n# 4.3 设计模式：模板方法模式\n\n模板方法模式为抽象类的应用。\n\n# 4.3.1 模板方法模式的使用场景\n\n当系统中出现同一个功能多处在开发，而该功能中大部分代码是一样的，只有其中部分可能不同的时候，通常用模板方法模式。\n\n# 4.3.2 模板方法模式的实现步骤\n\n * 把功能定义成一个所谓的模板方法，放在抽象类中，模板方法中只定义通用且能确定的代码（一个通用结构）\n * 模板方法中不能决定的功能定义成抽象方法让具体子类去实现\n\n# 4.3.3 案例：中小学生写作文\n\n需求：中、小学生都要写《我的爸爸》，每类学生的标题、第一段、最后一段的内容必须一样，正文自己发挥。\n\n解决：父类定义为抽象方法，将共同部分实现，剩下的正文书写部分定义为抽象方法，让子类去实现。\n\n模板方法建议使用 final 修饰，更专业，原因：\n\n模板方法是给子类直接使用的，不是让子类重写的，一旦子类重写了模板方法就失效了。\n\n使用者只需要关心自己需要实现的功能即可。\n\n如，下图中，用 final 修饰模板方法 write，防止子类对其重写。\n\n\n\n\n# 5. 接口\n\n\n# 5.1 接口的概述和特点\n\n# 5.1.1 啥是接口\n\n * 接口是一种规范，规范一定是公开的\n\n * 是一种特殊的抽象类\n\n * 关键字：interface\n\n * 定义格式：\n   \n   public interface 接口名 {\n          // 常量\n          // 抽象方法\n   }\n   \n   \n   1\n   2\n   3\n   4\n   \n\n# 5.1.2 接口的特点\n\n * 是一种特殊的抽象类\n * 默认是公开的\n * jdk8 之前接口中只能是抽象方法和常量，没有其他成分了。\n   * 若有其他东西，就变成普通的抽象类了\n * 接口不能实例化。\n * 接口中的成员都是 public 修饰的，写不写都是，因为规范的目的是为了公开化。\n   * 成员变量可以省略 public static，也是默认公开的\n   * 成员方法直接不写 public 常用\n\n\n# 5.2 接口的基本使用：被实现\n\n接口是用来被类实现（implements）的，实现接口的类称为**实现类**。实现类可以理解成所谓的子类。\n\n示例：\n\n修饰符 class 实现类 implements 接口1, 接口2, 接口3 , ... {\n}\n\n\n1\n2\n\n\n接口可以被类单实现，也可以被类多实现。\n\n⚠️ 一个类实现接口，必须重写完全部接口的全部抽象方法，否则这个类需要定义成抽象类\n\ninterface vs abstract\n\n * 接口没对象\n\n * 接口可以多实现（implements）\n\n * 抽象类一个儿子只能有一个亲爸，可以有多个儿子有同一个亲爸\n\n * 接口一个儿子可以有多个干爹\n\n提示\n\n * 类和类的关系：单继承\n * 类和接口的关系：多实现\n * 接口和接口的关系：多继承，一个接口可以同时继承多个接口\n   * 作用：规范合并，整合多个接口为同一个接口，便于子类实现\n   * 例如，篮球运动员要实现运动员、遵纪守法、人的接口，在定义这个类时需要对多个接口进行实现，但若晕哦动员接口已经多继承了遵纪守法、人的接口时，篮球运动员就可以只实现运动员接口了\n\n\n# 5.3 jdk8 开始接口新增方法\n\njdk8 版本开始后，java 对接口的成员方法进行了新增。\n\n原因：\n\n当项目 1.0 成功上线没问题之后， 2.0 版本需要对某个接口进行丰富，加入更多抽象方法，此时，如果修改这个接口，就意味着此接口的所有实现类都要去实现所有的这些方法，这些实现类都需要再去修改代码。\n\n问题来啦！ 咋就能在丰富接口功能的同时又不对子类代码进行更改呢？？\n\n——solve：允许接口中直接定义带有方法体的方法，故jdk8 之后新增的方法有：默认方法、静态方法、私有方法三种，他们都会默认被 public 修饰。\n\n# 5.3.1 默认方法\n\n本质上就是之前提到的普通实例方法，必须有 default 修饰。\n\n默认会 public 修饰。\n\n⚠️ 需要用接口的实现类的对象来调用。\n\n# 5.3.2 静态方法\n\n必须 static 修饰，默认会 public 修饰。\n\n⚠️ 注意：接口的静态方法必须用本身的接口名来调用。\n\n# 5.3.3 私有方法\n\n本质就是私有的实例方法，必须使用 private 修饰，从 jdk 1.9 才开始有的。\n\n只能在**本类中（本接口中）**被其他的默认方法或者私有方法访问。\n\n⚠️ 只能在接口内部被调用。\n\n> heima：jdk8 新增的 3 种方法我们自己在开发中很少使用，通常是 java 源码涉及到的，我们需要理解、识别语法、明白调用关系即可。\n\n接口的注意事项\n\n1、接口不能创建对象。\n\n2、一个类实现多个接口，多个接口中有同样的静态方法不冲突。\n\n因为接口的静态方法只能用接口本身来调用。\n\n3、一个类继承了父类，同时又实现了接口，父类中和接口中有同名方法，默认用父类的。\n\n父类是亲爸，接口是干爹。\n\n一个 class 要先 extends 再implements。\n\n4、一个类实现了多个接口，多个接口中存在同名的默认方法，不冲突，这个类重写该方法即可。\n\n5、一个接口继承多个接口，是没有问题的，如果多个接口中存在规范冲突则不能多继承。',charsets:{cjk:!0},lastUpdated:"2023/03/15, 14:34:12",lastUpdatedTimestamp:1678890852e3},{title:"面向对象进阶3（多态、内部类、常用API）",frontmatter:{title:"面向对象进阶3（多态、内部类、常用API）",date:"2023-03-08T20:17:52.000Z",permalink:"/pages/a4fc75/",categories:["开发","Java","黑马Java入门基础-学习笔记"],tags:[null]},regularPath:"/%E5%BC%80%E5%8F%91/10.Java/05.%E9%BB%91%E9%A9%ACJava%E5%85%A5%E9%97%A8%E5%9F%BA%E7%A1%80-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/32.%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%BF%9B%E9%98%B63%EF%BC%88%E5%A4%9A%E6%80%81%E3%80%81%E5%86%85%E9%83%A8%E7%B1%BB%E3%80%81%E5%B8%B8%E7%94%A8API%EF%BC%89.html",relativePath:"开发/10.Java/05.黑马Java入门基础-学习笔记/32.面向对象进阶3（多态、内部类、常用API）.md",key:"v-b1a79552",path:"/pages/a4fc75/",headers:[{level:2,title:"1. 多态：面向对象三大特征之三",slug:"_1-多态-面向对象三大特征之三",normalizedTitle:"1. 多态：面向对象三大特征之三",charIndex:29},{level:3,title:"1.1 多态的概述、形式",slug:"_1-1-多态的概述、形式",normalizedTitle:"1.1 多态的概述、形式",charIndex:50},{level:3,title:"1.2 多态的优势",slug:"_1-2-多态的优势",normalizedTitle:"1.2 多态的优势",charIndex:410},{level:3,title:"1.3 多态下引用数据类型的类型转换",slug:"_1-3-多态下引用数据类型的类型转换",normalizedTitle:"1.3 多态下引用数据类型的类型转换",charIndex:736},{level:3,title:"1.4 多态的案例",slug:"_1-4-多态的案例",normalizedTitle:"1.4 多态的案例",charIndex:1719},{level:2,title:"2. 内部类",slug:"_2-内部类",normalizedTitle:"2. 内部类",charIndex:1934},{level:3,title:"2.1 内部类的概述",slug:"_2-1-内部类的概述",normalizedTitle:"2.1 内部类的概述",charIndex:1945},{level:3,title:"2.2 内部类的使用场景、作用",slug:"_2-2-内部类的使用场景、作用",normalizedTitle:"2.2 内部类的使用场景、作用",charIndex:2095},{level:3,title:"2.3 内部类的分类",slug:"_2-3-内部类的分类",normalizedTitle:"2.3 内部类的分类",charIndex:2304},{level:4,title:"2.3.1 静态内部类",slug:"_2-3-1-静态内部类",normalizedTitle:"2.3.1 静态内部类",charIndex:2318},{level:4,title:"2.3.2 成员内部类",slug:"_2-3-2-成员内部类",normalizedTitle:"2.3.2 成员内部类",charIndex:2616},{level:4,title:"2.3.3 局部内部类",slug:"_2-3-3-局部内部类",normalizedTitle:"2.3.3 局部内部类",charIndex:3081},{level:4,title:"2.3.4 匿名内部类",slug:"_2-3-4-匿名内部类",normalizedTitle:"2.3.4 匿名内部类",charIndex:3180},{level:4,title:"2.3.5 匿名内部类常见使用形式",slug:"_2-3-5-匿名内部类常见使用形式",normalizedTitle:"2.3.5 匿名内部类常见使用形式",charIndex:4097},{level:2,title:"3. 常用 API",slug:"_3-常用-api",normalizedTitle:"3. 常用 api",charIndex:4757},{level:3,title:"3.1 Object 类",slug:"_3-1-object-类",normalizedTitle:"3.1 object 类",charIndex:4771},{level:3,title:"3.2 Objects 类",slug:"_3-2-objects-类",normalizedTitle:"3.2 objects 类",charIndex:5330},{level:3,title:"3.3 StringBuilder 类",slug:"_3-3-stringbuilder-类",normalizedTitle:"3.3 stringbuilder 类",charIndex:6199},{level:3,title:"3.4 Math 类",slug:"_3-4-math-类",normalizedTitle:"3.4 math 类",charIndex:7226},{level:3,title:"3.5 System 类",slug:"_3-5-system-类",normalizedTitle:"3.5 system 类",charIndex:7776},{level:3,title:"3.6 BigDecimal 类",slug:"_3-6-bigdecimal-类",normalizedTitle:"3.6 bigdecimal 类",charIndex:8353}],headersStr:"1. 多态：面向对象三大特征之三 1.1 多态的概述、形式 1.2 多态的优势 1.3 多态下引用数据类型的类型转换 1.4 多态的案例 2. 内部类 2.1 内部类的概述 2.2 内部类的使用场景、作用 2.3 内部类的分类 2.3.1 静态内部类 2.3.2 成员内部类 2.3.3 局部内部类 2.3.4 匿名内部类 2.3.5 匿名内部类常见使用形式 3. 常用 API 3.1 Object 类 3.2 Objects 类 3.3 StringBuilder 类 3.4 Math 类 3.5 System 类 3.6 BigDecimal 类",content:'# 面向对象进阶3（多态、内部类、常用 API）\n\n\n# 1. 多态：面向对象三大特征之三\n\n\n# 1.1 多态的概述、形式\n\n * 啥是多态\n   * 同一父类型的对象，执行同一个行为时，会表现出不同的行为特征。\n * 多态的常见形式\n   * 父类类型 对象名称 = new 子类构造器; （父类类型指向一个子类的对象）\n   * 接口 对象名称 = new 实现类构造器;（接口相当于一个干爹，实现类相当于儿子）\n   * 具体的行为方法在子类中重写\n * 多态中成员访问特点-\n   * 方法调用：编译看左边，运行看右边。\n   * 变量调用：编译看左边，运行也看左边。（多态侧重行为多态，变量没有多态的概念）\n     * 即对于变量调用，还是会使用父类中的变量，而方法是会使用子类中重写的方法的。\n * 多态的前提\n   * 有继承/实现关系\n   * 有父类引用指向子类对象\n   * 有方法重写\n\n\n# 1.2 多态的优势\n\n 1. 在多态形式下，右边对象可以实现解耦合，便于扩展和维护。\n\nAnimal a = new Dog();\na.run(); // 后续业务行为随对象而变，后续代码无需修改\n\n\n1\n2\n\n\n上述代码中，若后续业务需要将 Dog 子类改为Tortoise 子类，则直接改“=”右侧的子类类型即可，后续代码中的行为随着对象的改变而直接变化了，无需修改很多后续的代码。\n\n 2. 定义方法的时候，使用父类型作为参数，该方法就可以接收这父类的一切子类对象，体现出多态的扩展性与便利\n\n多态下会产生的一个问题\n\n多态下不能使用子类的独有功能，因为编译时会使用左侧的父类中的行为。\n\nsolve：使用强制类型转换，将父转为子类型。\n\n\n# 1.3 多态下引用数据类型的类型转换\n\n在多态下会有两种类型转换：\n\n * 自动类型转换（从子到父）\n * 强制类型转换（从父到子）\n\n关于强制类型转换：\n\n * 子类类型 对象变量 = (子类)父类类型的变量\n   \n   代码示例：\n   \n   // 自动类型转换\n   Animal a = new Dog();\n   a.run();\n   // 强制类型转换:可以实现调用子类独有功能的\n   Dog d = (Dog) a;\n   d.lookDoor();\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   \n\n * 作用：可以解决多态下的劣势，可以实现调用子类独有的功能\n\n * 注意： 如果转型后的类型和对象真实类型不是同一种类型，那么在转换的时候就会报错 ClassCastException（类型转换异常）\n\n强转转换的一点建议\n\n规定：有继承或者实现关系的2个类型就可以强制类型转换，故编译时可能没问题，但运行时发现强制转换后的类型不是对象真实类型而报错。\n\nJava 建议强转转换前使用 instanceof 判断当前对象的真实类型，再进行强制转换。\n\n关于 instanceof 关键字的使用：\n\n变量名 instanceof 真实类型\n\n判断关键字左边的变量指向的对象的真实类型，是否是右边的类型或者是其子类类型，是则返回true，反之false。\n\n代码示例：\n\npublic static void go(Animal a){  // 参数类型为父类类型，保证各种动物都可以使用go方法\n    System.out.println("预备~~~");\n    a.run();\n    // 独有功能\n    if(a instanceof Tortoise){\n        Tortoise t = (Tortoise) a;\n        t.layEggs();\n    }else if(a instanceof Dog){\n        Dog d1 = (Dog) a;\n        d1.lookDoor();\n    }\n    System.out.println("结束~~~~");\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 1.4 多态的案例\n\n需求：设计一个电脑对象，可以安装2个USB设备。鼠标：被安装时可以完成接入、调用点击功能、拔出功能；键盘：被安装时可以完成接入、调用打字功能、拔出功能。\n\n分析：\n\n①定义一个USB的接口（申明USB设备的规范必须是：可以接入和拔出）。\n\n②提供2个USB实现类代表鼠标和键盘，让其实现USB接口，并分别定义独有功能。\n\n③创建电脑对象，创建2个USB实现类对象，分别安装到电脑中并触发功能的执行。\n\n\n# 2. 内部类\n\n\n# 2.1 内部类的概述\n\n内部类就是定义在一个类里面的类，里面的类可以理解成（寄生），外部类可以理解成（宿主）。\n\n如，心脏和人的关系：\n\npublic class People{\n    // 内部类\n    public class Heart{\n    }\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# 2.2 内部类的使用场景、作用\n\n * 当一个事物的内部，还有一个部分需要一个完整的结构进行描述，而这个内部的完整的结构又只为外部事物提供服务，那么整个内部的完整结构可以选择使用内部类来设计。\n * 内部类通常可以方便访问外部类的成员，包括私有的成员。\n * 内部类提供了更好的封装性，内部类本身就可以用 private、protected 等修饰，封装性可以做更多控制。（外部类只能用 public 修饰）\n\n\n# 2.3 内部类的分类\n\n# 2.3.1 静态内部类\n\n * 有static修饰，属于外部类本身\n * 特点、使用与普通类是一样的，类有的成分它都有，只是位置在别人里面而已\n * 可以直接访问外部类的静态成员，不能直接访问外部类的实例成员（可以创建一个外部类对象，再访问其实例成员）\n * 注意：开发中实际上用的还是比较少\n * 定义示例：\n\npublic class Outer{\n        // 静态成员内部类\n    public static class Inner{\n    }\n}\n\n\n1\n2\n3\n4\n5\n\n * 创建对象的格式：Outer.Inner in = new Outer.Inner();\n\n# 2.3.2 成员内部类\n\n * 无 static 修饰，属于外部类的对象\n * JDK16 之前，成员内部类中不能定义静态成员，JDK 16 开始也可以定义静态成员了\n * 特点：可以直接访问外部类的静态成员，实例方法中可以直接访问外部类的实例成员（因为必须先有外部类对象，才能有成员内部类对象，所以可以直接访问外部类对象的实例成员）\n * 定义示例：\n\npublic class Outer {\n    // 成员内部类\n    public class Inner {        \n    }\n}\n\n\n1\n2\n3\n4\n5\n\n * 创建对象格式：Outer.Inner in = new Outer().new Inner(); （注意外部类对象后面要加() ）\n * 相关面试题：\n   * 在成员内部类中访问所在外部类对象，格式：外部类名.this.value，如：System.out.println(People.this.heartbeat);\n   * 访问当前对象的成员变量，要用 this.value\n\n# 2.3.3 局部内部类\n\n * 鸡肋语法，了解即可\n * 局部内部类放在方法、代码块、构造器等执行体中\n * 局部内部类编译后也会有对应的类文件，其类文件名为： 外部类$N内部类.class\n\n# 2.3.4 匿名内部类\n\n * 本质上是一个没有名字的局部内部类，定义在方法中、代码块中、等\n\n * 作用：方便创建子类对象，最终目的为了简化代码编写\n\n * 特点\n   \n   * 匿名内部类写出来就会产生一个匿名内部类的对象\n   * 匿名内部类的对象类型相当于是当前 new 的那个的类型的子类类型（可以视为是 Animal 的子类 Tiger 类）\n\n * 格式\n\nnew 类|抽象类名|或者接口名() {\n    重写方法;\n};\n\n\n1\n2\n3\n\n\nAnimal a = new Animal() {\n    public void run() {\n    }\n};\na. run();\n\n\n1\n2\n3\n4\n5\n\n\n⚠️ 直接 new abstract_class() 是不可以的，故后面加上 {} 进行方法的重写，实现一个匿名内部类。\n\n简单示例：\n\nline3 等号后 ~ line8 的部分相当于 Tiger 类了。\n\npublic class Test {\n    public static void main(String[] args) {\n        Animal a = new Animal(){\n            @Override\n            public void run() {\n                System.out.println("老虎跑的块~~~");\n            }\n        };\n        a.run();\n    }\n}\n\n//class Tiger extends Animal{\n//    @Override\n//    public void run() {\n//        System.out.println("老虎跑的块~~~");\n//    }\n//}\n\nabstract class Animal{\n    public abstract void run();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n# 2.3.5 匿名内部类常见使用形式\n\n匿名内部类通常作为方法的实际参数进行传输。\n\n示例代码：\n\npublic class Test2 {\n    public static void main(String[] args) {\n        \n        go(new Swimming() {\n            @Override\n            public void swim() {\n                System.out.println("运动员泳🏊的贼快~~~~~");\n            }\n        });\n\n    /**\n       学生 老师 运动员可以一起参加游泳比赛\n     */\n    public static void go(Swimming s){\n        System.out.println("开始。。。");\n        s.swim();\n        System.out.println("结束。。。");\n    }\n}\n    \ninterface Swimming{\n    void swim();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n对象回调：\n\n提示\n\n开发中不是我们主动去定义匿名内部类的，而是别人需要我们写或者我们可以写的时候才会使用。\n\n匿名内部类的代码可以实现代码进一步的简化。\n\n\n# 3. 常用 API\n\n\n# 3.1 Object 类\n\n * Object 类的方法是一切子类对象都可以直接使用的，所以我们要学习 Object 类的方法。\n\n * 一个类要么默认继承了 Object 类，要么间接继承了 Object 类，Object 类是 Java 中的祖宗类\n\n * Object类的常用方法\n\n方法名                               说明\npublic String toString()          默认是返回当前对象在堆内存中的地址信息:类的全限名@内存地址\npublic boolean equals(Object o)   默认是比较当前对象与另一个对象的地址是否相同，相同返回true，不同返回false\n\n * 一般直接在 IDEA 中自动重写对应类的这两个方法即可。\n\ntoString 方法：\n\n因为 toString 默认输出对象的地址在开发中毫无意义，更多是希望看到对象的内容数据）\n\ntoString 方法存在的意义就是为了被子类重写，以便返回对象的内容信息，而不是地址信息\n\nequals 方法：\n\n直接比较两个对象的地址是否相同完全可以用 “==” 替代 equals\n\n父类 equals 方法存在的意义就是为了被子类重写，以便子类自己来定制比较规则\n\n\n# 3.2 Objects 类\n\nObjects 是一个工具类，提供了一些方法去完成一些功能\n\nObjects 类与 Object 类也是继承关系。\n\nObjects 类是从 JDK1.7 之后才有的。\n\n官方在进行字符串比较时（自动重写的 equals 方法），没有用字符串对象的的 equals 方法，而是选择了 Objects 的 equals 方法来比较。\n\n原因：使用Objects 的 equals 方法在进行对象的内容比较时会更安全。\n\n使用 Objects 的 equals 方法在进行对象的内容比较时更安全的原因\n\nObjects 的 equals 方法在比较时，底层会先进行非空判断，从而可以避免空指针异常。再进行 equals 比较\n\n源码分析：\n\npublic static boolean equals(Object a, Object b) {\n    return (a == b) || (a != null && a.equals(b));\n}\n\n\n1\n2\n3\n\n\n若直接使用 equals 方法比较时，可能会出现空指针异常，例如：\n\npublic class Test {\n    public static void main(String[] args) {\n        String s1 = null;\n        String s2 = new String("itheima");\n\n        // System.out.println(s1.equals(s2));   // 留下了隐患，可能出现空指针异常。\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nString 的 equals 方法 VS 类的 equals 方法\n\n字符串可以直接用 equals 比较内容，因为 String 类已经重写过该方法了；但自定义的类要重写 equals 方法。\n\n⚠️ String 不能用 “==” 比较内容是否一样，因为 “==” 会视为比较的二者为不同的对象\n\n\n# 3.3 StringBuilder 类\n\n * StringBuilder 是一个可变的字符串类，我们可以把它看成是一个对象容器。（String 是不可变字符串类）\n\n * 作用：提高字符串的操作效率，如拼接、修改等。\n\n * StringBuilder 常用方法\n\n方法名称                                说明\npublic StringBuilder append(任意类型)   添加数据并返回StringBuilder对象本身\npublic StringBuilder reverse()      将对象的内容反转，会直接将对象本身修改\npublic int length()                 返回对象内容长度\npublic String toString()            通过toString()就可以实现把StringBuilder转换为String\n\n * StringBuilder 支持链式编程，e.g. sb1.append("a").append("b").append("c").append("我爱你中国");\n\n⚠️ 注意：StringBuilder 只是拼接字符串的手段，效率好，使用时最终还是要转成 String。 用 toString 恢复 String。故 定义字符串用 String，拼接、修改等操作字符串使用 StringBuilder。\n\n示例代码：\n\nStringBuilder sb2 = new StringBuilder();\nsb2.append("123").append("456");\n// 恢复成String类型\nString rs = sb2.toString();\ncheck(rs); // 使用字符串\n\npublic static void check(String data){\n    System.out.println(data);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n内存原理\n\nString 类拼接字符串时，一个加号会导致堆内存中创建两个对象，一个是拼接时的 StringBuilder 对象，一个是拼好后转换过去的 String 对象。\n\n\n\nStringBuilder 类拼接字符串时，只会在堆内存中创建一个 StringBuilder 对象，所有拼接操作都在这个对象中完成。效率变高。\n\n\n\n\n# 3.4 Math 类\n\n包含执行基本数字运算的方法，Math类没有提供公开的构造器\n\n**如何使用类中的成员呢？**看类的成员是否都是静态的，如果是，通过类名就可以直接调用\n\nMath 类的常用方法\n\n方法名                                           说明\npublic static int abs(int a)                  获取参数绝对值\npublic static double ceil(double a)           向上取整\npublic static double floor(double a)          向下取整\npublic static int round(float a)              四舍五入\npublic static int max(int a,int b)            获取两个int值中的较大值\npublic static double pow(double a,double b)   返回a的b次幂的值\npublic static double random()                 返回值为double的随机值，范围[0.0,1.0)\n\n\n# 3.5 System 类\n\nSystem 也是一个工具类，代表了当前系统，提供了一些与系统相关的方法\n\nSystem 类的常用方法\n\n方法名                                                            说明\npublic static void exit(int status)                            终止当前运行的 Java 虚拟机，非零表示异常终止\npublic static long currentTimeMillis()                         返回当前系统的时间毫秒值形式\npublic static void arraycopy(数据源数组, 起始索引, 目的地数组, 起始索引, 拷贝个数)   数组拷贝 （了解）\n\n注意：System.exit() 相当于删库跑路，可不能瞎用！！！\n\n关于时间毫秒值：\n\n * 计算机认为时间是有起点的，起始时间： 1970年1月1日 00:00:00\n\n * 时间毫秒值：指的是从1970年1月1日 00:00:00走到此刻的总的毫秒数，应该是很大的。 1s = 1000ms。\n\n * System.currentTimeMillis() 可以用来进行时间的计算：性能分析。\n\n\n# 3.6 BigDecimal 类\n\n（大数据类型）用于解决浮点型运算精度失真的问题\n\n浮点型运算的时候直接+ * / 可能会出现数据失真（精度问题）。\n\nBigDecimal 的使用：\n\n创建对象 BigDecimal 封装浮点型数据（最好的方式是调用方法）\n\n⚠️ 阿里开发规范：禁止使用构造方法 BigDecimal(double)的方式把 double 值转化为 BigDerimal 对象。\n\n原因：BigDecimal(double)存在精度损失风险，在精确计算或值比较的场景中可能会导致业务逻辑异常。如:BigDecimalg = new BigDecimal(0.1F);实际的存储值为:0.10000000149\n\n正例：优先推荐入参为String 的构造方法，或使用 BigDecimal 的 valueof 方法，此方法内部其实执行了Double 的 toString，而 Double 的 toString 按 double 的实际能表达的精度对尾数进行了截断。\n\nBigDecimal recommend1 = new BigDecimal("0.1");\n\nBigDecimal recommend2 = BigDecimal.valueOf(0.1);\n\n⚠️ 注意：BigDecimal 只是手段，效率好，使用时最终还是要转成 对应的 double 数据类型。 使用 doubleValue() 转为 double。\n\n示例代码：\n\n// 包装浮点型数据成为大数据对象 BigDeciaml\nBigDecimal a1 = BigDecimal.valueOf(a);\nBigDecimal b1 = BigDecimal.valueOf(b);\nBigDecimal c1 = a1.add(b1);\n// BigDecimal c1 = a1.subtract(b1);\n// BigDecimal c1 = a1.multiply(b1);\n// BigDecimal c1 = a1.divide(b1);\nSystem.out.println(c1);\n\n// 目的：double\ndouble rs = c1.doubleValue();\nSystem.out.println(rs);\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n⚠️ BigDecimal 是一定要精度运算的\n\n如，10/3 就无法精确运算，故 BigDecimal 会抛出异常。\n\nsolve： public BigDecimal divide (另一个BigDecimal对象，精确几位，舍入模式)',normalizedContent:'# 面向对象进阶3（多态、内部类、常用 api）\n\n\n# 1. 多态：面向对象三大特征之三\n\n\n# 1.1 多态的概述、形式\n\n * 啥是多态\n   * 同一父类型的对象，执行同一个行为时，会表现出不同的行为特征。\n * 多态的常见形式\n   * 父类类型 对象名称 = new 子类构造器; （父类类型指向一个子类的对象）\n   * 接口 对象名称 = new 实现类构造器;（接口相当于一个干爹，实现类相当于儿子）\n   * 具体的行为方法在子类中重写\n * 多态中成员访问特点-\n   * 方法调用：编译看左边，运行看右边。\n   * 变量调用：编译看左边，运行也看左边。（多态侧重行为多态，变量没有多态的概念）\n     * 即对于变量调用，还是会使用父类中的变量，而方法是会使用子类中重写的方法的。\n * 多态的前提\n   * 有继承/实现关系\n   * 有父类引用指向子类对象\n   * 有方法重写\n\n\n# 1.2 多态的优势\n\n 1. 在多态形式下，右边对象可以实现解耦合，便于扩展和维护。\n\nanimal a = new dog();\na.run(); // 后续业务行为随对象而变，后续代码无需修改\n\n\n1\n2\n\n\n上述代码中，若后续业务需要将 dog 子类改为tortoise 子类，则直接改“=”右侧的子类类型即可，后续代码中的行为随着对象的改变而直接变化了，无需修改很多后续的代码。\n\n 2. 定义方法的时候，使用父类型作为参数，该方法就可以接收这父类的一切子类对象，体现出多态的扩展性与便利\n\n多态下会产生的一个问题\n\n多态下不能使用子类的独有功能，因为编译时会使用左侧的父类中的行为。\n\nsolve：使用强制类型转换，将父转为子类型。\n\n\n# 1.3 多态下引用数据类型的类型转换\n\n在多态下会有两种类型转换：\n\n * 自动类型转换（从子到父）\n * 强制类型转换（从父到子）\n\n关于强制类型转换：\n\n * 子类类型 对象变量 = (子类)父类类型的变量\n   \n   代码示例：\n   \n   // 自动类型转换\n   animal a = new dog();\n   a.run();\n   // 强制类型转换:可以实现调用子类独有功能的\n   dog d = (dog) a;\n   d.lookdoor();\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   \n\n * 作用：可以解决多态下的劣势，可以实现调用子类独有的功能\n\n * 注意： 如果转型后的类型和对象真实类型不是同一种类型，那么在转换的时候就会报错 classcastexception（类型转换异常）\n\n强转转换的一点建议\n\n规定：有继承或者实现关系的2个类型就可以强制类型转换，故编译时可能没问题，但运行时发现强制转换后的类型不是对象真实类型而报错。\n\njava 建议强转转换前使用 instanceof 判断当前对象的真实类型，再进行强制转换。\n\n关于 instanceof 关键字的使用：\n\n变量名 instanceof 真实类型\n\n判断关键字左边的变量指向的对象的真实类型，是否是右边的类型或者是其子类类型，是则返回true，反之false。\n\n代码示例：\n\npublic static void go(animal a){  // 参数类型为父类类型，保证各种动物都可以使用go方法\n    system.out.println("预备~~~");\n    a.run();\n    // 独有功能\n    if(a instanceof tortoise){\n        tortoise t = (tortoise) a;\n        t.layeggs();\n    }else if(a instanceof dog){\n        dog d1 = (dog) a;\n        d1.lookdoor();\n    }\n    system.out.println("结束~~~~");\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 1.4 多态的案例\n\n需求：设计一个电脑对象，可以安装2个usb设备。鼠标：被安装时可以完成接入、调用点击功能、拔出功能；键盘：被安装时可以完成接入、调用打字功能、拔出功能。\n\n分析：\n\n①定义一个usb的接口（申明usb设备的规范必须是：可以接入和拔出）。\n\n②提供2个usb实现类代表鼠标和键盘，让其实现usb接口，并分别定义独有功能。\n\n③创建电脑对象，创建2个usb实现类对象，分别安装到电脑中并触发功能的执行。\n\n\n# 2. 内部类\n\n\n# 2.1 内部类的概述\n\n内部类就是定义在一个类里面的类，里面的类可以理解成（寄生），外部类可以理解成（宿主）。\n\n如，心脏和人的关系：\n\npublic class people{\n    // 内部类\n    public class heart{\n    }\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# 2.2 内部类的使用场景、作用\n\n * 当一个事物的内部，还有一个部分需要一个完整的结构进行描述，而这个内部的完整的结构又只为外部事物提供服务，那么整个内部的完整结构可以选择使用内部类来设计。\n * 内部类通常可以方便访问外部类的成员，包括私有的成员。\n * 内部类提供了更好的封装性，内部类本身就可以用 private、protected 等修饰，封装性可以做更多控制。（外部类只能用 public 修饰）\n\n\n# 2.3 内部类的分类\n\n# 2.3.1 静态内部类\n\n * 有static修饰，属于外部类本身\n * 特点、使用与普通类是一样的，类有的成分它都有，只是位置在别人里面而已\n * 可以直接访问外部类的静态成员，不能直接访问外部类的实例成员（可以创建一个外部类对象，再访问其实例成员）\n * 注意：开发中实际上用的还是比较少\n * 定义示例：\n\npublic class outer{\n        // 静态成员内部类\n    public static class inner{\n    }\n}\n\n\n1\n2\n3\n4\n5\n\n * 创建对象的格式：outer.inner in = new outer.inner();\n\n# 2.3.2 成员内部类\n\n * 无 static 修饰，属于外部类的对象\n * jdk16 之前，成员内部类中不能定义静态成员，jdk 16 开始也可以定义静态成员了\n * 特点：可以直接访问外部类的静态成员，实例方法中可以直接访问外部类的实例成员（因为必须先有外部类对象，才能有成员内部类对象，所以可以直接访问外部类对象的实例成员）\n * 定义示例：\n\npublic class outer {\n    // 成员内部类\n    public class inner {        \n    }\n}\n\n\n1\n2\n3\n4\n5\n\n * 创建对象格式：outer.inner in = new outer().new inner(); （注意外部类对象后面要加() ）\n * 相关面试题：\n   * 在成员内部类中访问所在外部类对象，格式：外部类名.this.value，如：system.out.println(people.this.heartbeat);\n   * 访问当前对象的成员变量，要用 this.value\n\n# 2.3.3 局部内部类\n\n * 鸡肋语法，了解即可\n * 局部内部类放在方法、代码块、构造器等执行体中\n * 局部内部类编译后也会有对应的类文件，其类文件名为： 外部类$n内部类.class\n\n# 2.3.4 匿名内部类\n\n * 本质上是一个没有名字的局部内部类，定义在方法中、代码块中、等\n\n * 作用：方便创建子类对象，最终目的为了简化代码编写\n\n * 特点\n   \n   * 匿名内部类写出来就会产生一个匿名内部类的对象\n   * 匿名内部类的对象类型相当于是当前 new 的那个的类型的子类类型（可以视为是 animal 的子类 tiger 类）\n\n * 格式\n\nnew 类|抽象类名|或者接口名() {\n    重写方法;\n};\n\n\n1\n2\n3\n\n\nanimal a = new animal() {\n    public void run() {\n    }\n};\na. run();\n\n\n1\n2\n3\n4\n5\n\n\n⚠️ 直接 new abstract_class() 是不可以的，故后面加上 {} 进行方法的重写，实现一个匿名内部类。\n\n简单示例：\n\nline3 等号后 ~ line8 的部分相当于 tiger 类了。\n\npublic class test {\n    public static void main(string[] args) {\n        animal a = new animal(){\n            @override\n            public void run() {\n                system.out.println("老虎跑的块~~~");\n            }\n        };\n        a.run();\n    }\n}\n\n//class tiger extends animal{\n//    @override\n//    public void run() {\n//        system.out.println("老虎跑的块~~~");\n//    }\n//}\n\nabstract class animal{\n    public abstract void run();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n# 2.3.5 匿名内部类常见使用形式\n\n匿名内部类通常作为方法的实际参数进行传输。\n\n示例代码：\n\npublic class test2 {\n    public static void main(string[] args) {\n        \n        go(new swimming() {\n            @override\n            public void swim() {\n                system.out.println("运动员泳🏊的贼快~~~~~");\n            }\n        });\n\n    /**\n       学生 老师 运动员可以一起参加游泳比赛\n     */\n    public static void go(swimming s){\n        system.out.println("开始。。。");\n        s.swim();\n        system.out.println("结束。。。");\n    }\n}\n    \ninterface swimming{\n    void swim();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n对象回调：\n\n提示\n\n开发中不是我们主动去定义匿名内部类的，而是别人需要我们写或者我们可以写的时候才会使用。\n\n匿名内部类的代码可以实现代码进一步的简化。\n\n\n# 3. 常用 api\n\n\n# 3.1 object 类\n\n * object 类的方法是一切子类对象都可以直接使用的，所以我们要学习 object 类的方法。\n\n * 一个类要么默认继承了 object 类，要么间接继承了 object 类，object 类是 java 中的祖宗类\n\n * object类的常用方法\n\n方法名                               说明\npublic string tostring()          默认是返回当前对象在堆内存中的地址信息:类的全限名@内存地址\npublic boolean equals(object o)   默认是比较当前对象与另一个对象的地址是否相同，相同返回true，不同返回false\n\n * 一般直接在 idea 中自动重写对应类的这两个方法即可。\n\ntostring 方法：\n\n因为 tostring 默认输出对象的地址在开发中毫无意义，更多是希望看到对象的内容数据）\n\ntostring 方法存在的意义就是为了被子类重写，以便返回对象的内容信息，而不是地址信息\n\nequals 方法：\n\n直接比较两个对象的地址是否相同完全可以用 “==” 替代 equals\n\n父类 equals 方法存在的意义就是为了被子类重写，以便子类自己来定制比较规则\n\n\n# 3.2 objects 类\n\nobjects 是一个工具类，提供了一些方法去完成一些功能\n\nobjects 类与 object 类也是继承关系。\n\nobjects 类是从 jdk1.7 之后才有的。\n\n官方在进行字符串比较时（自动重写的 equals 方法），没有用字符串对象的的 equals 方法，而是选择了 objects 的 equals 方法来比较。\n\n原因：使用objects 的 equals 方法在进行对象的内容比较时会更安全。\n\n使用 objects 的 equals 方法在进行对象的内容比较时更安全的原因\n\nobjects 的 equals 方法在比较时，底层会先进行非空判断，从而可以避免空指针异常。再进行 equals 比较\n\n源码分析：\n\npublic static boolean equals(object a, object b) {\n    return (a == b) || (a != null && a.equals(b));\n}\n\n\n1\n2\n3\n\n\n若直接使用 equals 方法比较时，可能会出现空指针异常，例如：\n\npublic class test {\n    public static void main(string[] args) {\n        string s1 = null;\n        string s2 = new string("itheima");\n\n        // system.out.println(s1.equals(s2));   // 留下了隐患，可能出现空指针异常。\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nstring 的 equals 方法 vs 类的 equals 方法\n\n字符串可以直接用 equals 比较内容，因为 string 类已经重写过该方法了；但自定义的类要重写 equals 方法。\n\n⚠️ string 不能用 “==” 比较内容是否一样，因为 “==” 会视为比较的二者为不同的对象\n\n\n# 3.3 stringbuilder 类\n\n * stringbuilder 是一个可变的字符串类，我们可以把它看成是一个对象容器。（string 是不可变字符串类）\n\n * 作用：提高字符串的操作效率，如拼接、修改等。\n\n * stringbuilder 常用方法\n\n方法名称                                说明\npublic stringbuilder append(任意类型)   添加数据并返回stringbuilder对象本身\npublic stringbuilder reverse()      将对象的内容反转，会直接将对象本身修改\npublic int length()                 返回对象内容长度\npublic string tostring()            通过tostring()就可以实现把stringbuilder转换为string\n\n * stringbuilder 支持链式编程，e.g. sb1.append("a").append("b").append("c").append("我爱你中国");\n\n⚠️ 注意：stringbuilder 只是拼接字符串的手段，效率好，使用时最终还是要转成 string。 用 tostring 恢复 string。故 定义字符串用 string，拼接、修改等操作字符串使用 stringbuilder。\n\n示例代码：\n\nstringbuilder sb2 = new stringbuilder();\nsb2.append("123").append("456");\n// 恢复成string类型\nstring rs = sb2.tostring();\ncheck(rs); // 使用字符串\n\npublic static void check(string data){\n    system.out.println(data);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n内存原理\n\nstring 类拼接字符串时，一个加号会导致堆内存中创建两个对象，一个是拼接时的 stringbuilder 对象，一个是拼好后转换过去的 string 对象。\n\n\n\nstringbuilder 类拼接字符串时，只会在堆内存中创建一个 stringbuilder 对象，所有拼接操作都在这个对象中完成。效率变高。\n\n\n\n\n# 3.4 math 类\n\n包含执行基本数字运算的方法，math类没有提供公开的构造器\n\n**如何使用类中的成员呢？**看类的成员是否都是静态的，如果是，通过类名就可以直接调用\n\nmath 类的常用方法\n\n方法名                                           说明\npublic static int abs(int a)                  获取参数绝对值\npublic static double ceil(double a)           向上取整\npublic static double floor(double a)          向下取整\npublic static int round(float a)              四舍五入\npublic static int max(int a,int b)            获取两个int值中的较大值\npublic static double pow(double a,double b)   返回a的b次幂的值\npublic static double random()                 返回值为double的随机值，范围[0.0,1.0)\n\n\n# 3.5 system 类\n\nsystem 也是一个工具类，代表了当前系统，提供了一些与系统相关的方法\n\nsystem 类的常用方法\n\n方法名                                                            说明\npublic static void exit(int status)                            终止当前运行的 java 虚拟机，非零表示异常终止\npublic static long currenttimemillis()                         返回当前系统的时间毫秒值形式\npublic static void arraycopy(数据源数组, 起始索引, 目的地数组, 起始索引, 拷贝个数)   数组拷贝 （了解）\n\n注意：system.exit() 相当于删库跑路，可不能瞎用！！！\n\n关于时间毫秒值：\n\n * 计算机认为时间是有起点的，起始时间： 1970年1月1日 00:00:00\n\n * 时间毫秒值：指的是从1970年1月1日 00:00:00走到此刻的总的毫秒数，应该是很大的。 1s = 1000ms。\n\n * system.currenttimemillis() 可以用来进行时间的计算：性能分析。\n\n\n# 3.6 bigdecimal 类\n\n（大数据类型）用于解决浮点型运算精度失真的问题\n\n浮点型运算的时候直接+ * / 可能会出现数据失真（精度问题）。\n\nbigdecimal 的使用：\n\n创建对象 bigdecimal 封装浮点型数据（最好的方式是调用方法）\n\n⚠️ 阿里开发规范：禁止使用构造方法 bigdecimal(double)的方式把 double 值转化为 bigderimal 对象。\n\n原因：bigdecimal(double)存在精度损失风险，在精确计算或值比较的场景中可能会导致业务逻辑异常。如:bigdecimalg = new bigdecimal(0.1f);实际的存储值为:0.10000000149\n\n正例：优先推荐入参为string 的构造方法，或使用 bigdecimal 的 valueof 方法，此方法内部其实执行了double 的 tostring，而 double 的 tostring 按 double 的实际能表达的精度对尾数进行了截断。\n\nbigdecimal recommend1 = new bigdecimal("0.1");\n\nbigdecimal recommend2 = bigdecimal.valueof(0.1);\n\n⚠️ 注意：bigdecimal 只是手段，效率好，使用时最终还是要转成 对应的 double 数据类型。 使用 doublevalue() 转为 double。\n\n示例代码：\n\n// 包装浮点型数据成为大数据对象 bigdeciaml\nbigdecimal a1 = bigdecimal.valueof(a);\nbigdecimal b1 = bigdecimal.valueof(b);\nbigdecimal c1 = a1.add(b1);\n// bigdecimal c1 = a1.subtract(b1);\n// bigdecimal c1 = a1.multiply(b1);\n// bigdecimal c1 = a1.divide(b1);\nsystem.out.println(c1);\n\n// 目的：double\ndouble rs = c1.doublevalue();\nsystem.out.println(rs);\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n⚠️ bigdecimal 是一定要精度运算的\n\n如，10/3 就无法精确运算，故 bigdecimal 会抛出异常。\n\nsolve： public bigdecimal divide (另一个bigdecimal对象，精确几位，舍入模式)',charsets:{cjk:!0},lastUpdated:"2023/03/15, 14:34:12",lastUpdatedTimestamp:1678890852e3},{title:"面向对象进阶4（常用日期API、正则、Arrays类、Lambda）",frontmatter:{title:"面向对象进阶4（常用日期API、正则、Arrays类、Lambda）",date:"2023-03-12T10:11:10.000Z",permalink:"/pages/4cb625/",categories:["开发","Java","黑马Java入门基础-学习笔记"],tags:[null]},regularPath:"/%E5%BC%80%E5%8F%91/10.Java/05.%E9%BB%91%E9%A9%ACJava%E5%85%A5%E9%97%A8%E5%9F%BA%E7%A1%80-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/33.%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%BF%9B%E9%98%B64%EF%BC%88%E5%B8%B8%E7%94%A8%E6%97%A5%E6%9C%9FAPI%E3%80%81%E6%AD%A3%E5%88%99%E3%80%81Arrays%E7%B1%BB%E3%80%81Lambda%EF%BC%89.html",relativePath:"开发/10.Java/05.黑马Java入门基础-学习笔记/33.面向对象进阶4（常用日期API、正则、Arrays类、Lambda）.md",key:"v-433c42bb",path:"/pages/4cb625/",headers:[{level:2,title:"1. 日期与时间",slug:"_1-日期与时间",normalizedTitle:"1. 日期与时间",charIndex:41},{level:3,title:"1.1 Date 类",slug:"_1-1-date-类",normalizedTitle:"1.1 date 类",charIndex:88},{level:3,title:"1.2 SimpleDateFormat",slug:"_1-2-simpledateformat",normalizedTitle:"1.2 simpledateformat",charIndex:593},{level:3,title:"1.3 Calendar",slug:"_1-3-calendar",normalizedTitle:"1.3 calendar",charIndex:1020},{level:2,title:"2. JDK8 新增日期类",slug:"_2-jdk8-新增日期类",normalizedTitle:"2. jdk8 新增日期类",charIndex:1557},{level:3,title:"2.1 LocalDate、LocalTime、LocalDateTime",slug:"_2-1-localdate、localtime、localdatetime",normalizedTitle:"2.1 localdate、localtime、localdatetime",charIndex:1937},{level:3,title:"2.2 Instant 时间戳",slug:"_2-2-instant-时间戳",normalizedTitle:"2.2 instant 时间戳",charIndex:3722},{level:3,title:"2.3 DateTimeFormatter",slug:"_2-3-datetimeformatter",normalizedTitle:"2.3 datetimeformatter",charIndex:4139},{level:3,title:"2.4 Duration/Period/ChronoUnit",slug:"_2-4-duration-period-chronounit",normalizedTitle:"2.4 duration/period/chronounit",charIndex:5080},{level:4,title:"2.4.1 Period 类",slug:"_2-4-1-period-类",normalizedTitle:"2.4.1 period 类",charIndex:5246},{level:4,title:"2.4.2 Duration 类",slug:"_2-4-2-duration-类",normalizedTitle:"2.4.2 duration 类",charIndex:5914},{level:4,title:"2.4.3 ChronoUnit 类",slug:"_2-4-3-chronounit-类",normalizedTitle:"2.4.3 chronounit 类",charIndex:6759},{level:2,title:"3. 包装类",slug:"_3-包装类",normalizedTitle:"3. 包装类",charIndex:8542},{level:2,title:"4. 正则表达式",slug:"_4-正则表达式",normalizedTitle:"4. 正则表达式",charIndex:9749},{level:2,title:"5. Arrays 类",slug:"_5-arrays-类",normalizedTitle:"5. arrays 类",charIndex:12140},{level:2,title:"6. Lambda 表达式",slug:"_6-lambda-表达式",normalizedTitle:"6. lambda 表达式",charIndex:13781}],headersStr:"1. 日期与时间 1.1 Date 类 1.2 SimpleDateFormat 1.3 Calendar 2. JDK8 新增日期类 2.1 LocalDate、LocalTime、LocalDateTime 2.2 Instant 时间戳 2.3 DateTimeFormatter 2.4 Duration/Period/ChronoUnit 2.4.1 Period 类 2.4.2 Duration 类 2.4.3 ChronoUnit 类 3. 包装类 4. 正则表达式 5. Arrays 类 6. Lambda 表达式",content:'# 面向对象进阶4（常用日期API、正则、Arrays类、Lambda）\n\n\n# 1. 日期与时间\n\n> 这部分的内容了解即可，JDK8 新增的日期类比本部分中的好用\n\n\n# 1.1 Date 类\n\nDate 类代表当前所在系统的日期时间信息\n\n构造器\n\n名称                       说明\npublic Date()            创建一个Date对象，代表的是系统当前此刻日期时间。\npublic Date(long time)   把时间毫秒值转换成Date日期对象\n\n常用方法\n\n名称                               说明\npublic long getTime()            返回从1970年1月1日 00:00:00走到此刻的总的毫秒数\npublic void setTime(long time)   设置日期对象的时间为当前时间毫秒值对应的时间\n\n * 日期对象如何创建，如何获取时间毫秒值？\n   \n   * public Date();\n   \n   * public long getTime();\n\n * 时间毫秒值怎么恢复成日期对象?\n   \n   * public Date(long time);\n   \n   * public void setTime(long time);\n\n\n# 1.2 SimpleDateFormat\n\n作用：\n\n 1. 完成日期时间的格式化操作\n    \n    public SimpleDateFormat(String pattern)：构造一个SimpleDateFormat，使用指定的格式\n    \n    格式化方法                                     说明\n    public final String format(Date date)     将日期格式化成日期/时间字符串\n    public final String format(Object time)   将时间毫秒值式化成日期/时间字符串\n\n 2. 解析字符串时间成为日期对象\n    \n    2011-11-11 11:11:22 -> Date日期对象\n    \n    public Date parse(String source)：从给定字符串的开始解析文本以生成日期\n\n\n# 1.3 Calendar\n\n * Calendar代表了系统此刻日期对应的日历对象\n\n * Calendar是一个抽象类，不能直接创建对象\n   \n   Calendar日历类创建日历对象的方法：public static Calendar getInstance()，获取当前日历对象\n\n * Calendar常用方法\n   \n   方法名                                     说明\n   public int get(int field)               取日期中的某个字段信息。\n   public void set(int field,int value)    修改日历的某个字段信息。\n   public void add(int field,int amount)   为某个字段增加/减少指定的值\n   public final Date getTime()             拿到此刻日期对象。\n   public long getTimeInMillis()           拿到此刻时间毫秒值\n\n⚠️ **注意：calendar是可变日期对象，一旦修改后其对象本身表示的时间将产生变化\n\n\n# 2. JDK8 新增日期类\n\n * 从Java 8开始，java.time包提供了新的日期和时间API，主要涉及的类型有：\n   \n   * LocalDate：不包含具体时间的日期。\n   \n   * LocalTime：不含日期的时间。\n   \n   * LocalDateTime：包含了日期及时间。\n   \n   * Instant：代表的是时间戳。\n   \n   * DateTimeFormatter 用于做时间的格式化和解析的\n   \n   * Duration:用于计算两个“时间”间隔\n   \n   * Period:用于计算两个“日期”间隔\n\n * 新增的API严格区分了时刻、本地日期、本地时间，并且，对日期和时间进行运算更加方便\n\n * 新API的类型几乎全部是不变类型（和String的使用类似），可以放心使用不必担心被修改\n\n\n# 2.1 LocalDate、LocalTime、LocalDateTime\n\n分别表示日期、时间、日期时间对象，他们的类的实例是不可变的对象，他们三者构建对象和API都是通用的\n\n构建对象的方式如下：\n\n方法名                         说明                 \npublic static Xxxx now();   静态方法，根据当前时间创建对象    LocaDate localDate = LocalDate.now(); LocalTime llocalTime =\n                                               LocalTime.now(); LocalDateTime localDateTime =\n                                               LocalDateTime.now();\npublic static Xxxx of(…);   静态方法，指定日期/时间创建对象   LocalDate localDate1 = LocalDate.of(2099 , 11,11); LocalTime\n                                               localTime1 = LocalTime.of(11, 11, 11); LocalDateTime\n                                               localDateTime1 = LocalDateTime.of(2020, 10, 6, 13, 23, 43);\n\nLocalDate、LocalTime、LocalDateTime获取信息的API：\n\n方法名                               说明\npublic int geYear()               获取年\npublic int getMonthValue()        获取月份（1-12）\nPublic int getDayOfMonth()        获取月中第几天乘法\nPublic int getDayOfYear()         获取年中第几天\nPublic DayOfWeek getDayOfWeek()   获取星期\n\n提示\n\n具体使用时查看 IDEA 提示的方法即可\n\n转换相关 API：\n\nLocalDateTime的转换API：\n\n方法名                              说明\npublic LocalDate toLocalDate()   转换成一个LocalDate对象\npublic LocalTime toLocalTime()   转换成一个LocalTime对象\n\n和时间修改相关的 API：\n\nLocalDateTime 综合了 LocalDate 和 LocalTime 里面的方法，所以下面只用 LocalDate 和 LocalTime 来举例。这些方法返回的是一个新的实例引用，因为LocalDateTime 、LocalDate 、LocalTime 都是不可变的\n\n方法名                                                  说明\nplusDays, plusWeeks, plusMonths, plusYears           向当前 LocalDate 对象添加几天、 几周、几个月、几年\nminusDays, minusWeeks, minusMonths, minusYears       从当前 LocalDate 对象减去几天、 几周、几个月、几年\nwithDayOfMonth, withDayOfYear, withMonth, withYear   将月份天数、年份天数、月份、年 份 修 改 为 指 定 的 值 并 返 回 新 的 LocalDate 对象\nisBefore, isAfter, equals                            比较两个 LocalDate\n\n\n# 2.2 Instant 时间戳\n\nJDK8 获取时间戳特别简单，且功能更丰富。Instant 类由一个静态的工厂方法 now() 可以返回当前时间戳\n\n \n\n\n \n\n\n \n\n\n\nInstant instant = Instant.now();\n System.out.println("当前时间戳是：" + instant);\n\n Date date = Date.from(instant);\n System.out.println("当前时间戳是：" + date);\n\n instant = date.toInstant();\n System.out.println(instant);\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n💡 时间戳是包含日期和时间的，与 java.util.Date 很类似，事实上 Instant 就是类似 JDK8 以前的 Date。\n\n💡 Instant和Date这两个类可以进行转换\n\n\n# 2.3 DateTimeFormatter\n\n在 JDK8 中，引入了一个全新的日期与时间格式器 DateTimeFormatter，正反都能调用format方法。\n\n示例代码：\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\npublic class Demo06DateTimeFormat {\n    public static void main(String[] args) {\n        // 本地此刻  日期时间 对象\n        LocalDateTime ldt = LocalDateTime.now();\n        System.out.println(ldt);\n\n        // 解析/格式化器\n        DateTimeFormatter dtf = DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss EEE a");\n        // 正向格式化（对象调用可以瞎搞）\n        System.out.println(dtf.format(ldt));\n        // 逆向格式化\n        System.out.println(ldt.format(dtf));\n\n        // 解析字符串时间\n        DateTimeFormatter dtf1 = DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss");\n        // 解析当前字符串时间成为本地日期时间对象\n        LocalDateTime ldt1 = LocalDateTime.parse("2019-11-11 11:11:11" ,  dtf1);\n        System.out.println(ldt1);\n        System.out.println(ldt1.getDayOfYear());\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n格式化的时间形式的常用的模式对应关系如下：\n\n\n# 2.4 Duration/Period/ChronoUnit\n\nJDK8 中，用来计算两个**“日期”间隔的类：java.time.Period；用来计算两个“时间”间隔**的类：java.time.Duration。\n\n最全的工具类：java.time.temporal.ChronoUnit，可以用于比较所有的时间单位。\n\n# 2.4.1 Period 类\n\n主要是 Period 类方法 getYears()，getMonths() 和 getDays() 来计算,只能精确到年月日。\n\n用于 LocalDate 之间的比较\n\n示例代码：\n\npublic class Demo07Period {\n    public static void main(String[] args) {\n        // 当前本地 年月日\n        LocalDate today = LocalDate.now();\n        System.out.println(today);//\n\n        // 生日的 年月日\n        LocalDate birthDate = LocalDate.of(1998, 10, 13);\n        System.out.println(birthDate);\n\n        Period period = Period.between(birthDate, today);//第二个参数减第一个参数\n\n        System.out.println(period.getYears());\n        System.out.println(period.getMonths());\n        System.out.println(period.getDays());\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n# 2.4.2 Duration 类\n\n提供了使用基于时间的值测量时间量的方法\n\n用于 LocalDateTime 之间的比较。也可用于 Instant 之间的比较\n\n示例代码：\n\npublic class Demo08Duration {\n    public static void main(String[] args) {\n        // 本地日期时间对象。\n        LocalDateTime today = LocalDateTime.now();\n        System.out.println(today);\n\n        // 出生的日期时间对象\n        LocalDateTime birthDate = LocalDateTime.of(2021,8,06,01,00,00);\n\n        System.out.println(birthDate);\n\n        Duration duration = Duration.between(today, birthDate);//第二个参数减第一个参数\n\n        System.out.println(duration.toDays());//两个时间差的天数\n        System.out.println(duration.toHours());//两个时间差的小时数\n        System.out.println(duration.toMinutes());//两个时间差的分钟数\n        System.out.println(duration.toMillis());//两个时间差的毫秒数\n        System.out.println(duration.toNanos());//两个时间差的纳秒数\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n# 2.4.3 ChronoUnit 类\n\nChronoUnit 类可用于在单个时间单位内测量一段时间，这个工具类是最全的了，可以用于比较所有的时间单位。\n\n示例代码：\n\npublic class Demo09ChronoUnit {\n    public static void main(String[] args) {\n        // 本地日期时间对象：此刻的\n        LocalDateTime today = LocalDateTime.now();\n        System.out.println(today);\n\n        // 生日时间\n        LocalDateTime birthDate = LocalDateTime.of(1990,10,1,\n                10,50,59);\n        System.out.println(birthDate);\n\n        System.out.println("相差的年数：" + ChronoUnit.YEARS.between(birthDate, today));\n        System.out.println("相差的月数：" + ChronoUnit.MONTHS.between(birthDate, today));\n        System.out.println("相差的周数：" + ChronoUnit.WEEKS.between(birthDate, today));\n        System.out.println("相差的天数：" + ChronoUnit.DAYS.between(birthDate, today));\n        System.out.println("相差的时数：" + ChronoUnit.HOURS.between(birthDate, today));\n        System.out.println("相差的分数：" + ChronoUnit.MINUTES.between(birthDate, today));\n        System.out.println("相差的秒数：" + ChronoUnit.SECONDS.between(birthDate, today));\n        System.out.println("相差的毫秒数：" + ChronoUnit.MILLIS.between(birthDate, today));\n        System.out.println("相差的微秒数：" + ChronoUnit.MICROS.between(birthDate, today));\n        System.out.println("相差的纳秒数：" + ChronoUnit.NANOS.between(birthDate, today));\n        System.out.println("相差的半天数：" + ChronoUnit.HALF_DAYS.between(birthDate, today));\n        System.out.println("相差的十年数：" + ChronoUnit.DECADES.between(birthDate, today));\n        System.out.println("相差的世纪（百年）数：" + ChronoUnit.CENTURIES.between(birthDate, today));\n        System.out.println("相差的千年数：" + ChronoUnit.MILLENNIA.between(birthDate, today));\n        System.out.println("相差的纪元数：" + ChronoUnit.ERAS.between(birthDate, today));\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n\n\n\n# 3. 包装类\n\n8种基本数据类型对应的引用类型\n\n基本数据类型    引用数据类型\nbyte      Byte\nshort     Short\nint       Integer\nlong      Long\nchar      Character\nfloat     Float\ndouble    Double\nboolean   Boolean\n\n💡 提供包装类的原因：\n\n 1. Java为了实现一切皆对象，为8种基本类型提供了对应的引用类型。\n 2. 集合和泛型只支持包装类型，不支持基本数据类型\n\n包装类的特性：\n\n * 自动装箱：基本类型的数据和变量可以直接赋值给包装类型的变量\n\n * **自动拆箱：**包装类型的变量可以直接赋值给基本数据类型的变量\n\n包装类的特有功能：\n\n * ✨ 包装类的变量的默认值可以是null，容错率更高\n\n * 可以把基本类型的数据转换成字符串类型(用处不大)\n   \n   * 因为可以直接+字符串得到字符串类型\n     \n     如：String rs2 = i3 + "";\n   \n   * ①调用toString()方法得到字符串结果。\n     \n     ②调用Integer.toString(基本类型的数据)。\n\n * ✨ 可以把字符串类型的数值转换成真实的数据类型（真的很有用）\n   \n   * ①Integer.parseInt(“字符串类型的整数”)\n     \n     ②Double.parseDouble(“字符串类型的小数”)\n     \n     ③Integer/Double.valueOf(“字符串类型的数值”) --\x3e 比前两个好使，直接使用统一的方法\n   \n   * 代码示例：\n     \n     String number = "23";\n     //转换成整数\n     // int age = Integer.parseInt(number);\n     int age = Integer.valueOf(number);\n     System.out.println(age + 1);  // 24\n     \n     String number1 = "99.9";\n     //转换成小数\n     //double score = Double.parseDouble(number1);\n     double score = Double.valueOf(number1);\n     System.out.println(score + 0.1);  // 100.0\n     \n     \n     1\n     2\n     3\n     4\n     5\n     6\n     7\n     8\n     9\n     10\n     11\n     \n\n\n# 4. 正则表达式\n\n正则表达式可以用一些规定的字符来制定规则，并用来校验数据格式的合法。如，校验用户名、密码、验证码等输入数据的合法性。\n\n字符串对象提供了匹配正则表达式的方法：\n\npublic boolean matches([String regex): 判断是否匹配正则表达式，匹配返回true，不匹配返回false\n\n匹配规则：\n\n * 字符类(默认匹配一个字符)\n   \n   正则表达式           匹配结果\n   [abc]           只能是a, b, 或c\n   [^abc]          除了a, b, c之外的任何字符\n   [a-zA-Z]        a到z A到Z，包括（范围）\n   [a-d[m-p]]]     a到d，或m通过p：（[a-dm-p]联合）\n   [a-z&&[def]]    d, e, 或f(交集)\n   [a-z&&[^bc]]    a到z，除了b和c\n   [a-z&&[^m-p]]   a到z，除了m到p\n\n * 预定义的字符类(默认匹配一个字符)\n   \n   正则表达式   匹配结果\n   .       任何字符\n   \\d      一个数字： [0-9]\n   \\D      非数字： [^0-9]\n   \\s      一个空白字符：[ \\t\\n\\x0B\\f\\r]\n   \\S      非空白字符：[^\\s]\n   \\w      [a-zA-Z_0-9] 英文、数字、下划线\n   \\W      [^\\w] 一个非单词字符\n   \n   ⚠️ 此处的 “\\...” 在写代码时要用“\\\\”。\n\n * 贪婪的量词（配合匹配多个字符）\n   \n   正则表达式    匹配结果\n   X?       X , 一次或根本不\n   X*       X，零次或多次\n   X+       X，一次或多次\n   X{n}     X，正好n次\n   X{n,}    X，至少n次\n   X{n,m}   X，至少n但不超过m次\n\n正则表达式在字符串方法中的使用：\n\n方法名                                                    说明\npublic String replaceAll(String regex,String newStr)   按照正则表达式匹配的内容进行替换\npublic String[] split(String regex)：                   按照正则表达式匹配的内容进行分割字符串，反回一个字符串数组。\n\n代码示例：\n\npublic class RegexDemo04 {\n    public static void main(String[] args) {\n        String names = "小路dhdfhdf342蓉儿43fdffdfbjdfaf小何";\n\n        String[] arrs = names.split("\\\\w+");\n        for (int i = 0; i < arrs.length; i++) {\n            System.out.println(arrs[i]);\n        }\n\n        String names2 = names.replaceAll("\\\\w+", "  ");\n        System.out.println(names2);  // 小路  蓉儿  小何\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n使用正则表达式爬取信息中的内容：\n\n示例代码：\n\npublic class RegexDemo05 {\n    public static void main(String[] args) {\n        String rs = "来黑马程序学习Java,电话020-43422424，或者联系邮箱" +\n                "itcast@itcast.cn,电话18762832633，0203232323" +\n                "邮箱bozai@itcast.cn，400-100-3233 ，4001003232";\n\n        // 需求：从上面的内容中爬取出 电话号码和邮箱。\n        // 1、定义爬取规则，字符串形式\n        String regex = "(\\\\w{1,30}@[a-zA-Z0-9]{2,20}(\\\\.[a-zA-Z0-9]{2,20}){1,2})|(1[3-9]\\\\d{9})|(0\\\\d{2,6}-?\\\\d{5,20})|(400-?\\\\d{3,9}-?\\\\d{3,9})";\n\n        // 2、把这个爬取规则编译成匹配对象。\n        Pattern pattern = Pattern.compile(regex);\n\n        // 3、得到一个内容匹配器对象\n        Matcher matcher = pattern.matcher(rs);\n\n        // 4、开始找了\n        while (matcher.find()) {\n            String rs1 = matcher.group();\n            System.out.println(rs1);\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n\n# 5. Arrays 类\n\nArrays 类是数组操作工具类，专门用于操作数组元素的。\n\nArrays类的常用 API ：\n\n方法名                                                            说明\npublic static String toString(类型[] a)                          返回数组的内容（字符串形式）\npublic static void sort(类型[] a)                                对数组进行默认升序排序\npublic static <T> void sort(类型[] a, Comparator<? super T> c)   使用比较器对象自定义排序\npublic static int binarySearch(int[] a, int key)               二分搜索数组中的数据，存在返回索引，不存在返回-1\n\n代码示例：\n\nint[] arr = {10, 2, 55, 23, 24, 100};\nSystem.out.println(Arrays.toString(arr));\n\nArrays.sort(arr);\nSystem.out.println(Arrays.toString(arr));\n\n\n1\n2\n3\n4\n5\n\n\nArrays 类对于 Comparator 比较器的支持：\n\n可以通过设置 Comparator 接口对应的比较器对象，来定制比较规则\n\n * 如果认为左边数据 大于 右边数据 返回正整数\n   \n   如果认为左边数据 小于 右边数据 返回负整数\n   \n   如果认为左边数据 等于 右边数据 返回0\n\n⚠️ 被排序的数组 必须是引用类型的元素\n\n代码示例：\n\n\n\n\n\n\n\n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\n\n\n        // 2、需求：降序排序！(自定义比较器对象，只能支持引用类型的排序！！)\n        Integer[] ages1 = {34, 12, 42, 23};\n        /**\n           参数一：被排序的数组 必须是引用类型的元素\n           参数二：匿名内部类对象，代表了一个比较器对象。\n         */\n        Arrays.sort(ages1, new Comparator<Integer>() {\n            @Override\n            public int compare(Integer o1, Integer o2) {\n                // 指定比较规则。\n//                if(o1 > o2){\n//                    return 1;\n//                }else if(o1 < o2){\n//                    return -1;\n//                }\n//                return 0;\n                // return o1 - o2; // 默认升序\n                return o2 - o1; //  降序\n            }\n        });\n        System.out.println(Arrays.toString(ages1));\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n上述比较规则可以简化为：\n\nArrays.sort(ages1, ( o1,  o2 ) ->  o2 - o1 );\n\n\n1\n\n\n\n# 6. Lambda 表达式\n\nLambda表达式是JDK 8开始后的一种新语法形式\n\n**作用：**简化匿名内部类的代码写法\n\nLambda 表达式的简化格式：\n\n(匿名内部类被重写方法的形参列表) -> {\n  被重写方法的方法体代码。\n }\n\n注：-> 是语法形式，无实际含义\n\n\n1\n2\n3\n4\n5\n\n\n⚠️ 注意: Lambda 表达式只能简化函数式接口的匿名内部类的写法形式\n\n函数式接口要求：\n\n 1. 必须是接口\n 2. 接口中有且仅有一个抽象方法\n 3. 若有@FunctionalInterface注解，则表明该接口是一个函数式接口\n\n示例简化常见函数式接口：\n\n\n\n\n\n**Lambda 表达式的省略规则: **\n\n * 参数类型可以省略不写。\n * 如果只有一个参数，参数类型可以省略，同时()也可以省略。\n * 如果Lambda表达式的方法体代码只有一行代码。可以省略大括号不写,同时要省略分号！\n * 如果Lambda表达式的方法体代码只有一行代码。可以省略大括号不写。此时，如果这行代码是return语句，必须省略return不写，同时也必须省略";"不写',normalizedContent:'# 面向对象进阶4（常用日期api、正则、arrays类、lambda）\n\n\n# 1. 日期与时间\n\n> 这部分的内容了解即可，jdk8 新增的日期类比本部分中的好用\n\n\n# 1.1 date 类\n\ndate 类代表当前所在系统的日期时间信息\n\n构造器\n\n名称                       说明\npublic date()            创建一个date对象，代表的是系统当前此刻日期时间。\npublic date(long time)   把时间毫秒值转换成date日期对象\n\n常用方法\n\n名称                               说明\npublic long gettime()            返回从1970年1月1日 00:00:00走到此刻的总的毫秒数\npublic void settime(long time)   设置日期对象的时间为当前时间毫秒值对应的时间\n\n * 日期对象如何创建，如何获取时间毫秒值？\n   \n   * public date();\n   \n   * public long gettime();\n\n * 时间毫秒值怎么恢复成日期对象?\n   \n   * public date(long time);\n   \n   * public void settime(long time);\n\n\n# 1.2 simpledateformat\n\n作用：\n\n 1. 完成日期时间的格式化操作\n    \n    public simpledateformat(string pattern)：构造一个simpledateformat，使用指定的格式\n    \n    格式化方法                                     说明\n    public final string format(date date)     将日期格式化成日期/时间字符串\n    public final string format(object time)   将时间毫秒值式化成日期/时间字符串\n\n 2. 解析字符串时间成为日期对象\n    \n    2011-11-11 11:11:22 -> date日期对象\n    \n    public date parse(string source)：从给定字符串的开始解析文本以生成日期\n\n\n# 1.3 calendar\n\n * calendar代表了系统此刻日期对应的日历对象\n\n * calendar是一个抽象类，不能直接创建对象\n   \n   calendar日历类创建日历对象的方法：public static calendar getinstance()，获取当前日历对象\n\n * calendar常用方法\n   \n   方法名                                     说明\n   public int get(int field)               取日期中的某个字段信息。\n   public void set(int field,int value)    修改日历的某个字段信息。\n   public void add(int field,int amount)   为某个字段增加/减少指定的值\n   public final date gettime()             拿到此刻日期对象。\n   public long gettimeinmillis()           拿到此刻时间毫秒值\n\n⚠️ **注意：calendar是可变日期对象，一旦修改后其对象本身表示的时间将产生变化\n\n\n# 2. jdk8 新增日期类\n\n * 从java 8开始，java.time包提供了新的日期和时间api，主要涉及的类型有：\n   \n   * localdate：不包含具体时间的日期。\n   \n   * localtime：不含日期的时间。\n   \n   * localdatetime：包含了日期及时间。\n   \n   * instant：代表的是时间戳。\n   \n   * datetimeformatter 用于做时间的格式化和解析的\n   \n   * duration:用于计算两个“时间”间隔\n   \n   * period:用于计算两个“日期”间隔\n\n * 新增的api严格区分了时刻、本地日期、本地时间，并且，对日期和时间进行运算更加方便\n\n * 新api的类型几乎全部是不变类型（和string的使用类似），可以放心使用不必担心被修改\n\n\n# 2.1 localdate、localtime、localdatetime\n\n分别表示日期、时间、日期时间对象，他们的类的实例是不可变的对象，他们三者构建对象和api都是通用的\n\n构建对象的方式如下：\n\n方法名                         说明                 \npublic static xxxx now();   静态方法，根据当前时间创建对象    locadate localdate = localdate.now(); localtime llocaltime =\n                                               localtime.now(); localdatetime localdatetime =\n                                               localdatetime.now();\npublic static xxxx of(…);   静态方法，指定日期/时间创建对象   localdate localdate1 = localdate.of(2099 , 11,11); localtime\n                                               localtime1 = localtime.of(11, 11, 11); localdatetime\n                                               localdatetime1 = localdatetime.of(2020, 10, 6, 13, 23, 43);\n\nlocaldate、localtime、localdatetime获取信息的api：\n\n方法名                               说明\npublic int geyear()               获取年\npublic int getmonthvalue()        获取月份（1-12）\npublic int getdayofmonth()        获取月中第几天乘法\npublic int getdayofyear()         获取年中第几天\npublic dayofweek getdayofweek()   获取星期\n\n提示\n\n具体使用时查看 idea 提示的方法即可\n\n转换相关 api：\n\nlocaldatetime的转换api：\n\n方法名                              说明\npublic localdate tolocaldate()   转换成一个localdate对象\npublic localtime tolocaltime()   转换成一个localtime对象\n\n和时间修改相关的 api：\n\nlocaldatetime 综合了 localdate 和 localtime 里面的方法，所以下面只用 localdate 和 localtime 来举例。这些方法返回的是一个新的实例引用，因为localdatetime 、localdate 、localtime 都是不可变的\n\n方法名                                                  说明\nplusdays, plusweeks, plusmonths, plusyears           向当前 localdate 对象添加几天、 几周、几个月、几年\nminusdays, minusweeks, minusmonths, minusyears       从当前 localdate 对象减去几天、 几周、几个月、几年\nwithdayofmonth, withdayofyear, withmonth, withyear   将月份天数、年份天数、月份、年 份 修 改 为 指 定 的 值 并 返 回 新 的 localdate 对象\nisbefore, isafter, equals                            比较两个 localdate\n\n\n# 2.2 instant 时间戳\n\njdk8 获取时间戳特别简单，且功能更丰富。instant 类由一个静态的工厂方法 now() 可以返回当前时间戳\n\n \n\n\n \n\n\n \n\n\n\ninstant instant = instant.now();\n system.out.println("当前时间戳是：" + instant);\n\n date date = date.from(instant);\n system.out.println("当前时间戳是：" + date);\n\n instant = date.toinstant();\n system.out.println(instant);\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n💡 时间戳是包含日期和时间的，与 java.util.date 很类似，事实上 instant 就是类似 jdk8 以前的 date。\n\n💡 instant和date这两个类可以进行转换\n\n\n# 2.3 datetimeformatter\n\n在 jdk8 中，引入了一个全新的日期与时间格式器 datetimeformatter，正反都能调用format方法。\n\n示例代码：\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\npublic class demo06datetimeformat {\n    public static void main(string[] args) {\n        // 本地此刻  日期时间 对象\n        localdatetime ldt = localdatetime.now();\n        system.out.println(ldt);\n\n        // 解析/格式化器\n        datetimeformatter dtf = datetimeformatter.ofpattern("yyyy-mm-dd hh:mm:ss eee a");\n        // 正向格式化（对象调用可以瞎搞）\n        system.out.println(dtf.format(ldt));\n        // 逆向格式化\n        system.out.println(ldt.format(dtf));\n\n        // 解析字符串时间\n        datetimeformatter dtf1 = datetimeformatter.ofpattern("yyyy-mm-dd hh:mm:ss");\n        // 解析当前字符串时间成为本地日期时间对象\n        localdatetime ldt1 = localdatetime.parse("2019-11-11 11:11:11" ,  dtf1);\n        system.out.println(ldt1);\n        system.out.println(ldt1.getdayofyear());\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n格式化的时间形式的常用的模式对应关系如下：\n\n\n# 2.4 duration/period/chronounit\n\njdk8 中，用来计算两个**“日期”间隔的类：java.time.period；用来计算两个“时间”间隔**的类：java.time.duration。\n\n最全的工具类：java.time.temporal.chronounit，可以用于比较所有的时间单位。\n\n# 2.4.1 period 类\n\n主要是 period 类方法 getyears()，getmonths() 和 getdays() 来计算,只能精确到年月日。\n\n用于 localdate 之间的比较\n\n示例代码：\n\npublic class demo07period {\n    public static void main(string[] args) {\n        // 当前本地 年月日\n        localdate today = localdate.now();\n        system.out.println(today);//\n\n        // 生日的 年月日\n        localdate birthdate = localdate.of(1998, 10, 13);\n        system.out.println(birthdate);\n\n        period period = period.between(birthdate, today);//第二个参数减第一个参数\n\n        system.out.println(period.getyears());\n        system.out.println(period.getmonths());\n        system.out.println(period.getdays());\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n# 2.4.2 duration 类\n\n提供了使用基于时间的值测量时间量的方法\n\n用于 localdatetime 之间的比较。也可用于 instant 之间的比较\n\n示例代码：\n\npublic class demo08duration {\n    public static void main(string[] args) {\n        // 本地日期时间对象。\n        localdatetime today = localdatetime.now();\n        system.out.println(today);\n\n        // 出生的日期时间对象\n        localdatetime birthdate = localdatetime.of(2021,8,06,01,00,00);\n\n        system.out.println(birthdate);\n\n        duration duration = duration.between(today, birthdate);//第二个参数减第一个参数\n\n        system.out.println(duration.todays());//两个时间差的天数\n        system.out.println(duration.tohours());//两个时间差的小时数\n        system.out.println(duration.tominutes());//两个时间差的分钟数\n        system.out.println(duration.tomillis());//两个时间差的毫秒数\n        system.out.println(duration.tonanos());//两个时间差的纳秒数\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n# 2.4.3 chronounit 类\n\nchronounit 类可用于在单个时间单位内测量一段时间，这个工具类是最全的了，可以用于比较所有的时间单位。\n\n示例代码：\n\npublic class demo09chronounit {\n    public static void main(string[] args) {\n        // 本地日期时间对象：此刻的\n        localdatetime today = localdatetime.now();\n        system.out.println(today);\n\n        // 生日时间\n        localdatetime birthdate = localdatetime.of(1990,10,1,\n                10,50,59);\n        system.out.println(birthdate);\n\n        system.out.println("相差的年数：" + chronounit.years.between(birthdate, today));\n        system.out.println("相差的月数：" + chronounit.months.between(birthdate, today));\n        system.out.println("相差的周数：" + chronounit.weeks.between(birthdate, today));\n        system.out.println("相差的天数：" + chronounit.days.between(birthdate, today));\n        system.out.println("相差的时数：" + chronounit.hours.between(birthdate, today));\n        system.out.println("相差的分数：" + chronounit.minutes.between(birthdate, today));\n        system.out.println("相差的秒数：" + chronounit.seconds.between(birthdate, today));\n        system.out.println("相差的毫秒数：" + chronounit.millis.between(birthdate, today));\n        system.out.println("相差的微秒数：" + chronounit.micros.between(birthdate, today));\n        system.out.println("相差的纳秒数：" + chronounit.nanos.between(birthdate, today));\n        system.out.println("相差的半天数：" + chronounit.half_days.between(birthdate, today));\n        system.out.println("相差的十年数：" + chronounit.decades.between(birthdate, today));\n        system.out.println("相差的世纪（百年）数：" + chronounit.centuries.between(birthdate, today));\n        system.out.println("相差的千年数：" + chronounit.millennia.between(birthdate, today));\n        system.out.println("相差的纪元数：" + chronounit.eras.between(birthdate, today));\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n\n\n\n# 3. 包装类\n\n8种基本数据类型对应的引用类型\n\n基本数据类型    引用数据类型\nbyte      byte\nshort     short\nint       integer\nlong      long\nchar      character\nfloat     float\ndouble    double\nboolean   boolean\n\n💡 提供包装类的原因：\n\n 1. java为了实现一切皆对象，为8种基本类型提供了对应的引用类型。\n 2. 集合和泛型只支持包装类型，不支持基本数据类型\n\n包装类的特性：\n\n * 自动装箱：基本类型的数据和变量可以直接赋值给包装类型的变量\n\n * **自动拆箱：**包装类型的变量可以直接赋值给基本数据类型的变量\n\n包装类的特有功能：\n\n * ✨ 包装类的变量的默认值可以是null，容错率更高\n\n * 可以把基本类型的数据转换成字符串类型(用处不大)\n   \n   * 因为可以直接+字符串得到字符串类型\n     \n     如：string rs2 = i3 + "";\n   \n   * ①调用tostring()方法得到字符串结果。\n     \n     ②调用integer.tostring(基本类型的数据)。\n\n * ✨ 可以把字符串类型的数值转换成真实的数据类型（真的很有用）\n   \n   * ①integer.parseint(“字符串类型的整数”)\n     \n     ②double.parsedouble(“字符串类型的小数”)\n     \n     ③integer/double.valueof(“字符串类型的数值”) --\x3e 比前两个好使，直接使用统一的方法\n   \n   * 代码示例：\n     \n     string number = "23";\n     //转换成整数\n     // int age = integer.parseint(number);\n     int age = integer.valueof(number);\n     system.out.println(age + 1);  // 24\n     \n     string number1 = "99.9";\n     //转换成小数\n     //double score = double.parsedouble(number1);\n     double score = double.valueof(number1);\n     system.out.println(score + 0.1);  // 100.0\n     \n     \n     1\n     2\n     3\n     4\n     5\n     6\n     7\n     8\n     9\n     10\n     11\n     \n\n\n# 4. 正则表达式\n\n正则表达式可以用一些规定的字符来制定规则，并用来校验数据格式的合法。如，校验用户名、密码、验证码等输入数据的合法性。\n\n字符串对象提供了匹配正则表达式的方法：\n\npublic boolean matches([string regex): 判断是否匹配正则表达式，匹配返回true，不匹配返回false\n\n匹配规则：\n\n * 字符类(默认匹配一个字符)\n   \n   正则表达式           匹配结果\n   [abc]           只能是a, b, 或c\n   [^abc]          除了a, b, c之外的任何字符\n   [a-za-z]        a到z a到z，包括（范围）\n   [a-d[m-p]]]     a到d，或m通过p：（[a-dm-p]联合）\n   [a-z&&[def]]    d, e, 或f(交集)\n   [a-z&&[^bc]]    a到z，除了b和c\n   [a-z&&[^m-p]]   a到z，除了m到p\n\n * 预定义的字符类(默认匹配一个字符)\n   \n   正则表达式   匹配结果\n   .       任何字符\n   \\d      一个数字： [0-9]\n   \\d      非数字： [^0-9]\n   \\s      一个空白字符：[ \\t\\n\\x0b\\f\\r]\n   \\s      非空白字符：[^\\s]\n   \\w      [a-za-z_0-9] 英文、数字、下划线\n   \\w      [^\\w] 一个非单词字符\n   \n   ⚠️ 此处的 “\\...” 在写代码时要用“\\\\”。\n\n * 贪婪的量词（配合匹配多个字符）\n   \n   正则表达式    匹配结果\n   x?       x , 一次或根本不\n   x*       x，零次或多次\n   x+       x，一次或多次\n   x{n}     x，正好n次\n   x{n,}    x，至少n次\n   x{n,m}   x，至少n但不超过m次\n\n正则表达式在字符串方法中的使用：\n\n方法名                                                    说明\npublic string replaceall(string regex,string newstr)   按照正则表达式匹配的内容进行替换\npublic string[] split(string regex)：                   按照正则表达式匹配的内容进行分割字符串，反回一个字符串数组。\n\n代码示例：\n\npublic class regexdemo04 {\n    public static void main(string[] args) {\n        string names = "小路dhdfhdf342蓉儿43fdffdfbjdfaf小何";\n\n        string[] arrs = names.split("\\\\w+");\n        for (int i = 0; i < arrs.length; i++) {\n            system.out.println(arrs[i]);\n        }\n\n        string names2 = names.replaceall("\\\\w+", "  ");\n        system.out.println(names2);  // 小路  蓉儿  小何\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n使用正则表达式爬取信息中的内容：\n\n示例代码：\n\npublic class regexdemo05 {\n    public static void main(string[] args) {\n        string rs = "来黑马程序学习java,电话020-43422424，或者联系邮箱" +\n                "itcast@itcast.cn,电话18762832633，0203232323" +\n                "邮箱bozai@itcast.cn，400-100-3233 ，4001003232";\n\n        // 需求：从上面的内容中爬取出 电话号码和邮箱。\n        // 1、定义爬取规则，字符串形式\n        string regex = "(\\\\w{1,30}@[a-za-z0-9]{2,20}(\\\\.[a-za-z0-9]{2,20}){1,2})|(1[3-9]\\\\d{9})|(0\\\\d{2,6}-?\\\\d{5,20})|(400-?\\\\d{3,9}-?\\\\d{3,9})";\n\n        // 2、把这个爬取规则编译成匹配对象。\n        pattern pattern = pattern.compile(regex);\n\n        // 3、得到一个内容匹配器对象\n        matcher matcher = pattern.matcher(rs);\n\n        // 4、开始找了\n        while (matcher.find()) {\n            string rs1 = matcher.group();\n            system.out.println(rs1);\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n\n# 5. arrays 类\n\narrays 类是数组操作工具类，专门用于操作数组元素的。\n\narrays类的常用 api ：\n\n方法名                                                            说明\npublic static string tostring(类型[] a)                          返回数组的内容（字符串形式）\npublic static void sort(类型[] a)                                对数组进行默认升序排序\npublic static <t> void sort(类型[] a, comparator<? super t> c)   使用比较器对象自定义排序\npublic static int binarysearch(int[] a, int key)               二分搜索数组中的数据，存在返回索引，不存在返回-1\n\n代码示例：\n\nint[] arr = {10, 2, 55, 23, 24, 100};\nsystem.out.println(arrays.tostring(arr));\n\narrays.sort(arr);\nsystem.out.println(arrays.tostring(arr));\n\n\n1\n2\n3\n4\n5\n\n\narrays 类对于 comparator 比较器的支持：\n\n可以通过设置 comparator 接口对应的比较器对象，来定制比较规则\n\n * 如果认为左边数据 大于 右边数据 返回正整数\n   \n   如果认为左边数据 小于 右边数据 返回负整数\n   \n   如果认为左边数据 等于 右边数据 返回0\n\n⚠️ 被排序的数组 必须是引用类型的元素\n\n代码示例：\n\n\n\n\n\n\n\n\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\n\n\n        // 2、需求：降序排序！(自定义比较器对象，只能支持引用类型的排序！！)\n        integer[] ages1 = {34, 12, 42, 23};\n        /**\n           参数一：被排序的数组 必须是引用类型的元素\n           参数二：匿名内部类对象，代表了一个比较器对象。\n         */\n        arrays.sort(ages1, new comparator<integer>() {\n            @override\n            public int compare(integer o1, integer o2) {\n                // 指定比较规则。\n//                if(o1 > o2){\n//                    return 1;\n//                }else if(o1 < o2){\n//                    return -1;\n//                }\n//                return 0;\n                // return o1 - o2; // 默认升序\n                return o2 - o1; //  降序\n            }\n        });\n        system.out.println(arrays.tostring(ages1));\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n上述比较规则可以简化为：\n\narrays.sort(ages1, ( o1,  o2 ) ->  o2 - o1 );\n\n\n1\n\n\n\n# 6. lambda 表达式\n\nlambda表达式是jdk 8开始后的一种新语法形式\n\n**作用：**简化匿名内部类的代码写法\n\nlambda 表达式的简化格式：\n\n(匿名内部类被重写方法的形参列表) -> {\n  被重写方法的方法体代码。\n }\n\n注：-> 是语法形式，无实际含义\n\n\n1\n2\n3\n4\n5\n\n\n⚠️ 注意: lambda 表达式只能简化函数式接口的匿名内部类的写法形式\n\n函数式接口要求：\n\n 1. 必须是接口\n 2. 接口中有且仅有一个抽象方法\n 3. 若有@functionalinterface注解，则表明该接口是一个函数式接口\n\n示例简化常见函数式接口：\n\n\n\n\n\n**lambda 表达式的省略规则: **\n\n * 参数类型可以省略不写。\n * 如果只有一个参数，参数类型可以省略，同时()也可以省略。\n * 如果lambda表达式的方法体代码只有一行代码。可以省略大括号不写,同时要省略分号！\n * 如果lambda表达式的方法体代码只有一行代码。可以省略大括号不写。此时，如果这行代码是return语句，必须省略return不写，同时也必须省略";"不写',charsets:{cjk:!0},lastUpdated:"2023/03/15, 14:34:12",lastUpdatedTimestamp:1678890852e3},{title:"面向对象进阶5（集合体系）",frontmatter:{title:"面向对象进阶5（集合体系）",date:"2023-03-15T15:18:28.000Z",permalink:"/pages/6013df/",categories:["开发","Java","黑马Java入门基础-学习笔记"],tags:[null]},regularPath:"/%E5%BC%80%E5%8F%91/10.Java/05.%E9%BB%91%E9%A9%ACJava%E5%85%A5%E9%97%A8%E5%9F%BA%E7%A1%80-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/34.%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%BF%9B%E9%98%B65%EF%BC%88%E9%9B%86%E5%90%88%E4%BD%93%E7%B3%BB%EF%BC%89.html",relativePath:"开发/10.Java/05.黑马Java入门基础-学习笔记/34.面向对象进阶5（集合体系）.md",key:"v-4f80c998",path:"/pages/6013df/",headers:[{level:2,title:"1. 集合体系概述",slug:"_1-集合体系概述",normalizedTitle:"1. 集合体系概述",charIndex:2},{level:3,title:"1.1 集合与数组",slug:"_1-1-集合与数组",normalizedTitle:"1.1 集合与数组",charIndex:16},{level:3,title:"1.2 集合类的体系结构",slug:"_1-2-集合类的体系结构",normalizedTitle:"1.2 集合类的体系结构",charIndex:234},{level:3,title:"1.3 Collection 集合的体系",slug:"_1-3-collection-集合的体系",normalizedTitle:"1.3 collection 集合的体系",charIndex:337},{level:3,title:"1.4 集合对泛型的支持",slug:"_1-4-集合对泛型的支持",normalizedTitle:"1.4 集合对泛型的支持",charIndex:595},{level:4,title:"1.4.1 自定义泛型类",slug:"_1-4-1-自定义泛型类",normalizedTitle:"1.4.1 自定义泛型类",charIndex:981},{level:4,title:"1.4.2 自定义泛型方法",slug:"_1-4-2-自定义泛型方法",normalizedTitle:"1.4.2 自定义泛型方法",charIndex:1480},{level:4,title:"1.4.3 自定义泛型接口",slug:"_1-4-3-自定义泛型接口",normalizedTitle:"1.4.3 自定义泛型接口",charIndex:1961},{level:4,title:"1.4.4 泛型通配符、上下限",slug:"_1-4-4-泛型通配符、上下限",normalizedTitle:"1.4.4 泛型通配符、上下限",charIndex:3222},{level:2,title:"2. Collection 集合",slug:"_2-collection-集合",normalizedTitle:"2. collection 集合",charIndex:3412},{level:3,title:"2.1 关于 Collection 自身",slug:"_2-1-关于-collection-自身",normalizedTitle:"2.1 关于 collection 自身",charIndex:3433},{level:3,title:"2.2 常见的数据结构",slug:"_2-2-常见的数据结构",normalizedTitle:"2.2 常见的数据结构",charIndex:8231},{level:3,title:"2.3 Collection 之 List 系列集合",slug:"_2-3-collection-之-list-系列集合",normalizedTitle:"2.3 collection 之 list 系列集合",charIndex:8441},{level:4,title:"2.3.1 ArrayList 集合的底层原理",slug:"_2-3-1-arraylist-集合的底层原理",normalizedTitle:"2.3.1 arraylist 集合的底层原理",charIndex:8944},{level:4,title:"2.3.2 LinkedList 集合的底层原理",slug:"_2-3-2-linkedlist-集合的底层原理",normalizedTitle:"2.3.2 linkedlist 集合的底层原理",charIndex:9095},{level:3,title:"2.4 Collection 之 Set 系列集合",slug:"_2-4-collection-之-set-系列集合",normalizedTitle:"2.4 collection 之 set 系列集合",charIndex:10347},{level:4,title:"2.4.1 HashSet 集合的底层原理",slug:"_2-4-1-hashset-集合的底层原理",normalizedTitle:"2.4.1 hashset 集合的底层原理",charIndex:10586},{level:4,title:"2.4.2 LinkedHashSet 集合",slug:"_2-4-2-linkedhashset-集合",normalizedTitle:"2.4.2 linkedhashset 集合",charIndex:11464},{level:4,title:"2.4.3 TreeSet 集合",slug:"_2-4-3-treeset-集合",normalizedTitle:"2.4.3 treeset 集合",charIndex:11606},{level:3,title:"2.5 Collection 体系的特点、使用场景总结",slug:"_2-5-collection-体系的特点、使用场景总结",normalizedTitle:"2.5 collection 体系的特点、使用场景总结",charIndex:14124},{level:2,title:"3. Collections 集合工具类",slug:"_3-collections-集合工具类",normalizedTitle:"3. collections 集合工具类",charIndex:14449}],headersStr:"1. 集合体系概述 1.1 集合与数组 1.2 集合类的体系结构 1.3 Collection 集合的体系 1.4 集合对泛型的支持 1.4.1 自定义泛型类 1.4.2 自定义泛型方法 1.4.3 自定义泛型接口 1.4.4 泛型通配符、上下限 2. Collection 集合 2.1 关于 Collection 自身 2.2 常见的数据结构 2.3 Collection 之 List 系列集合 2.3.1 ArrayList 集合的底层原理 2.3.2 LinkedList 集合的底层原理 2.4 Collection 之 Set 系列集合 2.4.1 HashSet 集合的底层原理 2.4.2 LinkedHashSet 集合 2.4.3 TreeSet 集合 2.5 Collection 体系的特点、使用场景总结 3. Collections 集合工具类",content:'# 1. 集合体系概述\n\n\n# 1.1 集合与数组\n\n集合和数组都是容器\n\n * 关于存储元素的个数：\n   \n   数组定义后类型确定，长度固定\n   \n   集合类型可以不固定，大小是可变的\n\n * 关于存储元素的类型：\n   \n   数组可以存储基本类型和引用类型的数据\n   \n   集合只能存引用数据类型的数据\n\n * 关于适合的场景：\n   \n   数组适合做数据个数和类型确定的场景\n   \n   集合适合做数据个数不确定，且要做增删元素的场景\n\n\n# 1.2 集合类的体系结构\n\n\n\n集合类分为两种体系：Collection 和 Map。Collection 单列集合，每个元素（数据）只包含一个值；Map 双列集合，每个元素包含两个值（键值对）。\n\n\n# 1.3 Collection 集合的体系\n\n\n\n> 上图中只是列出了几个常用的类型。\n\nCollection 集合分为两类常用的集合体系：\n\n * List 系列集合：添加的元素有序、可重复、有索引\n   * ArrayList、LinekdList ：有序、可重复、有索引\n * Set 系列集合：添加的元素是无序、不重复、无索引\n   * HashSet: 无序、不重复、无索引；LinkedHashSet: 有序、不重复、无索引\n   * TreeSet：**按照大小默认升序排序、**不重复、无索引\n\n\n# 1.4 集合对泛型的支持\n\n集合体系的全部接口和实现类都是支持泛型的使用的，可以在编译阶段约束集合只能操作某种数据类型。（把运行时期的问题提前到了编译期间，避免了强制类型转换可能出现的异常）\n\nCollection<String> lists = new ArrayList<String>();\nCollection<String> lists = new ArrayList<>(); // JDK 1.7开始后面的泛型类型申明可以省略不写\n\n\n1\n2\n\n\n⚠️ 注意：集合和泛型都只能支持引用数据类型，不支持基本数据类型，所以集合中存储的元素都认为是对象\n\n泛型的原理：\n\n把出现泛型变量的地方全部替换成传输的真实数据类型。\n\n泛型的定义位置：\n\n * 类后面 --- > 泛型类\n * 方法申明上 --- > 泛型方法\n * 接口后面 --- > 泛型接口\n\n# 1.4.1 自定义泛型类\n\n泛型类的格式：修饰符 class 类名<泛型变量>{ }，此处泛型变量 T 可以随便写为任意标识，常见的如 E、T、K、V 等\n\n作用：编译阶段约定操作的数据的类型，类似于集合的作用。\n\n示例代码：\n\n\n\n\n\n \n\n\n\n \n\n\n\n\n\n\n\n\n\n\npublic class MyArrayList<E> {\n    private ArrayList lists = new ArrayList();\n\n    public void add(E e){  // 不是泛型方法。只是使用类定义的这个泛型 E，而不是他自己定义了泛型\n        lists.add(e);\n    }\n\n    public void remove(E e){\n        lists.remove(e);\n    }\n\n    @Override\n    public String toString() {\n        return lists.toString();\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\n# 1.4.2 自定义泛型方法\n\n泛型方法的格式：修饰符 <泛型变量> 方法返回值 方法名称(形参列表){}\n\n作用：方法中可以使用泛型接收一切实际类型的参数，方法更具备通用性\n\n示例代码：\n\npublic static void main(String[] args) {\n    String[] names = {"小璐", "蓉容", "小何"};\n    printArray(names);\n\n    Integer[] ages = {10, 20, 30};\n    printArray(ages);\n\n    Integer[] ages2 = getArr(ages);  // 调用泛型函数，得到的内容不需要强转为具体的类型\n    String[]  names2 = getArr(names);  // 传进去啥类型，返回出来还是啥类型\n}\n\npublic static <T> T[] getArr(T[] arr){\n    return arr;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n# 1.4.3 自定义泛型接口\n\n泛型接口的格式：修饰符 interface 接口名称<泛型变量>{}\n\n作用：泛型接口可以让实现类选择当前功能需要操作的数据类型。\n\n实现类可以在实现接口的时候传入自己操作的数据类型，这样重写的方法都将是针对于该类型的操作。\n\n示例代码：\n\n\n\n\n\n\n\n\n \n \n\n \n\n\n\n \n\n \n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n \n\n \n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n// 需求：教务系统，提供一个接口可约束一定要完成数据（学生，老师）的增删改查操作\npublic class Student {\n}\n\npublic class Teacher {\n}\n\npublic interface Data<E> {  // 操作数据的接口\n    void add(E e);\n    void delete(int id);\n    void update(E e);\n    E queryById(int id);\n}\n\npublic class StudentData implements Data<Student>{  // 操作学生类数据的实现\n    @Override\n    public void add(Student student) {\n\n    }\n\n    @Override\n    public void delete(int id) {\n\n    }\n\n    @Override\n    public void update(Student student) {\n\n    }\n\n    @Override\n    public Student queryById(int id) {\n        return null;\n    }\n}\n\npublic class TeacherData implements Data<Teacher>{  // 操作教师类数据的实现\n    @Override\n    public void add(Teacher teacher) {\n\n    }\n\n    @Override\n    public void delete(int id) {\n\n    }\n\n    @Override\n    public void update(Teacher teacher) {\n\n    }\n\n    @Override\n    public Teacher queryById(int id) {\n        return null;\n    }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n\n\n# 1.4.4 泛型通配符、上下限\n\n通配符：?\n\n * ? 可以在“使用泛型”的时候代表一切类型。就是在应该填泛型的位置，填 “<?>” 。\n\n * E T K V 是在定义泛型的时候使用的。\n\n泛型的上下限：\n\n * 泛型上限： <? extends Car>，必须是Car或者其子类\n * 泛型下限：<? super Car> ，必须是Car或者其父类 ，用的相对较少\n\n\n# 2. Collection 集合\n\n\n# 2.1 关于 Collection 自身\n\nCollection 是单列集合的祖宗接口，它的功能是全部单列集合都可以继承使用的。\n\nCollection 的常用 API：\n\n方法名称                                  说明\npublic boolean add(E e)               把给定的对象添加到当前集合中\npublic boolean addAll(E e)            把c2(参数)集合的元素全部倒入到c1(被调集合)中去\npublic void clear()                   清空集合中所有的元素\npublic boolean remove(E e)            把给定的对象在当前集合中删除\npublic boolean contains(Object obj)   判断当前集合中是否包含给定的对象\npublic boolean isEmpty()              判断当前集合是否为空\npublic int size()                     返回集合中元素的个数。\npublic Object[] toArray()             把集合中的元素，存储到数组中\n\nCollection 集合的遍历：\n\n * 法1：迭代器\n   \n   迭代器（Java 中为 Iterator）是集合的专用遍历方式。\n   \n   Collection 集合获取迭代器：\n   \n   Iterator<E> iterator()，返回集合中的迭代器对象，该迭代器对象默认指向当前集合的 0 索引\n   \n   Iterator中的常用方法：\n   \n   方法名称                说明\n   boolean hasNext()   询问当前位置是否有元素存在，存在返回true ,不存在返回false\n   E next()            获取当前位置的元素，并同时将迭代器对象移向下一个位置，注意防止取出越界。\n   \n   迭代器取元素越界会出现 NoSuchElementException 异常。\n   \n   遍历流程的示例代码：\n   \n   \n   \n   \n   \n   \n   \n   \n   \n    \n   \n   \n   \n    \n    \n   \n   \n   \n   \n   \n   \n   public class CollectionDemo01 {\n       public static void main(String[] args) {\n           ArrayList<String> lists = new ArrayList<>();\n           Collections.addAll(lists, "赵敏","小昭", "素素","灭绝");\n           System.out.println(lists);  // [赵敏, 小昭, 素素, 灭绝]\n   \n           // 1、得到当前集合的迭代器对象。\n           Iterator<String> it = lists.iterator();\n   \n           // 2、定义while循环\n           while (it.hasNext()){\n               String ele = it.next();\n               System.out.println(ele);\n           }\n           System.out.println("-----------------------------");\n       }\n   }\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   10\n   11\n   12\n   13\n   14\n   15\n   16\n   17\n   \n\n * 法2：foreach / 增强 for 循环\n   \n   增强 for 循环：既可以遍历集合也可以遍历数组\n   \n   遍历格式：\n   \n    for(被遍历集合或者数组中元素的类型 变量名称 : 被遍历集合或者数组){\n     //在此处使用变量即可，该变量就是元素\n   }\n   \n   \n   1\n   2\n   3\n   \n   \n   遍历流程的示例代码：\n   \n   public static void main(String[] args) {\n       Collection<String> lists = new ArrayList<>();\n       System.out.println(lists);  // [赵敏, 小昭, 殷素素, 周芷若]\n   \n       for (String ele : lists) {\n           System.out.println(ele);\n       }\n   }\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   \n   \n   ⚠️ 注意：修改第三方变量的值不会影响到集合中的元素。即，在上述代码中修改 ele 的值，不会影响到 lists 中当前元素的值，故不能通过 foreach 循环来修改元素的值。\n   \n   使用增强 for 的快捷键\n   \n   IDEA 中输入：lists.for，此时会自动提示增强 for\n\n * 法3：lambda 表达式\n   \n   JDK 1.8开始之后的新技术Lambda表达式，故有一种更简单、更直接的遍历集合的方式\n   \n   Collection 结合 Lambda 遍历集合的 API：\n   \n   方法名称                                                说明\n   default void forEach(Consumer<? super T> action):   结合lambda遍历集合\n   \n   遍历流程的示例代码：\n   \n   lists.forEach(new Consumer<String>() {\n       @Override\n       public void accept(String s) {\n           System.out.println(s);\n       }\n   });\n   \n   // 简化为：《需要掌握的方法》\n   lists.forEach(s -> {\n       System.out.println(s);\n   });\n   \n   // 进一步简化:\n   lists.forEach(s ->  System.out.println(s) );\n   \n   // 终版简化：\n   lists.forEach(System.out::println );\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   10\n   11\n   12\n   13\n   14\n   15\n   16\n   17\n   \n   \n   📝 consumer 的具体含义先不用管，会用 forEach 这个方法遍历就行了。\n\n集合中存储的元素是元素对象的地址\n\n集合的并发修改异常问题\n\nQ：当我们从集合中找出某个元素并删除的时候可能出现一种并发修改异常问题\n\n哪些遍历存在问题？\n\n * 迭代器遍历集合且直接用集合删除元素的时候可能出现\n * 增强 for 循环遍历集合且直接用集合删除元素的时候可能出现\n * Lambda 遍历不能边遍历边删除，会出 bug\n\n哪种遍历且删除元素不出问题？\n\n * 迭代器遍历集合但是用迭代器自己的删除方法操作可以解决\n * 使用 for 循环遍历并删除元素不会存在这个问题\n\n示例：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n    public static void main(String[] args) {\n        // 1、准备数据\n        ArrayList<String> list = new ArrayList<>();\n        // 添加一批元素\n        System.out.println(list); // [黑马, Java, Java, 赵敏, 赵敏, 素素]\n\n        // 需求：删除全部的Java信息。\n        // a、迭代器遍历删除\n        Iterator<String> it = list.iterator();\n        while (it.hasNext()){\n            String ele = it.next();\n            if("Java".equals(ele)){\n                // 删除Java\n                // list.remove(ele); // 集合删除会出毛病\n                it.remove(); // 删除迭代器所在位置的元素值（没毛病）\n            }\n        }\n        System.out.println(list);\n\n        // b、foreach遍历删除 (会出现问题，这种无法解决的，foreach不能边遍历边删除，会出bug)\n        for (String s : list) {\n            if("Java".equals(s)){\n                list.remove(s);\n            }\n        }\n\n        // c、lambda表达式(会出现问题，这种无法解决的，Lambda遍历不能边遍历边删除，会出bug)\n        list.forEach(s -> {\n            if("Java".equals(s)){\n                list.remove(s);\n            }\n        });\n\n        // d、for循环(边遍历边删除集合没毛病，但是必须从后面开始遍历删除才不会出现漏掉应该删除的元素)\n        for (int i = list.size() - 1; i >= 0 ; i--) {\n            String ele = list.get(i);\n            if("Java".equals(ele)){\n                list.remove(ele);\n            }\n        }\n        System.out.println(list);\n    }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n\n\n\n# 2.2 常见的数据结构\n\n队列：先进先出，后进后出。\n\n栈：后进先出，先进后出。\n\n数组：内存连续区域，查询快，增删慢。\n\n链表：元素是游离的，查询慢，首尾操作极快。\n\n二叉树：永远只有一个根节点, 每个结点不超过2个子节点的树。\n\n查找二叉树：小的左边，大的右边，但是可能树很高，查询性能变差。\n\n平衡查找二叉树：让树的高度差不大于1，增删改查都提高了。\n\n红黑树（就是基于红黑规则实现了自平衡的排序二叉树）\n\n\n# 2.3 Collection 之 List 系列集合\n\nList 系列集合特点：（1）有序：存储和取出的元素顺序一致；（2）有索引：可以通过索引操作元素；（3）可重复：存储的元素可以重复。\n\n常见的两种为 ArrayList、LinekdList。\n\nList 系列集合特有的方法：\n\n> List集合因为支持索引，所以多了很多索引操作的独特api，其他Collection的功能List也都继承了\n\n方法名称                            说明\nvoid add(int index,E element)   在此集合中的指定位置插入指定的元素\nE remove(int index)             删除指定索引处的元素，返回被删除的元素\nE set(int index,E element)      修改指定索引处的元素，返回被修改的元素\nE get(int index)                返回指定索引处的元素\n\nList 系列集合的遍历方式：\n\n①迭代器\n\n②增强for循环\n\n③Lambda表达式\n\n④for循环（因为List集合存在索引）\n\n# 2.3.1 ArrayList 集合的底层原理\n\nArrayList 底层是基于数组实现的：根据索引定位元素，快；增删相对慢，需要做元素的移位操作。\n\n第一次创建集合并添加第一个元素的时候，在底层创建一个默认长度为10的数组\n\nList集合存储的元素要超过容量时：扩容到原来大小的 1.5 倍。\n\n# 2.3.2 LinkedList 集合的底层原理\n\nLinkedList 底层基于双链表实现的，查询元素慢，增删首尾元素非常快，所以多了很多首尾操作的特有 API。\n\nList 系列集合特有的方法：\n\n方法名称                        说明\npublic void addFirst(E e)   在该列表开头插入指定的元素\npublic void addLast(E e)    将指定的元素追加到此列表的末尾\npublic E getFirst()         返回此列表中的第一个元素\npublic E getLast()          返回此列表中的最后一个元素\npublic E removeFirst()      从此列表中删除并返回第一个元素\npublic E removeLast()       从此列表中删除并返回最后一个元素\n\n✨ LinkedList 可以完成队列结构，和栈结构 （双链表），示例代码：\n\npublic static void main(String[] args) {\n    // 1、做一个队列：\n    LinkedList<String> queue = new LinkedList<>();\n    // 入队\n    queue.addLast("1号");\n    queue.addLast("2号");\n    queue.addLast("3号");\n    System.out.println(queue);\n    // 出队\n    System.out.println(queue.removeFirst());\n    System.out.println(queue.removeFirst());\n    System.out.println(queue);\n\n    // 2、做一个栈\n    LinkedList<String> stack = new LinkedList<>();\n    // 入栈 压栈 (push)\n    stack.push("第1颗子弹");\n    stack.push("第2颗子弹");\n    stack.push("第3颗子弹");\n    stack.push("第4颗子弹");\n    System.out.println(stack);\n\n    // 出栈  弹栈 pop\n    System.out.println(stack.pop());\n    System.out.println(stack.pop());\n    System.out.println(stack.pop());\n    System.out.println(stack);\n\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n\n# 2.4 Collection 之 Set 系列集合\n\nSet 系列集合的特点：（1）无序：存取顺序不一致；（2）不重复：可以去除重复；（3）无索引：没有带索引的方法，不能用普通for循环遍历，也不能通过索引来获取元素。\n\nSet 集合实现类的特点：\n\n * HashSet : 无序、不重复、无索引\n * LinkedHashSet：有序、不重复、无索引\n * TreeSet：排序、不重复、无索引\n\nSet 集合的功能：基本与 Collection 的 API 一致。\n\n# 2.4.1 HashSet 集合的底层原理\n\nHashSet 集合底层采取哈希表存储的数据：对增删改查性能都很好。\n\nHash表的组成：\n\n * JDK8之前的，底层使用数组 + 链表组成\n * JDK8开始后，底层采用数组 + 链表 + 红黑树组成\n\nHash 值：\n\nJDK 根据对象的地址，按照某种规则算出来的 int 类型的数值。\n\n通过 Object 类的 API public int hashCode() 来返回对象的哈希值。\n\n对象的 Hash 值的特点：\n\n * 同一个对象多次调用 hashCode() 方法返回的哈希值是相同的\n * 默认情况下，不同对象的哈希值不同\n\nHashSet 原理详细流程解析：\n\n 1. 创建一个默认长度 16 、加载因子 0.75 的数组，数组名table\n 2. 根据元素的哈希值跟数组的长度求余计算出应存入的位置（哈希算法）\n 3. 判断当前位置是否为 null，如果是 null 直接存入\n 4. 如果位置不为 null，表示有元素，则调用 equals 方法比较属性值\n    1. 如果一样，则不存；\n    2. 如果不一样，则存入数组：\n    * JDK 7 新元素占老元素位置，指向老元素\n    * JDK 8 中新元素挂在老元素下面\n 5. 当挂在元素下面的数据过多时，查询性能降低。 从 JDK8 开始，当链表长度超过 8 的时候，自动转换为红黑树。\n 6. 当数组存满到 16*0.75=12 时，就自动扩容，每次扩容原先的两倍。\n\n> 哈希表引入红黑树进一步提高了操作数据的性能。\n\n总结：\n\n * HashSet 元素无序的底层原理：使用了哈希表（Hash 值的计算规则导致了无序）。\n\n * HashSet 去重复的底层原理：当该元素要存入的位置不为 null 时，会进行元素比较，不一样的才会存入。如流程 4 中所述。\n\n💡 如果希望 Set 集合认为两个内容一样（而非地址一样）的对象是重复的，必须重写对象的 hashCode() 和 equals() 方法\n\n# 2.4.2 LinkedHashSet 集合\n\n特点：有序 不重复 无索引\n\nLinkedHashSet 集合中“有序”的特点指的是保证存储和取出的元素顺序一致。\n\nLinkedHashSet 集合底层也是基于哈希表实现的，只是每个元素又额外多了一个双链表机制记录存储的顺序。\n\n# 2.4.3 TreeSet 集合\n\n特点：不重复 无索引 可排序\n\nTreeSet 集合中“可排序”的特点指的是按照元素的大小默认升序（有小到大）排序.\n\nTreeSet 集合底层是基于红黑树的数据结构实现排序的，增删改查性能都较好.\n\n💡 TreeSet 集合是一定要排序的，可以将元素按照指定的规则进行排序。\n\nTreeSet 集合默认的排序规则：\n\n * 数值类型：Integer , Double，官方默认按照大小进行升序排序。\n * 字符串类型：默认按照首字符的编号升序排序。\n * 自定义类型如 Student 对象，TreeSet 无法直接排序。\n\n使用 TreeSet 存储自定义类型，需要制定排序规则:\n\n * 方法一：让自定义的类（如苹果类）实现 Comparable 接口重写里面的 compareTo 方法来定制比较规则；\n * 方法二（推荐）：TreeSet 集合有参数构造器，可以设置 Comparator 接口对应的比较器对象，来定制比较规则。\n\n关于返回值的规则：\n\n * 元素1 > 元素2：return 正整数；\n * 元素1 < 元素2：return 负整数；\n * 元素1 == 元素2：return 0，此时 Treeset 集合只会保留一个元素，认为两者重复。\n\n示例代码：\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n \n\n\n\n\n\npublic class Apple implements Comparable<Apple>{\n    private String name;\n    private String color;\n    private double price;\n    private int weight;\n\n    public Apple() {\n    }\n\n    @Override\n    public String toString() {\n        return "Apple{" +\n                "name=\'" + name + \'\\\'\' +\n                ", color=\'" + color + \'\\\'\' +\n                ", price=" + price +\n                ", weight=" + weight +\n                \'}\';\n    }\n\n    /**\n      方式一：类自定义比较规则\n      o1.compareTo(o2)\n     * @param o\n     * @return\n     */\n    @Override\n    public int compareTo(Apple o) {\n        // 按照重量进行比较的\n        return this.weight - o.weight ; // 去重重量重复的元素\n        // return this.weight - o.weight >= 0 ? 1 : -1; // 保留重量重复的元素\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\npublic class SetDemo5 {\n    public static void main(String[] args) {\n        // 方式二：集合自带比较器对象进行规则定制\n        //\n//        Set<Apple> apples = new TreeSet<>(new Comparator<Apple>() {\n//            @Override\n//            public int compare(Apple o1, Apple o2) {\n//                // return o1.getWeight() - o2.getWeight(); // 升序\n//                // return o2.getWeight() - o1.getWeight(); // 降序\n//                // 注意：浮点型建议直接使用Double.compare进行比较\n//                // return Double.compare(o1.getPrice() , o2.getPrice()); // 升序\n//                return Double.compare(o2.getPrice() , o1.getPrice()); // 降序\n//            }\n//        });\n\n        Set<Apple> apples = new TreeSet<>(( o1,  o2) ->  Double.compare(o2.getPrice() , o1.getPrice())  );\n        apples.add(new Apple("红富士", "红色", 9.9, 500));\n        apples.add(new Apple("青苹果", "绿色", 15.9, 300));\n        apples.add(new Apple("绿苹果", "青色", 29.9, 400));\n        apples.add(new Apple("黄苹果", "黄色", 9.8, 500));\n        System.out.println(apples);\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n\n# 2.5 Collection 体系的特点、使用场景总结\n\n * 如果希望元素可以重复，又有索引，索引查询要快？\n   * 用 ArrayList 集合，基于数组的。（用的最多）\n * 如果希望元素可以重复，又有索引，增删首尾操作快？\n   * 用 LinkedList 集合，基于链表的。\n * 如果希望增删改查都快，但是元素不重复、无序、无索引。\n   * 用 HashSet 集合，基于哈希表的\n * 如果希望增删改查都快，但是元素不重复、有序、无索引。\n   * 用 LinkedHashSet 集合，基于哈希表和双链表。\n * 如果要对对象进行排序。\n   * 用 TreeSet 集合，基于红黑树。后续也可以用List集合实现排序\n\n\n# 3. Collections 集合工具类\n\njava.utils.Collections：是集合工具类\n\n作用：用来操作集合的一个工具类。\n\n⚠️ Collections 并不属于集合，只是一个为了操作集合而造出的一个工具类。\n\nCollections 的常用API：\n\n方法名称                                                        说明\npublic static <T> boolean addAll(Collection<? super T> c,   给集合对象批量添加元素\nT... elements)\npublic static void shuffle(List<?> list)                    打乱List集合元素的顺序\n\nCollections 排序相关API：\n\n使用范围：只能对于List集合的排序。\n\n排序方式1：\n\n方法名称                                        说明\npublic static <T> void sort(List<T> list)   将集合中元素按照默认规则排序\n\n⚠️ 注意：本方式不可以直接对自定义类型的List集合排序，除非自定义类型实现了比较规则Comparable接口。\n\n排序方式2：\n\n方法名称                                                           说明\npublic static <T> void sort(List<T> list, Comparator<? super   将集合中元素按照指定规则排序\nT> c)\n\n示例代码 1： (使用排序方式 1)\n\npublic class CollectionsDemo01 {\n    public static void main(String[] args) {\n        List<String> names = new ArrayList<>();\n        //names.add("楚留香");\n        //names.add("胡铁花");\n        //names.add("张无忌");\n        //names.add("陆小凤");\n        Collections.addAll(names, "楚留香","胡铁花", "张无忌","陆小凤");\n        System.out.println(names);\n\n        // 2、public static void shuffle(List<?> list) :打乱集合顺序。\n        Collections.shuffle(names);\n        System.out.println(names);\n\n        // 3、 public static <T> void sort(List<T> list):将集合中元素按照默认规则排序。 （排值特性的元素）\n        List<Integer> list = new ArrayList<>();\n        Collections.addAll(list, 12, 23, 2, 4);\n        System.out.println(list);\n        Collections.sort(list);\n        System.out.println(list);\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n示例代码 2： (使用排序方式 2)\n\npublic class CollectionsDemo02 {\n    public static void main(String[] args) {\n        List<Apple> apples = new ArrayList<>(); // 可以重复！\n        apples.add(new Apple("红富士", "红色", 9.9, 500));\n        apples.add(new Apple("青苹果", "绿色", 15.9, 300));\n        apples.add(new Apple("绿苹果", "青色", 29.9, 400));\n        apples.add(new Apple("黄苹果", "黄色", 9.8, 500));\n\n//        Collections.sort(apples); // 方法一：可以的，Apple类已经重写了比较规则\n//        System.out.println(apples);\n\n        // 方式二：sort方法自带比较器对象\n//        Collections.sort(apples, new Comparator<Apple>() {\n//            @Override\n//            public int compare(Apple o1, Apple o2) {\n//                return Double.compare(o1.getPrice() , o2.getPrice()); // 按照价格排序！！\n//            }\n//        });\n\n        Collections.sort(apples, ( o1,  o2) ->  Double.compare(o1.getPrice() , o2.getPrice()) );\n        System.out.println(apples);\n\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n',normalizedContent:'# 1. 集合体系概述\n\n\n# 1.1 集合与数组\n\n集合和数组都是容器\n\n * 关于存储元素的个数：\n   \n   数组定义后类型确定，长度固定\n   \n   集合类型可以不固定，大小是可变的\n\n * 关于存储元素的类型：\n   \n   数组可以存储基本类型和引用类型的数据\n   \n   集合只能存引用数据类型的数据\n\n * 关于适合的场景：\n   \n   数组适合做数据个数和类型确定的场景\n   \n   集合适合做数据个数不确定，且要做增删元素的场景\n\n\n# 1.2 集合类的体系结构\n\n\n\n集合类分为两种体系：collection 和 map。collection 单列集合，每个元素（数据）只包含一个值；map 双列集合，每个元素包含两个值（键值对）。\n\n\n# 1.3 collection 集合的体系\n\n\n\n> 上图中只是列出了几个常用的类型。\n\ncollection 集合分为两类常用的集合体系：\n\n * list 系列集合：添加的元素有序、可重复、有索引\n   * arraylist、linekdlist ：有序、可重复、有索引\n * set 系列集合：添加的元素是无序、不重复、无索引\n   * hashset: 无序、不重复、无索引；linkedhashset: 有序、不重复、无索引\n   * treeset：**按照大小默认升序排序、**不重复、无索引\n\n\n# 1.4 集合对泛型的支持\n\n集合体系的全部接口和实现类都是支持泛型的使用的，可以在编译阶段约束集合只能操作某种数据类型。（把运行时期的问题提前到了编译期间，避免了强制类型转换可能出现的异常）\n\ncollection<string> lists = new arraylist<string>();\ncollection<string> lists = new arraylist<>(); // jdk 1.7开始后面的泛型类型申明可以省略不写\n\n\n1\n2\n\n\n⚠️ 注意：集合和泛型都只能支持引用数据类型，不支持基本数据类型，所以集合中存储的元素都认为是对象\n\n泛型的原理：\n\n把出现泛型变量的地方全部替换成传输的真实数据类型。\n\n泛型的定义位置：\n\n * 类后面 --- > 泛型类\n * 方法申明上 --- > 泛型方法\n * 接口后面 --- > 泛型接口\n\n# 1.4.1 自定义泛型类\n\n泛型类的格式：修饰符 class 类名<泛型变量>{ }，此处泛型变量 t 可以随便写为任意标识，常见的如 e、t、k、v 等\n\n作用：编译阶段约定操作的数据的类型，类似于集合的作用。\n\n示例代码：\n\n\n\n\n\n \n\n\n\n \n\n\n\n\n\n\n\n\n\n\npublic class myarraylist<e> {\n    private arraylist lists = new arraylist();\n\n    public void add(e e){  // 不是泛型方法。只是使用类定义的这个泛型 e，而不是他自己定义了泛型\n        lists.add(e);\n    }\n\n    public void remove(e e){\n        lists.remove(e);\n    }\n\n    @override\n    public string tostring() {\n        return lists.tostring();\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\n# 1.4.2 自定义泛型方法\n\n泛型方法的格式：修饰符 <泛型变量> 方法返回值 方法名称(形参列表){}\n\n作用：方法中可以使用泛型接收一切实际类型的参数，方法更具备通用性\n\n示例代码：\n\npublic static void main(string[] args) {\n    string[] names = {"小璐", "蓉容", "小何"};\n    printarray(names);\n\n    integer[] ages = {10, 20, 30};\n    printarray(ages);\n\n    integer[] ages2 = getarr(ages);  // 调用泛型函数，得到的内容不需要强转为具体的类型\n    string[]  names2 = getarr(names);  // 传进去啥类型，返回出来还是啥类型\n}\n\npublic static <t> t[] getarr(t[] arr){\n    return arr;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n# 1.4.3 自定义泛型接口\n\n泛型接口的格式：修饰符 interface 接口名称<泛型变量>{}\n\n作用：泛型接口可以让实现类选择当前功能需要操作的数据类型。\n\n实现类可以在实现接口的时候传入自己操作的数据类型，这样重写的方法都将是针对于该类型的操作。\n\n示例代码：\n\n\n\n\n\n\n\n\n \n \n\n \n\n\n\n \n\n \n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n \n\n \n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n// 需求：教务系统，提供一个接口可约束一定要完成数据（学生，老师）的增删改查操作\npublic class student {\n}\n\npublic class teacher {\n}\n\npublic interface data<e> {  // 操作数据的接口\n    void add(e e);\n    void delete(int id);\n    void update(e e);\n    e querybyid(int id);\n}\n\npublic class studentdata implements data<student>{  // 操作学生类数据的实现\n    @override\n    public void add(student student) {\n\n    }\n\n    @override\n    public void delete(int id) {\n\n    }\n\n    @override\n    public void update(student student) {\n\n    }\n\n    @override\n    public student querybyid(int id) {\n        return null;\n    }\n}\n\npublic class teacherdata implements data<teacher>{  // 操作教师类数据的实现\n    @override\n    public void add(teacher teacher) {\n\n    }\n\n    @override\n    public void delete(int id) {\n\n    }\n\n    @override\n    public void update(teacher teacher) {\n\n    }\n\n    @override\n    public teacher querybyid(int id) {\n        return null;\n    }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n\n\n# 1.4.4 泛型通配符、上下限\n\n通配符：?\n\n * ? 可以在“使用泛型”的时候代表一切类型。就是在应该填泛型的位置，填 “<?>” 。\n\n * e t k v 是在定义泛型的时候使用的。\n\n泛型的上下限：\n\n * 泛型上限： <? extends car>，必须是car或者其子类\n * 泛型下限：<? super car> ，必须是car或者其父类 ，用的相对较少\n\n\n# 2. collection 集合\n\n\n# 2.1 关于 collection 自身\n\ncollection 是单列集合的祖宗接口，它的功能是全部单列集合都可以继承使用的。\n\ncollection 的常用 api：\n\n方法名称                                  说明\npublic boolean add(e e)               把给定的对象添加到当前集合中\npublic boolean addall(e e)            把c2(参数)集合的元素全部倒入到c1(被调集合)中去\npublic void clear()                   清空集合中所有的元素\npublic boolean remove(e e)            把给定的对象在当前集合中删除\npublic boolean contains(object obj)   判断当前集合中是否包含给定的对象\npublic boolean isempty()              判断当前集合是否为空\npublic int size()                     返回集合中元素的个数。\npublic object[] toarray()             把集合中的元素，存储到数组中\n\ncollection 集合的遍历：\n\n * 法1：迭代器\n   \n   迭代器（java 中为 iterator）是集合的专用遍历方式。\n   \n   collection 集合获取迭代器：\n   \n   iterator<e> iterator()，返回集合中的迭代器对象，该迭代器对象默认指向当前集合的 0 索引\n   \n   iterator中的常用方法：\n   \n   方法名称                说明\n   boolean hasnext()   询问当前位置是否有元素存在，存在返回true ,不存在返回false\n   e next()            获取当前位置的元素，并同时将迭代器对象移向下一个位置，注意防止取出越界。\n   \n   迭代器取元素越界会出现 nosuchelementexception 异常。\n   \n   遍历流程的示例代码：\n   \n   \n   \n   \n   \n   \n   \n   \n   \n    \n   \n   \n   \n    \n    \n   \n   \n   \n   \n   \n   \n   public class collectiondemo01 {\n       public static void main(string[] args) {\n           arraylist<string> lists = new arraylist<>();\n           collections.addall(lists, "赵敏","小昭", "素素","灭绝");\n           system.out.println(lists);  // [赵敏, 小昭, 素素, 灭绝]\n   \n           // 1、得到当前集合的迭代器对象。\n           iterator<string> it = lists.iterator();\n   \n           // 2、定义while循环\n           while (it.hasnext()){\n               string ele = it.next();\n               system.out.println(ele);\n           }\n           system.out.println("-----------------------------");\n       }\n   }\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   10\n   11\n   12\n   13\n   14\n   15\n   16\n   17\n   \n\n * 法2：foreach / 增强 for 循环\n   \n   增强 for 循环：既可以遍历集合也可以遍历数组\n   \n   遍历格式：\n   \n    for(被遍历集合或者数组中元素的类型 变量名称 : 被遍历集合或者数组){\n     //在此处使用变量即可，该变量就是元素\n   }\n   \n   \n   1\n   2\n   3\n   \n   \n   遍历流程的示例代码：\n   \n   public static void main(string[] args) {\n       collection<string> lists = new arraylist<>();\n       system.out.println(lists);  // [赵敏, 小昭, 殷素素, 周芷若]\n   \n       for (string ele : lists) {\n           system.out.println(ele);\n       }\n   }\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   \n   \n   ⚠️ 注意：修改第三方变量的值不会影响到集合中的元素。即，在上述代码中修改 ele 的值，不会影响到 lists 中当前元素的值，故不能通过 foreach 循环来修改元素的值。\n   \n   使用增强 for 的快捷键\n   \n   idea 中输入：lists.for，此时会自动提示增强 for\n\n * 法3：lambda 表达式\n   \n   jdk 1.8开始之后的新技术lambda表达式，故有一种更简单、更直接的遍历集合的方式\n   \n   collection 结合 lambda 遍历集合的 api：\n   \n   方法名称                                                说明\n   default void foreach(consumer<? super t> action):   结合lambda遍历集合\n   \n   遍历流程的示例代码：\n   \n   lists.foreach(new consumer<string>() {\n       @override\n       public void accept(string s) {\n           system.out.println(s);\n       }\n   });\n   \n   // 简化为：《需要掌握的方法》\n   lists.foreach(s -> {\n       system.out.println(s);\n   });\n   \n   // 进一步简化:\n   lists.foreach(s ->  system.out.println(s) );\n   \n   // 终版简化：\n   lists.foreach(system.out::println );\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   10\n   11\n   12\n   13\n   14\n   15\n   16\n   17\n   \n   \n   📝 consumer 的具体含义先不用管，会用 foreach 这个方法遍历就行了。\n\n集合中存储的元素是元素对象的地址\n\n集合的并发修改异常问题\n\nq：当我们从集合中找出某个元素并删除的时候可能出现一种并发修改异常问题\n\n哪些遍历存在问题？\n\n * 迭代器遍历集合且直接用集合删除元素的时候可能出现\n * 增强 for 循环遍历集合且直接用集合删除元素的时候可能出现\n * lambda 遍历不能边遍历边删除，会出 bug\n\n哪种遍历且删除元素不出问题？\n\n * 迭代器遍历集合但是用迭代器自己的删除方法操作可以解决\n * 使用 for 循环遍历并删除元素不会存在这个问题\n\n示例：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n    public static void main(string[] args) {\n        // 1、准备数据\n        arraylist<string> list = new arraylist<>();\n        // 添加一批元素\n        system.out.println(list); // [黑马, java, java, 赵敏, 赵敏, 素素]\n\n        // 需求：删除全部的java信息。\n        // a、迭代器遍历删除\n        iterator<string> it = list.iterator();\n        while (it.hasnext()){\n            string ele = it.next();\n            if("java".equals(ele)){\n                // 删除java\n                // list.remove(ele); // 集合删除会出毛病\n                it.remove(); // 删除迭代器所在位置的元素值（没毛病）\n            }\n        }\n        system.out.println(list);\n\n        // b、foreach遍历删除 (会出现问题，这种无法解决的，foreach不能边遍历边删除，会出bug)\n        for (string s : list) {\n            if("java".equals(s)){\n                list.remove(s);\n            }\n        }\n\n        // c、lambda表达式(会出现问题，这种无法解决的，lambda遍历不能边遍历边删除，会出bug)\n        list.foreach(s -> {\n            if("java".equals(s)){\n                list.remove(s);\n            }\n        });\n\n        // d、for循环(边遍历边删除集合没毛病，但是必须从后面开始遍历删除才不会出现漏掉应该删除的元素)\n        for (int i = list.size() - 1; i >= 0 ; i--) {\n            string ele = list.get(i);\n            if("java".equals(ele)){\n                list.remove(ele);\n            }\n        }\n        system.out.println(list);\n    }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n\n\n\n# 2.2 常见的数据结构\n\n队列：先进先出，后进后出。\n\n栈：后进先出，先进后出。\n\n数组：内存连续区域，查询快，增删慢。\n\n链表：元素是游离的，查询慢，首尾操作极快。\n\n二叉树：永远只有一个根节点, 每个结点不超过2个子节点的树。\n\n查找二叉树：小的左边，大的右边，但是可能树很高，查询性能变差。\n\n平衡查找二叉树：让树的高度差不大于1，增删改查都提高了。\n\n红黑树（就是基于红黑规则实现了自平衡的排序二叉树）\n\n\n# 2.3 collection 之 list 系列集合\n\nlist 系列集合特点：（1）有序：存储和取出的元素顺序一致；（2）有索引：可以通过索引操作元素；（3）可重复：存储的元素可以重复。\n\n常见的两种为 arraylist、linekdlist。\n\nlist 系列集合特有的方法：\n\n> list集合因为支持索引，所以多了很多索引操作的独特api，其他collection的功能list也都继承了\n\n方法名称                            说明\nvoid add(int index,e element)   在此集合中的指定位置插入指定的元素\ne remove(int index)             删除指定索引处的元素，返回被删除的元素\ne set(int index,e element)      修改指定索引处的元素，返回被修改的元素\ne get(int index)                返回指定索引处的元素\n\nlist 系列集合的遍历方式：\n\n①迭代器\n\n②增强for循环\n\n③lambda表达式\n\n④for循环（因为list集合存在索引）\n\n# 2.3.1 arraylist 集合的底层原理\n\narraylist 底层是基于数组实现的：根据索引定位元素，快；增删相对慢，需要做元素的移位操作。\n\n第一次创建集合并添加第一个元素的时候，在底层创建一个默认长度为10的数组\n\nlist集合存储的元素要超过容量时：扩容到原来大小的 1.5 倍。\n\n# 2.3.2 linkedlist 集合的底层原理\n\nlinkedlist 底层基于双链表实现的，查询元素慢，增删首尾元素非常快，所以多了很多首尾操作的特有 api。\n\nlist 系列集合特有的方法：\n\n方法名称                        说明\npublic void addfirst(e e)   在该列表开头插入指定的元素\npublic void addlast(e e)    将指定的元素追加到此列表的末尾\npublic e getfirst()         返回此列表中的第一个元素\npublic e getlast()          返回此列表中的最后一个元素\npublic e removefirst()      从此列表中删除并返回第一个元素\npublic e removelast()       从此列表中删除并返回最后一个元素\n\n✨ linkedlist 可以完成队列结构，和栈结构 （双链表），示例代码：\n\npublic static void main(string[] args) {\n    // 1、做一个队列：\n    linkedlist<string> queue = new linkedlist<>();\n    // 入队\n    queue.addlast("1号");\n    queue.addlast("2号");\n    queue.addlast("3号");\n    system.out.println(queue);\n    // 出队\n    system.out.println(queue.removefirst());\n    system.out.println(queue.removefirst());\n    system.out.println(queue);\n\n    // 2、做一个栈\n    linkedlist<string> stack = new linkedlist<>();\n    // 入栈 压栈 (push)\n    stack.push("第1颗子弹");\n    stack.push("第2颗子弹");\n    stack.push("第3颗子弹");\n    stack.push("第4颗子弹");\n    system.out.println(stack);\n\n    // 出栈  弹栈 pop\n    system.out.println(stack.pop());\n    system.out.println(stack.pop());\n    system.out.println(stack.pop());\n    system.out.println(stack);\n\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n\n# 2.4 collection 之 set 系列集合\n\nset 系列集合的特点：（1）无序：存取顺序不一致；（2）不重复：可以去除重复；（3）无索引：没有带索引的方法，不能用普通for循环遍历，也不能通过索引来获取元素。\n\nset 集合实现类的特点：\n\n * hashset : 无序、不重复、无索引\n * linkedhashset：有序、不重复、无索引\n * treeset：排序、不重复、无索引\n\nset 集合的功能：基本与 collection 的 api 一致。\n\n# 2.4.1 hashset 集合的底层原理\n\nhashset 集合底层采取哈希表存储的数据：对增删改查性能都很好。\n\nhash表的组成：\n\n * jdk8之前的，底层使用数组 + 链表组成\n * jdk8开始后，底层采用数组 + 链表 + 红黑树组成\n\nhash 值：\n\njdk 根据对象的地址，按照某种规则算出来的 int 类型的数值。\n\n通过 object 类的 api public int hashcode() 来返回对象的哈希值。\n\n对象的 hash 值的特点：\n\n * 同一个对象多次调用 hashcode() 方法返回的哈希值是相同的\n * 默认情况下，不同对象的哈希值不同\n\nhashset 原理详细流程解析：\n\n 1. 创建一个默认长度 16 、加载因子 0.75 的数组，数组名table\n 2. 根据元素的哈希值跟数组的长度求余计算出应存入的位置（哈希算法）\n 3. 判断当前位置是否为 null，如果是 null 直接存入\n 4. 如果位置不为 null，表示有元素，则调用 equals 方法比较属性值\n    1. 如果一样，则不存；\n    2. 如果不一样，则存入数组：\n    * jdk 7 新元素占老元素位置，指向老元素\n    * jdk 8 中新元素挂在老元素下面\n 5. 当挂在元素下面的数据过多时，查询性能降低。 从 jdk8 开始，当链表长度超过 8 的时候，自动转换为红黑树。\n 6. 当数组存满到 16*0.75=12 时，就自动扩容，每次扩容原先的两倍。\n\n> 哈希表引入红黑树进一步提高了操作数据的性能。\n\n总结：\n\n * hashset 元素无序的底层原理：使用了哈希表（hash 值的计算规则导致了无序）。\n\n * hashset 去重复的底层原理：当该元素要存入的位置不为 null 时，会进行元素比较，不一样的才会存入。如流程 4 中所述。\n\n💡 如果希望 set 集合认为两个内容一样（而非地址一样）的对象是重复的，必须重写对象的 hashcode() 和 equals() 方法\n\n# 2.4.2 linkedhashset 集合\n\n特点：有序 不重复 无索引\n\nlinkedhashset 集合中“有序”的特点指的是保证存储和取出的元素顺序一致。\n\nlinkedhashset 集合底层也是基于哈希表实现的，只是每个元素又额外多了一个双链表机制记录存储的顺序。\n\n# 2.4.3 treeset 集合\n\n特点：不重复 无索引 可排序\n\ntreeset 集合中“可排序”的特点指的是按照元素的大小默认升序（有小到大）排序.\n\ntreeset 集合底层是基于红黑树的数据结构实现排序的，增删改查性能都较好.\n\n💡 treeset 集合是一定要排序的，可以将元素按照指定的规则进行排序。\n\ntreeset 集合默认的排序规则：\n\n * 数值类型：integer , double，官方默认按照大小进行升序排序。\n * 字符串类型：默认按照首字符的编号升序排序。\n * 自定义类型如 student 对象，treeset 无法直接排序。\n\n使用 treeset 存储自定义类型，需要制定排序规则:\n\n * 方法一：让自定义的类（如苹果类）实现 comparable 接口重写里面的 compareto 方法来定制比较规则；\n * 方法二（推荐）：treeset 集合有参数构造器，可以设置 comparator 接口对应的比较器对象，来定制比较规则。\n\n关于返回值的规则：\n\n * 元素1 > 元素2：return 正整数；\n * 元素1 < 元素2：return 负整数；\n * 元素1 == 元素2：return 0，此时 treeset 集合只会保留一个元素，认为两者重复。\n\n示例代码：\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n \n\n\n\n\n\npublic class apple implements comparable<apple>{\n    private string name;\n    private string color;\n    private double price;\n    private int weight;\n\n    public apple() {\n    }\n\n    @override\n    public string tostring() {\n        return "apple{" +\n                "name=\'" + name + \'\\\'\' +\n                ", color=\'" + color + \'\\\'\' +\n                ", price=" + price +\n                ", weight=" + weight +\n                \'}\';\n    }\n\n    /**\n      方式一：类自定义比较规则\n      o1.compareto(o2)\n     * @param o\n     * @return\n     */\n    @override\n    public int compareto(apple o) {\n        // 按照重量进行比较的\n        return this.weight - o.weight ; // 去重重量重复的元素\n        // return this.weight - o.weight >= 0 ? 1 : -1; // 保留重量重复的元素\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\npublic class setdemo5 {\n    public static void main(string[] args) {\n        // 方式二：集合自带比较器对象进行规则定制\n        //\n//        set<apple> apples = new treeset<>(new comparator<apple>() {\n//            @override\n//            public int compare(apple o1, apple o2) {\n//                // return o1.getweight() - o2.getweight(); // 升序\n//                // return o2.getweight() - o1.getweight(); // 降序\n//                // 注意：浮点型建议直接使用double.compare进行比较\n//                // return double.compare(o1.getprice() , o2.getprice()); // 升序\n//                return double.compare(o2.getprice() , o1.getprice()); // 降序\n//            }\n//        });\n\n        set<apple> apples = new treeset<>(( o1,  o2) ->  double.compare(o2.getprice() , o1.getprice())  );\n        apples.add(new apple("红富士", "红色", 9.9, 500));\n        apples.add(new apple("青苹果", "绿色", 15.9, 300));\n        apples.add(new apple("绿苹果", "青色", 29.9, 400));\n        apples.add(new apple("黄苹果", "黄色", 9.8, 500));\n        system.out.println(apples);\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n\n# 2.5 collection 体系的特点、使用场景总结\n\n * 如果希望元素可以重复，又有索引，索引查询要快？\n   * 用 arraylist 集合，基于数组的。（用的最多）\n * 如果希望元素可以重复，又有索引，增删首尾操作快？\n   * 用 linkedlist 集合，基于链表的。\n * 如果希望增删改查都快，但是元素不重复、无序、无索引。\n   * 用 hashset 集合，基于哈希表的\n * 如果希望增删改查都快，但是元素不重复、有序、无索引。\n   * 用 linkedhashset 集合，基于哈希表和双链表。\n * 如果要对对象进行排序。\n   * 用 treeset 集合，基于红黑树。后续也可以用list集合实现排序\n\n\n# 3. collections 集合工具类\n\njava.utils.collections：是集合工具类\n\n作用：用来操作集合的一个工具类。\n\n⚠️ collections 并不属于集合，只是一个为了操作集合而造出的一个工具类。\n\ncollections 的常用api：\n\n方法名称                                                        说明\npublic static <t> boolean addall(collection<? super t> c,   给集合对象批量添加元素\nt... elements)\npublic static void shuffle(list<?> list)                    打乱list集合元素的顺序\n\ncollections 排序相关api：\n\n使用范围：只能对于list集合的排序。\n\n排序方式1：\n\n方法名称                                        说明\npublic static <t> void sort(list<t> list)   将集合中元素按照默认规则排序\n\n⚠️ 注意：本方式不可以直接对自定义类型的list集合排序，除非自定义类型实现了比较规则comparable接口。\n\n排序方式2：\n\n方法名称                                                           说明\npublic static <t> void sort(list<t> list, comparator<? super   将集合中元素按照指定规则排序\nt> c)\n\n示例代码 1： (使用排序方式 1)\n\npublic class collectionsdemo01 {\n    public static void main(string[] args) {\n        list<string> names = new arraylist<>();\n        //names.add("楚留香");\n        //names.add("胡铁花");\n        //names.add("张无忌");\n        //names.add("陆小凤");\n        collections.addall(names, "楚留香","胡铁花", "张无忌","陆小凤");\n        system.out.println(names);\n\n        // 2、public static void shuffle(list<?> list) :打乱集合顺序。\n        collections.shuffle(names);\n        system.out.println(names);\n\n        // 3、 public static <t> void sort(list<t> list):将集合中元素按照默认规则排序。 （排值特性的元素）\n        list<integer> list = new arraylist<>();\n        collections.addall(list, 12, 23, 2, 4);\n        system.out.println(list);\n        collections.sort(list);\n        system.out.println(list);\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n示例代码 2： (使用排序方式 2)\n\npublic class collectionsdemo02 {\n    public static void main(string[] args) {\n        list<apple> apples = new arraylist<>(); // 可以重复！\n        apples.add(new apple("红富士", "红色", 9.9, 500));\n        apples.add(new apple("青苹果", "绿色", 15.9, 300));\n        apples.add(new apple("绿苹果", "青色", 29.9, 400));\n        apples.add(new apple("黄苹果", "黄色", 9.8, 500));\n\n//        collections.sort(apples); // 方法一：可以的，apple类已经重写了比较规则\n//        system.out.println(apples);\n\n        // 方式二：sort方法自带比较器对象\n//        collections.sort(apples, new comparator<apple>() {\n//            @override\n//            public int compare(apple o1, apple o2) {\n//                return double.compare(o1.getprice() , o2.getprice()); // 按照价格排序！！\n//            }\n//        });\n\n        collections.sort(apples, ( o1,  o2) ->  double.compare(o1.getprice() , o2.getprice()) );\n        system.out.println(apples);\n\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n',charsets:{cjk:!0},lastUpdated:"2023/03/29, 08:00:21",lastUpdatedTimestamp:1680076821e3},{title:"面向对象进阶6（集合体系之Map）",frontmatter:{title:"面向对象进阶6（集合体系之Map）",date:"2023-03-30T11:30:45.000Z",permalink:"/pages/134c54/",categories:["开发","Java","黑马Java入门基础-学习笔记"],tags:[null]},regularPath:"/%E5%BC%80%E5%8F%91/10.Java/05.%E9%BB%91%E9%A9%ACJava%E5%85%A5%E9%97%A8%E5%9F%BA%E7%A1%80-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/35.%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%BF%9B%E9%98%B66%EF%BC%88%E9%9B%86%E5%90%88%E4%BD%93%E7%B3%BB%E4%B9%8BMap%EF%BC%89.html",relativePath:"开发/10.Java/05.黑马Java入门基础-学习笔记/35.面向对象进阶6（集合体系之Map）.md",key:"v-3161e9d4",path:"/pages/134c54/",headers:[{level:2,title:"1. Map 集合",slug:"_1-map-集合",normalizedTitle:"1. map 集合",charIndex:2},{level:3,title:"1.1 关于 Map 集合自身",slug:"_1-1-关于-map-集合自身",normalizedTitle:"1.1 关于 map 集合自身",charIndex:16},{level:3,title:"1.2 Map 集合体系",slug:"_1-2-map-集合体系",normalizedTitle:"1.2 map 集合体系",charIndex:222},{level:3,title:"1.3 Map 集合的遍历",slug:"_1-3-map-集合的遍历",normalizedTitle:"1.3 map 集合的遍历",charIndex:1023},{level:4,title:"1.3.1 遍历方式一：键找值",slug:"_1-3-1-遍历方式一-键找值",normalizedTitle:"1.3.1 遍历方式一：键找值",charIndex:1153},{level:4,title:"1.3.2 遍历方式二：键值对流程",slug:"_1-3-2-遍历方式二-键值对流程",normalizedTitle:"1.3.2 遍历方式二：键值对流程",charIndex:2034},{level:4,title:"1.3.3 遍历方式三：Lambda",slug:"_1-3-3-遍历方式三-lambda",normalizedTitle:"1.3.3 遍历方式三：lambda",charIndex:3372},{level:3,title:"1.4 Map 集合之实现类",slug:"_1-4-map-集合之实现类",normalizedTitle:"1.4 map 集合之实现类",charIndex:4349},{level:4,title:"1.4.1 HashMap",slug:"_1-4-1-hashmap",normalizedTitle:"1.4.1 hashmap",charIndex:4367}],headersStr:"1. Map 集合 1.1 关于 Map 集合自身 1.2 Map 集合体系 1.3 Map 集合的遍历 1.3.1 遍历方式一：键找值 1.3.2 遍历方式二：键值对流程 1.3.3 遍历方式三：Lambda 1.4 Map 集合之实现类 1.4.1 HashMap",content:'# 1. Map 集合\n\n\n# 1.1 关于 Map 集合自身\n\nMap 集合是一种双列集合，也被称为“键值对集合”。每个元素包含两个数据。每个元素的格式：key=value(键值对元素)\n\nMap 集合的完整格式：\n\n{key1=value1 , key2=value2 , key3=value3 , ...}\n\n> Collection集合的格式: [元素1,元素2,元素3..]\n\nMap 集合非常适合做购物车这样的业务场景。\n\n\n# 1.2 Map 集合体系\n\n使用最多的 Map 集合是 HashMap。\n\n重点掌握 HashMap , LinkedHashMap , TreeMap。其他的后续理解。\n\nMap 集合体系的特点：\n\n * Map 集合的特点都是由键决定的。\n * Map 集合的键是无序、不重复、无索引的，值不做要求（可以重复）。\n * Map 集合后面重复的键对应的值会覆盖前面重复键的值。\n * Map 集合的键值对都可以为 null。\n\nMap 集合实现类特点:\n\n * HashMap: 元素按照键是无序，不重复，无索引，值不做要求。（与Map体系一致）\n * LinkedHashMap: 元素按照键是有序，不重复，无索引，值不做要求。\n * TreeMap：元素按照建是排序，不重复，无索引的，值不做要求。\n\nMap 集合常用 API:\n\n说明：Map 是双列集合的祖宗接口，它的功能是全部双列集合都可以继承使用的。\n\n方法名称                                  说明\nV put(K key,V value)                  添加元素\nV remove(Object key)                  根据键删除键值对元素\nvoid clear()                          移除所有的键值对元素\nboolean containsKey(Object key)       判断集合是否包含指定的键\nboolean containsValue(Object value)   判断集合是否包含指定的值\nboolean isEmpty()                     判断集合是否为空\nint size()                            集合的长度，也就是集合中键值对的个数\n\n\n# 1.3 Map 集合的遍历\n\nMap 集合遍历有三种方式：\n\n * 键找值的方式遍历：先获取Map集合全部的键，再根据遍历键找值。\n * 键值对的方式遍历，把“键值对“看成一个整体，难度较大。\n * JDK 1.8开始之后的新技术：Lambda表达式。\n\n# 1.3.1 遍历方式一：键找值\n\n示例代码：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n \n\n\n\n\n\n\n\n/**\n    a.“键找值”的方式遍历Map集合。\n        1.先获取Map集合的全部键的Set集合。\n        2.遍历键的Set集合，然后通过键找值。\n */\npublic class MapDemo01 {\n    public static void main(String[] args) {\n        Map<String , Integer> maps = new HashMap<>();\n        // 1.添加元素: 无序，不重复，无索引。\n        maps.put("娃娃",30);\n        maps.put("iphoneX",100);\n        maps.put("huawei",1000);\n        maps.put("生活用品",10);\n        maps.put("手表",10);\n        System.out.println(maps);\n        // maps = {huawei=1000, 手表=10, 生活用品=10, iphoneX=100, 娃娃=30}\n\n        // 1、键找值：第一步：先拿到集合的全部键。\n        Set<String> keys = maps.keySet();\n        // 2、第二步：遍历每个键，根据键提取值\n        for (String key : keys) {\n            int value = maps.get(key);\n            System.out.println(key + "===>" + value);\n        }\n\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n\n\n# 1.3.2 遍历方式二：键值对流程\n\n示例代码：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n \n \n\n\n\n\n\n\n/**\n    b.“键值对”的方式遍历：\n        1.把Map集合转换成一个Set集合:Set<Map.Entry<K, V>> entrySet();\n        2.此时键值对元素的类型就确定了，类型是键值对实体类型：Map.Entry<K, V>\n        3.接下来就可以用foreach遍历这个Set集合，类型用Map.Entry<K, V>\n */\npublic class MapDemo02 {\n    public static void main(String[] args) {\n        Map<String , Integer> maps = new HashMap<>();\n        // 1.添加元素: 无序，不重复，无索引。\n        maps.put("娃娃",30);\n        maps.put("iphoneX",100);\n        maps.put("huawei",1000);\n        maps.put("生活用品",10);\n        maps.put("手表",10);\n        System.out.println(maps);\n        /**\n            maps = {huawei=1000, 手表=10, 生活用品=10, iphoneX=100, 娃娃=30}\n                👇\n            使用foreach遍历map集合.发现Map集合的键值对元素直接是没有类型的。所以不可以直接foreach遍历集合。\n                👇\n            可以通过调用Map的方法 entrySet把Map集合转换成Set集合形式  maps.entrySet();\n                👇\n            此时可以使用foreach遍历\n       */\n       // 1、把Map集合转换成Set集合\n        Set<Map.Entry<String, Integer>> entries = maps.entrySet();\n        // 2、开始遍历\n        for(Map.Entry<String, Integer> entry : entries){\n            String key = entry.getKey();\n            int value = entry.getValue();\n            System.out.println(key + "====>" + value);\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n\n\n# 1.3.3 遍历方式三：Lambda\n\n示例代码：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n \n\n\n\n\n\n\n/**\n    c.JDK 1.8开始之后的新技术：Lambda表达式。（暂时了解）\n */\npublic class MapDemo03 {\n    public static void main(String[] args) {\n        Map<String , Integer> maps = new HashMap<>();\n        // 1.添加元素: 无序，不重复，无索引。\n        maps.put("娃娃",30);\n        maps.put("iphoneX",100);//  Map集合后面重复的键对应的元素会覆盖前面重复的整个元素！\n        maps.put("huawei",1000);\n        maps.put("生活用品",10);\n        maps.put("手表",10);\n        System.out.println(maps);\n\n        //  maps = {huawei=1000, 手表=10, 生活用品=10, iphoneX=100, 娃娃=30}\n\n//        maps.forEach(new BiConsumer<String, Integer>() {\n//            @Override\n//            public void accept(String key, Integer value) {\n//                System.out.println(key + "---\x3e" + value);\n//            }\n//        });\n\n        maps.forEach((k, v) -> {\n                System.out.println(k + "---\x3e" + v);\n        });\n\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n\n# 1.4 Map 集合之实现类\n\n# 1.4.1 HashMap\n\nHashMap 是 Map 里面的一个实现类。\n\nHashMap 的特点：\n\n * HashMap 特点都是由键决定的：无序、不重复、无索引。\n * 没有额外需要学习的特有方法，直接使用 Map 里面的方法就可以了。\n * HashMap 跟 HashSet 底层原理是一模一样的，都是哈希表结构，只是 HashMap 的每个元素包含两个值而已。\n\n实际上：Set 系列集合的底层就是 Map 实现的，只是 Set 集合中的元素只要键数据，不要值数据。\n\n源码：\n\npublic HashSet() {\n    map = new HashMap<>();\n}\n\n\n1\n2\n3\n',normalizedContent:'# 1. map 集合\n\n\n# 1.1 关于 map 集合自身\n\nmap 集合是一种双列集合，也被称为“键值对集合”。每个元素包含两个数据。每个元素的格式：key=value(键值对元素)\n\nmap 集合的完整格式：\n\n{key1=value1 , key2=value2 , key3=value3 , ...}\n\n> collection集合的格式: [元素1,元素2,元素3..]\n\nmap 集合非常适合做购物车这样的业务场景。\n\n\n# 1.2 map 集合体系\n\n使用最多的 map 集合是 hashmap。\n\n重点掌握 hashmap , linkedhashmap , treemap。其他的后续理解。\n\nmap 集合体系的特点：\n\n * map 集合的特点都是由键决定的。\n * map 集合的键是无序、不重复、无索引的，值不做要求（可以重复）。\n * map 集合后面重复的键对应的值会覆盖前面重复键的值。\n * map 集合的键值对都可以为 null。\n\nmap 集合实现类特点:\n\n * hashmap: 元素按照键是无序，不重复，无索引，值不做要求。（与map体系一致）\n * linkedhashmap: 元素按照键是有序，不重复，无索引，值不做要求。\n * treemap：元素按照建是排序，不重复，无索引的，值不做要求。\n\nmap 集合常用 api:\n\n说明：map 是双列集合的祖宗接口，它的功能是全部双列集合都可以继承使用的。\n\n方法名称                                  说明\nv put(k key,v value)                  添加元素\nv remove(object key)                  根据键删除键值对元素\nvoid clear()                          移除所有的键值对元素\nboolean containskey(object key)       判断集合是否包含指定的键\nboolean containsvalue(object value)   判断集合是否包含指定的值\nboolean isempty()                     判断集合是否为空\nint size()                            集合的长度，也就是集合中键值对的个数\n\n\n# 1.3 map 集合的遍历\n\nmap 集合遍历有三种方式：\n\n * 键找值的方式遍历：先获取map集合全部的键，再根据遍历键找值。\n * 键值对的方式遍历，把“键值对“看成一个整体，难度较大。\n * jdk 1.8开始之后的新技术：lambda表达式。\n\n# 1.3.1 遍历方式一：键找值\n\n示例代码：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n \n\n\n\n\n\n\n\n/**\n    a.“键找值”的方式遍历map集合。\n        1.先获取map集合的全部键的set集合。\n        2.遍历键的set集合，然后通过键找值。\n */\npublic class mapdemo01 {\n    public static void main(string[] args) {\n        map<string , integer> maps = new hashmap<>();\n        // 1.添加元素: 无序，不重复，无索引。\n        maps.put("娃娃",30);\n        maps.put("iphonex",100);\n        maps.put("huawei",1000);\n        maps.put("生活用品",10);\n        maps.put("手表",10);\n        system.out.println(maps);\n        // maps = {huawei=1000, 手表=10, 生活用品=10, iphonex=100, 娃娃=30}\n\n        // 1、键找值：第一步：先拿到集合的全部键。\n        set<string> keys = maps.keyset();\n        // 2、第二步：遍历每个键，根据键提取值\n        for (string key : keys) {\n            int value = maps.get(key);\n            system.out.println(key + "===>" + value);\n        }\n\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n\n\n# 1.3.2 遍历方式二：键值对流程\n\n示例代码：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n \n \n\n\n\n\n\n\n/**\n    b.“键值对”的方式遍历：\n        1.把map集合转换成一个set集合:set<map.entry<k, v>> entryset();\n        2.此时键值对元素的类型就确定了，类型是键值对实体类型：map.entry<k, v>\n        3.接下来就可以用foreach遍历这个set集合，类型用map.entry<k, v>\n */\npublic class mapdemo02 {\n    public static void main(string[] args) {\n        map<string , integer> maps = new hashmap<>();\n        // 1.添加元素: 无序，不重复，无索引。\n        maps.put("娃娃",30);\n        maps.put("iphonex",100);\n        maps.put("huawei",1000);\n        maps.put("生活用品",10);\n        maps.put("手表",10);\n        system.out.println(maps);\n        /**\n            maps = {huawei=1000, 手表=10, 生活用品=10, iphonex=100, 娃娃=30}\n                👇\n            使用foreach遍历map集合.发现map集合的键值对元素直接是没有类型的。所以不可以直接foreach遍历集合。\n                👇\n            可以通过调用map的方法 entryset把map集合转换成set集合形式  maps.entryset();\n                👇\n            此时可以使用foreach遍历\n       */\n       // 1、把map集合转换成set集合\n        set<map.entry<string, integer>> entries = maps.entryset();\n        // 2、开始遍历\n        for(map.entry<string, integer> entry : entries){\n            string key = entry.getkey();\n            int value = entry.getvalue();\n            system.out.println(key + "====>" + value);\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n\n\n# 1.3.3 遍历方式三：lambda\n\n示例代码：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n \n\n\n\n\n\n\n/**\n    c.jdk 1.8开始之后的新技术：lambda表达式。（暂时了解）\n */\npublic class mapdemo03 {\n    public static void main(string[] args) {\n        map<string , integer> maps = new hashmap<>();\n        // 1.添加元素: 无序，不重复，无索引。\n        maps.put("娃娃",30);\n        maps.put("iphonex",100);//  map集合后面重复的键对应的元素会覆盖前面重复的整个元素！\n        maps.put("huawei",1000);\n        maps.put("生活用品",10);\n        maps.put("手表",10);\n        system.out.println(maps);\n\n        //  maps = {huawei=1000, 手表=10, 生活用品=10, iphonex=100, 娃娃=30}\n\n//        maps.foreach(new biconsumer<string, integer>() {\n//            @override\n//            public void accept(string key, integer value) {\n//                system.out.println(key + "---\x3e" + value);\n//            }\n//        });\n\n        maps.foreach((k, v) -> {\n                system.out.println(k + "---\x3e" + v);\n        });\n\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n\n# 1.4 map 集合之实现类\n\n# 1.4.1 hashmap\n\nhashmap 是 map 里面的一个实现类。\n\nhashmap 的特点：\n\n * hashmap 特点都是由键决定的：无序、不重复、无索引。\n * 没有额外需要学习的特有方法，直接使用 map 里面的方法就可以了。\n * hashmap 跟 hashset 底层原理是一模一样的，都是哈希表结构，只是 hashmap 的每个元素包含两个值而已。\n\n实际上：set 系列集合的底层就是 map 实现的，只是 set 集合中的元素只要键数据，不要值数据。\n\n源码：\n\npublic hashset() {\n    map = new hashmap<>();\n}\n\n\n1\n2\n3\n',charsets:{cjk:!0},lastUpdated:"2023/03/30, 09:25:20",lastUpdatedTimestamp:168016832e4},{title:"面向对象进阶-补充（可变参数）",frontmatter:{title:"面向对象进阶-补充（可变参数）",date:"2023-03-29T15:22:10.000Z",permalink:"/pages/e64834/",categories:["开发","Java","黑马Java入门基础-学习笔记"],tags:[null]},regularPath:"/%E5%BC%80%E5%8F%91/10.Java/05.%E9%BB%91%E9%A9%ACJava%E5%85%A5%E9%97%A8%E5%9F%BA%E7%A1%80-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/40.%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%BF%9B%E9%98%B6-%E8%A1%A5%E5%85%85%EF%BC%88%E5%8F%AF%E5%8F%98%E5%8F%82%E6%95%B0%EF%BC%89.html",relativePath:"开发/10.Java/05.黑马Java入门基础-学习笔记/40.面向对象进阶-补充（可变参数）.md",key:"v-78a8ae4e",path:"/pages/e64834/",headers:[{level:2,title:"1. 可变参数",slug:"_1-可变参数",normalizedTitle:"1. 可变参数",charIndex:2},{level:3,title:"1.1 可变参数是啥",slug:"_1-1-可变参数是啥",normalizedTitle:"1.1 可变参数是啥",charIndex:14},{level:3,title:"1.2 可变参数的作用",slug:"_1-2-可变参数的作用",normalizedTitle:"1.2 可变参数的作用",charIndex:89},{level:3,title:"1.3 可变参数的注意事项",slug:"_1-3-可变参数的注意事项",normalizedTitle:"1.3 可变参数的注意事项",charIndex:141}],headersStr:"1. 可变参数 1.1 可变参数是啥 1.2 可变参数的作用 1.3 可变参数的注意事项",content:'# 1. 可变参数\n\n\n# 1.1 可变参数是啥\n\n可变参数用在形参中可以接收多个数据\n\n可变参数的格式：数据类型...参数名称\n\n可变参数在方法内部本质上就是个数组。\n\n\n# 1.2 可变参数的作用\n\n传输参数非常灵活方便：可以不传输参数、传一个或多个参数、传一个数组。\n\n\n# 1.3 可变参数的注意事项\n\n 1. 一个形参列表中可变参数只能有一个\n 2. 可变参数必须放在形参列表的最后面\n\n示例代码：\n\npublic class MethodDemo {\n    public static void main(String[] args) {\n\n        sum(); // 1、不传参数\n        sum(10); // 2、可以传输一个参数\n        sum(10, 20, 30); // 3、可以传输多个参数\n        sum(new int[]{10, 20, 30, 40, 50}); // 4、可以传输一个数组\n    }\n\n    /**\n       注意：一个形参列表中只能有一个可变参数,可变参数必须放在形参列表的最后面\n     * @param nums\n     */\n    public static void sum(int...nums){\n        // 注意：可变参数在方法内部其实就是一个数组。 nums\n        System.out.println("元素个数：" + nums.length);\n        System.out.println("元素内容：" + Arrays.toString(nums));\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n',normalizedContent:'# 1. 可变参数\n\n\n# 1.1 可变参数是啥\n\n可变参数用在形参中可以接收多个数据\n\n可变参数的格式：数据类型...参数名称\n\n可变参数在方法内部本质上就是个数组。\n\n\n# 1.2 可变参数的作用\n\n传输参数非常灵活方便：可以不传输参数、传一个或多个参数、传一个数组。\n\n\n# 1.3 可变参数的注意事项\n\n 1. 一个形参列表中可变参数只能有一个\n 2. 可变参数必须放在形参列表的最后面\n\n示例代码：\n\npublic class methoddemo {\n    public static void main(string[] args) {\n\n        sum(); // 1、不传参数\n        sum(10); // 2、可以传输一个参数\n        sum(10, 20, 30); // 3、可以传输多个参数\n        sum(new int[]{10, 20, 30, 40, 50}); // 4、可以传输一个数组\n    }\n\n    /**\n       注意：一个形参列表中只能有一个可变参数,可变参数必须放在形参列表的最后面\n     * @param nums\n     */\n    public static void sum(int...nums){\n        // 注意：可变参数在方法内部其实就是一个数组。 nums\n        system.out.println("元素个数：" + nums.length);\n        system.out.println("元素内容：" + arrays.tostring(nums));\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n',charsets:{cjk:!0},lastUpdated:"2023/03/29, 07:33:42",lastUpdatedTimestamp:1680075222e3},{title:"面向对象",frontmatter:{title:"面向对象",date:"2022-03-28T16:39:56.000Z",permalink:"/pages/017edb/",categories:["开发","Java"],tags:[null]},regularPath:"/%E5%BC%80%E5%8F%91/10.Java/10.%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1.html",relativePath:"开发/10.Java/10.面向对象.md",key:"v-147908a9",path:"/pages/017edb/",headers:[{level:2,title:"1. 模板方法模式",slug:"_1-模板方法模式",normalizedTitle:"1. 模板方法模式",charIndex:2},{level:3,title:"1.1 抽象类",slug:"_1-1-抽象类",normalizedTitle:"1.1 抽象类",charIndex:16},{level:3,title:"1.2 模板方法",slug:"_1-2-模板方法",normalizedTitle:"1.2 模板方法",charIndex:254},{level:2,title:"2. 接口",slug:"_2-接口",normalizedTitle:"2. 接口",charIndex:549},{level:3,title:"2.1 基本知识",slug:"_2-1-基本知识",normalizedTitle:"2.1 基本知识",charIndex:559},{level:3,title:"2.2 接口新增的方法",slug:"_2-2-接口新增的方法",normalizedTitle:"2.2 接口新增的方法",charIndex:825},{level:3,title:"2.3 使用接口的注意事项（面试中涉及）",slug:"_2-3-使用接口的注意事项-面试中涉及",normalizedTitle:"2.3 使用接口的注意事项（面试中涉及）",charIndex:1132},{level:2,title:"3. 多态",slug:"_3-多态",normalizedTitle:"3. 多态",charIndex:1432},{level:4,title:"(1) 什么是多态",slug:"_1-什么是多态",normalizedTitle:"(1) 什么是多态",charIndex:1441},{level:4,title:"(2) 多态的常见形式",slug:"_2-多态的常见形式",normalizedTitle:"(2) 多态的常见形式",charIndex:1510},{level:4,title:"(3) 多态中成员访问特点",slug:"_3-多态中成员访问特点",normalizedTitle:"(3) 多态中成员访问特点",charIndex:1767},{level:4,title:"(4) 多态的前提",slug:"_4-多态的前提",normalizedTitle:"(4) 多态的前提",charIndex:1874},{level:4,title:"(5) 优势",slug:"_5-优势",normalizedTitle:"(5) 优势",charIndex:1916},{level:4,title:"(6) 多态下引用数据类型的类型转换",slug:"_6-多态下引用数据类型的类型转换",normalizedTitle:"(6) 多态下引用数据类型的类型转换",charIndex:2278},{level:2,title:"4. 内部类",slug:"_4-内部类",normalizedTitle:"4. 内部类",charIndex:3301},{level:3,title:"4.1 静态内部类",slug:"_4-1-静态内部类",normalizedTitle:"4.1 静态内部类",charIndex:3329},{level:3,title:"4.2 成员内部类（非静态内部类）",slug:"_4-2-成员内部类-非静态内部类",normalizedTitle:"4.2 成员内部类（非静态内部类）",charIndex:3602},{level:3,title:"4.3 局部内部类",slug:"_4-3-局部内部类",normalizedTitle:"4.3 局部内部类",charIndex:4111},{level:3,title:"4.4 *匿名内部类",slug:"_4-4-匿名内部类",normalizedTitle:"4.4 *匿名内部类",charIndex:4136},{level:4,title:"(1) 概述",slug:"_1-概述",normalizedTitle:"(1) 概述",charIndex:4150},{level:4,title:"(2) 常见使用形式",slug:"_2-常见使用形式",normalizedTitle:"(2) 常见使用形式",charIndex:4926}],headersStr:"1. 模板方法模式 1.1 抽象类 1.2 模板方法 2. 接口 2.1 基本知识 2.2 接口新增的方法 2.3 使用接口的注意事项（面试中涉及） 3. 多态 (1) 什么是多态 (2) 多态的常见形式 (3) 多态中成员访问特点 (4) 多态的前提 (5) 优势 (6) 多态下引用数据类型的类型转换 4. 内部类 4.1 静态内部类 4.2 成员内部类（非静态内部类） 4.3 局部内部类 4.4 *匿名内部类 (1) 概述 (2) 常见使用形式",content:'# 1. 模板方法模式\n\n\n# 1.1 抽象类\n\n如果一个类中的某个方法的具体实现不能确定，就可以申明成abstract修饰的抽象方法（不能写方法体了），这个类必须用abstract修饰，被称为抽象类。\n\n\n\n抽象的使用总结与注意事项：\n\n * 抽象类可以理解成类的不完整设计图，是用来被子类继承的。\n * 一个类如果继承了抽象类，那么这个类必须重写完抽象类的全部抽象方法，否则这个类也必须定义成抽象类。\n * 抽象类没有创建对象的能力。\n * 抽象类中不一定有抽象方法，有抽象方法的类一定是抽象类\n\n\n# 1.2 模板方法\n\n模板方法模式实现步骤：\n\n * 把功能定义成一个所谓的模板方法，放在抽象类中，模板方法中只定义通用且能确定的代码。\n * 模板方法中不能决定的功能定义成抽象方法让具体子类去实现。\n\n提示\n\n模板方法我们是建议使用final修饰的,模板方法是给子类直接使用的，不是让子类重写的， 一旦子类重写了模板方法就失效了。\n\n例如，中学生和小学生写《我的爸爸》这篇作文，他俩除了文章主体部分不同，别的地方都一样，此时，可以定义一个抽象类，用一个公共的模板方法来实现相同的部分，不同的部分在这个抽象类中声明一个抽象方法，让子类在此处来实现他们分别的功能。如下图代码所示：\n\n\n\n\n# 2. 接口\n\n\n# 2.1 基本知识\n\n接口体现了一种规范，约束类一定要干啥事。规范一定是公开的。\n\nJDK 8 之前接口中只能有抽象方法和常量。\n\n * 关键字：interface\n\n * 接口的实现：implements 接口1,接口2,...\n\n几种关系：\n\n * 类和类的关系：单继承。\n * 类和接口的关系：多实现。\n * 接口和接口的关系：多继承，一个接口可以同时继承多个接口。\n\n接口多继承的作用: 规范合并，整合多个接口为同一个接口，便于子类实现。（子类只需要implements一个接口就可以了，不用很累赘地实现很多个接口）\n\n\n# 2.2 接口新增的方法\n\nJDK8开始后新增了那些方法 ?\n\n * 默认方法：default修饰，实现类对象调用。\n * 静态方法：static修饰，必须用当前接口名调用。不能用子类调用静态方法。\n * 私有方法：private修饰，jdk9开始才有的，只能在接口内部被调用。\n * 他们都会默认被public修饰。\n\n注意\n\nJDK8新增的3种方法我们自己在开发中很少使用，通常是Java源码涉及到的，我们需要理解、识别语法、明白调用关系即可。\n\n提示\n\n切换模块的编译版本，选择JDK版本：File -> Project Structure -> Modules ->language level\n\n\n\n\n# 2.3 使用接口的注意事项（面试中涉及）\n\n比较偏的一些语法，实际开发中通常不用，只有在一些面试中可能会涉及。\n\n 1. 接口不能创建对象\n\n 2. 一个类实现多个接口，多个接口中有同样的静态方法不冲突。\n\n 3. 一个类继承了父类，同时又实现了接口，父类中和接口中有同名方法，默认用父类的。\n    \n    继承只能在实现之前写，即先有亲爸再有干爹。接口为干爹，继承为亲爸。\n\n 4. 一个类实现了多个接口，多个接口中存在同名的默认方法，不冲突，这个类重写该方法即可。\n\n 5. 一个接口继承多个接口，是没有问题的，即使多个接口中有重名的方法，但如果多个接口中存在规范冲突则不能多继承。\n\n\n# 3. 多态\n\n# (1) 什么是多态\n\n同类型的对象，执行同一个行为，会表现出不同的行为特征。\n\n父类的引用类型指向子类的构造，向上造型，即为多态。\n\n# (2) 多态的常见形式\n\n * 父类类型 对象名称 = new 子类构造器;\n * 接口 对象名称 = new 实现类构造器;\n\nAnimal a = new Dog();\na.run(); // 方法调用：编译看左，运行看右\nSystem.out.println(a.name); // 方法调用：编译看左，运行也看左，动物名称\n\nAnimal a1 = new Dog();\na1.run();\nSystem.out.println(a1.name); // 动物名称\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n# (3) 多态中成员访问特点\n\n * 方法调用：编译看左，运行看右。=> 因此多态下不能使用子类的独有功能。\n * 变量调用：编译看左，运行也看左。（多态侧重行为多态）\n\n因此上述代码的输出结果都是动物名称。\n\n# (4) 多态的前提\n\n有继承/实现关系；有父类引用指向子类对象；有方法重写。\n\n# (5) 优势\n\n * 在多态形式下，右边对象可以实现解耦合，便于扩展和维护。\n\nAnimal a = new Dog(); // 后续业务更改时只需要修改此处new的Dog即可\na.run(); // 后续业务行为随对象而变，后续代码无需修改\n\n\n1\n2\n\n * 定义方法的时候，使用父类型作为参数，该方法就可以接收这父类的一切子类对象，体现出多态的扩展性与便利。\n\n    public static void go(Animal a){\n        System.out.println("开始。。。");\n        a.run();\n        System.out.println("结束。。。");\n    }\n// 这个函数可以传上面代码中的a, 也可以传a1\n\n\n1\n2\n3\n4\n5\n6\n\n\n# (6) 多态下引用数据类型的类型转换\n\n * 自动类型转换（从子到父)：子类对象赋值给父类类型的变量指向。\n   \n   // 自动类型转换\n   Animal a = new Dog();\n   a.run();\n   //a.lookDoor(); // 多态下无法调用子类独有功能\n   \n   \n   1\n   2\n   3\n   4\n   \n\n * 强制类型转换吗（从父到子)\n   \n   * 此时必须进行强制类型转换：子类 对象变量 = (子类)父类类型的变量\n     \n     // 强制类型转换:可以实现调用子类独有功能的\n     Dog d = (Dog) a;\n     d.lookDoor();\n     \n     \n     1\n     2\n     3\n     \n   \n   * 作用：可以解决多态下的劣势，可以实现调用子类独有的功能。\n   \n   * 注意： 如果转型后的类型和对象真实类型不是同一种类型，那么在转换的时候就会出现ClassCastException\n\n建议\n\n建议强制转换前，先判断变量指向对象的真实类型，再强制类型转换。\n\n变量名 instanceof 真实类型 判断关键字左边的变量指向的对象的真实类型，是否是右边的类型或者是其子类类型，是则返回true\n\n以上判断是很有必要的，因为很有可能在方法内部看不到这个对象到底是啥类型。如下代码所示，不知道传进来的 Animal 到底是狗还是乌龟：\n\n    public static void go(Animal a){\n        System.out.println("预备~~~");\n        a.run();\n        // 独有功能\n        if(a instanceof Tortoise){\n            Tortoise t = (Tortoise) a;\n            t.layEggs();\n        }else if(a instanceof Dog){\n            Dog d1 = (Dog) a;\n            d1.lookDoor();\n        }\n        System.out.println("结束~~~~");\n    }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 4. 内部类\n\n内部类就是定义在一个类里面的类\n\n\n# 4.1 静态内部类\n\n有static修饰，属于外部类本身。它的特点和使用与普通类是完全一样的，类有的成分它都有，只是位置在别人里面而已。\n\npublic class Outer{\n    // 静态成员内部类\n    public static class Inner{\n    }\n}\n\n\n1\n2\n3\n4\n5\n\n\n静态内部类创建对象的格式：外部类名.内部类名 对象名 = new 外部类名.内部类构造器; 范例：Outer.Inner in = new Outer.Inner();\n\n> 这种语法比较少用，一般还是分开定义两种类的。\n\n\n# 4.2 成员内部类（非静态内部类）\n\n无static修饰，属于外部类的对象。JDK16之前，成员内部类中不能定义静态成员，JDK 16开始也可以定义静态成员了。\n\npublic class Outer {\n    // 成员内部类\n    public class Inner {\n        \n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n\n\n成员内部类创建对象的格式：格式：外部类名.内部类名 对象名 = new 外部类构造器.new 内部类构造器(); 范例：Outer.Inner in = new Outer().new Inner();\n\n（先有外部对象，然后才能创建成员内部类的对象）\n\n关于static\n\nstatic 修饰的是表示属于类的，而不是属于对象的。若有1000个对象，那么属于对象的部分也是有1000个，而 static 修饰的部分只有一个，因为只有一个这样的类。所以对象里面是不存在静态的。\n\n> 成员内部类比静态内部类更常用，因为他有对象创建的先后次序。企业内部，必须先有车这个对象，再有发动机对象。\n\n注意\n\n在成员内部类中访问所在外部类的对象，格式为：外部类名.this\n\n\n# 4.3 局部内部类\n\n鸡肋语法，了解即可\n\n\n# 4.4 *匿名内部类\n\n# (1) 概述\n\n本质上是一个没有名字的局部内部类，定义在方法中、代码块中、等。\n\n作用：方便创建子类对象，最终目的为了简化代码编写。\n\n点击展开代码\n\n/**\n      目标：学习匿名内部类的形式和特点。\n */\npublic class Test {\n    public static void main(String[] args) {\n        Animal a = new Animal(){\n            @Override\n            public void run() {\n                System.out.println("老虎跑的块~~~");\n            }\n        };\n        a.run();\n    }\n}\n\n//class Tiger extends Animal{\n//    @Override\n//    public void run() {\n//        System.out.println("老虎跑的块~~~");\n//    }\n//}\n\nabstract class Animal{\n    public abstract void run();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n上面这段代码中虽然 Animal 是个抽象类，但是在 Test 中也可以用 Animal 来创建一个匿名内部类。匿名内部类写出来就会产生一个匿名内部类的对象。匿名内部类的对象类型相当于是当前new的那个的类型的子类类型。即产生的匿名内部类相当于注释掉的 Tiger 子类对象。\n\n匿名内部类也会产生 Class 文件。\n\n# (2) 常见使用形式\n\n有了匿名内部类之后，可以不是必须要定义另外的Class去实现相应的接口了，可以直接在 new 的时候定义匿名内部类出来进行接口的实现。\n\n具体的一个例子\n\n/**\n    目标：掌握匿名内部类的使用形式（语法）\n */\npublic class Test2 {\n    public static void main(String[] args) {\n        Swimming s = new Swimming() {\n            @Override\n            public void swim() {\n                System.out.println("学生快乐的自由泳🏊‍");\n            }\n        };\n        go(s);\n\n        System.out.println("--------------");\n\n        Swimming s1 = new Swimming() {\n            @Override\n            public void swim() {\n                System.out.println("老师泳🏊的贼快~~~~~");\n            }\n        };\n        go(s1);\n\n        go(new Swimming() {\n            @Override\n            public void swim() {\n                System.out.println("运动员泳🏊的贼快~~~~~");\n            }\n        });\n\n        System.out.println("--------------");\n\n    /**\n       学生 老师 运动员可以一起参加游泳比赛\n     */\n    public static void go(Swimming s){\n        System.out.println("开始。。。");\n        s.swim();\n        System.out.println("结束。。。");\n    }\n}\n\n\ninterface Swimming{\n    void swim();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n\n\n经常用匿名内部类方法的入参形式，如下图：\n\n\n\n啥时候用匿名内部类\n\n开发中不是我们主动去定义匿名内部类的，而是别人需要我们写或者我们可以写的时候才会使用。能写的时候才要写，可遇不可求。',normalizedContent:'# 1. 模板方法模式\n\n\n# 1.1 抽象类\n\n如果一个类中的某个方法的具体实现不能确定，就可以申明成abstract修饰的抽象方法（不能写方法体了），这个类必须用abstract修饰，被称为抽象类。\n\n\n\n抽象的使用总结与注意事项：\n\n * 抽象类可以理解成类的不完整设计图，是用来被子类继承的。\n * 一个类如果继承了抽象类，那么这个类必须重写完抽象类的全部抽象方法，否则这个类也必须定义成抽象类。\n * 抽象类没有创建对象的能力。\n * 抽象类中不一定有抽象方法，有抽象方法的类一定是抽象类\n\n\n# 1.2 模板方法\n\n模板方法模式实现步骤：\n\n * 把功能定义成一个所谓的模板方法，放在抽象类中，模板方法中只定义通用且能确定的代码。\n * 模板方法中不能决定的功能定义成抽象方法让具体子类去实现。\n\n提示\n\n模板方法我们是建议使用final修饰的,模板方法是给子类直接使用的，不是让子类重写的， 一旦子类重写了模板方法就失效了。\n\n例如，中学生和小学生写《我的爸爸》这篇作文，他俩除了文章主体部分不同，别的地方都一样，此时，可以定义一个抽象类，用一个公共的模板方法来实现相同的部分，不同的部分在这个抽象类中声明一个抽象方法，让子类在此处来实现他们分别的功能。如下图代码所示：\n\n\n\n\n# 2. 接口\n\n\n# 2.1 基本知识\n\n接口体现了一种规范，约束类一定要干啥事。规范一定是公开的。\n\njdk 8 之前接口中只能有抽象方法和常量。\n\n * 关键字：interface\n\n * 接口的实现：implements 接口1,接口2,...\n\n几种关系：\n\n * 类和类的关系：单继承。\n * 类和接口的关系：多实现。\n * 接口和接口的关系：多继承，一个接口可以同时继承多个接口。\n\n接口多继承的作用: 规范合并，整合多个接口为同一个接口，便于子类实现。（子类只需要implements一个接口就可以了，不用很累赘地实现很多个接口）\n\n\n# 2.2 接口新增的方法\n\njdk8开始后新增了那些方法 ?\n\n * 默认方法：default修饰，实现类对象调用。\n * 静态方法：static修饰，必须用当前接口名调用。不能用子类调用静态方法。\n * 私有方法：private修饰，jdk9开始才有的，只能在接口内部被调用。\n * 他们都会默认被public修饰。\n\n注意\n\njdk8新增的3种方法我们自己在开发中很少使用，通常是java源码涉及到的，我们需要理解、识别语法、明白调用关系即可。\n\n提示\n\n切换模块的编译版本，选择jdk版本：file -> project structure -> modules ->language level\n\n\n\n\n# 2.3 使用接口的注意事项（面试中涉及）\n\n比较偏的一些语法，实际开发中通常不用，只有在一些面试中可能会涉及。\n\n 1. 接口不能创建对象\n\n 2. 一个类实现多个接口，多个接口中有同样的静态方法不冲突。\n\n 3. 一个类继承了父类，同时又实现了接口，父类中和接口中有同名方法，默认用父类的。\n    \n    继承只能在实现之前写，即先有亲爸再有干爹。接口为干爹，继承为亲爸。\n\n 4. 一个类实现了多个接口，多个接口中存在同名的默认方法，不冲突，这个类重写该方法即可。\n\n 5. 一个接口继承多个接口，是没有问题的，即使多个接口中有重名的方法，但如果多个接口中存在规范冲突则不能多继承。\n\n\n# 3. 多态\n\n# (1) 什么是多态\n\n同类型的对象，执行同一个行为，会表现出不同的行为特征。\n\n父类的引用类型指向子类的构造，向上造型，即为多态。\n\n# (2) 多态的常见形式\n\n * 父类类型 对象名称 = new 子类构造器;\n * 接口 对象名称 = new 实现类构造器;\n\nanimal a = new dog();\na.run(); // 方法调用：编译看左，运行看右\nsystem.out.println(a.name); // 方法调用：编译看左，运行也看左，动物名称\n\nanimal a1 = new dog();\na1.run();\nsystem.out.println(a1.name); // 动物名称\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n# (3) 多态中成员访问特点\n\n * 方法调用：编译看左，运行看右。=> 因此多态下不能使用子类的独有功能。\n * 变量调用：编译看左，运行也看左。（多态侧重行为多态）\n\n因此上述代码的输出结果都是动物名称。\n\n# (4) 多态的前提\n\n有继承/实现关系；有父类引用指向子类对象；有方法重写。\n\n# (5) 优势\n\n * 在多态形式下，右边对象可以实现解耦合，便于扩展和维护。\n\nanimal a = new dog(); // 后续业务更改时只需要修改此处new的dog即可\na.run(); // 后续业务行为随对象而变，后续代码无需修改\n\n\n1\n2\n\n * 定义方法的时候，使用父类型作为参数，该方法就可以接收这父类的一切子类对象，体现出多态的扩展性与便利。\n\n    public static void go(animal a){\n        system.out.println("开始。。。");\n        a.run();\n        system.out.println("结束。。。");\n    }\n// 这个函数可以传上面代码中的a, 也可以传a1\n\n\n1\n2\n3\n4\n5\n6\n\n\n# (6) 多态下引用数据类型的类型转换\n\n * 自动类型转换（从子到父)：子类对象赋值给父类类型的变量指向。\n   \n   // 自动类型转换\n   animal a = new dog();\n   a.run();\n   //a.lookdoor(); // 多态下无法调用子类独有功能\n   \n   \n   1\n   2\n   3\n   4\n   \n\n * 强制类型转换吗（从父到子)\n   \n   * 此时必须进行强制类型转换：子类 对象变量 = (子类)父类类型的变量\n     \n     // 强制类型转换:可以实现调用子类独有功能的\n     dog d = (dog) a;\n     d.lookdoor();\n     \n     \n     1\n     2\n     3\n     \n   \n   * 作用：可以解决多态下的劣势，可以实现调用子类独有的功能。\n   \n   * 注意： 如果转型后的类型和对象真实类型不是同一种类型，那么在转换的时候就会出现classcastexception\n\n建议\n\n建议强制转换前，先判断变量指向对象的真实类型，再强制类型转换。\n\n变量名 instanceof 真实类型 判断关键字左边的变量指向的对象的真实类型，是否是右边的类型或者是其子类类型，是则返回true\n\n以上判断是很有必要的，因为很有可能在方法内部看不到这个对象到底是啥类型。如下代码所示，不知道传进来的 animal 到底是狗还是乌龟：\n\n    public static void go(animal a){\n        system.out.println("预备~~~");\n        a.run();\n        // 独有功能\n        if(a instanceof tortoise){\n            tortoise t = (tortoise) a;\n            t.layeggs();\n        }else if(a instanceof dog){\n            dog d1 = (dog) a;\n            d1.lookdoor();\n        }\n        system.out.println("结束~~~~");\n    }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 4. 内部类\n\n内部类就是定义在一个类里面的类\n\n\n# 4.1 静态内部类\n\n有static修饰，属于外部类本身。它的特点和使用与普通类是完全一样的，类有的成分它都有，只是位置在别人里面而已。\n\npublic class outer{\n    // 静态成员内部类\n    public static class inner{\n    }\n}\n\n\n1\n2\n3\n4\n5\n\n\n静态内部类创建对象的格式：外部类名.内部类名 对象名 = new 外部类名.内部类构造器; 范例：outer.inner in = new outer.inner();\n\n> 这种语法比较少用，一般还是分开定义两种类的。\n\n\n# 4.2 成员内部类（非静态内部类）\n\n无static修饰，属于外部类的对象。jdk16之前，成员内部类中不能定义静态成员，jdk 16开始也可以定义静态成员了。\n\npublic class outer {\n    // 成员内部类\n    public class inner {\n        \n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n\n\n成员内部类创建对象的格式：格式：外部类名.内部类名 对象名 = new 外部类构造器.new 内部类构造器(); 范例：outer.inner in = new outer().new inner();\n\n（先有外部对象，然后才能创建成员内部类的对象）\n\n关于static\n\nstatic 修饰的是表示属于类的，而不是属于对象的。若有1000个对象，那么属于对象的部分也是有1000个，而 static 修饰的部分只有一个，因为只有一个这样的类。所以对象里面是不存在静态的。\n\n> 成员内部类比静态内部类更常用，因为他有对象创建的先后次序。企业内部，必须先有车这个对象，再有发动机对象。\n\n注意\n\n在成员内部类中访问所在外部类的对象，格式为：外部类名.this\n\n\n# 4.3 局部内部类\n\n鸡肋语法，了解即可\n\n\n# 4.4 *匿名内部类\n\n# (1) 概述\n\n本质上是一个没有名字的局部内部类，定义在方法中、代码块中、等。\n\n作用：方便创建子类对象，最终目的为了简化代码编写。\n\n点击展开代码\n\n/**\n      目标：学习匿名内部类的形式和特点。\n */\npublic class test {\n    public static void main(string[] args) {\n        animal a = new animal(){\n            @override\n            public void run() {\n                system.out.println("老虎跑的块~~~");\n            }\n        };\n        a.run();\n    }\n}\n\n//class tiger extends animal{\n//    @override\n//    public void run() {\n//        system.out.println("老虎跑的块~~~");\n//    }\n//}\n\nabstract class animal{\n    public abstract void run();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n上面这段代码中虽然 animal 是个抽象类，但是在 test 中也可以用 animal 来创建一个匿名内部类。匿名内部类写出来就会产生一个匿名内部类的对象。匿名内部类的对象类型相当于是当前new的那个的类型的子类类型。即产生的匿名内部类相当于注释掉的 tiger 子类对象。\n\n匿名内部类也会产生 class 文件。\n\n# (2) 常见使用形式\n\n有了匿名内部类之后，可以不是必须要定义另外的class去实现相应的接口了，可以直接在 new 的时候定义匿名内部类出来进行接口的实现。\n\n具体的一个例子\n\n/**\n    目标：掌握匿名内部类的使用形式（语法）\n */\npublic class test2 {\n    public static void main(string[] args) {\n        swimming s = new swimming() {\n            @override\n            public void swim() {\n                system.out.println("学生快乐的自由泳🏊‍");\n            }\n        };\n        go(s);\n\n        system.out.println("--------------");\n\n        swimming s1 = new swimming() {\n            @override\n            public void swim() {\n                system.out.println("老师泳🏊的贼快~~~~~");\n            }\n        };\n        go(s1);\n\n        go(new swimming() {\n            @override\n            public void swim() {\n                system.out.println("运动员泳🏊的贼快~~~~~");\n            }\n        });\n\n        system.out.println("--------------");\n\n    /**\n       学生 老师 运动员可以一起参加游泳比赛\n     */\n    public static void go(swimming s){\n        system.out.println("开始。。。");\n        s.swim();\n        system.out.println("结束。。。");\n    }\n}\n\n\ninterface swimming{\n    void swim();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n\n\n经常用匿名内部类方法的入参形式，如下图：\n\n\n\n啥时候用匿名内部类\n\n开发中不是我们主动去定义匿名内部类的，而是别人需要我们写或者我们可以写的时候才会使用。能写的时候才要写，可遇不可求。',charsets:{cjk:!0},lastUpdated:"2022/03/30, 06:54:33",lastUpdatedTimestamp:1648623273e3},{title:"常用API",frontmatter:{title:"常用API",date:"2022-04-02T10:39:16.000Z",permalink:"/pages/e76788/",categories:["开发","Java"],tags:[null]},regularPath:"/%E5%BC%80%E5%8F%91/10.Java/15.%E5%B8%B8%E7%94%A8API.html",relativePath:"开发/10.Java/15.常用API.md",key:"v-f49e53d6",path:"/pages/e76788/",headers:[{level:2,title:"1. Object",slug:"_1-object",normalizedTitle:"1. object",charIndex:12},{level:2,title:"2. Objects",slug:"_2-objects",normalizedTitle:"2. objects",charIndex:543},{level:2,title:"3. StringBuilder",slug:"_3-stringbuilder",normalizedTitle:"3. stringbuilder",charIndex:993},{level:2,title:"4. Math",slug:"_4-math",normalizedTitle:"4. math",charIndex:2516},{level:2,title:"5. System",slug:"_5-system",normalizedTitle:"5. system",charIndex:2582},{level:2,title:"6. BigDecimal",slug:"_6-bigdecimal",normalizedTitle:"6. bigdecimal",charIndex:2620}],headersStr:"1. Object 2. Objects 3. StringBuilder 4. Math 5. System 6. BigDecimal",content:'# 常用API\n\n\n# 1. Object\n\n * toString方法\n   \n   // 直接输出对象变量，默认可以省略toString调用不写的\n   System.out.println(s);\n   // 和下面这句话同义\n   System.out.println(s.toString());\n   \n   \n   1\n   2\n   3\n   4\n   \n   \n   toString 存在的意义\n   \n   父类toString()方法存在的意义就是为了被子类重写，以便返回对象的内容信息，而不是地址信息！！\n   \n   快捷方式：\n   \n   输入tos， IDEA 会自动提示 Generate 自动生成返回内容的信息。\n\n * equals方法\n   \n   直接比较两个对象的地址是否相同完全可以用“==”替代equals。\n   \n   System.out.println(s1.equals(s2));\n   // 此时s1若==null，会报错空指针异常。\n   \n   \n   1\n   2\n   \n   \n   equals 存在的意义\n   \n   父类equals方法存在的意义就是为了被子类重写，以便子类自己来定制比较规则。\n\n\n# 2. Objects\n\n * equals 方法\n   \n   比 Object API 中的 equals 方法更安全，不会有空指针异常。\n   \n   System.out.println(Objects.equals(s1, s2));\n   \n   \n   1\n   \n   \n   但此时还是得重写 Object 中的 equals 方法，因为此时 Objects 源码中调用的 equals 方法还是重写的那个方法。\n   \n   对象进行内容比较的时候建议使用什么？为什么？\n   \n   建议使用 Objects 提供的 equals 方法。比较的结果是一样的，但是更安全。\n\n * isNull 方法\n   \n   System.out.println(Objects.isNull(s1)); \n   System.out.println(s1 == null); \n   \n   \n   1\n   2\n   \n   \n   这俩写法完全一样，但是调用 API 更专业。\n\n\n# 3. StringBuilder\n\nStringBuilder 是个可变的字符串类，可以把它看成一个对象容器。\n\n作用：提高字符串的操作效率，如拼接、修改等。\n\n常用方法：\n\n * append(任意类型)\n   \n   // 支持链式编程\n   sb1.append("a").append("b").append("c").append("我爱你中国");\n   // 反转+append也可以\n   sb1.reverse().append("110");\n   \n   \n   1\n   2\n   3\n   4\n   \n   \n   以上操作都可行是因为append和reverse都是返回 this 这个当前的对象。\n\n * reverse()\n\n * length()\n\n * toString()\n   \n   可用来把 StringBuild 恢复成 String 类型。StringBuild 已重写了 toString 方法。\n   \n   // 例1\n   String rs = sb2.toString();\n   check(rs);\n   public static void check(String data) {\n       System.out.println(data);\n   }\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   \n   \n   // 例2\n   /**\n      1、定义方法接收任意整型数组，返回数组内容格式\n    */\n   public static String toString(int[] arr){\n      if(arr != null){\n           // 2、开始拼接内容。\n          StringBuilder sb = new StringBuilder("[");\n          for (int i = 0; i < arr.length; i++) {\n              sb.append(arr[i] ).append(i == arr.length - 1 ? "" : ", ");\n          }\n          sb.append("]");\n          return sb.toString(); // 转成String类型返回去\n      }else {\n          return null;\n      }\n   }\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   10\n   11\n   12\n   13\n   14\n   15\n   16\n   17\n   \n\nStringBuilder 和 String\n\nStringBuilder只是拼接字符串的手段：效率好，最终的目的还是要恢复成String类型。\n\n并且 String 类型和 StringBuild 不同，String 类型的参数不能直接传 StringBuild 对象。String 是不可变字符串，而 StringBuilder 是个可变的字符串类。\n\n为什么拼接、反转字符串建议使用StringBuilder?\n\nString ：内容是不可变的、拼接字符串性能差。 StringBuilder：内容是可变的、拼接字符串性能好、代码优雅。\n\n定义字符串使用String 拼接、修改等操作字符串使用StringBuilder\n\nStringBuilder 高效的原因，如下原理图：\n\n\n\n\n\n\n# 4. Math\n\n是个工具类，没有公开构造器。其中的方法都是静态的，直接用类名调用即可，不需要创建对象，即不能实例化。\n\n\n\n\n# 5. System\n\n是个工具类，不能实例化。直接用类名调用。\n\n\n\n\n# 6. BigDecimal\n\n用于解决浮点型运算精度失真的问题。\n\n实际开发中并不创建 BigDecimal 对象，而是调用方法来使其成为 BigDecimal 对象。如：public static BigDecimal valueOf(double val): 包装浮点数成为BigDecimal对象。或者传进来字符串类型的值。直接用构造器可能还是会损失精度。\n\ndouble 和 BigDecimal\n\ndouble 是目的，BigDecimal 是手段。\n\ndouble rs = c1.doubleValue();\n\n\n1\n\n\nBigDecimal 是一定要精度运算的，除不尽的会崩，因此需要指定的小数位数。',normalizedContent:'# 常用api\n\n\n# 1. object\n\n * tostring方法\n   \n   // 直接输出对象变量，默认可以省略tostring调用不写的\n   system.out.println(s);\n   // 和下面这句话同义\n   system.out.println(s.tostring());\n   \n   \n   1\n   2\n   3\n   4\n   \n   \n   tostring 存在的意义\n   \n   父类tostring()方法存在的意义就是为了被子类重写，以便返回对象的内容信息，而不是地址信息！！\n   \n   快捷方式：\n   \n   输入tos， idea 会自动提示 generate 自动生成返回内容的信息。\n\n * equals方法\n   \n   直接比较两个对象的地址是否相同完全可以用“==”替代equals。\n   \n   system.out.println(s1.equals(s2));\n   // 此时s1若==null，会报错空指针异常。\n   \n   \n   1\n   2\n   \n   \n   equals 存在的意义\n   \n   父类equals方法存在的意义就是为了被子类重写，以便子类自己来定制比较规则。\n\n\n# 2. objects\n\n * equals 方法\n   \n   比 object api 中的 equals 方法更安全，不会有空指针异常。\n   \n   system.out.println(objects.equals(s1, s2));\n   \n   \n   1\n   \n   \n   但此时还是得重写 object 中的 equals 方法，因为此时 objects 源码中调用的 equals 方法还是重写的那个方法。\n   \n   对象进行内容比较的时候建议使用什么？为什么？\n   \n   建议使用 objects 提供的 equals 方法。比较的结果是一样的，但是更安全。\n\n * isnull 方法\n   \n   system.out.println(objects.isnull(s1)); \n   system.out.println(s1 == null); \n   \n   \n   1\n   2\n   \n   \n   这俩写法完全一样，但是调用 api 更专业。\n\n\n# 3. stringbuilder\n\nstringbuilder 是个可变的字符串类，可以把它看成一个对象容器。\n\n作用：提高字符串的操作效率，如拼接、修改等。\n\n常用方法：\n\n * append(任意类型)\n   \n   // 支持链式编程\n   sb1.append("a").append("b").append("c").append("我爱你中国");\n   // 反转+append也可以\n   sb1.reverse().append("110");\n   \n   \n   1\n   2\n   3\n   4\n   \n   \n   以上操作都可行是因为append和reverse都是返回 this 这个当前的对象。\n\n * reverse()\n\n * length()\n\n * tostring()\n   \n   可用来把 stringbuild 恢复成 string 类型。stringbuild 已重写了 tostring 方法。\n   \n   // 例1\n   string rs = sb2.tostring();\n   check(rs);\n   public static void check(string data) {\n       system.out.println(data);\n   }\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   \n   \n   // 例2\n   /**\n      1、定义方法接收任意整型数组，返回数组内容格式\n    */\n   public static string tostring(int[] arr){\n      if(arr != null){\n           // 2、开始拼接内容。\n          stringbuilder sb = new stringbuilder("[");\n          for (int i = 0; i < arr.length; i++) {\n              sb.append(arr[i] ).append(i == arr.length - 1 ? "" : ", ");\n          }\n          sb.append("]");\n          return sb.tostring(); // 转成string类型返回去\n      }else {\n          return null;\n      }\n   }\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   10\n   11\n   12\n   13\n   14\n   15\n   16\n   17\n   \n\nstringbuilder 和 string\n\nstringbuilder只是拼接字符串的手段：效率好，最终的目的还是要恢复成string类型。\n\n并且 string 类型和 stringbuild 不同，string 类型的参数不能直接传 stringbuild 对象。string 是不可变字符串，而 stringbuilder 是个可变的字符串类。\n\n为什么拼接、反转字符串建议使用stringbuilder?\n\nstring ：内容是不可变的、拼接字符串性能差。 stringbuilder：内容是可变的、拼接字符串性能好、代码优雅。\n\n定义字符串使用string 拼接、修改等操作字符串使用stringbuilder\n\nstringbuilder 高效的原因，如下原理图：\n\n\n\n\n\n\n# 4. math\n\n是个工具类，没有公开构造器。其中的方法都是静态的，直接用类名调用即可，不需要创建对象，即不能实例化。\n\n\n\n\n# 5. system\n\n是个工具类，不能实例化。直接用类名调用。\n\n\n\n\n# 6. bigdecimal\n\n用于解决浮点型运算精度失真的问题。\n\n实际开发中并不创建 bigdecimal 对象，而是调用方法来使其成为 bigdecimal 对象。如：public static bigdecimal valueof(double val): 包装浮点数成为bigdecimal对象。或者传进来字符串类型的值。直接用构造器可能还是会损失精度。\n\ndouble 和 bigdecimal\n\ndouble 是目的，bigdecimal 是手段。\n\ndouble rs = c1.doublevalue();\n\n\n1\n\n\nbigdecimal 是一定要精度运算的，除不尽的会崩，因此需要指定的小数位数。',charsets:{cjk:!0},lastUpdated:"2022/04/07, 08:01:03",lastUpdatedTimestamp:1649318463e3},{title:"并发、并行、异步、同步（暂存）",frontmatter:{title:"并发、并行、异步、同步（暂存）",date:"2022-04-07T15:21:00.000Z",permalink:"/pages/5de326/",categories:["开发","Java"],tags:[null]},regularPath:"/%E5%BC%80%E5%8F%91/10.Java/20.%E5%B9%B6%E5%8F%91%E3%80%81%E5%B9%B6%E8%A1%8C%E3%80%81%E5%BC%82%E6%AD%A5%E3%80%81%E5%90%8C%E6%AD%A5%EF%BC%88%E6%9A%82%E5%AD%98%EF%BC%89.html",relativePath:"开发/10.Java/20.并发、并行、异步、同步（暂存）.md",key:"v-00a73f02",path:"/pages/5de326/",headers:[{level:2,title:"1. 并发 VS. 并行（parallelism）",slug:"_1-并发-vs-并行-parallelism",normalizedTitle:"1. 并发 vs. 并行（parallelism）",charIndex:2},{level:2,title:"2. 同步 VS. 异步",slug:"_2-同步-vs-异步",normalizedTitle:"2. 同步 vs. 异步",charIndex:132},{level:3,title:"2.1 多线程编程（Multi-threading） VS. （单线程）异步编程（Asynchronous Programming）",slug:"_2-1-多线程编程-multi-threading-vs-单线程-异步编程-asynchronous-programming",normalizedTitle:"2.1 多线程编程（multi-threading） vs. （单线程）异步编程（asynchronous programming）",charIndex:388},{level:3,title:"2.2 异步编程",slug:"_2-2-异步编程",normalizedTitle:"2.2 异步编程",charIndex:631}],headersStr:"1. 并发 VS. 并行（parallelism） 2. 同步 VS. 异步 2.1 多线程编程（Multi-threading） VS. （单线程）异步编程（Asynchronous Programming） 2.2 异步编程",content:'# 1. 并发 VS. 并行（parallelism）\n\n并发单纯代表计算机能同时执行多项任务，具体怎么实现的会有多种形式。\n\n * 单核：分配时间片，进程或线程进行上下文切换，实现并发。\n * 多核：多核处理器上，可以在不同的核心上真正并行地执行任务。\n\n\n# 2. 同步 VS. 异步\n\n * 同步：必须等前一个任务完毕之后才能开始下一个任务，没有并发、并行的概念。\n\n * 异步：不同任务之间不互相等待，直到任务完成之后才回来通知你。\n   \n   典型实现方式：多线程。\n   \n   * 若在多核心上运行，则不同线程分配到不同的核心上运行。\n   * 若在单核心上运行，或通过设置亲和力（Affinity）强制将线程绑定到某个核心上，则会通过分配时间片的方式进行并发地执行各个线程。\n   \n   python 的 asyncio 就是原生的异步编程方式，\n\n\n# 2.1 多线程编程（Multi-threading） VS. （单线程）异步编程（Asynchronous Programming）\n\n * 多线程编程：适合计算量密集的应用。视频、图像处理、科学计算等，不让 CPU 核心消耗在无畏的等待上。\n\n\n\n * 异步编程：I/O密集型程序应用异步编程。\n   \n   用多线程编程容易造成资源浪费，各个线程都会处于等待 I/O 操作的过程中，线程自身会占用额外内存，并且线程之间的切换会有额外的开销，以及线程之间的资源竞争问题。\n\n\n\n\n# 2.2 异步编程\n\n不同任务之间不互相等待，直到任务完成之后才回来通知你，通常以回调函数（callback）的方式来通知你。这种编程模式避免了程序的阻塞，提高了 CPU 执行效率。尤其适用 I/O 密集、操作数据库、访问文件等操作。\n\n * Promise (承诺) ： 寓意这个去这个请求会在未来某一个时刻返回\n   \n   解决了回调地狱的问题\n   \n   例如： fetch 向服务器请求，返回Promise对象,渲染前端，如果可以使用 then 进行接受返回的结果\n\nfetch("https://www.woshishuaige.om").then((res)=>{\n\n})\n\n\n1\n2\n3\n\n\n * async / await\n   \n   用 async 标记一个函数为异步函数，在这样的函数中，可以用 await 来调用其他的异步函数，这样避免了用 Promise ， 以及一系列的 then 等等。\n   \n   不能在全局和普通函数中使用 await 关键字，只能被应用异步，所以想要使用 await 就必须用 async 修饰函数。',normalizedContent:'# 1. 并发 vs. 并行（parallelism）\n\n并发单纯代表计算机能同时执行多项任务，具体怎么实现的会有多种形式。\n\n * 单核：分配时间片，进程或线程进行上下文切换，实现并发。\n * 多核：多核处理器上，可以在不同的核心上真正并行地执行任务。\n\n\n# 2. 同步 vs. 异步\n\n * 同步：必须等前一个任务完毕之后才能开始下一个任务，没有并发、并行的概念。\n\n * 异步：不同任务之间不互相等待，直到任务完成之后才回来通知你。\n   \n   典型实现方式：多线程。\n   \n   * 若在多核心上运行，则不同线程分配到不同的核心上运行。\n   * 若在单核心上运行，或通过设置亲和力（affinity）强制将线程绑定到某个核心上，则会通过分配时间片的方式进行并发地执行各个线程。\n   \n   python 的 asyncio 就是原生的异步编程方式，\n\n\n# 2.1 多线程编程（multi-threading） vs. （单线程）异步编程（asynchronous programming）\n\n * 多线程编程：适合计算量密集的应用。视频、图像处理、科学计算等，不让 cpu 核心消耗在无畏的等待上。\n\n\n\n * 异步编程：i/o密集型程序应用异步编程。\n   \n   用多线程编程容易造成资源浪费，各个线程都会处于等待 i/o 操作的过程中，线程自身会占用额外内存，并且线程之间的切换会有额外的开销，以及线程之间的资源竞争问题。\n\n\n\n\n# 2.2 异步编程\n\n不同任务之间不互相等待，直到任务完成之后才回来通知你，通常以回调函数（callback）的方式来通知你。这种编程模式避免了程序的阻塞，提高了 cpu 执行效率。尤其适用 i/o 密集、操作数据库、访问文件等操作。\n\n * promise (承诺) ： 寓意这个去这个请求会在未来某一个时刻返回\n   \n   解决了回调地狱的问题\n   \n   例如： fetch 向服务器请求，返回promise对象,渲染前端，如果可以使用 then 进行接受返回的结果\n\nfetch("https://www.woshishuaige.om").then((res)=>{\n\n})\n\n\n1\n2\n3\n\n\n * async / await\n   \n   用 async 标记一个函数为异步函数，在这样的函数中，可以用 await 来调用其他的异步函数，这样避免了用 promise ， 以及一系列的 then 等等。\n   \n   不能在全局和普通函数中使用 await 关键字，只能被应用异步，所以想要使用 await 就必须用 async 修饰函数。',charsets:{cjk:!0},lastUpdated:"2023/05/17, 13:14:17",lastUpdatedTimestamp:1684329257e3},{title:"Spring依赖注入原理",frontmatter:{title:"Spring依赖注入原理",date:"2023-04-22T16:11:16.000Z",permalink:"/pages/0fc51e/",categories:["开发","Java","《Spring Boot 进阶（郑天民）》-学习笔记"],tags:[null]},regularPath:"/%E5%BC%80%E5%8F%91/10.Java/30.%E3%80%8ASpring%20Boot%20%E8%BF%9B%E9%98%B6-%E9%83%91%E5%A4%A9%E6%B0%91%E3%80%8B/05.Spring%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5%E7%9A%84%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90.html",relativePath:"开发/10.Java/30.《Spring Boot 进阶-郑天民》/05.Spring依赖注入的原理分析.md",key:"v-cafc5bfe",path:"/pages/0fc51e/",headers:[{level:2,title:"1. 基本概念",slug:"_1-基本概念",normalizedTitle:"1. 基本概念",charIndex:2},{level:2,title:"2. Spring依赖注入原理分析",slug:"_2-spring依赖注入原理分析",normalizedTitle:"2. spring依赖注入原理分析",charIndex:88},{level:3,title:"2.1 Bean 的注册",slug:"_2-1-bean-的注册",normalizedTitle:"2.1 bean 的注册",charIndex:338},{level:3,title:"2.2 Bean 的实例化",slug:"_2-2-bean-的实例化",normalizedTitle:"2.2 bean 的实例化",charIndex:1861},{level:2,title:"3. Spring 循环依赖分析",slug:"_3-spring-循环依赖分析",normalizedTitle:"3. spring 循环依赖分析",charIndex:3600},{level:3,title:"3.1 三级缓存结构",slug:"_3-1-三级缓存结构",normalizedTitle:"3.1 三级缓存结构",charIndex:3829},{level:3,title:"3.2 三级缓存如何发挥作用的？",slug:"_3-2-三级缓存如何发挥作用的",normalizedTitle:"3.2 三级缓存如何发挥作用的？",charIndex:4144},{level:3,title:"3.3 循环依赖解决方案",slug:"_3-3-循环依赖解决方案",normalizedTitle:"3.3 循环依赖解决方案",charIndex:5609}],headersStr:"1. 基本概念 2. Spring依赖注入原理分析 2.1 Bean 的注册 2.2 Bean 的实例化 3. Spring 循环依赖分析 3.1 三级缓存结构 3.2 三级缓存如何发挥作用的？ 3.3 循环依赖解决方案",content:"# 1. 基本概念\n\n依赖注入（Dependency Injection, DI）：在系统运行时基于某个对象的使用需求，动态提供他所依赖的其他对象，通过依赖注入实现。\n\n\n# 2. Spring依赖注入原理分析\n\nSpring 中涉及大量类和组件之间的协作与交互。原理上讲，任何一个框架都存在一条核心执行流程，只要抓住这条主流程，我们就能把握框架的整体代码结构，Spring 也不例外。无论采用何种依赖注入机制，前提都是 SpringIoC 容器正常启动。因此，IoC 容器初始化就是我们理解和把握依赖注人实现机制的前提。\n\n下面我们讲解 IoC 容器的初始化过程。结合 Bean 的生命周期，将其梳理为两大步骤：\n\n * Bean 的注册\n * Bean 的实例化\n\n\n# 2.1 Bean 的注册\n\n在使用Spring时，我们可以通过获取一个应用上下文(ApplicationContext)对象来操作各种 Bean，示例代码如下：\n\nAnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(AppConfig.class);\n\n\n1\n\n * 这里的 ApplicationContext 接口代表的就是一个Spring IoC 容器，而在 Spring 中存在大批 ApplicationContext 接口的实现类。如果使用基于注解的配置方式，就可以使用上述代码中的 AnnotationConfigApplicationContext 来初始化容器上下文对象。\n\n看一下 AnnotationConfigApplicationContext 的启动流程，这一流程位于它的构造函数中，如下：\n\npublic AnnotationConfigApplicationContext(Class<?>...annotatedClasses) {\n  this();\n  //根据注解配置类注册 Bean\n  register(annotatedClasses);\n  //刷新容器\n  refresh();\n}\n\npublic AnnotationConfigApplicationContext(String...basePackages) {\n  this();\n  //根据包路径配置扫描 Bean\n  scan(basePackages);\n  // 刷新容器\n  refresh();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n * 这两个构造函数的作用很明确，一个是根据注解配置类注册 Bean，另一个则是根据包路径配置扫描 Bean。\n\n这里我们以 register() 方法为例，来讨论 Bean 的注册过程。该 register() 会依赖 AnnolatedBeanDeinitionReader 工具类来完成 Bean 的注册。这个工具类会遍历所有传入的 annotatedClasses 注解类，然后通过 doRegisterBean() 方法完成注册。\n\n在 doRegisterBean() 方法中，包含了 Bean 注册过程中的三个核心步骤，如下图：\n\n * 首先，我们构建用来描述 Bean 实例信息的 BeanDefinition 对象，这需要将注解配置类信息转成 AnnotatedGenericBeanDefinition 数据结构，而它就是一种 BeanDefinition，包含了 Bean 的构造函数参数、各种属性值以及所添加的注解信息。\n   * Bean 的属性值：如 Student 类的 age、name 等，就是属性\n * 然后，我们设置 BeanDefinition 属性，这一步骤完成了对 @Scope、@Primary、@Lazy 等注解的处理。\n * 最后，通过 registerBeanDefinition() 方法完成 Bean 的注册，该方法内部通过 ListableBeanFactory 的实现类 DefaultListableBeanFactory将 Bean 定义信息注册到 Spring IoC 容器中。\n   * ListableBeanFactory 是 Spring 中常用的一个 BeanFactory，通过这个接口，我们可以一次获取多个 Bean。\n\n\n# 2.2 Bean 的实例化\n\n上一小小节中的 Bean 的注册并未完成实例化，只是将 Bean 的定义加载到了容器中。\n\n要根据注册的 Bean 的定义调用 ApplicationContext 接口的抽象实现类 AbstractApplicationContext 中的 refresh() 方法刷新容器，正如我们在前面看到的 AnnotationConfigApplicationContext 构造函数所执行的那样。可以说，refresh() 方法是整个 Spring 容器中最为核心的一个方法，我们这里只对 refresh() 中和依赖注入相关的部分讨论。\n\nrefresh() 方法中，\n\n * obtainFreshBeanFactory() 方法完成 BeanDefinition 的注册并返回一个BeanFactory。对于 AnnotationConfigApplicationContext 而言，这一步实际上就是将 BeanDefinition 注册到 DefaultListableBeanFactory 而已，我们在前面已经介绍了这一步骤。\n * 而 finishBeanFactorylnitialization() 方法才是真正的完成 Bean 实例化的入口。\n\n在 finishBeanFactorylnitialization() 对 Bean 的实例化又经历了一番折腾：\n\n * 完成 Bean 的实例化的代码实际上位于法它的子类 DefaultListableBeanFactory 中，的prelnstantiateSingletons() 方法；\n * 该方法调用 getBean() 方法，可以从 BeanFactory 中获取 Bean，而 Bean 的初始化过程也被封装在这个方法中。\n * 在 getBean() 中，发现实际上是由实现抽象方法 createBean() 的唯一 BeanFactory —— AbstractAutowireCapableBeanFactory 中，的 doCreateBean() 方法中真正完成 Bean 的创建。\n\ndoCreateBean() 方法中包含三个核心子方法，他们的名称和作用如下图，经过大量裁剪之后得到的代码如下所示。\n\nprotected object docreateBean(final String beanName, final RootBeanDefinitioimbd, final @Nullable object[] args) throws BeanCreationException {\n  //1. 初始化Bean\n  instanceWrapper =createBeanInstance(beanName，mbd，args);\n\n  //2. 初始化Bean实例\n  populateBean(beanName， mbd，instanceWrapper);\n  \n  //3. 执行初始化 Bean 实例的回调\n  exposedObject=initializeBean(beanName，exposedObject，mbd);\n\n  return exposedObject;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n * createBeanInstance0 方法用于根据配置生成具体的 Bean，最终通过基于构造器的反射方法实现这一目标。请注意，执行完这一步之后，Bean 已经被创建了但还不完整，因为属性还没有被注入。\n * 接下来的 populateBean() 方法就是用于实现属性的自动注人，包含 byName、byType 类型的自动装配，以及基于 @Autowired、@Value 注解的属性设值。执行完这一步之后，可以说 Bean 已经是完整的了。\n * 最后的 initializeBean()方法则更多是一种扩展性的实现机制，用于在 Bean初始化完成之后执行一些定制化操作。\n\n至此，针对整个 Bean 的注人过程(即 Bean 的注册和实例化)，我们围绕核心流程做了剖析和总结。\n\n\n# 3. Spring 循环依赖分析\n\n使用 Ioc 容器时的一个常见问题：循环依赖。\n\n在单例作用域下，Setter 方法注入能够解决循环依赖问题而构造器注入则不能。\n\n对于单例作用域来说，Spring 容器在整个生命周期内，有且只有一个 Bean 对象，所以很容易想到这个对象应该存在于缓存中。Spring为了解决单例 Bean 的循环依赖问题，使用了三级缓存。这是 Spring 在设计和实现上的一大特色，也是开发人员在面试过程中经常遇到的话题。\n\n\n# 3.1 三级缓存结构\n\n所谓的三级缓存，在Spring中表现为三个 Map 对象，如下的代码所示：\n\n这三个Map 对象定义在 DefaultSingletonBeanRegistry 类中，该类是 DefaultListableBeanFactory 的父类。\n\n * singletonObjects 变量就是策一级缓存，用来持有完整的 Bean实例\n * earlySingletonObjects 中存放的是那些提前暴露的对象，也就是已经创建但还没有完成属性汪人的对象，属于第二级缓存\n * singletonFactories 存放用来创建earlySingletonObjects 的工厂对象，属于第三级缓存\n\n\n# 3.2 三级缓存如何发挥作用的？\n\n我们通过分析获取 Bean 的代码流程来理解对三级缓存的访问过程。\n\nprotected object getSingleton(String beanName, boolean allowEarlyReference) {\n    //首先从一级缓存singletonObjects 中获取Object \n    singletonObject = this.singletonObjects.get(beanName);\n\n    //如果获取不到，就从二级缓存 earlysingletonobjects 中获取\n    if (singletonobject == null && isSingletonCurrentlyInCreation(beanName)) {\n      synchronized (this.singletonObjects) {\n        singletonObject = this.earlySingletonObjects.get(beanName);\n        \n        //如果还是获取不到，就从三级缓存 singletonPactory 中获取\n        if (singletonObject == null && allowEarlyReference){\n          ObjectFactory<?> singletonFactory = this.singletonFactories.get(beanName);\n          if (singletonFactory != null){\n            singletonObject = singletonFactory.getobject();\n            \n            //一旦获取成功，就把对象从第三级缓存移动到第二级缓存中\n            this.earlySingletonobjects.put(beanName，singletonObject);\n            this.singletonFactories.remove(beanName);\n          }\n        }\n      }\n    }\n    return singletonObject;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n看了这段代码，可能还是不理解 Spring 为什么要这样设计。事实上，解决循环依赖的关键还是要围绕 Bean 的生命周期。Spring 解决循环依赖的诀窍就在于 singletonFactories 这个第三级缓存。\n\n上一小小节我们介绍 Bean 的实例化时，我们知道它包含三个核心步骤，而在第一步和第二步之间，存在一个addSingletonFactory() 方法，用于初始化第三级缓存中的数据，他针对循环依赖问题暴露单例工厂类，代码如下图所示：\n\naddSingletonFactory() 方法的具体代码就不在这里展开了。\n\naddSingletonFactory() 方法的代码的执行时机是在已经通过构造函数创建 Bean，但还没有完成对 Bean 中完教属性的注人的时候。换句话说，Ben 已经可以被暴露出来进行识别了，但还不能正常使用。\n\n\n# 3.3 循环依赖解决方案\n\n接下来我们就来分析一下为什么通过这种机制就能解决循环依赖问题。\n\n让我们回顾基于 Setter 方法注入的循环依赖场景:\n\n现在我们就能够基于 Setter 方法注入来解决掉循环依赖了，整个流程如下图：\n\n基于 Setter 方法注入解决循环依赖的具体描述（对上图的解释）\n\n现在假设我们先初始化 ClassA。ClassA 首先通过 createBeanInstance() 方法创建了实例，并且将这个实例提前暴露到第三级缓存 singletonFactories 中。然后，ClassA 尝试通过 populateBean() 方法注人属性，发现自己依赖ClassB 这个属性，就会尝试去获取 ClassB的实例。\n\n显然，这时候 ClassB 还没有被创建，所以要走创建流程。ClassB 在初始化第一步的时候发现自己依赖了 ClassA，就会尝试从第一级缓存 singletonObjects 去获取 ClassA实例。因为 ClassA 这时候还没有被创建完毕，所以它在第一级缓存和第二级缓存中都不存在。当尝试访问第三级缓存时，因为 ClassA 已经提前暴露了，所以 ClassB 能够通过singletonFactories拿到 ClassA 对象并顺利完成所有初始化流程。\n\nClassB 对象创建完成之后会被放到第一级缓存中，这时候 ClassA 就能从第一级缓存中获取 ClassB 的实例，进而完成 ClassA 的所有初始化流。这样 ClassA 和 ClassB 都能够功完成创建过程，\n\n讲到这里，相信你也理解了为什么构造器注入无法解决循环依赖问题。这是因为构造器注人过程是发生在 Bean 初始化的第一个步骤 createBeanInstance() 中，而这个步骤还没有调用 addSingletonFactory0方法完成第三级缓存的构建，自然也就无法从该缓存中获取目标对象。",normalizedContent:"# 1. 基本概念\n\n依赖注入（dependency injection, di）：在系统运行时基于某个对象的使用需求，动态提供他所依赖的其他对象，通过依赖注入实现。\n\n\n# 2. spring依赖注入原理分析\n\nspring 中涉及大量类和组件之间的协作与交互。原理上讲，任何一个框架都存在一条核心执行流程，只要抓住这条主流程，我们就能把握框架的整体代码结构，spring 也不例外。无论采用何种依赖注入机制，前提都是 springioc 容器正常启动。因此，ioc 容器初始化就是我们理解和把握依赖注人实现机制的前提。\n\n下面我们讲解 ioc 容器的初始化过程。结合 bean 的生命周期，将其梳理为两大步骤：\n\n * bean 的注册\n * bean 的实例化\n\n\n# 2.1 bean 的注册\n\n在使用spring时，我们可以通过获取一个应用上下文(applicationcontext)对象来操作各种 bean，示例代码如下：\n\nannotationconfigapplicationcontext applicationcontext = new annotationconfigapplicationcontext(appconfig.class);\n\n\n1\n\n * 这里的 applicationcontext 接口代表的就是一个spring ioc 容器，而在 spring 中存在大批 applicationcontext 接口的实现类。如果使用基于注解的配置方式，就可以使用上述代码中的 annotationconfigapplicationcontext 来初始化容器上下文对象。\n\n看一下 annotationconfigapplicationcontext 的启动流程，这一流程位于它的构造函数中，如下：\n\npublic annotationconfigapplicationcontext(class<?>...annotatedclasses) {\n  this();\n  //根据注解配置类注册 bean\n  register(annotatedclasses);\n  //刷新容器\n  refresh();\n}\n\npublic annotationconfigapplicationcontext(string...basepackages) {\n  this();\n  //根据包路径配置扫描 bean\n  scan(basepackages);\n  // 刷新容器\n  refresh();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n * 这两个构造函数的作用很明确，一个是根据注解配置类注册 bean，另一个则是根据包路径配置扫描 bean。\n\n这里我们以 register() 方法为例，来讨论 bean 的注册过程。该 register() 会依赖 annolatedbeandeinitionreader 工具类来完成 bean 的注册。这个工具类会遍历所有传入的 annotatedclasses 注解类，然后通过 doregisterbean() 方法完成注册。\n\n在 doregisterbean() 方法中，包含了 bean 注册过程中的三个核心步骤，如下图：\n\n * 首先，我们构建用来描述 bean 实例信息的 beandefinition 对象，这需要将注解配置类信息转成 annotatedgenericbeandefinition 数据结构，而它就是一种 beandefinition，包含了 bean 的构造函数参数、各种属性值以及所添加的注解信息。\n   * bean 的属性值：如 student 类的 age、name 等，就是属性\n * 然后，我们设置 beandefinition 属性，这一步骤完成了对 @scope、@primary、@lazy 等注解的处理。\n * 最后，通过 registerbeandefinition() 方法完成 bean 的注册，该方法内部通过 listablebeanfactory 的实现类 defaultlistablebeanfactory将 bean 定义信息注册到 spring ioc 容器中。\n   * listablebeanfactory 是 spring 中常用的一个 beanfactory，通过这个接口，我们可以一次获取多个 bean。\n\n\n# 2.2 bean 的实例化\n\n上一小小节中的 bean 的注册并未完成实例化，只是将 bean 的定义加载到了容器中。\n\n要根据注册的 bean 的定义调用 applicationcontext 接口的抽象实现类 abstractapplicationcontext 中的 refresh() 方法刷新容器，正如我们在前面看到的 annotationconfigapplicationcontext 构造函数所执行的那样。可以说，refresh() 方法是整个 spring 容器中最为核心的一个方法，我们这里只对 refresh() 中和依赖注入相关的部分讨论。\n\nrefresh() 方法中，\n\n * obtainfreshbeanfactory() 方法完成 beandefinition 的注册并返回一个beanfactory。对于 annotationconfigapplicationcontext 而言，这一步实际上就是将 beandefinition 注册到 defaultlistablebeanfactory 而已，我们在前面已经介绍了这一步骤。\n * 而 finishbeanfactorylnitialization() 方法才是真正的完成 bean 实例化的入口。\n\n在 finishbeanfactorylnitialization() 对 bean 的实例化又经历了一番折腾：\n\n * 完成 bean 的实例化的代码实际上位于法它的子类 defaultlistablebeanfactory 中，的prelnstantiatesingletons() 方法；\n * 该方法调用 getbean() 方法，可以从 beanfactory 中获取 bean，而 bean 的初始化过程也被封装在这个方法中。\n * 在 getbean() 中，发现实际上是由实现抽象方法 createbean() 的唯一 beanfactory —— abstractautowirecapablebeanfactory 中，的 docreatebean() 方法中真正完成 bean 的创建。\n\ndocreatebean() 方法中包含三个核心子方法，他们的名称和作用如下图，经过大量裁剪之后得到的代码如下所示。\n\nprotected object docreatebean(final string beanname, final rootbeandefinitioimbd, final @nullable object[] args) throws beancreationexception {\n  //1. 初始化bean\n  instancewrapper =createbeaninstance(beanname，mbd，args);\n\n  //2. 初始化bean实例\n  populatebean(beanname， mbd，instancewrapper);\n  \n  //3. 执行初始化 bean 实例的回调\n  exposedobject=initializebean(beanname，exposedobject，mbd);\n\n  return exposedobject;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n * createbeaninstance0 方法用于根据配置生成具体的 bean，最终通过基于构造器的反射方法实现这一目标。请注意，执行完这一步之后，bean 已经被创建了但还不完整，因为属性还没有被注入。\n * 接下来的 populatebean() 方法就是用于实现属性的自动注人，包含 byname、bytype 类型的自动装配，以及基于 @autowired、@value 注解的属性设值。执行完这一步之后，可以说 bean 已经是完整的了。\n * 最后的 initializebean()方法则更多是一种扩展性的实现机制，用于在 bean初始化完成之后执行一些定制化操作。\n\n至此，针对整个 bean 的注人过程(即 bean 的注册和实例化)，我们围绕核心流程做了剖析和总结。\n\n\n# 3. spring 循环依赖分析\n\n使用 ioc 容器时的一个常见问题：循环依赖。\n\n在单例作用域下，setter 方法注入能够解决循环依赖问题而构造器注入则不能。\n\n对于单例作用域来说，spring 容器在整个生命周期内，有且只有一个 bean 对象，所以很容易想到这个对象应该存在于缓存中。spring为了解决单例 bean 的循环依赖问题，使用了三级缓存。这是 spring 在设计和实现上的一大特色，也是开发人员在面试过程中经常遇到的话题。\n\n\n# 3.1 三级缓存结构\n\n所谓的三级缓存，在spring中表现为三个 map 对象，如下的代码所示：\n\n这三个map 对象定义在 defaultsingletonbeanregistry 类中，该类是 defaultlistablebeanfactory 的父类。\n\n * singletonobjects 变量就是策一级缓存，用来持有完整的 bean实例\n * earlysingletonobjects 中存放的是那些提前暴露的对象，也就是已经创建但还没有完成属性汪人的对象，属于第二级缓存\n * singletonfactories 存放用来创建earlysingletonobjects 的工厂对象，属于第三级缓存\n\n\n# 3.2 三级缓存如何发挥作用的？\n\n我们通过分析获取 bean 的代码流程来理解对三级缓存的访问过程。\n\nprotected object getsingleton(string beanname, boolean allowearlyreference) {\n    //首先从一级缓存singletonobjects 中获取object \n    singletonobject = this.singletonobjects.get(beanname);\n\n    //如果获取不到，就从二级缓存 earlysingletonobjects 中获取\n    if (singletonobject == null && issingletoncurrentlyincreation(beanname)) {\n      synchronized (this.singletonobjects) {\n        singletonobject = this.earlysingletonobjects.get(beanname);\n        \n        //如果还是获取不到，就从三级缓存 singletonpactory 中获取\n        if (singletonobject == null && allowearlyreference){\n          objectfactory<?> singletonfactory = this.singletonfactories.get(beanname);\n          if (singletonfactory != null){\n            singletonobject = singletonfactory.getobject();\n            \n            //一旦获取成功，就把对象从第三级缓存移动到第二级缓存中\n            this.earlysingletonobjects.put(beanname，singletonobject);\n            this.singletonfactories.remove(beanname);\n          }\n        }\n      }\n    }\n    return singletonobject;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n看了这段代码，可能还是不理解 spring 为什么要这样设计。事实上，解决循环依赖的关键还是要围绕 bean 的生命周期。spring 解决循环依赖的诀窍就在于 singletonfactories 这个第三级缓存。\n\n上一小小节我们介绍 bean 的实例化时，我们知道它包含三个核心步骤，而在第一步和第二步之间，存在一个addsingletonfactory() 方法，用于初始化第三级缓存中的数据，他针对循环依赖问题暴露单例工厂类，代码如下图所示：\n\naddsingletonfactory() 方法的具体代码就不在这里展开了。\n\naddsingletonfactory() 方法的代码的执行时机是在已经通过构造函数创建 bean，但还没有完成对 bean 中完教属性的注人的时候。换句话说，ben 已经可以被暴露出来进行识别了，但还不能正常使用。\n\n\n# 3.3 循环依赖解决方案\n\n接下来我们就来分析一下为什么通过这种机制就能解决循环依赖问题。\n\n让我们回顾基于 setter 方法注入的循环依赖场景:\n\n现在我们就能够基于 setter 方法注入来解决掉循环依赖了，整个流程如下图：\n\n基于 setter 方法注入解决循环依赖的具体描述（对上图的解释）\n\n现在假设我们先初始化 classa。classa 首先通过 createbeaninstance() 方法创建了实例，并且将这个实例提前暴露到第三级缓存 singletonfactories 中。然后，classa 尝试通过 populatebean() 方法注人属性，发现自己依赖classb 这个属性，就会尝试去获取 classb的实例。\n\n显然，这时候 classb 还没有被创建，所以要走创建流程。classb 在初始化第一步的时候发现自己依赖了 classa，就会尝试从第一级缓存 singletonobjects 去获取 classa实例。因为 classa 这时候还没有被创建完毕，所以它在第一级缓存和第二级缓存中都不存在。当尝试访问第三级缓存时，因为 classa 已经提前暴露了，所以 classb 能够通过singletonfactories拿到 classa 对象并顺利完成所有初始化流程。\n\nclassb 对象创建完成之后会被放到第一级缓存中，这时候 classa 就能从第一级缓存中获取 classb 的实例，进而完成 classa 的所有初始化流。这样 classa 和 classb 都能够功完成创建过程，\n\n讲到这里，相信你也理解了为什么构造器注入无法解决循环依赖问题。这是因为构造器注人过程是发生在 bean 初始化的第一个步骤 createbeaninstance() 中，而这个步骤还没有调用 addsingletonfactory0方法完成第三级缓存的构建，自然也就无法从该缓存中获取目标对象。",charsets:{cjk:!0},lastUpdated:"2023/04/22, 13:40:03",lastUpdatedTimestamp:1682170803e3},{title:"基础",frontmatter:{title:"基础",date:"2022-05-15T21:16:06.000Z",permalink:"/pages/a53eb3/",categories:["开发","GoLang","码神之路-学习笔记"],tags:[null]},regularPath:"/%E5%BC%80%E5%8F%91/15.GoLang/05.%E7%A0%81%E7%A5%9E%E4%B9%8B%E8%B7%AF-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/05.%E5%9F%BA%E7%A1%80.html",relativePath:"开发/15.GoLang/05.码神之路-学习笔记/05.基础.md",key:"v-53b20642",path:"/pages/a53eb3/",headers:[{level:2,title:"1. 变量",slug:"_1-变量",normalizedTitle:"1. 变量",charIndex:65},{level:3,title:"1.1 标准格式",slug:"_1-1-标准格式",normalizedTitle:"1.1 标准格式",charIndex:129},{level:3,title:"1.2 基本类型",slug:"_1-2-基本类型",normalizedTitle:"1.2 基本类型",charIndex:257},{level:3,title:"1.3 不指明变量类型",slug:"_1-3-不指明变量类型",normalizedTitle:"1.3 不指明变量类型",charIndex:616}],headersStr:"1. 变量 1.1 标准格式 1.2 基本类型 1.3 不指明变量类型",content:'# 基础\n\n> 现在已经不用 GOROOT 和 GOPATH 那套了，直接用 go mod 即可。\n> \n> —— 大斌\n\n\n# 1. 变量\n\n> Go语言是静态类型语言，因此变量（variable）是有明确类型的，编译器也会检查变量类型的正确性。\n\n\n# 1.1 标准格式\n\nvar 变量名 变量类型\n\n\n1\n\n\n变量声明以关键字var开头，变量类型后置，行尾无须分号\n\n举个例子\n\n//声明了一个名为age的变量，类型为int\nvar age int\n\n\n1\n2\n\n\n> 变量的命名规则遵循驼峰命名法\n\n\n# 1.2 基本类型\n\n * bool\n * string\n * int（随系统，一般是占用4个字节）、int8(占一个字节)、int16(占两个字节)、int32(占4个字节)、int64（占8个字节）\n * uint（无符号整数）、uint8、uint16、uint32、uint64、uintptr\n * byte // uint8 的别名\n * rune // int32 的别名 代表一个 Unicode 码\n * float32、float64\n * complex64、complex128\n\n当一个变量被声明之后，系统自动赋予它该类型的零值：\n\nint 为 0，float 为 0.0，bool 为 false，string 为空字符串，指针为 nil\n\n所有的内存在 Go 中都是经过初始化的。\n\n\n# 1.3 不指明变量类型\n\n//设置游戏中角色的初始等级为1\nvar level = 1;\n\n\n1\n2\n\n\n像上面这种声明变量的方式，并没有指明类型，Go语言中，在编译时会自动推导类型\n\n我们可以使用\n\nfmt.Printf("%T", level)\n\n\n1\n\n\n进行类型输出。',normalizedContent:'# 基础\n\n> 现在已经不用 goroot 和 gopath 那套了，直接用 go mod 即可。\n> \n> —— 大斌\n\n\n# 1. 变量\n\n> go语言是静态类型语言，因此变量（variable）是有明确类型的，编译器也会检查变量类型的正确性。\n\n\n# 1.1 标准格式\n\nvar 变量名 变量类型\n\n\n1\n\n\n变量声明以关键字var开头，变量类型后置，行尾无须分号\n\n举个例子\n\n//声明了一个名为age的变量，类型为int\nvar age int\n\n\n1\n2\n\n\n> 变量的命名规则遵循驼峰命名法\n\n\n# 1.2 基本类型\n\n * bool\n * string\n * int（随系统，一般是占用4个字节）、int8(占一个字节)、int16(占两个字节)、int32(占4个字节)、int64（占8个字节）\n * uint（无符号整数）、uint8、uint16、uint32、uint64、uintptr\n * byte // uint8 的别名\n * rune // int32 的别名 代表一个 unicode 码\n * float32、float64\n * complex64、complex128\n\n当一个变量被声明之后，系统自动赋予它该类型的零值：\n\nint 为 0，float 为 0.0，bool 为 false，string 为空字符串，指针为 nil\n\n所有的内存在 go 中都是经过初始化的。\n\n\n# 1.3 不指明变量类型\n\n//设置游戏中角色的初始等级为1\nvar level = 1;\n\n\n1\n2\n\n\n像上面这种声明变量的方式，并没有指明类型，go语言中，在编译时会自动推导类型\n\n我们可以使用\n\nfmt.printf("%t", level)\n\n\n1\n\n\n进行类型输出。',charsets:{cjk:!0},lastUpdated:"2022/07/27, 11:28:29",lastUpdatedTimestamp:1658921309e3},{title:"前言",frontmatter:{title:"前言",date:"2022-04-12T20:06:38.000Z",permalink:"/pages/83009c/",categories:["网络","路由劫持","《深入浅出详解RPKI》"],tags:[null]},regularPath:"/%E7%BD%91%E7%BB%9C/5.%E8%B7%AF%E7%94%B1%E5%8A%AB%E6%8C%81/5.%E3%80%8A%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E8%AF%A6%E8%A7%A3RPKI%E3%80%8B/05.%E5%89%8D%E8%A8%80.html",relativePath:"网络/5.路由劫持/5.《深入浅出详解RPKI》/05.前言.md",key:"v-623e7b3d",path:"/pages/83009c/",headers:[{level:2,title:"缩略语",slug:"缩略语",normalizedTitle:"缩略语",charIndex:219}],headersStr:"缩略语",content:"# 前言\n\nIETF 推出了近40篇 RFC，以期构建一个支撑域间路由安全的互联网号码资源公钥基础设施。\n\n本书以 IETF 制定的 RFC 为基础，着眼于实际，从定义、原理、架构和实际应用出发，系统地介绍了 RPKI 。\n\nRPKI 是一个与互联网号码资源结构相结合的分层认证模型，在 X.509 证书框架下采用公钥—私钥的加密形式，用签名的方式为网络地址和路由宣告信息提供可信任的基础。RPKI 是互联网路由架构信任的基础。\n\n\n# 缩略语\n\nAS：Autonomous System 自治系统\n\nAFRINIC：Africa Network Information Centre 非洲互联网络信息中心\n\nAIA：Authority Information Access 权威信息访问\n\nAPNIC：Asia Pacific Network Information Centre 亚太互联网络信息中心\n\nARIN：American Registry for Internet Numbers 美国互联网号码注册中心\n\nBGP：Border Gateway Protocol 边界网关协议\n\nBGPsec：Border Gateway Protocol Security 边界路由协议安全\n\nCA：Certification Authority 认证权威\n\nCMS：Cryptographic Message Syntax 密码消息语法\n\nCNNIC：China Internet Network Information Center 中国互联网络信息中心\n\nCP：Certificate Policies 证书策略\n\nCPS：Certificate Practice Statement 证书操作声明\n\nCRL：Certificate Revocation List 证书撤销列表\n\nEE：End Entity 终端实体\n\nIP： Internet Protocol 互联网协议\n\nINR：Internet Number Resource 互联网号码资源\n\nIANA：Internet Assigned Number Authority 互联网号码分配机构\n\nLACNIC：Lation American and Caribbean Internet Address Registry 拉丁美洲和加勒比海 互联网地址注册机构\n\nRDI：Routing Domain Identifier 路由域标识符\n\nRIPE NCC：Reseaux IP Europeans Network Coordination Center 欧洲网络协调中心\n\nRIR：Regional Internet Registry 地区互联网注册机构\n\nROA：Router Origin Authorization 路由起源授权\n\nRPKI：Resource Public Key Infrastructure 互联网号码资源公钥基础设施\n\nRP：Relying Party 依赖方\n\nS-BGP：Secure Border Gateway Protocol 安全边界路由协议\n\nsoBGP：Secure Origin Border Gateway Protocol 安全源边界路由协议\n\nSIA：Subject Information Authority 主题信息权威\n\nTAO：Transfer Authorization Object 转移认证对象\n\nTA：Trust Anchor 信任锚\n\nTAL：Trust Anchor Locator 信任锚定位器",normalizedContent:"# 前言\n\nietf 推出了近40篇 rfc，以期构建一个支撑域间路由安全的互联网号码资源公钥基础设施。\n\n本书以 ietf 制定的 rfc 为基础，着眼于实际，从定义、原理、架构和实际应用出发，系统地介绍了 rpki 。\n\nrpki 是一个与互联网号码资源结构相结合的分层认证模型，在 x.509 证书框架下采用公钥—私钥的加密形式，用签名的方式为网络地址和路由宣告信息提供可信任的基础。rpki 是互联网路由架构信任的基础。\n\n\n# 缩略语\n\nas：autonomous system 自治系统\n\nafrinic：africa network information centre 非洲互联网络信息中心\n\naia：authority information access 权威信息访问\n\napnic：asia pacific network information centre 亚太互联网络信息中心\n\narin：american registry for internet numbers 美国互联网号码注册中心\n\nbgp：border gateway protocol 边界网关协议\n\nbgpsec：border gateway protocol security 边界路由协议安全\n\nca：certification authority 认证权威\n\ncms：cryptographic message syntax 密码消息语法\n\ncnnic：china internet network information center 中国互联网络信息中心\n\ncp：certificate policies 证书策略\n\ncps：certificate practice statement 证书操作声明\n\ncrl：certificate revocation list 证书撤销列表\n\nee：end entity 终端实体\n\nip： internet protocol 互联网协议\n\ninr：internet number resource 互联网号码资源\n\niana：internet assigned number authority 互联网号码分配机构\n\nlacnic：lation american and caribbean internet address registry 拉丁美洲和加勒比海 互联网地址注册机构\n\nrdi：routing domain identifier 路由域标识符\n\nripe ncc：reseaux ip europeans network coordination center 欧洲网络协调中心\n\nrir：regional internet registry 地区互联网注册机构\n\nroa：router origin authorization 路由起源授权\n\nrpki：resource public key infrastructure 互联网号码资源公钥基础设施\n\nrp：relying party 依赖方\n\ns-bgp：secure border gateway protocol 安全边界路由协议\n\nsobgp：secure origin border gateway protocol 安全源边界路由协议\n\nsia：subject information authority 主题信息权威\n\ntao：transfer authorization object 转移认证对象\n\nta：trust anchor 信任锚\n\ntal：trust anchor locator 信任锚定位器",charsets:{cjk:!0},lastUpdated:"2022/04/12, 13:24:26",lastUpdatedTimestamp:1649769866e3},{title:"简介",frontmatter:{title:"简介",date:"2022-04-12T20:22:28.000Z",permalink:"/pages/b6c83c/",categories:["网络","路由劫持","《深入浅出详解RPKI》"],tags:[null]},regularPath:"/%E7%BD%91%E7%BB%9C/5.%E8%B7%AF%E7%94%B1%E5%8A%AB%E6%8C%81/5.%E3%80%8A%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E8%AF%A6%E8%A7%A3RPKI%E3%80%8B/10.%E7%AE%80%E4%BB%8B.html",relativePath:"网络/5.路由劫持/5.《深入浅出详解RPKI》/10.简介.md",key:"v-551cf7ff",path:"/pages/b6c83c/",headers:[{level:2,title:"1.1 背景",slug:"_1-1-背景",normalizedTitle:"1.1 背景",charIndex:9},{level:3,title:"1.1.1 技术起源",slug:"_1-1-1-技术起源",normalizedTitle:"1.1.1 技术起源",charIndex:20},{level:3,title:"1.1.2 自治系统和路由劫持",slug:"_1-1-2-自治系统和路由劫持",normalizedTitle:"1.1.2 自治系统和路由劫持",charIndex:432},{level:3,title:"1.1.3 互联网号码资源分配架构",slug:"_1-1-3-互联网号码资源分配架构",normalizedTitle:"1.1.3 互联网号码资源分配架构",charIndex:616},{level:2,title:"1.2 RPKI 概述",slug:"_1-2-rpki-概述",normalizedTitle:"1.2 rpki 概述",charIndex:845},{level:3,title:"1.2.1 RPKI 的三个核心组成",slug:"_1-2-1-rpki-的三个核心组成",normalizedTitle:"1.2.1 rpki 的三个核心组成",charIndex:1206},{level:3,title:"1.2.2 工作原理",slug:"_1-2-2-工作原理",normalizedTitle:"1.2.2 工作原理",charIndex:1340}],headersStr:"1.1 背景 1.1.1 技术起源 1.1.2 自治系统和路由劫持 1.1.3 互联网号码资源分配架构 1.2 RPKI 概述 1.2.1 RPKI 的三个核心组成 1.2.2 工作原理",content:"# 简介\n\n\n# 1.1 背景\n\n\n# 1.1.1 技术起源\n\nRPKI 的概念最早诞生于描述S-BGP方 案的论文中。S-BGP 提出了一种附加签名的 BGP 扩展消息格式，用以验证路由通告中 IP 地址前缀和传播路径上 AS 号之间的绑定关系，从而避免路由劫持。基于这样的设计，数字证书和签名机制被引入 BGP 范畴， 从而顺理成章地需要一套公钥基础设施（Public Key Infostructure，PKI）的支持。为验证路由通告签名者所持有的公钥，该签名者的 IP 地址分配上游为其签发证书。一方面验证其持有的公钥，另一方面验证该签名者对某个 IP 地址前缀的所有权。基于 IP 地址资源分配关系而形成的公钥证书体系，RPKI 的基本框架就此形成。\n\n域名系统和域间路由系统作为互联网两大基础 性资源，对互联网的安全有着至关重要的影响。在域间路由系统层面，互联网社区则计划部署 RPKI 以期构建一个支撑域间路由安全的互联网基础资源管理体系。\n\n\n# 1.1.2 自治系统和路由劫持\n\n\n\n如上图所示，AS1 劫持了经过 AS2 通向IP地址前缀为218.113.28.10/15 的 AS5 的所有网络流量。\n\n期望可以让某个 IP 地址的真正持有者能以明确、可验证的方式授权一个或者多个 AS 作为其地址的初始路由广播者，并且每个 AS 都可以获得该授权信息并进行验证，进而避免类似路由劫持的网络事故发生。\n\n\n# 1.1.3 互联网号码资源分配架构\n\n当前互联网管理策略允许 IP 地址的持有者自由决定将其所持有的 IP 地址授权（分配）给谁使用。RPKI 的主要功能也是为上述授权（分配）关系提供可以验证的密码服务。一个 RPKI 证书与一次 IP 地址分配相对应，一个 RPKI 子证书与一次 IP 地址子分配相对应，所以 RPKI 同样采用了如图1-3所示的树形图。\n\n\n\n不过，在 RPKI 的树形分层体系中，AS号码的分配到了 NIR 这一级就终止了。\n\n\n# 1.2 RPKI 概述\n\nRPKI是由IETF安全域间路由工作组（Secure Inter-Domain Routing，SIDR）制定的一个专用的PKI框架。\n\nRPKI广泛采用了由PKIX（Public Key Infrastructure using X.509）定义的X.509证书规范。为了更好地理解RPKI技术，建议本书的读者最好事先熟悉 “Internet X.509 Public Key Infrastructure Certificate and Certificate Revocation List (CRL) Profile”（RFC5280）和 “X.509 Extensions for IP Addresses and AS Identifiers” （RFC3779）里的条款。\n\n\n# 1.2.1 RPKI 的三个核心组成\n\n * 整体架构规范，这是保证 RPKI 系统正常运行的基础。\n\n * 数字签名路由对象，直接为 IP/AS 分配提供密码验证服务。\n\n * 分布式的资料库系统，用于存储 PKI 对象以及签名路由对象，供用户访问和使用。\n\n\n# 1.2.2 工作原理\n\n....\n\n写不下去啦~类似于工具书，用到查就可以啦~",normalizedContent:"# 简介\n\n\n# 1.1 背景\n\n\n# 1.1.1 技术起源\n\nrpki 的概念最早诞生于描述s-bgp方 案的论文中。s-bgp 提出了一种附加签名的 bgp 扩展消息格式，用以验证路由通告中 ip 地址前缀和传播路径上 as 号之间的绑定关系，从而避免路由劫持。基于这样的设计，数字证书和签名机制被引入 bgp 范畴， 从而顺理成章地需要一套公钥基础设施（public key infostructure，pki）的支持。为验证路由通告签名者所持有的公钥，该签名者的 ip 地址分配上游为其签发证书。一方面验证其持有的公钥，另一方面验证该签名者对某个 ip 地址前缀的所有权。基于 ip 地址资源分配关系而形成的公钥证书体系，rpki 的基本框架就此形成。\n\n域名系统和域间路由系统作为互联网两大基础 性资源，对互联网的安全有着至关重要的影响。在域间路由系统层面，互联网社区则计划部署 rpki 以期构建一个支撑域间路由安全的互联网基础资源管理体系。\n\n\n# 1.1.2 自治系统和路由劫持\n\n\n\n如上图所示，as1 劫持了经过 as2 通向ip地址前缀为218.113.28.10/15 的 as5 的所有网络流量。\n\n期望可以让某个 ip 地址的真正持有者能以明确、可验证的方式授权一个或者多个 as 作为其地址的初始路由广播者，并且每个 as 都可以获得该授权信息并进行验证，进而避免类似路由劫持的网络事故发生。\n\n\n# 1.1.3 互联网号码资源分配架构\n\n当前互联网管理策略允许 ip 地址的持有者自由决定将其所持有的 ip 地址授权（分配）给谁使用。rpki 的主要功能也是为上述授权（分配）关系提供可以验证的密码服务。一个 rpki 证书与一次 ip 地址分配相对应，一个 rpki 子证书与一次 ip 地址子分配相对应，所以 rpki 同样采用了如图1-3所示的树形图。\n\n\n\n不过，在 rpki 的树形分层体系中，as号码的分配到了 nir 这一级就终止了。\n\n\n# 1.2 rpki 概述\n\nrpki是由ietf安全域间路由工作组（secure inter-domain routing，sidr）制定的一个专用的pki框架。\n\nrpki广泛采用了由pkix（public key infrastructure using x.509）定义的x.509证书规范。为了更好地理解rpki技术，建议本书的读者最好事先熟悉 “internet x.509 public key infrastructure certificate and certificate revocation list (crl) profile”（rfc5280）和 “x.509 extensions for ip addresses and as identifiers” （rfc3779）里的条款。\n\n\n# 1.2.1 rpki 的三个核心组成\n\n * 整体架构规范，这是保证 rpki 系统正常运行的基础。\n\n * 数字签名路由对象，直接为 ip/as 分配提供密码验证服务。\n\n * 分布式的资料库系统，用于存储 pki 对象以及签名路由对象，供用户访问和使用。\n\n\n# 1.2.2 工作原理\n\n....\n\n写不下去啦~类似于工具书，用到查就可以啦~",charsets:{cjk:!0},lastUpdated:"2022/04/12, 13:24:26",lastUpdatedTimestamp:1649769866e3}],themeConfig:{nav:[{text:"首页",link:"/"},{text:"开发",items:[{text:"Java",link:"/java/"},{text:"Golang",link:"/go/"}]},{text:"AI",items:[{text:"深度学习",link:"/deep-learning/"}]},{text:"基础",items:[{text:"Git",link:"/git/"},{text:"Linux",link:"/linux/"},{text:"DataStructure",link:"/datastructure/"},{text:"CloudNative",link:"/cloudnative/"}]},{text:"中间件",items:[{text:"Redis",link:"/redis/"},{text:"MySQL",link:"/mysql/"}]},{text:"网络",items:[{text:"路由劫持",link:"/route-hijack/"}]}],sidebarDepth:2,logo:"/img/mylogo.jpeg",repo:"n7301/blog",searchMaxSuggestions:10,lastUpdated:"上次更新",docsDir:"docs",editLinks:!0,editLinkText:"编辑",sidebar:{"/00.目录页/":[{title:"开发",collapsable:!0,children:[["05.开发/10.Java.md","Java","/java"],["05.开发/15.GoLang.md","GoLang","/go"]]},{title:"AI",collapsable:!0,children:[["10.AI/05.深度学习.md","深度学习","/deep-learning"]]},{title:"基础",collapsable:!0,children:[["15.基础/5.Git.md","Git","/git"],["15.基础/10.Linux.md","Linux","/linux"],["15.基础/15.数据结构.md","DataStructure","/datastructure"],["15.基础/20.云原生.md","CloudNative","/cloudnative"]]},{title:"中间件",collapsable:!0,children:[["20.中间件/05.Redis.md","Redis","/redis"],["20.中间件/06.MySQL.md","MySQL","/mysql"]]},{title:"网络",collapsable:!0,children:[["25.网络/5.路由劫持.md","路由劫持","/route-hijack"]]}],catalogue:{Java:"/java",GoLang:"/go","深度学习":"/deep-learning",Linux:"/linux","数据结构":"/datastructure","云原生":"/cloudnative",Git:"/git",Redis:"/redis",MySQL:"/mysql","路由劫持":"/route-hijack"},"/AI/":[{title:"深度学习",collapsable:!0,children:[{title:"李宏毅",collapsable:!0,children:[["05.深度学习/05.李宏毅/01.基本概念.md","基本概念","/pages/3a4ae9/"],["05.深度学习/05.李宏毅/05.神经网络训练不起来怎么办.md","神经网络训练不起来怎么办","/pages/e6f457/"]]}]}],"/中间件/":[{title:"Redis",collapsable:!0,children:[{title:"专栏：Redis 核心技术与实战",collapsable:!0,children:[["05.Redis/05.专栏：Redis 核心技术与实战/01.基础架构、数据结构与 IO 模型.md","基础架构、数据结构与 IO 模型","/pages/271391/"],["05.Redis/05.专栏：Redis 核心技术与实战/04.持久化机制：AOF日志和RDB快照.md","持久化机制：AOF日志和RDB快照","/pages/d1a6d3/"],["05.Redis/05.专栏：Redis 核心技术与实战/06.主从复制与哨兵机制.md","主从复制与哨兵机制","/pages/348567/"],["05.Redis/05.专栏：Redis 核心技术与实战/09.切片集群.md","切片集群","/pages/71b166/"],["05.Redis/05.专栏：Redis 核心技术与实战/11.Redis 中的数据结构.md","Redis 中的数据结构","/pages/2029a8/"],["05.Redis/05.专栏：Redis 核心技术与实战/14.时间序列数据的保存.md","时间序列数据的保存","/pages/a3ed18/"],["05.Redis/05.专栏：Redis 核心技术与实战/15.Redis 的消息队列方案.md","Redis 的消息队列方案","/pages/5d636a/"],["05.Redis/05.专栏：Redis 核心技术与实战/16.异步机制、CPU 架构对性能的影响.md","异步机制、CPU 架构对性能的影响","/pages/ca62e3/"],["05.Redis/05.专栏：Redis 核心技术与实战/18.如何应对变慢的 Redis.md","如何应对变慢的 Redis","/pages/f111bf/"],["05.Redis/05.专栏：Redis 核心技术与实战/20.Redis 的内存碎片、缓冲区.md","Redis 的内存碎片、缓冲区","/pages/6135bf/"],["05.Redis/05.专栏：Redis 核心技术与实战/23.Redis 用作缓存.md","Redis 用作缓存","/pages/d403e5/"],["05.Redis/05.专栏：Redis 核心技术与实战/25.Redis 用作缓存之缓存异常.md","Redis 用作缓存之缓存异常","/pages/cbe81b/"],["05.Redis/05.专栏：Redis 核心技术与实战/27.Redis 用作缓存之缓存污染.md","Redis 用作缓存之缓存污染","/pages/ea52c5/"],["05.Redis/05.专栏：Redis 核心技术与实战/28.Pika：基于SSD实现大容量Redis.md","Pika：基于SSD实现大容量Redis","/pages/8f7740/"],["05.Redis/05.专栏：Redis 核心技术与实战/29.无锁的原子操作和分布式锁.md","无锁的原子操作和分布式锁","/pages/5a1b01/"],["05.Redis/05.专栏：Redis 核心技术与实战/31.Redis 的事务机制.md","Redis 的事务机制","/pages/932816/"],["05.Redis/05.专栏：Redis 核心技术与实战/32.Redis 主从同步的坑.md","Redis 主从同步的坑","/pages/4140fe/"],["05.Redis/05.专栏：Redis 核心技术与实战/36.秒杀场景下的应用.md","秒杀场景下的应用","/pages/b6efd0/"],["05.Redis/05.专栏：Redis 核心技术与实战/37.集群的数据倾斜和通信开销问题.md","集群的数据倾斜和通信开销问题","/pages/d3d97d/"]]}]},{title:"MySQL",collapsable:!0,children:[{title:"专栏：MySQL 实战 45 讲",collapsable:!0,children:[["06.MySQL/05.专栏：MySQL 实战 45 讲/01.基础架构：一条SQL查询语句是如何执行的？.md","基础架构：一条SQL查询语句是如何执行的？","/pages/473452/"],["06.MySQL/05.专栏：MySQL 实战 45 讲/02.日志系统：一条SQL更新语句是如何执行的？.md","日志系统：一条SQL更新语句是如何执行的？","/pages/38bad9/"],["06.MySQL/05.专栏：MySQL 实战 45 讲/03.事务隔离.md","事务隔离","/pages/b99352/"],["06.MySQL/05.专栏：MySQL 实战 45 讲/04.深入浅出索引.md","深入浅出索引","/pages/1ea58b/"],["06.MySQL/05.专栏：MySQL 实战 45 讲/05.全局锁、表级锁和行锁.md","全局锁、表级锁和行锁","/pages/376254/"],["06.MySQL/05.专栏：MySQL 实战 45 讲/06.change buffer.md","change buffer","/pages/02bb58/"],["06.MySQL/05.专栏：MySQL 实战 45 讲/07.MySQL为什么有时候会加错索引.md","MySQL为什么有时候会加错索引","/pages/c4cff3/"],["06.MySQL/05.专栏：MySQL 实战 45 讲/08.怎么给字符串字段加索引.md","怎么给字符串字段加索引","/pages/fa9ec1/"]]}]}],"/基础/":[{title:"Git",collapsable:!0,children:[["5.Git/05.Git基础.md","Git基础","/pages/0d79ac/"],["5.Git/10.Git的使用.md","Git的使用","/pages/dc4ebe/"]]},{title:"Linux",collapsable:!0,children:[{title:"韩顺平2021课程笔记",collapsable:!0,children:[["10.Linux/05.韩顺平2021课程笔记/05.Linux基础篇.md","Linux 基础篇","/pages/c774f5/"],["10.Linux/05.韩顺平2021课程笔记/10.Linux实操篇（上）.md","Linux实操篇（上）","/pages/4a5b75/"],["10.Linux/05.韩顺平2021课程笔记/15.Linux实操篇（下）.md","Linux实操篇（下）","/pages/16468e/"],["10.Linux/05.韩顺平2021课程笔记/20.JavaEE与Python定制篇.md","JavaEE与Python定制篇","/pages/1e98d9/"],["10.Linux/05.韩顺平2021课程笔记/25.大数据定制篇-Shell编程.md","大数据定制篇-Shell编程","/pages/338288/"]]},{title:"From公众号",collapsable:!0,children:[["10.Linux/10.From公众号/5.带你实现Linux命令自由.md","带你实现Linux命令自由","/pages/dd2e0e/"]]}]},{title:"数据结构",collapsable:!0,children:[{title:"常见数据结构",collapsable:!0,children:[["15.数据结构/05.常见数据结构/05.LSM 树.md","LSM 树","/pages/c2aef8/"]]}]},{title:"云原生",collapsable:!0,children:[{title:"Kubernetes入门实战课-罗剑锋",collapsable:!0,children:[["20.云原生/15.Kubernetes入门实战课-罗剑锋/01.开篇词.md","开篇词","/pages/850e00/"],["20.云原生/15.Kubernetes入门实战课-罗剑锋/02.初识容器.md","初识容器","/pages/1cc8db/"],["20.云原生/15.Kubernetes入门实战课-罗剑锋/09.Kubernetes 的安装与基本架构.md","Kubernetes 的安装与基本架构","/pages/757154/"],["20.云原生/15.Kubernetes入门实战课-罗剑锋/11.YAML、Pod、Job、CronJob、ConfigMap、Secret.md","YAML、Pod、Job、CronJob、ConfigMap、Secret","/pages/c0d84b/"]]}]}],"/开发/":[{title:"Java",collapsable:!0,children:[{title:"黑马Java入门基础-学习笔记",collapsable:!0,children:[["10.Java/05.黑马Java入门基础-学习笔记/05.Java基础语法.md","Java 基础语法","/pages/483565/"],["10.Java/05.黑马Java入门基础-学习笔记/10.数组.md","数组","/pages/a6522a/"],["10.Java/05.黑马Java入门基础-学习笔记/15.方法.md","方法","/pages/615479/"],["10.Java/05.黑马Java入门基础-学习笔记/20.面向对象基础.md","面向对象基础","/pages/d4e408/"],["10.Java/05.黑马Java入门基础-学习笔记/25.常用API(String、ArrayList).md","常用API(String、ArrayList)","/pages/8f676c/"],["10.Java/05.黑马Java入门基础-学习笔记/30.面向对象进阶1（static、单例、代码块、继承）.md","面向对象进阶1（static、单例、代码块、继承）","/pages/46cfbb/"],["10.Java/05.黑马Java入门基础-学习笔记/31.面向对象进阶2（包、权限修饰符、抽象类、接口）.md","面向对象进阶2（包、权限修饰符、抽象类、接口）","/pages/b127ae/"],["10.Java/05.黑马Java入门基础-学习笔记/32.面向对象进阶3（多态、内部类、常用API）.md","面向对象进阶3（多态、内部类、常用API）","/pages/a4fc75/"],["10.Java/05.黑马Java入门基础-学习笔记/33.面向对象进阶4（常用日期API、正则、Arrays类、Lambda）.md","面向对象进阶4（常用日期API、正则、Arrays类、Lambda）","/pages/4cb625/"],["10.Java/05.黑马Java入门基础-学习笔记/34.面向对象进阶5（集合体系）.md","面向对象进阶5（集合体系）","/pages/6013df/"],["10.Java/05.黑马Java入门基础-学习笔记/35.面向对象进阶6（集合体系之Map）.md","面向对象进阶6（集合体系之Map）","/pages/134c54/"],["10.Java/05.黑马Java入门基础-学习笔记/40.面向对象进阶-补充（可变参数）.md","面向对象进阶-补充（可变参数）","/pages/e64834/"]]},["10.Java/10.面向对象.md","面向对象","/pages/017edb/"],["10.Java/15.常用API.md","常用API","/pages/e76788/"],["10.Java/20.并发、并行、异步、同步（暂存）.md","并发、并行、异步、同步（暂存）","/pages/5de326/"],{title:"《Spring Boot 进阶-郑天民》",collapsable:!0,children:[["10.Java/30.《Spring Boot 进阶-郑天民》/05.Spring依赖注入的原理分析.md","Spring依赖注入原理","/pages/0fc51e/"]]}]},{title:"GoLang",collapsable:!0,children:[{title:"码神之路-学习笔记",collapsable:!0,children:[["15.GoLang/05.码神之路-学习笔记/05.基础.md","基础","/pages/a53eb3/"]]}]}],"/网络/":[{title:"路由劫持",collapsable:!0,children:[{title:"《深入浅出详解RPKI》",collapsable:!0,children:[["5.路由劫持/5.《深入浅出详解RPKI》/05.前言.md","前言","/pages/83009c/"],["5.路由劫持/5.《深入浅出详解RPKI》/10.简介.md","简介","/pages/b6c83c/"]]}]}]},author:{name:"Nrich",link:"https://github.com/Nrich-sunny"},blogger:{avatar:"https://blog-1310567564.cos.ap-beijing.myqcloud.com/head.jpg",name:"Nrich",slogan:"小聪明"},social:{icons:[{iconClass:"icon-github",title:"GitHub",link:"https://github.com/Nrich-sunny"}]},footer:{createYear:2022,copyrightInfo:'Nrich | <a href="https://github.com/xugaoyi/vuepress-theme-vdoing/blob/master/LICENSE" target="_blank">MIT License</a>'},htmlModules:{}},locales:{"/":{lang:"zh-CN",title:"Nrich's blog",description:"web前端技术博客,专注web前端学习与总结。JavaScript,js,ES6,TypeScript,vue,React,python,css3,html5,Node,git,github等技术文章。",path:"/"}}};var ko=t(96),_o=t(97),Eo=t(11);var So={computed:{$filterPosts(){return this.$site.pages.filter(n=>{const{frontmatter:{pageComponent:e,article:t,home:i}}=n;return!(e||!1===t||!0===i)})},$sortPosts(){return(n=this.$filterPosts).sort((n,e)=>{const t=n.frontmatter.sticky,i=e.frontmatter.sticky;return t&&i?t==i?Object(Eo.a)(n,e):t-i:t&&!i?-1:!t&&i?1:Object(Eo.a)(n,e)}),n;var n},$sortPostsByDate(){return(n=this.$filterPosts).sort((n,e)=>Object(Eo.a)(n,e)),n;var n},$groupPosts(){return function(n){const e={},t={};for(let i=0,r=n.length;i<r;i++){const{frontmatter:{categories:r,tags:a}}=n[i];"array"===Object(Eo.n)(r)&&r.forEach(t=>{t&&(e[t]||(e[t]=[]),e[t].push(n[i]))}),"array"===Object(Eo.n)(a)&&a.forEach(e=>{e&&(t[e]||(t[e]=[]),t[e].push(n[i]))})}return{categories:e,tags:t}}(this.$sortPosts)},$categoriesAndTags(){return function(n){const e=[],t=[];for(let t in n.categories)e.push({key:t,length:n.categories[t].length});for(let e in n.tags)t.push({key:e,length:n.tags[e].length});return{categories:e,tags:t}}(this.$groupPosts)}}};Ht.component(ko.default),Ht.component(_o.default);function Ro(n){return n.toString().padStart(2,"0")}t(245);Ht.component("Badge",()=>Promise.all([t.e(0),t.e(3)]).then(t.bind(null,415))),Ht.component("CodeBlock",()=>Promise.resolve().then(t.bind(null,96))),Ht.component("CodeGroup",()=>Promise.resolve().then(t.bind(null,97)));t(246),t(247);var To=t(95),wo=t.n(To),Io=t(27);let Ao,Lo;var Bo;"valine"===(Bo="gitalk")?t.e(82).then(t.t.bind(null,335,7)).then(n=>Lo=n.default):"gitalk"===Bo&&Promise.all([t.e(0),t.e(81)]).then(t.t.bind(null,336,7)).then(()=>t.e(80).then(t.t.bind(null,337,7))).then(n=>Ao=n.default);function Co(n,e){const t={};return Reflect.ownKeys(n).forEach(i=>{if("string"==typeof n[i])try{t[i]=wo.a.render(n[i],e)}catch(e){console.warn(`Comment config option error at key named "${i}"`),console.warn("More info: "+e.message),t[i]=n[i]}else t[i]=n[i]}),t}console.log(`How to use "gitalk" in ${Io.name}@v${Io.version}:`,Io.homepage);const zo={gitalk:{render(n,e){const t=document.createElement("div");t.id=e;document.querySelector("main.page").appendChild(t);new Ao(Co({clientID:"a6e1355287947096b88b",clientSecret:"f0e77d070fabfcd5af95bebb82b2d574d7248d71",repo:"blog-gitalk-comment",owner:"xugaoyi",admin:["xugaoyi"],pagerDirection:"last",id:"<%- (frontmatter.permalink || frontmatter.to.path).slice(-16) %>",title:"「评论」<%- frontmatter.title %>",labels:["Gitalk","Comment"],body:"页面：<%- window.location.origin + (frontmatter.to.path || window.location.pathname) %>"},{frontmatter:n})).render(e)},clear(n){const e=document.querySelector("#"+n);return e&&e.remove(),!0}},valine:{render(n,e){const t=document.createElement("div");t.id=e;document.querySelector("main.page").appendChild(t),new Lo({...Co({clientID:"a6e1355287947096b88b",clientSecret:"f0e77d070fabfcd5af95bebb82b2d574d7248d71",repo:"blog-gitalk-comment",owner:"xugaoyi",admin:["xugaoyi"],pagerDirection:"last",id:"<%- (frontmatter.permalink || frontmatter.to.path).slice(-16) %>",title:"「评论」<%- frontmatter.title %>",labels:["Gitalk","Comment"],body:"页面：<%- window.location.origin + (frontmatter.to.path || window.location.pathname) %>"},{frontmatter:n}),el:"#"+e})},clear(n){const e=document.querySelector("#"+n);return e&&e.remove(),!0}}},Do="vuepress-plugin-comment";let Po=null;function Oo(n){return zo.gitalk.clear(Do)}function Mo(n){return!1!==n.comment&&!1!==n.comments}function jo(n){clearTimeout(Po);if(document.querySelector("main.page"))return zo.gitalk.render(n,Do);Po=setTimeout(()=>jo(n),200)}var Uo={mounted(){Po=setTimeout(()=>{const n={to:{},from:{},...this.$frontmatter};Oo()&&Mo(n)&&jo(n)},1e3),this.$router.afterEach((n,e)=>{if(n&&e&&n.path===e.path)return;const t={to:n,from:e,...this.$frontmatter};Oo()&&Mo(t)&&jo(t)})}},$o=Object(bo.a)(Uo,(function(){return(0,this._self._c)("div")}),[],!1,null,null,null).exports,Fo=[({Vue:n,options:e,router:t,siteData:i})=>{},({Vue:n,options:e,router:t,siteData:i})=>{i.pages.map(n=>{const{frontmatter:{date:e,author:t}}=n;"string"==typeof e&&"Z"===e.charAt(e.length-1)&&(n.frontmatter.date=function(n){n instanceof Date||(n=new Date(n));return`${n.getUTCFullYear()}-${Ro(n.getUTCMonth()+1)}-${Ro(n.getUTCDate())} ${Ro(n.getUTCHours())}:${Ro(n.getUTCMinutes())}:${Ro(n.getUTCSeconds())}`}(e)),t?n.author=t:i.themeConfig.author&&(n.author=i.themeConfig.author)}),n.mixin(So)},{},({Vue:n})=>{n.mixin({computed:{$dataBlock(){return this.$options.__data__block__}}})},{},{},({router:n})=>{"undefined"!=typeof window&&function(){var n=document.createElement("script"),e=window.location.protocol.split(":")[0];n.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(n,t)}()},({router:n})=>{"undefined"!=typeof window&&(window._hmt=window._hmt||[],function(){var n=document.createElement("script");n.src="https://hm.baidu.com/hm.js?503f098e7e5b3a5b5d8c5fc2938af002";var e=document.getElementsByTagName("script")[0];e.parentNode.insertBefore(n,e)}(),n.afterEach((function(n){_hmt.push(["_trackPageview",n.fullPath])})))},({Vue:n})=>{n.component("Comment",$o)}],No=["Comment"];class qo extends class{constructor(){this.store=new Ht({data:{state:{}}})}$get(n){return this.store.state[n]}$set(n,e){Ht.set(this.store.state,n,e)}$emit(...n){this.store.$emit(...n)}$on(...n){this.store.$on(...n)}}{}Object.assign(qo.prototype,{getPageAsyncComponent:al,getLayoutAsyncComponent:sl,getAsyncComponent:ll,getVueComponent:ol});var Go={install(n){const e=new qo;n.$vuepress=e,n.prototype.$vuepress=e}};function Ko(n,e){const t=e.toLowerCase();return n.options.routes.some(n=>n.path.toLowerCase()===t)}var Ho={props:{pageKey:String,slotKey:{type:String,default:"default"}},render(n){const e=this.pageKey||this.$parent.$page.key;return cl("pageKey",e),Ht.component(e)||Ht.component(e,al(e)),Ht.component(e)?n(e):n("")}},Jo={functional:!0,props:{slotKey:String,required:!0},render:(n,{props:e,slots:t})=>n("div",{class:["content__"+e.slotKey]},t()[e.slotKey])},Vo={computed:{openInNewWindowTitle(){return this.$themeLocaleConfig.openNewWindowText||"(opens new window)"}}},Qo=(t(253),t(254),Object(bo.a)(Vo,(function(){var n=this._self._c;return n("span",[n("svg",{staticClass:"icon outbound",attrs:{xmlns:"http://www.w3.org/2000/svg","aria-hidden":"true",focusable:"false",x:"0px",y:"0px",viewBox:"0 0 100 100",width:"15",height:"15"}},[n("path",{attrs:{fill:"currentColor",d:"M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"}}),this._v(" "),n("polygon",{attrs:{fill:"currentColor",points:"45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"}})]),this._v(" "),n("span",{staticClass:"sr-only"},[this._v(this._s(this.openInNewWindowTitle))])])}),[],!1,null,null,null).exports),Xo={functional:!0,render(n,{parent:e,children:t}){if(e._isMounted)return t;e.$once("hook:mounted",()=>{e.$forceUpdate()})}};Ht.config.productionTip=!1,Ht.use(qs),Ht.use(Go),Ht.mixin(function(n,e,t=Ht){!function(n){n.locales&&Object.keys(n.locales).forEach(e=>{n.locales[e].path=e});Object.freeze(n)}(e),t.$vuepress.$set("siteData",e);const i=new(n(t.$vuepress.$get("siteData"))),r=Object.getOwnPropertyDescriptors(Object.getPrototypeOf(i)),a={};return Object.keys(r).reduce((n,e)=>(e.startsWith("$")&&(n[e]=r[e].get),n),a),{computed:a}}(n=>class{setPage(n){this.__page=n}get $site(){return n}get $themeConfig(){return this.$site.themeConfig}get $frontmatter(){return this.$page.frontmatter}get $localeConfig(){const{locales:n={}}=this.$site;let e,t;for(const i in n)"/"===i?t=n[i]:0===this.$page.path.indexOf(i)&&(e=n[i]);return e||t||{}}get $siteTitle(){return this.$localeConfig.title||this.$site.title||""}get $canonicalUrl(){const{canonicalUrl:n}=this.$page.frontmatter;return"string"==typeof n&&n}get $title(){const n=this.$page,{metaTitle:e}=this.$page.frontmatter;if("string"==typeof e)return e;const t=this.$siteTitle,i=n.frontmatter.home?null:n.frontmatter.title||n.title;return t?i?i+" | "+t:t:i||"VuePress"}get $description(){const n=function(n){if(n){const e=n.filter(n=>"description"===n.name)[0];if(e)return e.content}}(this.$page.frontmatter.meta);return n||(this.$page.frontmatter.description||this.$localeConfig.description||this.$site.description||"")}get $lang(){return this.$page.frontmatter.lang||this.$localeConfig.lang||"en-US"}get $localePath(){return this.$localeConfig.path||"/"}get $themeLocaleConfig(){return(this.$site.themeConfig.locales||{})[this.$localePath]||{}}get $page(){return this.__page?this.__page:function(n,e){for(let t=0;t<n.length;t++){const i=n[t];if(i.path.toLowerCase()===e.toLowerCase())return i}return{path:"",frontmatter:{}}}(this.$site.pages,this.$route.path)}},xo)),Ht.component("Content",Ho),Ht.component("ContentSlotsDistributor",Jo),Ht.component("OutboundLink",Qo),Ht.component("ClientOnly",Xo),Ht.component("Layout",sl("Layout")),Ht.component("NotFound",sl("NotFound")),Ht.prototype.$withBase=function(n){const e=this.$site.base;return"/"===n.charAt(0)?e+n.slice(1):n},window.__VUEPRESS__={version:"1.9.5",hash:"88f8a87"},async function(n){const e="undefined"!=typeof window&&window.__VUEPRESS_ROUTER_BASE__?window.__VUEPRESS_ROUTER_BASE__:xo.routerBase||xo.base,t=new qs({base:e,mode:"history",fallback:!1,routes:yo,scrollBehavior:(n,e,t)=>t||(n.hash?!Ht.$vuepress.$get("disableScrollBehavior")&&{selector:decodeURIComponent(n.hash)}:{x:0,y:0})});!function(n){n.beforeEach((e,t,i)=>{if(Ko(n,e.path))i();else if(/(\/|\.html)$/.test(e.path))if(/\/$/.test(e.path)){const t=e.path.replace(/\/$/,"")+".html";Ko(n,t)?i(t):i()}else i();else{const t=e.path+"/",r=e.path+".html";Ko(n,r)?i(r):Ko(n,t)?i(t):i()}})}(t);const i={};try{await Promise.all(Fo.filter(n=>"function"==typeof n).map(e=>e({Vue:Ht,options:i,router:t,siteData:xo,isServer:n})))}catch(n){console.error(n)}return{app:new Ht(Object.assign(i,{router:t,render:n=>n("div",{attrs:{id:"app"}},[n("RouterView",{ref:"layout"}),n("div",{class:"global-ui"},No.map(e=>n(e)))])})),router:t}}(!1).then(({app:n,router:e})=>{e.onReady(()=>{n.$mount("#app")})})}]);